var store = [{
        "title": "객체 지향 설계 5원칙 - SOLID",
        "excerpt":"   SRP(Single Responsibility Principle) 단일 책임 원칙   OCP(Open Closed Principle) 개방 폐쇄 원칙   LSP(Liskov Substitution Principle) 리스코프 치환 원칙   ISP(Interface Segregation Principle) 인터페이스 분리 원칙   DIP(Dependency Inversion Principle) 의존 역전 원칙   높은 응집도와 낮은 결합도  개방 폐쇄 원칙은 높은 응집도와 낮은 결합도라는 소프트웨어 개발의 원리로 설명이 가능하다.   응집도가 높다는 것은 하나의 모듈, 클래스가 하나의 책임 또는 관심사에만 집중되어 있다는 뜻이다.    불필요하거나 직접 관련이 없는 외부의 관심과 책임이 얽혀 있지 않으며, 하나의 공통 관심사는 한 클래스에 모여 있다.   높은 응집도는 클래스 레벨뿐 아니라 패키지, 컴포넌트, 모듈에 이르기까지 그 대상의 크기가 달라도 동일한 원리로 적용될 수 있다.           높은 응집도   응집도가 높다는 것은 하나의 모듈, 클래스가 하나의 책임 또는 관심사에만 집중되어 있다는 뜻   혹은, 변화가 일어날 때 해당 모듈에서 변하는 부분이 크다는 것으로도 설명할 수 있다.     불필요하거나 직접 관련이 없는 외부의 관심과 책임이 얽혀 있지 않으며, 하나의 공통 관심사는 한 클래스에 모여 있다.   즉 변경이 일어날 때 모듈의 많은 부분이 함께 바뀐다면 응집도가 높다는 것이다.   만약 모듈의 일부분에만 변경이 일어나도 된다면, 모듈 전체에서 어떤 부분이 바뀌어야 하는지 파악해야 하고,  또 그 변경으로 인해 바뀌지 않는 부분에는 다른 영향을 미치지는 않는지 확인해야 하는 이중의 부담이 생기다.            낮은 결합도   책임과 관심사가 다른 오브젝트 또는 모듈과는 낮은 결합도, 즉 느슨하게 연결된 형태를 유지하는 것이 바람직하다.    느슨한 연결은 관계를 유지하는 데 꼭 필요한 최소한의 방법만 간접적인 형태로 제공하고, 나머지는 서로 독집적이고 알 필요도 없게 만들어주는 것이다.      결합도가 낮아지면 변화에 대응하는 속도가 높아지고, 구성이 깔끔해진다. 또한 확장하기에도 매우 편리하다.   여기서 결합도란 ‘하나의 오브젝트가 변경이 일어날 때에 관계를 맺고 있는 다른 오브젝트에게 변화를 요구하는 정도’라고 설명할 수 있다.   낮은 결합도란 결국, 하나의 변경이 발생할 때 여타 모듈과 객체로 변경에 대한 요구가 전파되지 않는 상태를 말한다.            결합도와 응집도   좋은 소프트웨어 설계를 위해서는 결합도는 낮추고 응집도는 높이는 것이 바람직하다.   결합도는 모듈(클래스) 간의 상호 의존 정도로서 결합도가 낮으면 모듈 간의 상호 의존성이 줄어들어 객체의 재사용이나 수정, 유지보수가 용이하다.   응집도는 하나의 모듈 내부에서 존재하는 구성 요소들의 기능적 관련성으로, 응집도가 높은 모듈은 하나의 책임에 집중하고 독립성이 높아져   재사용이나 기능의 수정, 유지보수가 용이하다.           1. SRP - 단일 책임 원칙  “어떤 클래스를 변경해야 하는 이유는 오직 하나뿐이어야 한다.”   역할(책임)을 분리하라는 것이 단일 책임 원칙이다.   단일 책임 원칙은 속성, 메서드, 패키지, 모듈, 컴포넌트, 프레임워크 등에도 적용할 수 있다.   단일 책임 원칙은 잘된 경우보다 잘못된 경우를 살펴보는 게 이해하는 데 좋다.      속성이 단일 책임 원칙을 지키기 못한 경우   여자는 반드시 대학교에 가고 남자는 절대로 가지 못하며 사람 클래스에 학번 속성이 있다고 가정하자.   class 사람 {       String 학번;   }    사람 여자 = new 사람();   사람 남자 = new 남자();    남자.학번 = \"201732017\";     사람형 참조 변수 남자가 가진 학번 속성에 값을 할당하거나 읽어 오는 코드를 제제할 방법이 없다.       하나의 속성이 여러 의미를 갖는 경우도 단일 책임 원칙을 지키지 못하는 경우이며 if문을 여기저기 사용해야 할 수도 있다.      메서드가 단일 책임 원칙을 지키지 못한 경우   강아지 클래스를 만들고 소변보다() 메서드를 구현했다고 해보자.   class 강아지 {        final static Boolean 암컷 = ture;       final static Boolean 수컷 = false;        void 소변보다() {           if(this.성별 == 수컷) {                // 한쪽 다리를 들고 소변을 본다.            } else {               // 다리를 들고 소변을 보지 않는다.              }       }    }       강아지가 암컷이냐 수컷이냐에 따라서 소변보다() 메서드에서 분기 처리가 진행된다.   소변보다() 메서드가 암컷과 수컷 강아지의 행위를 전부 구현하려고 하기 때문에 단일 책임 원칙을 위배하고 있는 것이다.   메서드가 단일 책임 원칙을 지키지 않을 경우 나타나는 대표적인 상황이 분기 처리를 위한 if문이다.   단일 책임 원칙과 객체 지향 4대 특성은 어떻게 결부돼 있을까?    단일 책임 원칙과 가장 관계가 깊은 것은 바로 모델링 과정을 담당하는 추상화임을 알 수 있다.     애플리케이션의 경계를 정하고 추상화를 통해 클래스들을 선별하고 속성과 메서드를 설계할 때 반드시 단일 책임 원칙을 고려하는 습관을 들이자.       2. OCP - 개방 폐쇄 원칙  “소프트웨어 엔티티(클래스, 모듈, 함수 등)는 확장에 대해서는 열려 있어야 하지만 변경에 대해서는 닫혀 있어야 한다.”  → 자신의 확장에는 열려 있고, 주변의 변화에 대해서는 닫혀 있어야 한다.               자바 애플리케이션                     ^                JDBC 인터페이스                     ^    JDBC 드라이버(오라클), JDBC 드라이버(MySQL), JDBC 드라이버(MS-SQL)                     ^              오라클, MySQL, MS-SQL       JDBC를 사용하는 클라이언트는 데이터베이스가 오라클에서 MySQL로 바뀌더라도 Connection을 설정하는 부분 외에는 따로 수정할 필요가 없다.         자바 애플리케이션은 JDBC 인터페이스라고 하는 완충 장치로 인해 변화에 영향을 받지 않는다.     데이터베이스라고 하는 주변의 변화에 닫혀 있는 것이다. 데이터베이스를 교체한다는 것은 데이터베이스가 자신의 확장에는 열려 있다는 것이다.   개방 폐쇄 원칙을 무시하고 프로그램을 작성하면 객체 지향 프로그래밍의 가장 큰 장점인 유연성, 재사용성, 유지보수성 등을 얻을 수 없다.       3. LSP - 리스코프 치환 원칙  “서브 타입은 언제나 자신의 기반 타입으로 교체할 수 있어야 한다.”   객체 지향에서의 상속은 조직도나 계층도가 아닌 뷴류도가 되어야 한다.   객체 지향의 상속은 다음의 조건을 만족해야 한다.     하위 클래스 is a kind of 상위 클래스 → 하위 분류는 상위 분류의 한 종류이다.   구현 클래스 is able to 인터페이스 → 구현 분류는 인터페이스할 수 있어야 한다.   “하위 클래스의 인스턴스는 상위형 객체 참조 변수에 대입해 상위 클래스의 인스턴스 역할을 하는 데 문제가 없어야 한다.”   리스코프 치환 원칙     하위형에서 선행 조건은 강화될 수 없다.   하위형에서 후행 조건은 약화될 수 없다.   하위형에서 상위형의 불변 조건은 반드시 유지돼야 한다.       4. ISP - 인터페이스 분리 원칙  “클라이언트는 자신이 사용하지 않는 메서드에 의존 관계를 맺으면 안 된다.”   단일 책임 원칙에서 제시한 해결책은 클래스를 토막내서 하나의 역할(책임)만 하는 다수의 클래스로 분할하는 것이었다.   그런데 꼭 그 방법뿐일까? 다른 선택 방법은 바로 ISP 즉, 인터페이스 분할 원칙이다.   결론적으로 단일 책임 원칙(SRP)과 인터페이스 분할 원칙(ISP)은 같은 문제에 대한 두 가지 다른 해결책이라고 볼 수 있다.   인터페이스 분할 원칙을 이야기할 때 등장하는 원칙 중 하나로 인터페이스 최소주의 원칙이라는 것이 있다.     인터페이스를 통해 메서드를 외부에 제공할 떄는 최소한의 메서드만 제공하라는 것이다.   상위 클래스는 풍성할수록 좋고, 인터페이스는 작을수록 좋다고 했다. 그 이유를 살펴보자.   리스코프 치환 원칙(LSP)에 따라 하위 객체는 상위 객체인 척 할 수 있다.      빈약한 상위 클래스   Class 사람 {     String 이름;     void 먹다() { . . . } }  Class 학생 extends 사람 {     String 생일;     String 주민등록번호;     String 학번;      void 자다() { . . . }     void 공부하다() { . . . } }  Class 군인 extends 사람 {     String 생일;     String 주민등록번호;     String 군번;      void 자다() { . . . }     void 훈련하다() { . . . } }       풍성한 상위 클래스   Class 사람 {     String 이름;     String 생일;     String 주민등록번호;      void 먹다() { . . . }     void 자다() { . . . } }   Class 학생 extends 사람 {     String 학번;      void 공부하다() { . . . } }  Class 군인 extends 사람 {     String 군번;      void 훈련하다() { . . . } }       빈약한 상위 클래스를 이용하는 경우   public static void main(String[] args) {     사람 김학생 = new 학생( . . . );     사람 이군인 = new 군인( . . . );      System.out.println(김학생.생일); // 사용불가     System.out.println(이군인.생일); // 사용불가       System.out.println((학생)김학생.생일); // 캐스팅 필요      System.out.println((군인)이군인.생일); // 캐스팅 필요   }   빈약한 상위 클래스를 이용한 경우 여기저기 형변환이 발생하면서 상속의 혜택을 제대로 누리지 못하고 있다.      풍성한 상위 클래스를 이용하는 경우   public static void main(String[] args) {     사람 김학생 = new 학생( . . . );     사람 이군인 = new 군인( . . . );      System.out.println(김학생.생일);      System.out.println(이군인.생일);         (학생)김학생.공부하다(); // 캐스팅 필요          (군인)이군인.훈련하다(); // 캐스팅 필요       }   학생과 군인이 자는 행위가 똑같다고 볼 수는 없다. 하지만 기능은 둘 다 필요하다.     이 경우 사용할 수 있는 객체 지향 기법이 바로 추상 메서드다.       5. DIP - 의존 역전 원칙   “고차원 모듈은 저차원 모듈에 의존하면 안 된다. 두 모듈 모두 다른 추상화된 것에 의존해야 한다.”     “추상화된 것은 구체적인 것에 의존하면 안 된다. 구체적인 것이 추상화된 것에 의존해야 한다.”    “자주 변경되는 구체(Concrete) 클래스에 의존하지 마라.”   자동차와 스노우타이어 사이에 다음과 같은 의존 관계가 있다.   자동차 -&gt; 스노우 타이어    자동차가 타이어에 의존한다.   그런데 자동차가 일반 타이어로 교체해야 한다고 가정해보자.   이런 경우 스노우 타이어를 일반 타이어로 교체할 때 자동차는 그 영향에 노출돼 있음을 알 수 있다.   자동차는 자기 자신보다 더 자주 변하는 스노우타이어에 의존하는 나쁜 관계를 갖고 있다.     다음과 같이 개선해보자.   자동차 --------&gt; &lt;&lt;interface&gt;&gt; 타이어                          ^            [스노우타이어][일반타이어][광폭타이어]   자동차가 구체적인 타이어들이 아닌 추상화된 타이어 인터페이스에만 의존하게 함으로써 자동차는 이제 타이어에 영향을 받지 않는 형태로 구성되었다.    이 설명은 바로 개방 폐쇄 원칙(OCP)에서도 나온 설명이다.   기존에는 스노우타이어가 그 무엇에도 의존하지 않는 클래스였는데     추상적인 것인 타이어 인터페이스에 의존하게 됐다. 이를 의존의 방향이 역전되었다고 한다.       자신보다 변하기 쉬운 것에 의존하던 것을 추상화된 인터페이스나 상위 클래스를 두어     변하기 쉬운 것의 변화에 영향받지 않게 하는 것이 의존 역전 원칙이다.       6. 정리     SRP(단일 책임 원칙) : 어떤 클래스를 변경해야 하는 이유는 오직 하나뿐이어야 한다.   OCP(개방 폐쇄 원칙) : 자신의 확장에는 열려 있고, 주변의 변화에 대해서는 닫혀 있어야 한다.   LSP(리스코프 치환 원칙) : 서브 타입은 언제나 자신의 기반 타입으로 교체할 수 있어야 한다.   ISP(인터페이스 분리 원칙) : 클라이언트는 자신이 사용하지 않는 메서드에 의존 관계를 맺으면 안 된다.   DIP(역전 의존 원칙) : 자신보다 변하기 쉬운 것에 의존하지 마라.   ","categories": ["OOP"],
        "tags": ["java","oop"],
        "url": "/2020-01-08/solid/",
        "teaser": null
      },{
        "title": "Spring Security",
        "excerpt":"1. Spring Security  1) authentication authorization  authentication   사용자의 신원을 식별하는 기능이다. 쉽게 말해서 로그인 기능, 로그인 아이디와 비밀번호를 사용하여 사용자 신원을 확인하는 방법이다.   authorization    권한 관리 기능이다.   현재 사용자가 어떤 권한을 가지고 있는지 이 기능을 실행할 수 있는 권한은 무엇인지의 정보를 바탕으로 권한 관리 및 통제를 수행한다.   role   authorization 에서 권한을 역할(role) 이라고 부르기도 한다.    예) 관리자 권한 = 관리자 역할   spring security 에서 권한(역할)은 다음과 같이 표현하는 것이 관례이다.   예) ROLE_ADMIN, ROLE_STUDENT   2) Spring Security  authentication 기능, authorization 기능, 보안 공격에 대한 보호 기능 등이 잘 구현된 프레임워크이다.   spring security 를 이용해서 로그인 기능과 권한관리 기능을 구현하는 것이 바람직하다.   3) Spring Security 확장 태그  &lt;%@ taglib uri=\"http://www.springframework.org/security/tags\" prefix=\"sec\" %&gt;   spring security 확장 태그를 사용하기 위한 선언이다. JSP 파일의 선두에 이 선언이 있어야 한다.   &lt;sec:authorize access=\"authenticated\"&gt;     . . . &lt;/sec:authorize&gt;  spring security 확장 태그이다.   현재 사용자가 로그인한 사용자인 경우에만 이 태그 사이의 내용이 출력된다.   &lt;sec:authentication property=\"user.loginId\" /&gt;  현재 로그인된 사용자 객체의 loginId 속성값을 출력한다.       즉 User 객체의 getLoginId() 메소드 리턴값이 출력된다.   &lt;sec:authentication property=\"user.name\" /&gt;  현재 로그인된 사용자 객체의 name 속성값을 출력한다.   &lt;sec:authentication property=\"user.email\" /&gt;  현재 로그인된 사용자 객체의 email 속성값을 출력한다.   4) Spring Security 권한 검사  @Secured(“ROLE_ADMINISTRATOR”)    이 어노테이션을 액션 메소드에 붙이면 그 액션 메소드는 “ROLE_ADMINISTRATOR” 권한을 가진 사용자만 실행할 수 있다.   이 권한이 없는 사용자가 실행하면 에러가 발생한다. 클래스에 붙였을 때도 권한이 없는 사용자가 실행하면 마찬가지로 에러가 발생한다.   request.IsUserInRole(String role)   Java 코드에서 현재 사용자 권한을 검사할 때, 이 메소드를 사용한다.  @RequestMapping(\"/user/index.do\") public String index(Model model, HttpServletRequest request) {     if (request.isUserInRole(\"ROLE_PROFESSOR\"))         return \"redirect:professor\";     if (request.isUserInRole(\"ROLE_ADMINISTRATOR\"))         return \"redirect:adminostrator\";     return \"redirect:student\"; }   뷰에서 사용자 권한을 검사할 때  &lt;sec:authorize access=\"hasRole('ROLE_ADMINISTRATOR')\"&gt;    . . . &lt;/sec:authorize&gt;  현재 사용자가 ROLE_ADMINISTRATOR 권한일 경우에 이 태그와 사이 내용을 출력한다.  ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-01-09/spring-security/",
        "teaser": null
      },{
        "title": "Nexters16 끄적끄적팀 CI/CD 자동 배포",
        "excerpt":"우리가 지금 사용하고 있는 git repository의 특정 branch(dev)에 push하면   자동으로 배포되도록 젠킨스를 사용하여 자동 배포 환경을 만들어봤다.       젠킨스란?  서버에 올릴 수 있는 상태로 만드는 것을 빌드라고 하는데 젠킨스는 빌드를 자동화 해주는 툴이다.   Nexters16 프로젝트에서 젠킨스 사용하기          프로젝트를 배포할 서버에 docker로 젠킨스를 설치            젠킨스에 maven, jdk 설정            git 연동               배포를 위한 shell 작성하기           ","categories": ["Jenkins"],
        "tags": ["jenkins"],
        "url": "/2020-01-10/jenkins/",
        "teaser": null
      },{
        "title": "JUnit Test란?",
        "excerpt":"    1. 배경지식  1) 테스트 구현이 필요한 이유  버그를 잡기위한 효과적인 수단은 테스트와 로그 메시지다.   사람이 직접 테스트를 실행하는 것은 대부분 너무 많은 시간이 필요하다.   아까까지 잘 돌아갔던 기능인데, 소스코드를 수정한 후 갑자기 에러가 발생하는 경우가 많다.  그래서 소스코드를 수정할 때 마다, 모든 기능들을 전부 다시 테스트 해야 안전한다.  사람의 수작업 없이 자동 테스트 할 수 있도록 테스트를 구현하는 것이 필수다.   출력된 값을 눈으로 확인해 보는 것도 시간이 걸린다.  결과 같이 정상인지 아닌지 확인해 보는 기능까지 테스트 코드에 구현해야 한다.  그래서 테스트 결과 정상인지 아닌지만 보고되어야 한다.   JUnit 테스트를 열심히 구현하지 않는 프로그래머는 버그 때문에 고생할 확률이 높다.          2) 단위 테스트  클래스를 하나씩 따로 테스트 하는 것이 단위 테스트(Unit Test)이다.   프로젝트 전체를 실행하면서 테스트하면 에러가 발생했을 경우에 문제의 원인이 어디에 있는지 알기 어려운 경우가 종종 있다.   클래스 하나 메소드 하나씩 따로 테스트하면, 에러를 찾고 수정하기 쉽다.          3) 통합 테스트  단위 테스트를 통과한 클래스들의 객체를 서로 연결하여 같이 테스트 하는 것이 통합 테스트이다.  예를들어, StudentMapper 클래스를 따로 단위 테스트하고 StudentService 클래스를 따로 단위 테스트하고,   이들 객체를 연결(@Autowired)하여 같이 테스트하는 것이 통합 테스트이다.          4) 테스트 Mock  StudentService 클래스는 StudentMapper 클래스의 메소드를 호출한다.   따라서 StudentService 클래스의 단위 테스트를 하려면 StudentMapper 클래스가 있어야 한다.   그런데 StudentService 객체와 StudentMapper 객체를 연결하여 같이 테스트하는 것은 통합 테스트이지 단위 테스트가 아니다.   StudentService 클래스를 단위 테스트할 때는 테스트용 가짜 StudentMapper 클래스를 만들어서 StudentService 객체에 연결하여 테스트 해야 한다.   이렇게 테스트용으로 만드는 가짜 클래스를 테스트 Mock 클래스라고 부른다.   Spring boot 앱에는 Mockito 프레임워크 라이브러리가 포함되어 있다.  Mockito를 이용해서 Mock을 구현해야 한다.          5) JUnit 라이브러리  Java 언어로 단위 테스트를 규현하기 위한 표준 라이브러리가 JUint이다.          6) import static     class import   import java.util.Arrays;           . . .  int[] a = new int[]{2, 3, 1, 6, 5, 7}; Arrays.sort(a);           Arrays 클래스가 import 되었기 때문에 Arrays.sort 메소드를 호출할 수 있다.          static method import   클래스가 아니고 클래스의 static method를 import 할 수도 있다.   import static java.util.Arrays.sort;  . . .         int[] a = new int[]{2, 3, 1, 6, 5, 7}; sort(a);   Arrays 클래스의 sort 메소드가 import 되었기 때문에 Arrays 클래스를 생략하고   바로 sort 메소드를 호출해도 된다.          Assert 클래스   JUnit 클래스를 구현할 때, 값이 맞는지 확인하기 위해 Assert 클래스의 static 메소드를 사용한다.   import static org.junit.Assert;  . . .            Assert.assertEquals(s1, s2); Assert.assertNotNull(s1); Assert.assertNull(s2); Assert.assertTrue(s1.equals(s2));          static import   import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertNotNull; import static org.junit.Assert.assertNull; import static org.junit.Assert.assertTrue;  . . .            assertEquals(s1, s2); assertNotNull(s1); assertNull(s2); assertTrue(s1.equals(s2));   Assert. 을 생략할 수 있다.         2. test1 프로젝트  전체 코드 보러가기       Student.java   import lombok.Data;  . . .  @Data   Lombok에 의해서 get/set 메소드 뿐만 아니라, equals 메소드와 hashcode 메소드도 자동으로 재정의된다.       StudentMapperTests.java   assertEquals(student1, student2);     student1, student2 값을 화면에 출력하고, 그 값이 동일한지 눈으로 확인하는 것은 바람직하지 않다.      값이 동일한지 확인하는 코드를 구현하는 것이 바람직하다.      Assert 클래스의 assertEquals 메소드는 두 객체의 값이 동일한지 검사하는 메소드이다.     동일하면 테스트 통과이고, 동일하지 않으면 테스트 실패이다.       @Transactional      테스트 클래스에 @Transactional을 붙여주면,      @Test 어노테이션이 붙은 테스트 메소드에서 실행한 DB insert/update/delete 작업은,   그 메소드가 리턴될 때 모두 자동으로 취소(rollback) 된다.      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-01-13/Junit-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EA%B5%AC%ED%98%84/",
        "teaser": null
      },{
        "title": "JPA 식별자 자동 생성",
        "excerpt":"JPA가 제공하는 데이터베이스 기본 키 생성 전략           직접 할당 : 기본 키를 어플리케이션에서 직접 할당한다. @Id 만 사용한다.            자동 생성 : 대리 키 사용 방식 @Id와 @GeneratedValue를 함께 사용한다.             IDENTITY : 기본 키 생성을 데이터베이스에 위임한다.       SEQUENCE : 데이터베이스 시퀀스를 사용해서 기본 키를 할당한다.       TABLE : 키 생성 테이블을 사용한다.       AUTO : 데이터베이스에 관계없이 식별자를 자동 생성하라는 의미, DB가 변경되더라도 수정할 필요 없다.               1. GenerationType.AUTO   @Id  @GeneratedValue // @GeneratedValue(strategy=GenerationType.AUTO) 와 동일  protected Long id;   JPA 공급자에 따라 기본 설정이 다르다.     Oracle을 사용할 경우 SEQUENCE가 기본   MS SQL Server의 경우 IDENTITY가 기본   (Hibernate 5.0부터) MySQL의 AUTO는 IDENTITY가 아닌 TABLE을 기본 시퀀스 전략으로 선택된다.       Spring Boot는 Hibernate의 id 생성 전략을 그대로 따라갈지 말지를 결정하는 useNewIdGeneratorMappings 설정이 있다.   1.5에선 기본값이 false, 2.0부터는 true Hibernate 5.0부터 MySQL의 AUTO는 IDENTITY가 아닌 TABLE을 기본 시퀀스 전략으로 선택된다.   즉, 1.5에선 Hibernate 5를 쓰더라도 AUTO를 따라가지 않기 때문에 IDENTITY가 선택되고 2.0에선 true이므로 Hibernate 5를 그대로 따라가기 때문에 TABLE이 선택되었다. (Hibernate 6.0에서 다시 IDENTITY로 돌아간다고 한다.)   ","categories": ["Spring","JPA"],
        "tags": ["spring","jpa"],
        "url": "/2020-01-14/Spring-Data-JPA/",
        "teaser": null
      },{
        "title": "Design Patterns in Spring Framework",
        "excerpt":"디자인 패턴은 객체 지향의 특성 중     상속(extends), 인터페이스(interface/implements), 합성(객체를 속성으로 사용)을 이용한다.   01 어댑터 패턴(Adapter Pattern)      02 프록시 패턴(Proxy Pattern)     03 데코레이터 패턴(Decorator Pattern)     04 싱글턴 패턴(Singleton Pattern)     05 템플릿 메서드 패턴(Template Method Pattern)     06 팩토리 메서드 패턴(Factory Method Pattern)     07 전략 패턴(Strategy Pattern)     08 템플릿 콜백 패턴(Template Callback Pattern - 견본/회신 패턴)     09 그 외  예제 코드       스프링 프레임워크를 설명하는 공식적인 정의는 다음과 같다.    자바 엔터프라이즈 개발을 편하게 해주는 오픈소스 경량급 애플리케이션 프레임워크   자바 객체지향의 원리와 이해의 저자는 다음과 같이 정의했다.   OOP 프레임워크   스프링은 객체지향의 특성과 설계 원칙을 적용한 프레임워크이기 때문이다.       객체 자향과 설계 패턴의 주요 목적은 유지보수성 향상이다.   유지보수가 필요한 이유는 다음과 같다.           불충분한 요구사항 정의            기능 추가            설계 결함            기술 환경의 변화       어댑터 패턴  어댑터를 번역하면 변환기라고 할 수 있다. 변환기의 역할은 서로 다른 두 인터페이스 사이에 통신이 가능하게 하는 것이다,   자바 언어의 구조를 보면 플랫폼별 JRE에 대해 얘기가 나오는데 이를 어댑터 패턴이라고 할 수 있고, 어댑터 패턴은 개방 폐쇄 원칙을 활용한 설계 패턴이라고 할 수 있다.     JRE가 어댑터의 역할을 수행하고 있는 것이다.   어댑터 패턴은 합성, 즉 객체를 속성으로 만들어서 참조하는 디자인 패턴으로 한 문장으로 정리하면  → 호출당하는 쪽의 메서드를 호출하는 쪽의 코드에 대응하도로 중간에 변환기를 통해 호출하는 패턴   문제 해결을 위해 어탭터 패턴을 사용한다면,   재사용 하려는 클래스와 공통 부모 클래스 사이에 adapter 클래스를 끼워넣는다.   클라이언트의 호출은 adapter 클래스가 받는다.   어떤 클래스에 대한 다른 사용법을 제공하기 위해 끼어들어가는 클래스를 wrapper class 라고 부른다.   재사용을 위해 가져온 클래스를 공통 인터페이스 규격에 맞추기 위해 중간에 wrapper를 끼워 넣는 구조가     adapter 패턴이다.   다형성으로 구현된 공통 인터페이스 구격에 맞추기 위한 목적의 구조가 아니라면   adapter 패턴이라고 부르지 않는다.   기존에 있는 시스템에 새로운 코드가 들어가거나 교체되어야 하는 경우 코드의 재사용성을 높이기 위한 방법이다.   다음은 어댑터 패턴의 구조이다.         Client : 서드파티 라이브러리나 외부 시스템을 사용하려는 쪽   Adaptee : 서드파티 라이브러리나 외부 시스템   Target Interface : Adapter가 구현하는 인터페이스이다.     클라이언트는 Target Interface를 통해 Adaptee인 서드파티 라이브러리를 사용하게 된다.   Adapter : Client와 Adaptee 중간에서 호환성이 없는 둘을 연결시켜주는 역할이다.     클라이언트는 Target Interface를 통해 어댑터에 요청을 보낸다.      어댑터는 클라이언트의 요청을 Adapter가 이해할 수 있는 방법으로 전달하고 처리는 Adaptee가 한다.   클라이언트에서는 Target Interface 를 호출하는 것 처럼 보인다.     하지만 클라이언트의 요청을 전달받은 (Target Interface 를 구현한) Adapter 는 자신이 감싸고 있는 Adaptee 에게 실질적인 처리를 위임한다.     Adapter 가 Adaptee 를 감싸고 있는 것 때문에 Wrapper 패턴이라고도 불린다.       프록시 패턴  프록시는 대리자, 대변인이라는 뜻을 가진 단어다. 프록시 패턴의 경우 실제 서비스 객체가 가진 메서드왁 같은 이름의 메서드를 사용하는데, 이를 위해 인터페이스를 사용한다.   인터페이스를 사용하면 서비스 객체가 들어갈 자리에 대리자 객체를 대신 투입해 클라이너트 쪽에서는 실제 서비스 객체를 통해   메서드를 호출하고 반환값을 받는지, 대리자 객테를 통해 메서드를 호출하고 반환값을 받는지 전혀 모르게 처리할 수도 있다.   다음은 프록시 패턴을 사용한 클래스 다이어그램이다.         Client는 프록시를 사용하여 원하는 서비스 메서드를 호출한다.   Service는 실제 서비스를 구현하고 있다. (IService 인터페이스 구현)   Proxy는 IService 인터페이스를 구현하고 (실제 서비스 참조 변수 사용) 실제 메서드를 호출한다.   다음은 프록시 패턴의 중요 포인트이다.      대리자는 실제 서비스와 같은 이름의 메서드를 구현한다. 이때 인터페이스를 사용한다.   대리자는 실제 서비스에 대한 참조 변수를 갖는다. (합성)   대리자는 실제 서비스와 같은 이름을 가진 메서드를 호출하고 그 값을 클라이언트에게 돌려준다.   대리자는 실제 서비스의 메서드 호출 전후에 별도의 로직을 수행할 수도 있다.   프록시 패턴은 실제 서비스 메서드의 반환 값에 가감하는 것을 목적으로 하지 않고 제어의 흐름을 변경하거나 다른 로직을 수행하기 위해 사용한다.   → 프록시 패턴은 제어 흐름을 조정하기 위한 목적으로 중간에 대리자를 두는 패턴이고 개방 폐쇄 원칙과 의존 역전 원칙이 적용된 설계 패턴이다.       데코레이터 패턴  데코레이터 패턴은 프록시 패턴과 구현 방법이 같다. 다만 프록시 패턴은 클라이언트가 최종적으로 돌려 받는 반환값을 조작하지 않고 그대로 전달하는 반면   데코레이터 패턴은 클라이언트가 받는 반환값에 장식을 덧입힌다.     장식자는 실제 서비스와 같은 이름의 메서드를 구현한다. 이때 인터페이스를 사용한다.   장식자는 실제 서비스에 대한 참조 변수를 갖는다. (합성)   장식자는 실제 서비스와 같은 이름을 가진 메서드를 호출하고, 그 반환값에 장식을 더해 클라이언트에게 돌려준다.   장식자는 실제 서비스의 메서드 호출 전후에 별도의 로직을 수행할 수도 있다.   → 메서드 호출의 반환값에 변화를 주기 위해 중간에 장식자를 두는 패턴    개방 폐쇄 원칙(OCP)과 의존 역전 원칙(DIP)이 적용된 설계 패턴임을 알 수 있다.       싱글턴 패턴  싱글턴 패턴이란 인스턴스를 하나만 만들어 사용하기 위한 패턴이다.  커넥션 풀, 스레드 풀, 디바이스 설정 객체 등과 같은 경우 인스턴스를 여러 개 만들게 되면 불필요한 자원을 사용하게 되고,   또 프로그램이 예상치 못한 결과를 낳을 수 있다. 싱글턴 패턴은 오직 인스턴스 하나만 만들고 그것을 계속해서 재사용 한다.   이를 구현하려면 객테 생성을 위한 new에 제약을 걸어야 하고, 만들어진 단일 객체를 반환할 수 있는 메서드가 필요하다.  따라서 다음 세 가지 요소가 반드시 필요하다.     new를 실행할 수 없도록 생성자에 private 접근 제어자를 지정한다.   유일한 단일 객체를 반환할 수 있는 정적 메서드가 필요하다.   유일한 단일 객체를 참조할 정적 참조 변수가 필요하다.   단일 객체인 경우 결국 공유 객체로 사용되기 때문에 속성을 갖지 않게 하는 것이 정석이다. 다만 읽기 전용 속성을 갖는 것은 문제가 되지 않는다.   → 클래스의 인스턴스, 즉 객체를 하나만 만들어 사용하는 패턴       템플릿 메서드 패턴  상위 클래스에 공통 로직을 수행하는 템플릿 메소드와 하위 클래스에 오버라이딩을 강제하는 추상 메서드 또는     선택적으로 오버라이딩할 수 있는 훅(Hook) 메서드를 두는 패턴을 템플릿 메서드 패턴이라고 한다.   → 상위 클래스의 견본 메서드에서 하위 클래스가 오버라이딩한 메서드를 호출하는 패턴   예제 코드를 보면 의존 역전 원칙(DIP)을 활용하고 있음을 알 수 있다.       팩토리 메서드 패턴  팩토리 메서드는 객체를 생성 반환하는 메서드를 말한다.   여기에 패턴을 붙이면 하위 클래스에서 팩토리 메서드를 오버라이딩해서 객체를 반환하게 하는 것을 의미한다.   → 오버라이드된 메서드가 객체를 반환하는 패턴   예제 코드를 보면 의존 역전 원칙(DIP)을 활용하고 있음을 알 수 있다.       전략 패턴  전략 패턴을 구성하는 세 요소는 꼭 기억해야 한다.     전략 메서드를 가진 전략 객체   전략 객체를 사용하는 컨텍스트(전략 객체의 사용자/소비자)   전략 객체를 생성해 컨텍스트에 주입하는 클라이언트(제 3자, 전략 객체의 공급자)   상속을 이용하는 템플릿 메서드 패턴과 객체 주입을 통한 전략 메서드 패턴 중에서 선택/적용할 수 있다.   단일 상속만이 가능한 자바 언어에서는 상속이라는 제한이 있는 템플릿 메서드 패턴보다는 전략 패턴이 더 많이 활용된다.   → 클라이언트가 전략을 생성해 전략을 실행할 컨텍스트에 주입하는 패턴     예제 코드를 보면 개발 폐쇄 원칙(OCP)과 의존 역전 원칙(DIP)이 적용된 것을 짐작할 수 있다.       템플릿 콜백 패턴  템플릿 콜백 패턴은 전략 패턴과 모든 것이 동일한데 전략을 익명 내부 클래스로 정의해서 사용한다는 특징이 있다.   → 전략을 익명 내부 클래스로 구현한 전략 패턴    전략 패턴의 일종이므로 개발 폐쇄 원칙(OCP)과 의존 역전 원칙(DIP)이 적용된 설계 패턴이다.       그 외 다른 패턴들  스프링은 다양한 디자인 패턴을 활용하고 있다. 특히 스프링 MVC의 경우 프론트 컨트롤러 패턴과 MVC 패턴을 활용하고 있다.   ","categories": ["Spring"],
        "tags": ["java","spring"],
        "url": "/2020-01-16/%EB%94%94%EC%9E%90%EC%9D%B8-%ED%8C%A8%ED%84%B4/",
        "teaser": null
      },{
        "title": "Spring Boot Profile 설정",
        "excerpt":"환경     local     내 컴퓨터 환경   develop      개발 서버 환경   production    실제 운영 서버 환경   test     테스트 서버 환경   1) application.properties  application-{profile}.properties 형식으로 파일을 생성한다.   application-default.properties application-dev.properties application-prod.properties   jpa application.properties 설정에서..   spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl   예를들어, 엔터티 클래스의 studentNumber 속성에 자동으로 연결될 데이터베이스 필드 명이    studentNumber 형태이면 이 설정이 필요하다. (camel case)  student_number 형태이면 이 설정이 필요없다. (snake case)    camel case의 예: departmentManagerOfficeNumber     snake case의 예: department_manager_office_number   2) application.yml     한 파일에 profile 설정이 가능   spring.profiles.active로 profile 설정이 가능하다.   --- 로 나누면 다른 파일에서 불러온 것처럼 사용할 수 있다.   profiles를 설정해주지 않으면 기본 default로 동작한다.   spring:   profiles:     active: local   jpa:     database-platform: org.hibernate.dialect.MySQL5InnoDBDialect     open-in-view: false     properties:       hibernate:         format_sql: true     generate-ddl: true     database: mysql     show-sql: true  --- #Production  spring:   profiles: production   datasource:     url:     username:      password:   --- #local spring:   profiles: local   datasource:     url:      username:      password:      지금 프로젝트에서는 젠킨스 자동 배포를 사용하고 있기 때문에 DB 관련 설정 파일을 분리해서 배포하는 경우,        default 파일의 active를 push 전에 production으로 다시 설정해줘야 하는 번거로움이 생긴다.          그래서 application.yml 파일을 하나로 관리하면서 서버에는 production으로 설정해놓고 git에 있는 코드를 clone(or pull) 해서 개발할 때는 각자 applicaiton.yml 파일을 만들고 슬랙으로 공유하는 게 좋은 것 같다 !  ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-01-19/spring-boot-profile-%EC%84%A4%EC%A0%95/",
        "teaser": null
      },{
        "title": "Spring IoC & DI",
        "excerpt":"   스프링 IoC의 용어 정리                         빈(bean)  빈 또는 빈 오브젝트는 스프링이 IoC 방식으로 관리하는 오브젝트라는 뜻이다. 관리되는 오브젝트라고 부르기도 한다.    스프링을 사용하는 애플리케이션에서 만들어지는 모든 오브젝트가 다 빈은 아니다.    그중에서 스프링이 직접 생성과 제어를 담당하는 오브젝트만을 빈이라고 부른다.                        빈 팩토리(bean factory)  스프링의 IoC를 담당하는 핵심 컨테이너를 가리킨다. 빈을 등록, 생성, 조회, 돌려주는 등의 부가적인 빈을 관리하는 기능을 담당한다.   보통은 이 빈 팩토리를 바로 사용하지 않고 이를 확장한 애플리케이션 컨텍스트를 이용한다.   BeanFactory라고 붙여쓰면 빈 팩토리가 구현하고 있는 가장 기본적인 인터페이스의 이름이 된다. 이 인터페이스에 getBean()과 같은 메소드가 정의되어 있다.                        애플리케이션 컨텍스트(application context)  빈 팩토리를 확장한 IoC 컨테이너이다. 빈을 등록하고 관리하는 기본적인 기능은 빈 팩토리와 동일하다.   ApplicationContext라고 적으면 애플리케이션 컨텍스트가 구현해야 하는 기본 인터페이스를 가리키는 것이다.   ApplicationContext는 BeanFactory를 상속한다.                        설정정보/설정 메타정보(configuration metadata)   스프링의 설정정보란 애플리케이션 컨텍스트 또는 빈 팩토리가 IoC를 적용하기 위해 사용하는 메타정보를 말한다.   설정정보는 보통 IoC 컨테이너에 의해 관리되는 애플리케이션 오브젝트를 생성하고 구성할 때 사용된다.                        컨테이너 또는 IoC 컨테이너   IoC 방식으로 빈을 관리한다는 의미에서 애플리케이션 컨텍스트나 빈 팩토리를 컨테이너 또는 IoC 컨테이너라고도 한다.                        스프링 프레임워크   스프링 프레임워크는 IoC 컨테이너, 애플리케이션 컨텍스트를 포함해서 스프링이 제공하는 모든 기능을 통틀어 말할 때 주로 사용한다.    그냥 스프링이라고 줄여서 말하기도 한다.                      제어권의 이전을 통한 제어관계 역전  일반적으로 main() 메서드와 같이 프로그램이 시작되는 시검에서 다음에 사용할 오브젝트를 결정하고   결정한 오브젝트를 생성, 메소드 호출, 그 오브젝트 메소드에서 사용할 것을 결정 등의 작업이 반복된다.    이런 프로그램 구조에서 각 오브젝트는 프로그램 흐름을 결정하거나 사용할 오브젝트를 구성하는 작업에 능동적으로 참여한다.   제어의 역전이란 이런 제어 흐름의 개념을 거꾸로 뒤집는 것이다.   제어의 역전에서는 오브젝트가 자신이 사용할 오브젝트를 스스로 선택하지 않는다. 생성하지도 않는다.   또 자신이 어떻게 만들어지고 사용되는지를 알 수 없다. 모든 제어 권한을 다른 대상에게 위임하기 때문이다.   제어의 역전 개념은 이미 폭넓게 적용되어 있다. 서블릿을 생각해보면,   서블릿을 개발해서 서버에 배포할 수는 있지만 그 실행을 개발자가 직접 제어할 수 있는 방법은 없다.   서블릿 안에 main() 메소드가 있어서 직접 실행할 수 있는 것도 아니다.   대신 서블릿에 대한 제어 권한을 가진 컨테이너가 적절한 시점에 서블릿 클래스의 오브젝트를 만들고 그 안의 메소드를 호출한다.   애플리케이션 컨텍스트의 동작방식  @Configuration이 붙은 클래스는 이 애플리케이션 컨텍스트가 활용하는 IoC 설정정보다.   애플리케이션 컨텍스트는 클래스를 설정정보로 등록해두고 @Bean이 붙은 메소드의 이름을 가져와 빈 목록을 만들어둔다.   클라이언트가 애플리케이션 컨텍스트의 getBean()을 호출하면 자신의 빈 목록에서 요청한 이름이 있는지 찾고,  있가면 빈을 생성하는 메소드를 호출해서 오브젝트를 생성시킨 후 클라이언트에 돌려준다.   애플리케이션 컨텍스트를 사용할 때의 장점     클라이언트는 구체적인 팩토리 클래스를 알 필요가 없다.   애플리케이션 컨텍스트는 종합 IoC 서비스를 제공해준다.   애플리케이션 컨텍스트는 빈을 검색하는 다양한 방법을 제공한다.   싱글톤 레지스트리로서의 애플리케이션 컨텍스트  애플리케이션 컨텍스트는 IoC 컨테이너이자 동시에 싱글톤을 저장하고 관리하는 싱글톤 레지스트리이기도 하다.   스프링은 별다른 설정이 없으면 내부에서 생성하는 빈 오브젝트를 모두 싱글톤으로 만든다.   왜 스프링은 싱글톤으로 빈을 만들까?          스프링이 주로 적용되는 대상이 자바 엔터프라이즈 기술을 사용하는 서버 환경이기 때문이다.   즉, 사용자가 많다는 말이다. 매번 클라이언트 요청이 올 때마다 각 로직을 담당하는 오브젝트를 새로 만들어서 사용한다고 생각해보자.   아무리 자바의 오브젝트 생성과 가비지 컬렉션이 좋아졌어도 서버가 감당하기 힘들다.   그래서 기본적으로 싱글톤으로 객체의 갯수를 제한한다.   싱글톤 레지스트리  스프링은 서버환경에서 싱글톤이 만들어져서 서비스 오브젝트 방식으로 사용되는 것은 적극 지지!   하지만 자바의 기본적인 싱글톤 패턴은 여러 가지 단점이 있다..  그래서 스프링은 직접 싱글톤 형태의 오브젝트를 마늗ㄹ고 관리하는 기능을 제공한다. 이것을 싱글톤 레지스트리라고 한다.   스프링 컨테이너는 싱글톤 관리 컨테이너이도 하다.   싱글톤 레지스트리 장점     static 메서드와 private 생성자를 사용해야 하는게 아니라 평범한 자바 클래스를 싱글톤으로 활용하게 해준다.     오브젝트 생성에 관한 모든 권한은 IoC 기능을 제공하는 애플리케이션 컨텍스트에게 있기 때문이다.   싱글톤 방식으로 사용될 어플리케이션 클래스라도 public 생성자를 가질 수 있다.   싱글톤으로 사용해야 하는 환경이 아니라면 간단히 오브젝트를 생성해서 사용할 수 있다.     따라서 테스트 환경에서 자유롭게 오브젝트를 만들 수 있고, 목 오브젝트로 대체하는 것도 간단하다.    생성자 파라미터를 이용해서 사용할 오브젝트를 넣어주게 할 수도 있다.   싱글톤 패턴과 달리 스프링이 지지하는 객체지향 설계 방식과 원칙, 디자인 패턴 등을 적용하는 데 제약이 없다.   스프링은 IoC 컨테이너일 뿐만 아니라,  고전적인 싱글톤 패턴을 대신해서 싱글톤을 만들고 관리해주는 싱글톤 레지스트리라는 점을 기억해두자!   싱글톤으로 만들어지기 때문에 주의해야 할 점     싱글톤이 멀티스레드 환경에서 서비스 형태의 오브젝트로 사용되는 경우에는 상태정보를 내부에 갖고 있지 않은  무상태 방식(stateless)으로 만들어져야 한다.       서로 값을 덮어쓰고 자신이 저장하지 않은 값을 읽어올 수 있기 때문에 싱글톤은 기본적으로   인스턴스 필드의 값을 변경하고 유지하는 상태유지 방식(stateful)으로 만들지 않는다.            이를 지키지 않고 서버에 배포하면 여러 사용자가 동시에 접속했을 때 데이터가 엉망이 될 수 있다.  읽기전용의 값이라면 초기화 시점에서 인스턴스 변수에 저장해두고 공유하는 것은 아무런 문제가 없다.            스프링의 싱글톤 빈으로 사용되는 클래스를 만들 때는 바뀌는 정보는 로컬 변수로 정의하거나, 파라미터로 주고받으면서 사용하게 해야 한다.   초기에 설정해서 바뀌지 않는 읽기전용 인스턴스 변수는 문제가 없지만, 매번 새로운 값으로 바뀌는 인스턴스 변수는 심각한 문제가 발생한다.   무상태 방식이란?   객체에 인스턴스 필드가 없으면 stateless 이다.    final 키워드를 사용한 상수는 괜찮다.             다음과 같은 형태이다.   class Stateless {        final String TEST = \"Test!\"; // immutable             void test() {         System.out.println(TEST);     } }   스프링 빈의 스코프  스프링이 관리하는 오브젝트, 즉 빈이 생성되고, 존재하고, 적용되는 범위에 대해 알아보자!   스프링에서 이것을 빈의 스코프라고 한다. 스프링 빈의 기본 스코프는 싱글톤이다.    싱글톤 스코프는 컨테이너 내에 한 개의 오브젝트만 만들어져서, 강제로 제거 하지 않는 한 스프링 컨테이너가 존재하는 동안 계속 유지된다.   경우에 따라 싱글톤 외의 스코프를 가질 수 있다.     프로토타입 스코프 : 싱글톤 스코프와는 다르게 컨테이너에 빈을 요청할 때마다 매번 새로운 오브젝트를 만든다.   리퀘스트 스코프 : 웹을 통해 새로운 HTTP 요청이 생길때마다 생성된다.   프로그래밍에서 의존성이란?  스프링의 IoC(Inversion of Control / 제어의 역전)라고도 하는 DI(Dependency Injection / 의존성 주입)을 알아보기 전에   자바에서의 의존성이 무엇인지도 알아보자.   new Car();  Car 객체 생성자에서 new Tire();     의존성을 단순하게 정의해서 new라고 하자.      new를 실행하는 Car와 Tire사이에서 Car가 Tire에 의존한다.   결론적으로 전체가 부분에 의존한다고 할 수 있다.  의존하는 객체(전체)와 의존되는 객체(부분) 사이에 집합 관계와 구성 관계로 구분할 수도 있다.   일단 전체가 부분에 의존한다는 것과 프로그래밍에서 의존 관계는 new로 표현된다는 것만 기억하자!     집합 관계 : 부분이 전체와 다른 생명 주기를 가질 수 있다. 예) 집 vs. 냉장고   구성 관계 : 부분은 전체와 같은 생명 주기를 갖는다. 예) 사람 vs. 심장    (1) 스프링 없이 의존성 주입하기 1 - 생성자를 통한 의존성 주입    (2) 스프링 없이 의존성 주입하기 2 - 속성을 통한 의존성 주입    (3) 스프링을 통한 의존성 주입 1 - XML 파일 사용    (4) 스프링을 통한 의존성 주입 2 - 스프링 설정 파일(XML)에서 속성 주입    (5) 스프링을 통한 의존성 주입 3 - @Autowired를 통한 속성 주입    (6) 스프링을 통한 의존성 주입 4 - @Resource를 통한 속성 주입   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-01-31/spring-DI-IoC/",
        "teaser": null
      },{
        "title": "Redis 사용해보자!",
        "excerpt":"1. Redis란?  in-memory 기반의 data structure 저장 기술로 데이터베이스 서버, 데이터 캐싱 등이 가능한 시스템이다.   특징     오픈소스 소프트웨어   디스크가 아닌 메모리 기반의 데이터 저장소   NoSQL&amp;Cache 솔루션이며, 메모리 기반으로 구성된다.   명시적으로 삭제, expire를 설정하지 않으면 데이터는 삭제되지 않는다.   여러개의 서버 구성이 가능하다.   데이터베이스로 사용할 수 있으며 Cache로도 사용될 수 있는 기술이다.   사용 가능한 데이터형     String   List   Set   Sorted set   Hash   장점     리스트, 배열과 같은 데이터 처리에 유용   메모리를 사용하면서 영속적인 데이터 보존이 가능   Redis server는 1개의 싱글 스레드로 수행되기 떄문에 서버 하나에 여러 서버를 띄울 수 있음   2. Redis 설치 및 spring boot 에서 사용     docker 이용해서 설치 및 접속   # 최신 이미지 가져오기, 레디스 서버 실행  docker pull redis  docker run --name redis -d -p 6379:6379 redis  # Docker의 redis-cli로 접속   docker run -it --link redis:redis --rm redis redis-cli -h redis -p 6379   # Redis-cli로 직접 접속하기: 연결된 6379 포트를 사용 redis-cli -p 6379  # Shell로 Docker 리눅스에 접속  docker exec -it redis /bin/bash      의존성 추가   &lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt;      application.yml 설정 정보 추가   redis:     host:      port:      passwd:   3. Nexters16 프로젝트에서 Redis 사용하기  회원끼리 편지를 주고 받는 기능을 위해 우리는 회원가입 시 사용자에게 전화번호를 받고 인증까지 진행하기로 했다.      전화번호 인증을 하려면 인증 코드도 저장해야 하고 인증 결과도 저장해야 하는데   redis를 이용해서 몇가지 데이터를 key-value 형태로 저장하는게 좋겠다는 회의 결과가 나왔다!   프로젝트에서 redis 사용   Java의 redis client는 크게 jedis와 lettuce 2가지가 있는데, 우리는 lettuce를 사용하고 있다.   spring boot 2.0에서 lettuce가 기본 클라이언트가 되서 사용해보기 시작했는데  어떤 점에서 lettuce가 더 좋을지 알아보자!           Jedis   여러 스레드에서 Jedis 인스턴스를 공유하려 할 때 jedis는 스레드에 안전하지 않다. 따라서 멀티 스레드 환경에서 고려할 상황이 생긴다.   안전한 방법은 pooling(Thread-pool)과 같은 jedis-pool을 사용하는 것이지만 물리적인 비용의 증가가 따른다.    (connection할 인스턴스를 미리 만들어놓고 대기하는 연결비용의 증가)              Spring Boot 2.0에서는 기본 의존성인 lettuce를 제거하고 Jedis를 등록해야 한다.                 Lettuce  Lettuce는 Netty(비동기 이벤트 기반 고성능 네트워크 프레임워크)   기반의 레디스 클라이언트이다. Thread-safe!       비동기로 요청을 처리하기 때문에 고성능을 자랑한다.       Jedis에 비해 몇배 이상의 성능과 하드웨어 자원 절약이 가능하다.       connection 인스턴스의 공유라는 점에서 Thread-safe인 lettuce를 사용해야 겠다는 생각이 들지만     Single-Thread의 레디스에 데이터에 접근할 때? 혹은 다른 관점에서는 어떨지 더 알아보면 좋을 것 같다.     일단 지금 진행중인 프로젝트에서   이런 방식으로 redis에 저장하고       인증이 완료되면 session을 통해 redis에 인증 여부를 저장하려고 하는데     session에 대한 개념이 부족해 더 공부해봐야 할 것 같다!       ","categories": ["Spring","Redis"],
        "tags": ["spring","redis"],
        "url": "/2020-02-02/spring-boot-redis/",
        "teaser": null
      },{
        "title": "Lombok이란",
        "excerpt":"Lombok 이란?  자바에서 DTO, VO 등에서 반복적으로 사용되는 코드를 annotation을 통해 쉽게 작성할 수 있게 도와주는 라이브러리   동작 원리  롬복 어노테이션이 붙은 자바 소스를 컴파일할 때 annotation processor로 등록된 lombok processor가  어노테이션을 확인하고 그에 맞는 코드를 자동으로 생성해서 바이트코드로 변환 한다.   사용 방법     의존성 설정   plugin 설정   compile 설정   설정은 lombok.config 파일에서   세부적인 설정이 가능한데 기본적으로 disable로 설정되어있는 어노테이션은 flagUsage를 ALLOW로 설정해야 사용이 가능해진다.  lombok.---.flagUsage = ALLOW   Lombok annotation  val  lombok.var.flagUsage = ALLOW   위와 같은 설정이 필요하다.   @NonNul  null 값이 될 수 없다는 것을 명시한다.    null이 전달되면 예외를 던지는데 설정을 통해 던져지는 예외를 IllegalArgumentException으로도 설정할 수 있다.     lombok.config 파일에서 lombok.nonNull.exceptionType = IllegalArgumentException     이렇게 설정해주면 IllegalArgumentException으로 catch할 수 있고 NullPointException에 대한 대비책이 될 수 있다.   @Cleanup  try-with-resource 구문과 비슷한 효과를 가진다.   구문이 종료될 때 AutoCloseable 인터페이스의 close()가 호출되는 try-with-resource와 달리 Scope가 종료될 때 close()가 호출된다.   /**  * 이 메소드가 종료될 때 scanner.close()가 호출된다.  */ public static void getAndPrint() {   @Cleanup val scanner = new Scanner(System.in);   val value = scanner.nextLine();   System.out.println(value); }   @Setter / @Getter  필드의 setter/getter를 만든다.    어노테이션의 파라미터로 AccessLevel을 이용해 setter/getter의 접근제한자를 설정할 수 있다.  private final로 선언된 필드는 @Getter의 파라미터 중 lazy를 true로 설정할 수 있는데,   lazy를 true로 설정할 경우 해당 필드의 getter가 호출 될 때 필드의 값을 설정한다.   @ToString  toString() 메소드를 생성한다. @ToString(exclude={“제외할 값”}) 처럼 원하지 않는 속성은 제외할 수 있다.    includeFieldNames로 필드명을 생략할지 포함할지 여부, callSuper로 상위 클래스의 toString()을 호출할지 여부를 설정할 수 있다.   @EqualsAndHashCode  해당 객체의 equals()와 hashCode() 메소드를 생성한다.   @NoArgsConstructor / @AllArgsConstructor / @RequiredArgsConstructor  클래스의 생성자를 만들어준다.  세 종류를 중복해서 사용할 수 있다.   세 가지 어노테이션 모두 객체를 만드는 static 메소드의 이름을 입력받는 staticName, 생성자의 접근제한자를 설정하는 access를 파라미터로 입력할 수 있다.  @NoArgsConstructor - 파라미터가 없는 생성자  @AllArgsConstructor - 모든 필드를 파라미터로 가지는 생성자  @RequiredArgsConstructor - 기본 값이 없고 @NonNull 어노테이션이 붙은 필드를 파라미터로 입력받는 생성자   @Data  @ToString, @EqualsAndHashCode,  @Getter, @Setter, @RequiredArgsConstructor를 합쳐 둔 어노테이션이다.   하지만 세부 설정을 하려면 각각의 어노테이션을 붙여야 한다는 점,   @RequiredArgsConstructor 어노테이션으로 만들어지는 생성자는 다른 생성자가 없을 때에만 만들어진다는 점을 주의해야 한다.   @Value  @Data 어노테이션과 비슷하지만 필드를 변경할 수 없는 ‘불변 객체’가 만들어진다.     필드에 @Wither 어노테이션을 이용하면 with필드명(값) 메소드가 만들어지는데,   이 메소드를 이용하면 값을 변경한 새로운 객체를 만들어준다.  @Value 어노테이션은 val 어노테이션을 사용하기 때문에  val 어노테이션이 사용가능한 상태에서만 @Value 어노테이션도 사용이 가능하다.   @Builder  빌더 패턴을 적용한 객체 생성 메소드/클래스를 만들어준다.     builderClassName 파라미터로 nested(중첩) 빌더 클래스의 이름을 (클래스명Builder가 기본),      builderMethodName으로 빌더 클래스를 반환하는 static 메소드의 이름을 (builder()가 기본),         buildMethodName으로 객체를 반환하는 빌드 메소드의 이름 (build()가 기본)을 설정할 수 있다.   필드에 @Builder.Default 어노테이션을 붙여 기본 값을 설정할 수 있고,  @Singular 어노테이션을 붙여 빈 collection을 자동으로 만들 수 있다.   @Singluar 어노테이션은 파라미터로 builder에서 값을 추가할 때 사용되는 메소드의 이름을 입력받는다.     또,@Singular 어노테이션으로 만들어진 collection은 수정할 수 없다.   @SneakyThrows  메소드 선언부에 사용되는 throws 키워드 대신 사용하는 어노테이션으로 예외 클래스를 파라미터로 입력받는다.  예외 발생 시 Throwable 타입으로 반환한다.   @Syncronized  메소드에 사용되는 어노테이션으로 기본적으로 지원되는 synchronized 키워드보다 더 세세한 설정이 가능한 어노테이션이다.     synchronized 키워드는 static 혹은 instance 단위로 락을 걸지만 @Synchronized 어노테이션은 파라미터로 입력받는 Object 단위로 락을 건다.     파라미터로 아무 것도 입력하지 않으면 어노테이션이 사용된 메소드 단위로 락을 건다.   @Log  클래스 상단에 항상 선언하는 static final log 필드를 자동으로 생성해준다.      지원되는 Logger에 따라 다른 어노테이션이 사용된다.   주의할 점  @Data를 조심!  ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-02-04/lombok/",
        "teaser": null
      },{
        "title": "쿠키(cookie)",
        "excerpt":"쿠키란  쿠키는 웹 브라우저가 보관하는 데이터이다. 웹 브라우저는 웹 서버에 요청을 보낼 때 쿠키를 함께 전송하며,   웹 서버는 웹 브라우저가 전송한 쿠키를 사용해서 필요한 데이터를 읽을 수 있다.   쿠키는 웹 서버와 웹 브라우저 양쪽에서 생상헐 수 있는데, JSP에서 생성하는 쿠키는 웹 서버에서 생성하는 쿠키이다.   쿠키 동작 방식      (1) 쿠키 생성 단계   쿠키를 사용하려면 먼저 쿠키를 생성해야 한다. JSP 프로그래밍에서 쿠키는 웹 서버 측에서 생성한다.   생성한 쿠키를 응답 데이터의 헤더에 저장해서 웹 브라우저에 전송한다.   (2) 쿠키 저장 단계   웹 브라우저는 응답 데이터에 포함된 쿠키를 쿠키 저장소에 보관한다.   쿠키의 종류에 따라 메모리나 파일에 저장한다.   (3) 쿠키 전송 단계   웹 브라우저는 저장한 쿠키를 요청이 있을 때마다 웹 서버에 전송한다.   웹 서버는 웹 브라우저가 전송한 쿠키를 사용해서 필요한 작업을 수행한다.   웹 브라우저에 쿠키가 저장되면, 웹 브라우저는 쿠키가 삭제되기 전까지 웹 서버에 쿠키를 전송한다.     따라서 웹 어플리케이션을 사용하는 동안 지속적으로 유지해야 하는 정보는 쿠키를 사용해서 저장하면 된다.   장점     클라이언트에 저장하기 때문에 서버에 요청 시 빠르다.   단점     쿠키에 대한 정보를 매 헤더(Http Header)에 추가하여 보내기 때문에 상당한 트랙픽을 발생시킵니다.   결제정보등을 쿠키에 저장하였을때 쿠키가 유출되면 보안에 대한 문제점도 발생할 수 있습니다.   저장 용량에 제한이 있다.   1. 쿠키의 구성     이름 : 각각의 쿠키를 구성하는 데 사용되는 이름   값 : 쿠키의 이름과 관련된 값   유효시간 : 쿠키의 유지 시간   도메인 : 쿠키를 전송할 도메인   경로 : 쿠키를 전송할 요청 경로   하나의 웹 브라우저는 여러 개의 쿠키를 가질 수 있는데, 각 쿠키를 구분할 때 이름을 사용한다.   각 쿠키는 값을 가지고 서버는 이 값을 이용해서 원하는 작업을 한다.   유효시간을 사용하면 웹 브라우저가 쿠키를 얼마 동안 보관할지를 지정할 수 있다.   예를 들어 쿠키 유효 시간을 1시간으로 지정하면 1시간 뒤에 웹 브라우저가 해당 쿠키를 삭제하고   별도의 유효 시간을 지정하지 않으면 웹 브라우저를 종료할 때 쿠키를 함께 삭제한다.     유효 시간에 따라 브라우저를 종료해도 계속 남아 있을 수 있다.   또한, 지정한 도메인이나 경로로만 쿠키를 전송하도록 제한할 수 있다.   2. 쿠키의 종류     Session Cookie : 보통 만료시간(Expire date) 설정하고 메모리에만 저장되며 브라우저 종료시 쿠키를 삭제   Persistent Cookie\t: 장기간 유지되는 쿠키(예를 들어 Max-Age 1년), 파일로 저장되어 브라우저 종료와 관계없이 사용   Secure Cookie : HTTPS에서만 사용, 쿠키 정보가 암호화 되어 전송   Third-Party Cookie : 방문한 도메인과 다른 도메인의 쿠키 보통 광고 베너 등을 관리할 때 유입 경로를 추적하기 위해 사용   3. 쿠키 생성, 변경, 삭제 등  쿠키 사용 방법은 책 참고!   4. 쿠키를 사용한 로그인 상태 유지  쿠키를 이용하면 다음과 같은 방법으로 로그인 상태를 유지할 수 있다.    (1) 로그인에 성공하면 특정 이름을 갖는 쿠키를 생성한다.   (2) 해당 쿠키가 존재하면 로그인한 상태라고 판단한다.    (3) 로그아웃하면 해당 쿠키를 삭제한다.   예를 들어, 로그인에 성공하면 “AUTH”라는 쿠키를 생성하고,    “AUTH” 쿠키가 존재하면 로그인한 상태라고 인식하는 것이다.   ","categories": ["Web"],
        "tags": ["web"],
        "url": "/2020-02-06/cookie/",
        "teaser": null
      },{
        "title": "세션(session)",
        "excerpt":"서버 세션을 사용하면 클라이언트의 상태를 저장할 수 있다.    쿠키와의 차이점은 세션은 웹 브라우저가 아니라 서버에 값을 저장한다는 점이다.   서버는 세션을 사용해서 클라이언트 상태를 유지할 수 있기 때문에, 로그인한 사용자 정보를 유지하기 위한   목적으로 세션을 사용한다.   1. 세션 사용하기 : session 기본 객체  웹 브라우저에 정보를 보관할 때 쿠키를 사용한다면, 세션은 웹 컨테이너에 정보를 보관할 때 사용한다.    세션은 오직 서버에만 생성된다.      웹 컨테이너는 기본적으로 한 웹 브라우저마다 한 세션을 생성한다.   즉, 같은 JSP 페이지라도 웹 브라우저에 따라 서로 다른 세션을 사용한다.   웹 브라우저마다 세션이 따로 존재하기 때문에, 세션은 웹 브라우저와 관련된 정보를 저장하기에 알맞은 저장소이다.   즉, 쿠키가 클라이언트 측의 데이터 보관소라면 세션은 서버 측의 데이터 보관소인 것이다.   만료 시간을 정할 수 있지만 메모리에 저장하기 때문에 브라우저가 종료되면 사라지게 된다.   2. 세션 생성, 속성 사용, 종료 등  세션 사용 방법은 책 참고!   3. 세션을 사용한 로그인 상태 유지  세션을 사용해서 로그인을 처리하는 방식은 쿠키를 사용한 방식과 비슷하다.   (1) 로그인에 성공하면 session 기본 객체의 특정 속성에 데이터를 기록한다.   (2) 이후로 session 기본 객체의 특정 속성이 존재하면 로그인한 것으로 간주한다.   (3) 로그아웃할 경우 session.invalidate() 메소드를 호출하여 세션을 종료한다.   4. 서블릿 컨텍스트와 세션  예제로 설명!   webapp 폴더에 chap10 폴더와 chap10_2 폴더를 만들면   다음 두 URL을 사용해서 view.jsp를 실행할 수 있다.      http://localhost:8080/chap10/view.jsp   http://localhost:8080/chap10_2/view.jsp   JSESSIONID 쿠키를 서버에 전송한다고 했을 때,   같은 서버에서 /chap10 경로와 /chap10_2 경로가 서로 다른 JSESSIONID 값을 사용하는 이유는   두 경로가 서로 다른 웹 어플리케이션이기 때문이다.   세션 ID를 보관할 때 사용할 JSESSIONID 쿠키의 경로로 웹 어플리케이션의 컨텍스트 경로를 사용한다.   즉, 웹 어플리케이션의 컨텍스트 경로가 /chap10인 쿠키는 URL이 /chap10 경로로 시작하는 경우에만 전송되므로,   /chap10 웹 어플리케이션에서 생성한 JSESSIONID 쿠키는 /chap10 웹 어플리케이션에서만 사용한다.     /chap10_2도 마찬가지이다.   서로 다른 두 웹 어플리케이션이 다른 세션 ID를 사용하고 다른 JSESSIONID 쿠키를 사용한다는 것은,       다시 말하면 서로 다른 웹 어플리케이션이 세션을 공유하지 않음을 의미한다.       즉, 같은 웹 브라우저라 하더라도 /chap10 어플리케이션에서 사용하는 session 기본 객체와     /chap10_2 어플리케이션에서 사용하는 session 기본 객체가 다르다.   5. server-side 관점의 세션     장점            서버에 저장하기 때문에 관리하기 편하고 효율적이다.       쿠키 보다는 보안에 유리하다.           단점            서버에 부하를 초래할 수 있다.       로드 밸런싱(load balancing) 시스템 효율성 별로           세션 단점 해결 방법            load-balancing 문제                    세션 정보를 하나의 저장장치에 공유하는 것 ex) Redis           sticky session : 각각의 클라이언트를 다른 서버에 binding하는 방법                       서버 부하                    memory기반의 저장장치를 사용 ex) Redis                           6. client-side 관점의 세션     서버에 많은 양의 정보를 저장하지 않고 상태를 유지하기 위해 암호화가 적용된 쿠키를 사용   클라이언트에 저장된 쿠키가 데이터가 소프트웨어나 다른 사용자에 의해 손상될 경우도 있다.   클라이언트 세션은 기밀성과 무결성이 보장되어야 한다.   보장되어야 하는 것     Confidentiality : 서버이외에는 어느 누구도 세션데이터를 해석할 수 없어야 한다.   Data integrity : 서버와 별개로 세션 데이터를 조작해서는 안된다.   Authenticity : 서버를 제외하고는 올바른 세션을 시작할 수 없어야 한다.   ","categories": ["Web"],
        "tags": ["web"],
        "url": "/2020-02-06/session/",
        "teaser": null
      },{
        "title": "spring form validation",
        "excerpt":"Spring Form Validation 1   1. 배경지식  (1) spring form validation  입력폼에 입력된 내용의 오류를 spring이 자동으로 검사해주는 기능이다.   입력폼 submit 과정 #1                         spring web mvc로 구현한 입력폼의 submit 과정은 다음과 같다.           사용자가 웹 브라우저에서 입력폼에 데이터를 입력하고 submit 버튼을 누른다.            서버의 url이 요청된다. (http request)              입력폼에 입력된 데이터도 이 요청에 같이 담겨 전송된다. (request parameter)            spring web mvc 엔진이 그 요청을 받아서 요청된 url과 일치하는 액션메소드를 찾는다.      @RequestMapping(value=\"studentEdit\", method=RequestMethod.POST) public String studentEdit(@valid Student student, Model model,                      BingingResult bindingResult){ ... }           spring form validation 기능을 구현하기 위해,   @valid 어노테이션과 BindingResult 객체가 추가되었다.     검사결과를 bindingResult에 채워진 후에 액션 메소드가 호출된다.      위 액션메소드의 파라미터가 객체이기 때문에 spring web mvc 엔진이 아래의 일들을 자동으로 처리한다.     Student student = new Student(); // Student 객체 생성 student.setStudentNumber(\"201732017\"); // 생성된 객체에 request parameter 데이터를 채운다.   model.addAttribute(\"student\", student); // 객체를 model 객체에 등록한다.              Student 객체에 채워진 데이터에 문제가 없는지 검사한다.      데이터를 검사할 규칙이 Student 클래스에 등록되어 있어야 한다.     public class Student{  @NotEmpty   @Size(min=9, max=12)  Stirng studentNumber; \t  @NotEmpty  @Size(min=2)  String name;          spring form validation 기능을 구현하기 위해 @NotEmpty, @Size 어노테이션이 추가되었다.           Student 객체에 채워진 데이터가 이 어노테이션 규칙이 부합하는지 spring web mvc 엔진이 검사한다.     검사결과가 BindingResult 객체에 등록한다.       액션메소드가 호출된다.  studentEdit(student, model, bindingResult)   (2) 모델 클래스(model)          request parametet 데이터를 채우기 위한 객체      앞에서 설명한 입력폼 submit 과정에서 사용된 Student 클래스 처럼,              request parameter 데이터를 채우기 위한 클래스를 모델 클래스라고 부른다.            model 객체에 채워져 뷰에 전달되기 위한 객체        spring form validation 규칙을 설정하기 위한 어노테이션을 model 클래스에 추가해야 하는데,       그 어노테이션들은 Entity 클래스에서는 사용할 수 없다.       DTO - 데이터를 채워서 전달           model - 입력 받은 값을 view에서 controller에 전달                Entity - DB 테이블 구조 그대로   (3) 엔터티 클래스  JPA 프로그래밍에서 구현하게 되는 @Entity 어노테이션이 붙은 클래스를 엔터티 클래스라고 부른다.         엔터티 객체는 JPA Repository의 조회결과 데이터를 리턴할 때 사용되는 객체이다.        JPA Repository의 save 메소드를 호출하여 데이터를 저장할 때도 엔터티 객체를 사용한다.   (4) 모델 클래스와 엔터티 클래스  예를들어, 학생 테이블의 경우에 아래의 클래스들을 따로 구현한다.          모델 클래스 - StudentModel.java       엔터티 클래스 - Student.java   spring form validation 기능을 구현하기 위해서는 엔터티 클래스와 모델 클래스를 구별해서 따로 구현해야 한다.       spring form validation 기능을 구현하려면 @NotEmpty, @Size 어노테이션을 사용해야 하는데,      이 어노테이션들을 엔터티 클래스에 붙이는 것은 바람직하지 않기 때문이다. (중복이 많아지면 상속해서 구현한다.)   (5) 객체지향 설계  객체지향적으로 바람직한 구조를 만들기 위한 설계 원칙 중 하나는, 클래스들의 역할을 분명히 구분하는 것이다.           컨트롤러의 역할    컨트롤러의 역할은 이름 그대로 지휘 통제하는 것이다.       지휘 통제 역할만 해야 한다. 구체적으로 작업을 하는 것은 바람직하지 않다.            DAO(Data Access Object) 클래스의 역할         DAO의 역할은 데이터베이스 테이블에 SELECT/INSERT/UPDATE/DELETE 하는 작업을 하는 것이다.            Service 클래스의 역할       DAO 작업을 제외한 나머지 작업들은 서비스 클래스에 구현되어야 한다.       7. 컨트롤러 클래스 구현  (1) UserController.java  @RequestMapping(value=\"register\", method=RequestMethod.GET)        회원가입 입력폼이 처음 실행될 때, GET 방식의 register 액션 메소드가 실행된다.   model.addAttribute(\"departments\", departmentService.findAll());       user/register.jsp 뷰 파일을 실행할 때, 학과 목록이 출력되어야 하기 때문에       학과 목록이 모델이 들어있어야 한다.   @RequestMapping(value=\"register\", method=RequestMethod.POST)            submit 버튼을 눌렀을 때, POST 방식의 register 액션 메소드가 실행된다.   if(bindingResult.hasErrors()){ \tmodel.addAttribute(\"departments\", departmentService.findAll()); \treturn \"user/register\";  userModel 모델 객체에 채워진 데이터에 오류가 있다면, if문이 true가 된다.       회원가입 입력 항목에 에러가 있기 때문에 회원가입 입력폼이 다시 화면에 나타나야 한다.          그래서 “user/register” 뷰 이름을 리턴한다.   userService.save(userModel); return \"redirect:registerSuccess\";  데이터가 오류가 없으면, UserRegistrationModel 객체에 입력된 데이터를 user 테이블에 저장한다.         그리고 회원가입 성공 화면으로 리다이렉트한다.   8. 뷰 구현  (1) user/register.jsp  &lt;form:form method=\"post\" modelAttribute=\"userRegistrationModel\"&gt; \t... \t&lt;form:errors path=\"userid\" class=\"error\" /&gt;  userid 데이터 항목과 관련된 에러 메시지가 자동으로 여기에 표시된다.   코드 분석  Q. user/register.jsp 뷰 파일은 어떤 메소드의 뒤에 이어서 실행되는가?       A. register GET, POST 방식 메소드   Q. GET 방식 액션 메소드에서 userRegistrationModel 객체를 모델에 어떻게 등록하였는가?         A. userRegistrationModel 객체를 파라미터로 받아,        spring web mvc 엔진이 객체 생성 객체에 전달받은 파라미터 값 저장, model에 등록을 자동을 해준다.   Q. POST 방식 액션 메소드에서 userRegistrationModel 객체를 모델에 어떻게 등록하였는가?     A. 파라미터로 객체를 전달받으면 자동으로 model에 등록된다.   Q. GET 방식 액션 메소드에서 departments 객체를 모델에 어떻게 등록하였는가?         A. Model 객체에 addAttribute() 메소드를 이용하여 등록할 수 있다.   Q. POST 방식 액션 메소드에서 departments 객체를 모델에 어떻게 등록하였는가?       A. Model 객체에 addAttribute() 메소드를 이용하여 등록할 수 있다.   11. 사용자 아이디 중복 검사 기능 구현  user 테이블의 userid 필드      이 필드는 primary key 가 아니다. 이 필드로 unique index를 만들지도 않았다.                 그렇기 때문에 동일한 값이 INSERT 되어도 에러가 발생하지 않는다.   중복 방지를 위해 unique index를 만들어 주는게 좋다. 하지만 DB에 삽입하기 전에 먼저 검사해서        입력폼에서 에러를 표시해 주는 것이 바람직하다.          Spring Form Validation 2   1. validation message 수정  (1) 목표      위 화면에서 자동으로 출력된 에러 메시지 문구를 수정하자.   각 validation annotation에 대한 에러 메시지를 ValidationMessage.properties 파일에 등록해 주면 된다.   (2) ValidationMessage.properties 생성   javax.validation.constraints.Size.message=크기가 {min} 이상 {max} 이하이어야 합니다. org.hibernate.validator.constraints.Email.message=이메일 주소가 바르지 않습니다. org.hibernate.validator.constraints.NotEmpty.message=필수 입력항목입니다.   javax.validation.constraints.Size.message 는 @Size 어노테이션 클래스의 경로명                   org.hibernate.validator.constraints.Email.message 는 @Email 어노테이션 클래스의 경로명           org.hibernate.validator.constraints.NotEmpty.message 는 @NotEmpty 어노테이션 클래스의 경로명   2. 개별 항목에 대한 에러 메시지 등록  (1) 목표  @NotEmpty 어노테이션에 위배되는 모든 항목에 “필수 입력 항목입니다.” 에러메시지가 동일하게 출력된다.      항목에 따라서 다른 에러 메시지가 표시되어야 하는 경우에는         @NotEmpty 어노테이션에 message 애트리뷰트 값으로 에러 메시지를 등록하면 된다.   (2) message 애트리뷰트  어떤 항목의 @NotEmpty 에러 메시지를 다른 것으로 바꾸려면,      이 어노테이션에 message 애트리뷰트 값으로 에러 메시지를 등록하면 된다.   Example  @NotEmpty(message=\"학번을 입력하세요\") @Size(min=6, max=12, message=\"6 자리 이상 12 자리 이하이어야 합니다.\") @Min(value=1, message=\"양의 정수를 입력하세요\")   @Min(1)     위와같이 값이 한개인 어노테이션에서 그 값 한개인 애트리뷰트 이름은 value이다.       애트리뷰트 값이 하나 뿐일 때, value 이름을 생략할 수 있다.      하지만, 값이 여러개 일 때는 애트리뷰트 이름을 생략할 수 없다. -&gt; @Min(value=1, message=\"error message\")   3. 로직 에러 처리하기  (1) 목표  validation annotation에 의해서 자동으로 검사되기 힘든 에러들도 있다.     예를들어, 사용자 아이디 중복을 검사하려면 DB의 user 테이블을 조회해야 한다.      입력된 두 비밀번호가 일치하는지 검사하려면, 두 멤버변수를 비교해야 한다.       이런 에러 검사는 validation annotation으로 구현하기 힘들고 따로 직접 구현해야 한다.      로직 에러 처리하기 절차   (1) spring form validation 에러가 있다면, 회원가입 뷰 이름을 리턴한다.    회원가입 뷰 이름이 리턴되면 웹 브라우저 창에 회원가입 화면이 다시 출력된다.   (2) 입력된 두 비밀번호가 일치하는지 검사한다.   (3) 일치하지 않으면 비밀번호 불일치 에러이다.    \t(3-1) bindingResult 객체에 비밀번호 불일치 에러메시지를 등록한다.    \t(3-2) 회원가입 뷰 이름을 리턴한다.   (4) 입력된 사용자 아이디로 DB의 사용자 테이블에서 조회한다.   (5) 조회결과가 null이 아니면, 사용자 아이디 중복 에러이다.    \t(5-1) bindingResult 객체에 사용자 아이디 중복 에러 메시지를 등록한다.    \t(5-2) 회원가입 뷰 이름을 리턴한다.      bindingResult 객체에 에러 메시지 등록하기   bindingResult.rejectValue(\"password2\", null, \"비밀번호가 일치하지 않습니다.\");  rejectValue 메소드를 호출하여 에러 메시지를 등록한다.   첫번째 파라미터 : 에러가 발생한 멤버변수 이름    세번쨰 파라미터 : 에러 메시지   bindingResult에 위 에러가 등록되면, 아래 태그에 그 에러 메시지가 출력된다.  &lt;form:errors path=\"password2\" class=\"error\" /&gt;   (2) UserService.java  public boolean hasErrors(UserRegistrationModel userModel, BindingResult bindingResult){ \tif(bindingResult.hasErrors()){ \t\treturn true; \t} \t\t \t...  }   (3) UserController.java  public String register(...){ \tif(userService.hasErrors(userModel, bindingResult)){ \t\treturn \"user/register\"; \t}  \t...  }  Q. 아까 입력했던 내용이 view에 어떻게 나타나는걸까?    A. 액션 메소드의 파라미터가 객체일 때, 자동으로 일어나는 일은      userModel이 model에 자동으로 addAttribute 된다. (userRegistration이라는 이름으로)   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-02-14/spring-form-validation/",
        "teaser": null
      },{
        "title": "AOP",
        "excerpt":"AOP 예제 코드   AOP 란?  AOP는 Aspect-Oriented Programming의 약자이고, 이를 번역하면 관점 지향 프로그래밍이 된다.   스프링 DI가 의존성(new)에 대한 주입이라면 스프링 AOP는 로직(code) 주입이라고 할 수 있다.   DB 커넥션 준비  Statement 객체 준비   try{     DB 커넥션 연결      Statement 객체 세팅      insert / update / delete / select 실행  } catch ... {     예외처리  } catch ...{     예외처리  } final {     DB 자원 반납 }   어떤 데이터베이스 연산을 하든 공통적으로 나타나는 코드가 있다.  이를 바로 횡단 관심사라고 한다. 그리고 insert / update / delete / select 실행 이 부분을 핵심 관심사라고 한다.   코드 = 핵심 관심사 + 횡단 관심사   핵심 관심사는 모듈별로 다르지만 횡단 관심사는 모듈별로 반복되어 중복해서 나타나는 부분이다.   반복/중복은 분리해서 한 곳에서 관리하자.       그런데 AOP에서는 더욱 진보적인 방법을 사용한다.   로직을 주입한다면 어디에 주입할 수 있을까?    객체지향에서 로직(코드)이 있는 곳은 메소드의 안쪽이다.     메소드에 주입할 수 있는 곳은 총 5곳이다.     Around 메소드 전 구역   Before 메소드 시작 전 (시작 직후)   After 메소드 종료 후 (종료 직전)   AfterReturning 메소드 정상 종료 후   AfterThrowing 메소드에서 예외가 발생하면서 종료한 경우       AOP를 통해 어떻게 횡단 관심사를 분리해 낼 수 있는지,    분리된 횡단 관심사(로직)을 어떻게 실행 시간에 메서드에 주입할 수 있는지 알아보자.   예제 코드 : https://github.com/hyerin6/Spring/tree/master/ExpertSpring30/src/main/java/aop002   위 예제 코드에서 Boy와 Girl이 Person 인터페이스를 구현하고 스프링 AOP를 적용했다.   코드가 중복이 되거나 말거나 한 파일에 전부 구현했을 때와 달리     runSomething() 메서드만 AOP로 구현했는데 코드의 양이 상당히 늘어났다.   하지만 Boy.java 코드를 보면 횡단 관심사는 모두 사라졌고 핵심 관심사만 남았다.     Boy를 4개의 파일로 분할해서 개발해야해서 수고스러워 보이지만   추가 개발과 유지보수 관점에서 보면 엄청 편한 코드가 된 것이다.   AOP를 적용하면서 Boy.java에 단일 책임 원칙(SRP)을 자연스럽게 적용하게 된 것이다.     다른 개발자들은 핵심 관심사만 코딩하면 된다.   Q1. Boy.java와 Girl.java에서 try-catch-finally 부분이 사라진 이유는?          A. 횡단 관심사이기 때문이다.   Q2. implements Person 부분이 생긴 이유는?         A. 스프링 AOP가 interface 기반으로 작동하기 때문이다.   Q3. MyAspect.java 가 들어온 이유는?               A. Boy.java와 Girl.java에서 횡단 관심사를 지웠는데       결국 누군가는 횡단 관심사항을 처리해줘야 한다.      그것을 Aspect라고 부르고 MyAspect.java가 그 역할을 담당하는 것이다.   마지막으로 그럼 &lt;aop:aspectj-autoproxy /&gt;는 뭘까?            Boy.java와 Girl.java에서 구현한 runSomething()은     Pserson 인터페이스의 runSomething()메서드를 오버라이딩한 것이다.   boy.runSomething()을 호출하면 그 앞에 proxy가 그 요청을 받아 진짜 boy 객체에게 요청을 전달하게 된다.      결론적으로 중간에서 runSomething()을 감시하거나 조작할 수 있게되었다.      Spring AOP 는 바로 이렇게 Proxy를 사용하게 되어 호출하는 쪽(boy.runSomething() 메소드 호출)에서나   호출당하는 쪽(boy 객체), 그 누구도 Proxy가 존재하는지 조차 모른다.    스프링 프레임워크만이 그 존재를 알게 되는 것이다.   즉 &lt;aop:aspectj-autoproxy /&gt;는 Spring Framework에게 AOP Proxy를 자동(auto)으로 사용하라고 알려주는 지시자이다.   스프링 AOP의 핵심은 다음과 같다.     스프링 AOP는 인터페이스 기반이다.   스프링 AOP는 프록시 기반이다.   스프링 AOP는 런타임 기반이다.   용어 정리     Aspect 관점, 측면, 양상   Advisior 조언자, 고문   Adivice 조언, 충고   JoinPoint 결합점   Pointcut 자르는점   1. Pointcut - Aspect 적용 위치 지정자  @Before(\"execution(* runSomething())\") 의 의미는 뭘까?  지금 선언하고 있는 메소드를 * runSomething()가 실행되기 전에 실행하라는 의미이다.   여기서 public void before는 횡단 관심사를 실행하는 메소드가 된다.   결국 Pointcut이라고 하는 것은 횡단 관심사를 적용할 타깃 메소드를 선택하는 지시자(메소드 선택 필터)인 것이다.   이를 줄여서 표현하면 “타깃 클래스의 타깃 메소드 지정자”라고 할 수 있다.   스프링 AOP만 보자면 Aspect를 메소드에만 적용할 수 있으니 타깃 메소드 지정자라는 말이 틀리지 않다.   다른 AOP 프레임워크에서는 메소드뿐만 아니라 속성 등에도 Aspect를 적용할 수 있기 때문에 그것까지 고려한다면   Aspect 적용 위치 지정자(지시자)가 맞는 표현이다.   Pointcut을 메소드 선정 알고리즘이라고도 한다.   타깃 메소드 지정자에는 정규식과 AspectJ 표현식 등을 사용할 수 있다.  [접근제한자패턴] 리턴타입패턴 [패키지&amp;클래스패턴.]메소드이름패턴(파라미터패턴) [throws 예외패턴]   2. JoinPoint - 연결 가능한 지점  Pointcut은 JoinPoint의 부분 집합이다.   스프링 AOP는 인터페이스를 기반으로 한다고 설명했는데 그럼 인터페이스는 뭘까?  인터페이스는 추상 메소드의 집합체이다. 그럼 삼단 논법에 의해 스프링 AOP는 메소드에만 적용 가능하다는 결론에 도달한다.   JoinPoint란 “Aspect 적용이 가능한 모든 지점을 말한다.”라고 결론 지을 수 있다.   스프링 AOP에서 JoinPoint란 스프링 프레임워크가 관리하는 빈의 모든 메소드에 해당한다.    이것이 광의의 JoinPoint다. 협의의 JoinPoint는 코드 상에서 확인할 수 있다.   romeo.runSomething() 메소드를 호출한 상태라면 JoinPoint는 romeo 객체의 runSomething() 메소드가 된다.   JoinPoint 파라미터를 이용하면 실행 시점에 실제 호출된 메소드가 무엇인지, 실제 호출된 메소드를 소유한 객체가 무엇인지,   또 호출된 메소드의 파라미터는 무엇인지 등의 정보를 확인할 수 있다.      광의의 JoinPoint란 Aspect 적용이 가능한 모든 지점   협의의 JoinPoint란 호출된 객체의 메소드   3. Advice - 조언? 언제, 무엇을  Advice는 Pointcut에 적용할 로직, 즉 메소드를 의미한다. 여기에 언제라는 개념까지 포함하고 있다.   Advice란 Pointcut에 언제, 무엇을 적용할지 정의한 메소드다.   4. Aspect - Advice의 집합체  AOP에서 Aspect는 여러 개의 Advice와 여러 개의 Pointcut의 결합체를 의미하는 용어다.   Aspect = Advice들 + Pointcut들   Advice - 언제, 무엇을  Pointcut - 어디에    Aspect - 언제, 어디에, 무엇을   5. Advisor - 어디서, 언제, 무엇을  Advisor은 다음과 같다.   Advisor = 한 개의 Adivice + 한 개의 Pointcut   Advisor는 스프링 AOP에서만 사용하는 용어이며 다른 AOP 프레임워크에서는 사용하지 않는다.   또 스프링 버전이 올라가면서 이제는 쓰지 말라고 권고하는 기능이기도 하다.   Aspect가 나왔기 때문에 하나의 Advice와 하나의 Pointcut만을 결합하는 Advisor를 사용할 필요가 없어졌기 때문이다.   POJO와 XML 기반 AOP  @ 어노테이션 기반 - MyAspect.java가 스프링 프레임워크에 종속   POJO &amp; XML 기반 - 스프링 프레임워크에 종속되지 않음   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-02-25/spring-AOP/",
        "teaser": null
      },{
        "title": "Garbage Collection(2)",
        "excerpt":"2. garbage collection 과정   1) mark, sweep  garbage collection 과정(알고리즘)은 mark, sweep, compact 작업으로 구성된다.      mark  더 이상 변수에 의해 참조되지 않은 객체가 garbage 이다.  garbage를 찾는 작업이 mark 이다.  mark 작업은, 모든 변수를 뒤져서, 그 변수가 참조하는 객체에 표시(mark)를 한다.          sweep   mark 표시가 없는 객체는, 변수에 의해 참조되지 않는 garbage 이다.  garbage 객체를 삭제하는 작업이 sweep 이다.  참조 되지 않는 객체 (mark 표시가 없는 객체)를 삭제하면, 빈 공간이 흩어져 있게 된다.       새 객체를 생성할 때, 적당한 빈 공간을 찾아야 하는 부담이 있다.     객체를 생성하기에는 너무 작은 빈 공간들이, 객체들 사이에 존재하게 되어, 메모리가 낭비된다.          compact  mark, sweep은 필수 작업이지만, compact는 필수 작업이 아니다.    sweep 작업 결과 삭제되지 않고 살아 남은 객체들은, 메모리에 듬성듬성 위치하게 된다.  이 객체들을 한쪽으로 몰아서, 객체들이 차지하는 영역과, 비어있는 영역을 구분하여,  메모리에 빈 영역을 확보하는 작업이 compact 이다.  새 객체를 생성할 때, 빈공간의 시작 부분에 생성하면 되므로 빠르다.     compact 작업에 시간이 걸리지만,  compact 작업 후에는, 객체 생성이 빠르고, 메모리 낭비가 없다.       2) young generation / old generation  예를 들어서, 생성된 java 객체가 시간이 지나면 쓰레기(garbage)가 되어 청소(garbage collection) 대상이 된다고 상상해 보자.    생성된 객체의 대부분은 짧은 시간 안에 쓰레기가 된다. -&gt; 이런 특징을 또 이용해서 영역을 나눈다.   효율적인 쓰레기 청소를 위해서,  메모리 영역을 young generation 영역과 old generation 영역으로 나눈다.   객체를 처음 생성할 때 young generation 영역에 생성한다.  생성된 대부분의 객체는 금방 쓰레기가 되기 때문에, young generation 영역은 자주 청소(garbage collection) 해야 한다.   young generation 영역에서 정해진 시간 이상 제거되지 않고 오래 살아남은 객체는,   old generation 영역으로 옮겨 놓는다.   old generation 영역으로 옮겨진 객체들은, 비교적 오래 생존할 확률이 높다.  따라서 old generation 영역은 자주 청소할 필요가 없고, 가끔 청소하면 된다.       3) minor garbage collection / major garbage collection  young generation 영역은 자주 청소해야 한다. 이것을 minor garbage collection 이라고 부른다.   아주 가끔 old generation 영역과 young generation 영역을 전부 대청소 해주어야 한다.  이것을 major garbage collection 혹은 full garbage collection 이라고 부른다.       4) card table  old ganeration 영역의 객체의 멤버 변수가, young generation 영역의 객체를 참조하는 경우는 드물다.  (오래된 객체에서 젊은 객체로의 참조는 아주 적게 존재하기 때문)   old ganeration 영역의 객체의 멤버 변수에 의해서 참조되는 객체는, garbage가 아니다.    따라서 young generation 영역을 청소할 때,   old generation generation 영역의 객체의 멤버 변수들도 다 뒤져서 mark 해야 하는데, 이 작업에 시간이 많이 걸린다.   young generation 영역은 자주 garbage collection 해야 하는데,   그때마다 old generation 영역의 멤버 변수들을 전부 뒤지는 것은 부담이다.   그래서 다음과 같은 방법을 사용한다.   old generation 영역의 멤버 변수가 young generation 영역의 객체를 참조하는 경우에,     이 정보를 card table에 기록한다.       이 card table 기록 방법의 장단점은 다음과 같다.           단점      old generation 영역의 멤버 변수에 young generation 영역의 객체를 대입할 때마다  card table에 그 정보를 기록해야 한다.            장점      young generation 영역을 청소하기 위해서, mark 할 때, old generation 영역의 멤버 변수를 전부 뒤질 필요 없고, card table 기록만 보면 된다.       단점의 손해 보다, 장점의 이익이 훨씬 크기 때문에, card table 기록을 사용하여 garbage collection 한다.       5) Heap 영역 구조                Young Generation, Old Generation     Heap 영역의 일부이다.    여기에는 new 연산자로 생성된 객체들과 배열들이 들어있다.            Permanent Generation (Metaspace)         Permanent Generation에는, 클래스와 메소드에 대한 메타 정보가 저장된다.             클래스 구조에 대한 정보       메소드들의 bytecode       static 멤버 변수         Java8 이후부터는 Permanent Generation 영역의 이름이 Metaspace로 바뀌었고,      이 공간의 메모리 관리 기능도 개선되었다.           Java8 부터는 Metaspace를 Heap 영역의 일부로 보지 않고, 독립된 영역으로 본다.            3. young generation 영역의 garbage collection 과정  1) eden 영역, survivor 영역  young generation 영역은 한 개의 eden 영역과 두 개의 survivor 영역으로 나뉜다.  두 survivor 영역을 각각 survivor0, survivor1 라고 하자.   처음 실행할 때, eden 영역과 두 survivor 영역이 전부 빈 상태이다.   생성되는 객체는 처음에 eden영역에 위치한다.            before garbage collection               garbage collection #1  eden 영역이 꽉 차면, young generation 영역 전체를 garbage collection 한다. (mark, sweep)  (young generation 영역 전체 = eden 영역 + 두 survivor 영역)  young generation 영역을 garbage collection 하는 것은 minor garbage collection 이라고 부른다.               garbage collection 하고 난 후,   eden 영역에서 살아남은 객체들을 전부, survivor0 영역으로 차곡 차곡 옮긴다. (compact)  survivor0 영역으로 이동된 객체의 살아남은 횟수를 1로 기록한다.       garbage collection 결과, eden 영역과 survivor1 영역은 빈 공간이 된다.          garbage collection #2    객체들이 생성되어 eden 영역이 또 꽉 차면, young generation 영역 전체를 garbage collection 한다.      eden 영역에서 살아남은 객체들을 전부, 비어있던 survivor1 영역으로 옮긴다.   이 객체들의 살아남은 횟수를 1로 기록한다.  그리고 survivor0 영역에서 살아남은 객체들도 survivor1 영역으로 옮긴다.  이 객체들의 살아남은 횟수를 2로 기록한다.                 garbage collection 결과, eden 영역과 survivor0 영역은 빈 공간이 된다.          garbage collection #3  객체들이 생성되어 eden 영역이 또 꽉 차면, young generation 영역 전체를 garbage collection 한다.                 eden 영역에서 살아남은 객체들을 전부, 비어있던 survivor0 영역으로 옮긴다.     이 객체들의 살아남은 횟수를 1로 기록한다.    그리고 survivor1 영역에서 살아남은 객체들도 survivor0 영역으로 옮긴다.     이 객체들의 살아남은 횟수에 1을 더해서 기록한다.              2) old generation 영역으로 승진     garbage collection #9    9번째 garbage collection을 수행하면, 살아남은 횟수가 9인 객체가 존재할 수 있다.  이 객체들은 old generation 영역으로 이동한다.                old generation 영역의 garbage collection  old generation 영역을 차지하는 객체의 양이 디폴트 기준을 넘으면,       old generation 영역과 young generation 영역 전체에서 garbage collection이 진행된다.    full GC, major GC       3) copying collector  young generation 영역의 garbage collection 작업을 담당하는 엔진을, copying collector 라고 부른다.    young generation 영역의 GC는 mark 작업과 copy 작업으로 구성된다.           mark 작업     참조되는 객체과, 참조되지 않는 객체를 식별하게 된다.        참조되지 않는 객체가 garbage 이다.                   copy 작업     두 survivor 영역 중 한 곳은 언제나 빈 공간이다.    mark 작업에서 식별된 참조되는 객체들을, 이 빈 공간에 차곡 차곡 복사한다.                4. Java Garbage Collector 종류  Java VM(Virtual Machine) 내부에서 garbage collection 작업을 수행하는 엔진을 garbage collector라고 부른다.       Java VM 내부에 garbage collector가 여러 개 구현되어 있고,   Java VM을 실행할 때 command line parameter로 garbage collector를 선택할 수 있다.       1) Serial Garbage Collector  CPU 코어 수가 1개일 때, serial GC가 사용된다.  minor GC, magor GC 둘 다 싱글 스레드로 실행된다.  compact 작업까지 수행한다.   CPU가 많은 서버에서도 serial GC를 사용하기도 하는데, 서버 한 대에 JVM 여러 개를 동시에 실행하는 경우다.  서버 운영체제에서 JVM 한 개는, 하나의 운영체제 프로세스(process)로 실행된다.  하나의 운영체제 프로세스 내부에 스레드가 여러 개 생성될 수 있다.  즉 서버 한 대에 여러 개의 JVM 프로세스가 실행되는 경우에, 각 JVM 내부에서는 serial GC를 사용하기도 한다.   JVM 프로세스 뿐만 아니라, 다른 프로세스들도 같이 실행되는 서버에서,  JVM 프로세스가 CPU 코어를 독점하는 것을 막기 위해, serial GC를 선택할 수 있다.          Serial GC의 장점  Serial GC 작업이 진행되는 동안, 다른 작업들이 멈춰야 하는 대신, GC 작업이 효율적으로 진행된다.  비유를 하자면, 대청소를 하는 동안, 모든 작업을 중단하고 오로지 청소만 한다면,  효율적인 청소를 할 수가 있다.  즉 다른 GC 작업에 비해서, Serial GC 작업에 투입되어야 하는 CPU의 작업 총량이 적다.          Serial GC를 선택하는 경우 요약            CPU 코어가 한 개 뿐이다.       CPU 코어가 여러 개이지만, JVM 프로세스 혼자 CPU 코어를 독점하면 안된다.       Serial GC 작업 동안의 멈춤(stop-the-word) 현상을 허용할 수 있다. (길면 1~2초 정도가 될 수 있다고 함)       heap의 크기가 100mega 이하 정도로 작다.                  command line option    -XX:+UseSerialGC      명령의 예:  java -XX:+UseSerialGC -jar demo.jar       2) Parallel Garbage Collector  young generation영역의 garbage collection을 멀티 스레드로 실행한다.  CPU 코어가 여러 개인 경우에, parallel GC가 디폴트로 선택되고, 코어 수 만큼의 스레드로 GC를 수행한다.   parallel GC 는 parallel GC 와 parallel Old GC 로 나뉜다.   young generation 영역의 GC를 멀티 스레드로 실행하는 것은 parallelGC 와 parallelOldGC 에서 공통이다.  young generation 영역의 GC = mark + copy   mark + copy 작업은 멀티 스레드로 실행될 수 있다.         Parallel GC old generation 영역의 GC = 싱글 스레드           old generation 영역의 GC = mark + sweep + compact           sweep + compact 작업은 멀티 스레드로 실행될 수 없고 싱글 스레드로 수행되어야 한다.          Parallel Old GC     old generation 영역의 GC = 멀티 스레드    old generation 영역의 GC = mark + summary + compact    summary + compact 작업은 멀티 스레드로 실행될 수 있다.     Parallel Old GC를 Parallel Compating GC라고 부르기도 한다.          Parallel GC를 선택하는 경우 요약            CPU 코어들을 전부 활용하여 JVM 프로세스의 성능을 최대로 높이자       JVM 프로세스가 CPU 코어들을 전부 독점해도 된다.       Parallel GC 동안의 멈춤(stop-the-world) 현상을 허용할 수 있다. (Serial GC 경우보다는 짧다)       CPU 코어 수가 많고, 메모리 용량도 큰 경우에, parallel GC가 디폴트로 선택된다.                  command line option  -XX:+UseParallelGC               &lt;- Parallel GC 선택   -XX:+UseParallelOldGC            &lt;- Parallel Old GC 선택   -XX:ParallelGCThreads=스레드수     &lt;- Parallel GC가 사용할 스레드 수를 제한하기 위한 선택 옵션                                      이 옵션을 지정하지 않으면 CPU 코어 수 만큼의 스레드를 사용       3) Concurrent Mark Sweep Collector  Concurrent Mark Sweep Collector에서 앞글자만 따서 CMS collector라고 부른다.       concurrent low pause collector 라고 부르기도 한다.      GC 작업 동안의 정지(stop-the-world) 기간을 최대로 줄이기 위해 선택한다.      GC 작업 동안 애플리케이션 스레드도 같이 실행될 수 있도록 고안된 GC 이기 때문에, 정지 기간이 매우 짧다.   CMS GC는 총 6단계의 작업으로 구성되는데, 이 중에서 2 단계만 애플리케이션이 정지되고,       4 단계에서는 애플리케이션 스레드와 GC 스레드가 동시에 실행된다.   GC 작업이 애플리케이션 스레드와 동시에 진행될 수 있어야 하기 때문에,      GC 작업이 약간 비효율적으로 진행된다.      이 비효율 때문에, 정해진 시간 동안 처리한 작업 양을 비교하면, CMS GC가 parallel GC 보다 뒤쳐진다.      그리고 comat 작업을 포함하지 않아서, 메모리도 낭비된다.   정해진 시간 동안 처리한 작업 양 = throughput             full stop-the-world collection  old generation 영역이 가득 찬 경우에는, 애플리케이션 스레드들이 모두 멈춘 상태에서(stop-the-world),   전체 메모리 영역에 대한 garbage collection이 진행된다. 이 작업의 정지 기간이 꽤 길어진다.  이때에는 compact 작업도 포함된다.          장점   정지(stop-the-world) 기간이 매우 짧다.          단점            compat 작업을 하지 않기 때문에, 메모리가 낭비된다.       정해진 시간 동안 처리한 작업 양(throughput)이 parallel GC 보다 못하다.       가끔 full stop-the-world collection 작업이 필요해 질 수 있고, 이때는 정지 기간이 길다.                  CMS GC를 선택하는 경우 요약            GC 동안의 멈춤(stop-the-world) 현상을 허용할 수 없고, 애플리케이션이 언제나 즉시 반응해야 한다.       JVM 프로세스가 CPU 코어들을 전부 독점해도 된다.       heap의 크기가 4GB 이하이다. (heap의 크기가 4GB 이상이면, G1 GC를 사용해야 한다)                  command line option    -XX:+UseConcMarkSweepGC   -XX:ParallelCMSThreads=스레드 수       4) G1 Garbage Collector  G1 garbage collector는 Java7 부터 제공된다.  장기적으로 CMS collection를 대체하려고 개발된 GC이다.  4GB 이상 크기의 heap에 대한 효율적인 GC를 위해서 개발되었다.   full stop-the-world collection 작업 필요한 상황의 발생 확률이 CMS GC 보다 낮다.  CMS GC와는 달리 compat 작업을 포함한다.      command line opotion    -XX:+UseG1GC       5) JVM 프로세스 수     전략#1: JVM 프로세스 한 개  서버 한 대에 JVM 프로세스 한 개만 실행.  Java로 구현된 서비스들을 모두 이 프로세스에서 실행.  서비스를 동시에 여러 개 실행하려면, 많은 메모리가 필요할 테니, JVM의 heap 크기를 4GB 이상으로 설정.            장점                    서비스들 사이에 직접 메소드 호출할 수 있고, 파라미터나 리턴 값으로 데이터를 전달할 수 있다.                       단점                    4GB 보다 큰 heap을 GC 할 때, stop-the-world 시간이 10초 정도로 길어질 수 있다.  이 단점은 G1 GC를 채택하여 해결할 수 있다.           어느 한 서비스에 버그가 있어서 에러가 발생하면, 같은 JVM 에서 실행되는 다른 서비스들에게      영향을 줄 수 있다.                                  전략#2: JVM 프로세스 여러 개    서버 한대에 JVM 프로세스 여러 개를 실행.    Java로 구현된 서비스들 각각을 별개의 JVM 프로세스에서 실행.    각각의 JVM 프로세스는 서비스를 하나만 실행할 테니, JVM의 heap 크기를 적당한 정도로 제한.            장점                    각각의 JVM은 상대적으로 작은 크기의 heap을 GC 하기 때문에, stop-the-wolrd 시간이 짧다.           어느 한 JVM 프로세스에서 에러가 발생해도, 다른 JVM 프로세스에 영향을 줄 수 없다.           서비스 단위로 배포하고 관리하기 편하다. Docker를 이용하면, 더욱 편하다.                       단점                    서비스들 사이에 직접 메소드 호출은 불가능하고, 명령이나 데이터를 주고 받기 위해 네트웍 통신이 필요하다.                               6) Java VM command line paramter  Java VM(Virtual Machine)을 실행하기 위한 java.exe 명령의 command line parameter 중에서  메모리 설정과 관련된 것들은 다음과 같다.           -Xms숫자      heap 영역의 초기 크기를 설정한다.    예: -Xms6m       = 6mega로 설정                 -Xmx숫자  heap 영역의 최대 크기를 설정한다.    예: -Xmx80m       = 80mega로 설정                 -Xmn숫자  young generation 영역의 크기를 설정한다.                    -XX:+UseStringDeduplicationJVM   Java8 update20 JVM의 G1 Collector에는 String deduplication 기능이 추가되었다.    GC 과정에서, 내용이 동일한 String 객체들을 찾아서, 중복된 부분을 제거해 주는 기능이다.          ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-03-23/GC(2)/",
        "teaser": null
      },{
        "title": "Garbage Collection(1)",
        "excerpt":"1. 개념  1) garbage collection  Java 언어에서 new 연산자를 사용하여 생성된 객체가, 자동으로 제거되는 것을 garbage collection 이라 한다.  어떤 객체를 참조하는 변수가 하나라도 있다면, 그 객체는 사용되고 있는 것이고,  반대로 어떤 객체를 참조하는 변수가 하나도 없다면, 그 객체는 사용될 수 없으니 garbage collection 된다.   garbage collection은 JVM(Java virtual machine)에 의해서 자동으로 실행되는데,      (방문해보면서 mark 해놨는데 가리키고 있는게 아무것도 없는데 존재하면 그게 garbage 이다.)    이걸 확인하려면 메모리를 다 둘러봐야해서 시간이 꽤 걸리는 작업이기 때문에, 가끔 실행된다.           stop-the-world     garbage collection이 실행될 때, 그 JVM(Java virtual machine)에서 애플리케이션은 모두 정지되고,      오로지 garbage collection 작업만 실행된다.        즉 application thread는 모두 정지되고, garbage collection thread만 실행된다.         성능이 매우 중요한 애플리케이션의 경우에, garbage collection 동안 애플리케이션이 정지되는 것이 문제가 될 수 있다.            System.gc()      garbage collection 작업을 즉시 실행하도록 명령하는 메소드이다. 이 메소드를 호출하지 말자. virtual machine 스스로 garbage collection 할 때를 결정하도록 놔두자.       System은 클래스이다. gc()는 System 클래스의 static 메소드이다.   Q. 그렇다면 garbage collection이 자동으로 잘 처리 되도록 하려면 어떻게 해야할까?    A. 더 이상 사용하지 않는 객체를 참조하고 있는 변수에 null을 대입하자.   변수에 의해 참조되지 않는 객체는 자동으로 garbage collection이 되기 때문이다.       2) weak generational hypothesis  많은 경우에 Java 객체는 다음과 같은 특징을 갖는다.     대부분의 객체는 짧은 시간 안에 garbage가 된다. -&gt; 지역변수   오래된 객체의 멤버변수가 젊은 객체를 참조하는 경우는 아주 드물다. -&gt; 영역이 다르다.   대부분의 객체는 짧은 시간 안에 garbage가 된다.    메소드 내에서 잠깐 사용되고 끝나는 객체가 많다.  이런 객체는 지역 변수에 대입하여 사용한다.  메소드가 리턴될 때, 지역 변수가 없어지면, 그 지역 변수에 의해서만 참조되던 객체는 garbage가 되고, garbage collection 대상이 된다.   오래된 객체    지역 변수가 아니라, 멤버 변수에 의해 참조되는 객체는 일찍 제거되지 않고 꽤 오래 살아남는다.   static 멤버 변수에 의해 참조되는 객체는 더욱 오래 살아남는다.   즉 지역 변수가 참조하는 객체들은 금방 garbage collection 되지만,   멤버 변수가 참조하는 객체들은 꽤 오래 살아남는다.   오래된 객체의 멤버변수가 젊은 객체를 참조하는 경우는 아주 드물다.              오래된 객체의 멤버 변수가 참조하는 객체도 오래된 객체일 확률이 높고, 일찍 제거될 객체일 확률은 낮다.  일찍 제거될 객체는 대부분 지역 변수에 대입되어 사용되기 때문이다.   위 특징들을 활용하여 Java virtual machine의 garbage collection 기능이 구현되었다.    garbage collection의 성능이 좋아진 원인은 이러한 특징을 잘 잡았기 때문이다.       3) Java 컴파일     HotSpot       Oracle이 만든 Java virtual machine의 이름이 Java HotSpot Performance Engine 이다.  줄여서, HotSpot virtual machine 이라고 부르거나, 그냥 HotSpot 이라고 부른다.  즉 HotSpot은 Oracle이 만든 Java virtual machine의 제품명이다.          C/C++ 컴파일  C/C++ 컴파일러는 C/C++ 소스 코드를 기계어 코드로 변환한다.           C/C++ 소스 파일을 컴파일하여 생성된 *.exe 실행 파일에는 기계어 코드가 들어있다.           *.exe 파일은 직접 CPU에서 실행된다.           실행 파일의 구조는 운영체제에 따라 다르다.          표준 Java 컴파일  표준 Java 컴파일러는 Java 소스 코드를 bytecode로 컴파일한다.           *.java 소스 파일을 컴파일하여 생성된 *.class 파일에는 bytecode가 들어있다.           Java virtual machine이 *.class 파일을 읽어서 bytecode를 실행한다.                 표준 Java 컴파일러 실행 파일은 javac.exe 이다.             표준 Java 가상 기계 실행 파일은 java.exe 이다.          bytecode로 컴파일하는 이유         기계어 코드로 컴파일 하지 않고 bytecode로 컴파일하는 방식의 장단점은 다음과 같다.                  단점: 약간 느리다.            CPU가 기계어 코드를 직접 읽어서 실행하는 방식이 가장 빠르다.                            장점: CPU에 독립적이고, 운영체제에 독립적이다.        실행파일에 들어있는 기계어 코드는 CPU마다 다르다.        실행파일 구조는 운영체제마다 다르다.        그래서 Windows 실행파일을 맥에서 실행할 수 없다.          Java 소스파일을 컴파일하여 생성된 *.class 파일의 구조는 운영체제에 무관하다.           그리고 bytecode도 CPU에 무관하다.           따라서 Java로 개발한 앱은, 특정 운영체제나 CPU에 무관하게 배포될 수 있고,           Java virtual machine만 있으면 실행될 수 있다.                  JIT 컴파일 (Just In Time compilation)         Java는 JIT 컴파일 방식을 사용한다.         JIT 컴파일이란, bytecode를 실행하기 직전에 기계어 코드로 컴파일 하는 방식을 말한다. Java virtual machine은 실행하기 직전에, bytecode를 기계어 코드로 변환(컴파일)해서 실행한다.             bytecode를 해석해서 실행하는 것보다(인터프리터 방식), 기계어 코드로 변환해서 실행하는 쪽이 훨씬 더 빠르기 때문이다.             Java virtual machine 내부에는 JIT 컴파일러가 내장되어 있다.             이 JIT 컴파일러는 bytecode를 기계어 코드로 변환한다.          JVM JIT 컴파일 방식의 장단점  JVM(Java virtual machine)            단점: 변환된 기계어 코드를 따로 저장하지는 않기 때문에, 실행할 때마다 매번 다시 JIT 컴파일 해야 한다.       장점: dynamic optimization 가능                  dynamic optimization      컴파일러가 소스코드를 컴파일할 때, 소스코드와 동일한 순서로 기계어 코드를 생성하지 않고,      좀 더 빠르고 효율적으로 실행될 수 있도록, 실행 순서를 재배치하고 조정하여, 기계어 코드를 생성하는 것을,       컴파일러 최적화(compiler optimization)라고 한다.         소스코드를 컴파일할 때가 아니고, 실행하는 시점에, 실행 순서를 재배치하고 조정하여 기계어 코드를 생성하는 것을, 동적 최적화(dynamic optimization)라고 한다.    JVM의 JIT 컴파일러는 dynamic optimization을 수행한다.       4) process와 virtual memory  애플리케이션이 운영체제 메모리로 로드(load)되어 실행될 때, 이것을 프로세스(process)라고 부른다.   즉 운영체제 메모리로 로드되어 실행되는 애플리케이션을 프로세스라고 부른다.   운영체제는 프로세스에게 자원을 제공한다. 제공되는 자원은, 메모리, 파일, 소켓(socket), 세마포어(semaphore), 파이프(pipe) 등이다.    운영체제에 의해서, 각각의 프로세스는 서로 격리된다.    어떤 프로세스의 메모리나 자원을, 다른 프로세스가 건드릴 수 없다.          virtual memory          프로세스가 사용하는 메모리 주소는, 실제 메모리의 물리적 주소가 아니고, 가상의 주소이다. (virtual memory 주소)   이 가상의 주소는, 운영체제와 CPU에 의해서, DRAM 부품의 물리적 주소로 변환되어 실행된다.   어느 프로세스가 다른 프로세스나 운영체제 커널(kernel)의 물리적 메모리 주소를 사용하는 것은 불가능하다.  운영체제와 CPU가 그런 주소 변환을 허용하지 않기 때문이다.    즉, 어느 프로세스는 자신에게 주어진 virtual memory 주소만 사용할 수 있고, 자신에게 주어진 메모리에만 접근할 수 있다.          Intel CPU meltdown 결함         2017년에 문제가 되었던 인텔 CPU의 meltdown결함은, virtual memory 주소를 물리 주소로 변환하는 인텔 CPU의 기능에 헛점이 있다는 것이다.   이 결함을 이용하면, 운영체제 커널의 메모리 주소나, 다른 프로세스의 메모리 주소를 알아내고, 그 메모리에 접근하는 것이 가능하게 된다.  그래서, 결함이 있는 Intel CPU의 주소 변환 기능을 사용하지 않고, CPU가 담당했던 주소 변환까지 운영체제가 수행하도록 수정하는 것이, meltdown 결함 패치(patch)의 내용이다.     CPU가 하던 기능을 운영체제 SW가 해야 하므로, 이 패치를 적용하면, 컴퓨터가 조금 느려진다.       5) stack, heap, data, text segment  프로세스에게 주어진 메모리 공간은 세그먼트들로 나눠 사용된다.      text segment (code segment)             기계어 코드가 위치한 영역을 text segment라 한다.            소스코드에 포함된 문자열 상수가 숫자 상수들도 여기에 위치하는 경우도 있는데,             특정 컴파일러나 운영체제에서는 다를 수 있다.          heap segment            동적으로 할당되고 반납되는 메모리가 위치한 영역이다.            C언어의 malloc/free 함수를 사용하여 할당된 메모리는 heap에 위치한다.            Java 언어의 new 연산자를 사용하여 생성한 객체/배열은 heap에 위치한다.            Java에서 참조형 값들은 전부 heap에 위치한다.            heap 영역에서 불필요한 객체를 찾아 제거하는 작업이 garbage collection 이다.            Java의 garbage collection은 JVM에 의해서 자동으로 실행된다.          data segment            프로세스가 시작할 때부터 종료될 때까지 존재하는 변수들이 위치한 영역이다.            전역변수, static 지역 변수, static 멤버 변수가 여기에 위치한다. (C/C++ 언어)                Java 언어에는 전역변수, static 지역 변수가 없다.            Java 언어는 data segment라고 부르지 않는다.            Java 언어의 static 멤버 변수는 metaplace 영역에 위치한다.          stack segment                   stack segment는 함수나 메소드 호출 과정에서 사용되는 메모리 영역이다.            함수가 호출될 때 생성되는 지역 변수, 파라미터 변수가 stack segment에 생성된다.            함수의 리턴 값이나, 함수가 리턴할 때 되돌아갈 기계에 코드의 주소도 여기에 저장된다.          stack overflow 공격    함수가 리턴될 때 되돌아갈 기계에 코드의 주소가 stack segment에 저장되고,  지역 변수도 stack segment에 저장된다는 점을 노린 해킹 공격이다.    공격할 SW의 기계어 코드를 분석하여, 네트워크로 전송된 데이터가 어떤 함수의 지역 변수 배열에 저장되는 경우를 찾는다.   그 지역 변수 배열의 크기보다 더 큰 데이터를 전송해서,   데이터가 저장될 때, 배열의 뒤까지 넘치도록(overflow) 한다.   이렇게 넘쳐서 저장된 데이터가 함수가 리턴 주소가 저장된 곳까지 덮어쓰도록 한다.   함수가 리턴할 때, overflow 되어 변경된 주소로 리턴하게 된다.   즉 해커가 원하는 곳으로 리턴하게 되어 해커가 심어 놓은 기계어 코드가 실행하게 된다.          stack overflow 공격 막기   배열에 데이터를 저장하거나 복사할 때, 배열의 범위를 벗어나서 넘치게(overflow) 저장하지 말아야 한다.    Java 언어의 경우에는, VM이 이것을 검사하기 때문에, overflow가 가능하지 않다.    따라서 Java는 stack overflow 공격에 안전하다.   배열의 크기를 벗어난 곳에 접근하려 하는 경우에, Java에서는 IndexOutOfBoundsException이 발생한다.      C/C++ 언어에서는 overflow가 가능하므로, 코딩할 때 주의해야 한다.    그리고 overflow를 검사하지 않는 표준 함수의 사용을 자제하고 (예: strcpy, strcat, memcpy, sprinf)   overflow를 검사하는 표준 함수를 사용해야 한다. (예: strncpy, strncat, memcpy, snprintf)       6) process와 thread  process 내부에 thread가 생성된다.    process가 시작될 때, main thread가 자동으로 생성되고,    다른 스레드는 스레드 생성 명령을 실행하여 생성해야 한다.      스레드는 stack segment를 따로 소유한다.    스레드를 한 개 생성할 때마다, stack segment도 한 개 생성해서, thread에게 할당해야 한다.    heap segment, data, text segment는 thread들 사이에 공유된다.      ThreadLocal       Java 표준 라이브러리에 ThreadLocal 클래스가 있다.      thread들 사이에 공유되지 않는 객체를 생성하기 위해 ThreadLocal 클래스를 사용한다.       7) HotSpot java virtual machine 구조  HotSpot JVM의 주요 구성요소는 다음과 같다.     Class Loader      : 클래스 파일(*.class)을 메모리에 불러오는 역할을 담당   Runtime Data Area : 데이터를 보관하는 메모리 영역   Execution Engine  : 실행 엔진       runtime data areas 내부에서      method area     이영역에서 위치한 항목들은 다음과 같다.     method의 bytecode   static 멤버 변수   constant 값   method area 이름은 자주 사용되는 이름이 아니다.   이 영역의 대표적인 이름은, permanenet generation 영역이다. (Java7까지)  Java8 부터 이 영역의 이름이 metaplace로 바뀌었다. (세부 구조도 변경되었다.)          heap    Java 객체와 배열이 생성되는 영역이다. (heap segment)       garbage collection은, 더 이상 사용되지 않는 객체를 메모리에서 삭제하는 작업이다.       Java 객체들은 heap 영역에 위치한다. 즉 garbage collection 작업은 heap 영역을 청소하는 작업이다.          Java stack          지역 변수와 파라미터 변수가 생성되는 영역이다.        Java 메소드가 호출될 때, 그 메소드의 지역 변수와 파라미터 변수가 생성될 공간이 할당되어야 한다.        이 공간은, 메소드가 리턴될 때 반납된다. stack segment에 이 공간이 할당된다.        Java 메소드가 호출될 때 사용되는 stack segment를 Java stack 이라고 한다.             각 thread 마다 stack segment를 따로 소유한다.         즉 새 thread가 생성되면, 그 thread가 사용할 stack segment를 할당해야 한다.          Program Counter Registers        java thread가 현재 실행하고 있는 명령(bytecode)의 주소가 program counter register에 저장된다.        CPU 코어(core)의 address register와 유사한 역할을 한다.        각 java thread 마다 program counter register를 따로 소유해야 한다.          Native stack        Java 표준 라이브러리의 클래스의 메소드들 중에서, Java가 아니고 C로 구현된 메소드도 있다.        C로 구현된 메소드를 native method라고 부른다.        C로 구현된 메소드가 호출될 때 사용될 stack segment를 Native stack 이라고 한다.       8) Java thread 와 메모리 영역  각 Java thread 마다 따로 소유하는 메모리 영역     Program Counter Register   Java Stack (지역 변수, 파라미터 변수)   Native Stack      여러 Java thread들이 공유하는 메모리 영역     Heap (객체, 배열)   Method Area (상수, static 멤버 변수)      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-03-23/GC/",
        "teaser": null
      },{
        "title": "Naming & Security",
        "excerpt":"1. Springboot jpa &amp; Hibernate Naming Strategy (네이밍 전략)   local에서 jpa.hibernate.ddl-auto를 create로 설정해놨는데      자동 생성된 테이블의 컬럼명을 보니 snake_case로 생성되어 있었다..      application.yml     spring: jpa:   hibernate:     naming:       physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl          위 설정을 해주면 Entity 클래스의 변수명과 동일하게 생성된다.       2. Spring Security   회원가입 시 이메일 인증으로 사용자 인증을 하고 인증 완료 여부를  Role로 구분하려고 spring 표준 권한을 찾아봤다.   스프링에서 제공하는 기본 권한(Authority)     ROLE_ANONYMOUS : 모든 사용자   IS_AUTHENTICATED_ANONYMOUSLY : 익명 사용자   IS_AUTHENTICATED_FULLY : 인증된 사용자   IS_AUTHENTICATED_REMEMBERED : REMEMBERED 사용자   ROLE_RESTRICTED : 제한된 사용자   ROLE_USER : 일반 사용자   ROLE_ADMIN : 관리자   이번 프로젝트에서 미인증 사용자는 ROLE_RESTRICTED로     인증 완료 사용자는 IS_AUTHENTICATED_FULLY로 설정하기로 했다.   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-03/0403/",
        "teaser": null
      },{
        "title": "spring security & validation",
        "excerpt":"1. spring security 로그인 로직  (1) 사용자가 요청한다. (page)  (2) 사용자가 요청한 서비스가 로그인이 필요하다.   (3) spring security는 spring security context에서       Authentication 객채를 찾는다.  (4) 객체가 존재하지 않으면 login 페이지로 리다이렉트한다.   (5) 사용자가 로그인 정보를 입력하고 로그인하면      사용자가 입력한 ID(email)에 해당하는 UserDetails를 읽어와서     사용자가 입력한 정보들과 비교한다.   (6)로그인에 성공하면 Authentication 객체를   spring security context에 담는다.   2. validation  spring form validation 공부 자료  ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-04/0404/",
        "teaser": null
      },{
        "title": "Lombok, Interface, Factory Method",
        "excerpt":"1. Lombok   @Builder @Getter @NoArgsConstructor(access = AccessLevel.PROTECTED) @AllArgsConstructor(access = AccessLevel.PROTECTED) public class UserSigninDto {          . . .  }  위 코드는 프로젝트에서 사용할 DTO 클래스의 일부입니다.   @Getter  getter은 userService에서 유저 정보를 조회할 떄 사용된다.   @Builder 는 다음과 같은 장점이 있습니다.     setter는 그 의도가 분명하지 않고 객체를 언제든지 변경할 수 있는 상태가 되어서 객체의 안전성이 보장받기 힘듭니다.      setter 메소드가 없으므로 변경 불가능 객체를 만들 수 있다.   한 번에 객체를 생성하므로 객체 일관성이 깨지지 않는다.   build() 함수가 잘못된 값이 입력되었는지 검증하게 할 수도 있다.   @NoArgsConstructor(access = AccessLevel.PROTECTED)  validation 검사를 위해 필요한 생성자 입니다.   @AllArgsConstructor(access = AccessLevel.PROTECTED)  JPA에서는 프록시를 생성을 위해서 기본 생성자를 반드시 하나를 생성해야합니다.   2. Interface 추상화  인터페이스 사용 장점          개발 시간을 단축 시킬 수 있습니다.        이러한 특징을 가진 인터페이스를 사용하면 다른 개발자들이 각각의 부분을 완성할 때 까지 기다리지 않고     서로 규약만 정해두어 각자의 부분만 따로 나눠서 작성된 코드를 컴파일 할 수 있습니다.            클래스간 결합도를 낮출 수 있습니다.  코드의 종속성을 줄이고 유지보수성을 높이도록 해줍니다.            표준화가 가능합니다.  클래스의 기본틀을 제공하여 정형화된 개발이 가능합니다.       3. 팩토리 메소드  public User toEntityWithPasswordEncoder(PasswordEncoder passwordEncoder) {         return User.builder()                 .email(email)                 .password(passwordEncoder.encode(password1))                 .name(name)                 .phone(phone)                 .profile(profile)                 .userType(Role.ROLE_RESTRICTED)                 .enabled(false)                 .build();     }  위 코드는 프로젝트에서 사용할 DTO 클래스의 일부입니다.   toEntityWithPasswordEncoder 메소드는   UserSignup 모델 객체로부터 User Entity 객체를 생성해서 리턴합니다.    비밀번호 암호화와 userType, enabled 등 정해져 있는 값을 넣어 생성할 수 있습니다.   장점          이름을 가질 수 있다.      생성자에 넘기는 매개변수와 생성자 자체만으로는 반환될 객체의 특성을 제대로 설명하지 못한다.     하지만 팩토리 메소드 이름을 잘 지으면 반환될 객체의 특성을 쉽게 묘사할 수 있다.            입력 매개변수에 따라 매번 다른 클래스의 객체를 반환할 수 있다.            간결한 코드 작성이 가능하다.   반복되는 코드를 줄일 수 있다.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-05/0405/",
        "teaser": null
      },{
        "title": "JSP, JPA, form data",
        "excerpt":"1. JSP form 데이터 전달  회원가입 기능을 구현했는데 jsp form에 입력한 값이 액션 메서드에 전달되지 않았다.         form 확장 태그에 modelAttribute, action 등 필요한 속성을 전부 설정했는데,,   spring-mvc-form-tutorial        여기서 천천히 읽어봤는데 set 메서드명이 path 설정과 같아야 한다는 것을 알았다.   @Builder만 있으면 될 거라고 생각했는데 jsp에서 form 데이터 전달을 하기 위해서는 setter이 필요했다.   2. JPA Query Language  @Modifying(clearAutomatically = true) @Query(\"UPDATE User u          set u.enabled = true, u.userType='IS_AUTHENTICATED_FULLY'          where u.email = :email\") public int updateUserType(String email);   JPA에서 UPDATE / DELETE 명령인 경우에     @Modifying(clearAutomatically = true) 어노테이션을 반드시 붙여야 한다.   또한, @Modifying 어노테이션이 붙은 메소드를 호출하는 코드를 포함하는 메소드에        @Transactional 어노테이션을 반드시 붙여야 한다.   하지만 이번 프로젝트에서는 사용자 정보를 전부 다시 조회해서 다시 저장하는      JPA Repository 기본 메서드를 사용하는 방식으로 구현했다.   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-11/0411/",
        "teaser": null
      },{
        "title": "생성자 주입 & 필드 주입",
        "excerpt":"1. 생성자 주입 (Constructor Injection) &amp; 필드 주입 (Field Injection) 이란?      Field Injection (필드 주입)   @Autowired   private  UserService  userService;        Constructor Injection (생성자 주입)   private JavaMailSender javaMailSender;   private RedisTemplate&lt;String, String&gt; redisTemplate;     @Autowired   public EmailServiceImpl(JavaMailSender javaMailSender, RedisTemplate&lt;String, String&gt; redisTemplate){     this.javaMailSender = javaMailSender;     this.redisTemplate = redisTemplate; }   2. 왜 Constructor Injection을 추천하는가?   의존성 주입할 때 생성자 주입을 추천한다.   깔끔한 코드는 필드 주입인 것 같은데 왜 생성자 주입을 추천할까?           Single Responsibility Principle Violation (단일 책임의 원칙 위반)               새로운 의존성을 추가하는 것은 매우 쉽다.                          여기서 Constructor Injection을 사용하면 다른 Injection 타입에 비해 위기감 같은 걸 느끼게 해준다.                  Constructor의 파라미터가 많아짐과 동시에 하나의 클래스가 많은 책임을 떠안는다는 걸 알게된다.                이러한 것들이 리팩토링을 해야한다는 신호가 될 수 있다.            Dependency Hiding                DI(Dependency Injection) 컨테이너를 사용한다는 것은 클래스가 자신의 의존성만 책임진다는게 아니다.           제공된 의존성 또한 책임진다. 그래서 클래스가 어떤 의존성을 책임지지 않을 때,           메서드나 생성자를 통해(Setter나 Contructor) 확실히 커뮤니케이션이 되어야한다.           하지만 Field Injection은 숨은 의존성만 제공해준다.            DI 컨테이너의 결합성과 테스트 용이성          DI 프레임워크의 핵심 아이디어는 관리되는 클래스가 DI 컨테이너에 의존성이 없어야 한다.              즉, 필요한 의존성을 전달하면 독립적으로 인스턴스화 할 수 있는 단순 POJO이어야 한다.                          DI 컨테이너 없이도 유닛테스트에서 인스턴스화 시킬 수 있고, 각각 나누어서 테스트도 할 수 있다.                    컨테이너의 결합성이 없다면 관리하거나 관리하지 않는 클래스를 사용할 수 있고,                       다른 DI 컨테이너로 전환할 수 있다.               하지만, Field Injection을 사용하면 필요한 의존성을 가진 클래스를 곧바로 인스턴스화 시킬 수 없다.            불변성(Immutability)                 Constructor Injection과 다르게 Field Injection은 final을 선언할 수 없다.       그래서 객체가 변할 수 있다.            순환 의존성      Constructor Injection에서 순환 의존성을 가질 경우              BeanCurrentlyCreationExeption을 발생시킴으로써 순환 의존성을 알 수 있다.       참고 : https://www.vojtechruzicka.com/field-dependency-injection-considered-harmful/  ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-13/0413/",
        "teaser": null
      },{
        "title": "JPA DB Update 하려면?",
        "excerpt":"JPA userType 변경하려면?      처음 구현했을 때   userRepository.deleteByEmail(user.getEmail()); userRepository.flush(); userRepository.save(user);   save() 메소드에서 unique로 설정한 email 때문에 오류가 발생했기 때문에    처음에 userType 변경을 위 코드로 구현했다.   하지만 위 코드는 delete와 insert 쿼리가 필요하다.   jpa update를 하고 싶으면 그냥 Entity 클래스의 setter을 사용해 원하는 값을 넣어주면 된다.   DB 변경하는 부분에서 @Transactional 어노테이션이 필요하다는 것도 잊지말자..      수정 후   @Override @Transactional   public void updateUserType(String email){     User user = userRepository.findOneByEmail(email);     user.setUserType(IS_AUTHENTICATED_FULLY);     user.setEnabled(true); }   이렇게 엔티티의 변경사항을 데이터베이스에 자동으로 반영하는 기능을 변경 감지(dirty checking)라 한다.   JPA는 엔티티를 영속성 컨텍스트에 보관할 때, 최초 상태를 복사해서 저장해두는데 이것을 스냅샷이라고 한다.  그리고 플러시 시점에 스냅샷과 엔터티를 비교해 변경된 엔티티를 찾는다.   변경 감지는 영속성 컨텍스트가 관리하는 영속 상태의 엔티티에만 적용된다.   JPA이ㅡ 기본 전략은 모든 필드를 업데이트 하는 것인데     데이터베이스에 보내는 데이터 전송량이 증가하는 단점이 있지만, 다음과 같은 장점이 있기 때문에   모든 필드를 업데이트한다.           모든 필드를 사용하면 수정 쿼리가 항상 같다.    따라서 애플리케이션 로딩 시점에 수정 쿼리를 미리 생성해두고 사용할 수 있다.            데이터베이스에 동일한 쿼리를 보내면 데이터베이스는 이전에 한 번 파싱된 쿼리를 재사용할 수 있다.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-14/0414/",
        "teaser": null
      },{
        "title": "Spring Security : Signin",
        "excerpt":"1. Spring Security의 구조            1.1 유저가 로그인을 시도한다.        1.2 AuthenticationFilter 에서 UserDetails로 User DB에 접근한다.     1.3 DB에 있는 user라면 UserDetails에서 꺼내 session을 생성한다.     1.4 spring security의 인메모리 세션저장소인 SecurityContextHolder에 저장한다.      1.5 user에게 session ID와 함께 응답한다.       1.6 이후 사용자의 요청에서는 요청 쿠키에서 JSESSIONID를 검증해 유효하면 Authentication을 준다.   2. Spring Security - 인증 절차 인터페이스  2-1. UserDetails  각기 다른 어플리케이션의 User에 해당하는 Model에 UserDetails를 implements하여   spring security가 이애할 수 있는 형태의 User로 만들어줘야 한다.   로그인 로직에서 사용자가 입력한 정보와 DB에 저장된 사용자의 정보를 비교해야 하는데   UserDetails 인터페이스는 사용자의 정보를 담아두는 VO 역할을 한다고 할 수 있다.   UserDetails 인터페이스를 구현하려면 오러바이드해야 하는 메소드들이 있다.   사용자 정보에 관한 다른 정보를 추가해도 된다.   (다른 멤버변수들은 getter, setter를 만들어서 사용하면 된다.)           Collection&lt;? extends GrantedAuthority&gt; getAuthorities()       계정이 갖고있는 권한 목록을 리턴한다.            String getPassword()  계정의 비밀번호를 리턴한다.            String getUsername()   계정의 이름을 리턴한다.            boolean isAccountNonExpired()    계정이 만료되지 않았는지 리턴한다. (true : 만료되지 않음)            boolean isAccountNonLocked()  계정이 잠겨있지 않았는지 리턴한다. (true : 잠기지 않음)            boolean isCredentialNonExpired()      비밀번호가 만료되지 않았는지 리턴한다. (true : 만료되지 않음)            boolean isEnabled()     계정이 활성화(사용가능)인지 리턴한다. (true: 활성화)       UserDetails 인터페이스는 User Entity 클래스에 구현하지 않고,   CustomUserDetails 클래스에 implements한다.   CustomUserDetails.java   public class CustomUserDetails implements UserDetails {     private Long id;     private String email;     private String password;           @Enumerated(EnumType.STRING)     private Role userType;           private boolean enabled;          @ElementCollection(fetch = FetchType.EAGER)     @Builder.Default     private List&lt;String&gt; roles = new ArrayList&lt;&gt;();          @Override     public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() {     return this.roles.stream()                .map(SimpleGrantedAuthority::new)                .collect(Collectors.toList());     }          @Override     public String getUsername() { return null; }          @Override     public boolean isAccountNonExpired() { return false; }          @Override     public boolean isAccountNonLocked() { return false; }          @Override     public boolean isCredentialsNonExpired() { return false; }  }      위 코드는 이번 프로젝트에서 사용한 UserDetails 인터페이스의 일부이다.   2-2. UserDetailsService  UserDetailsService 인터페이스에는     DB에서 사용자 정보를 불러오는 메소드를 오버라이드 해야 한다.        loadUserByUsername() 메소드이다.     이 메소드에서 사용자 정보를 불러오는 작업을 하면 된다.     CustomUserDetails 타입으로 사용자의 정보를 가져오면 된다.   사용자 정보 유/무에 따라 예외, 사용자 정보를 리턴하면 된다.   @RequiredArgsConstructor @Service public class CustomUserDetailsService implements UserDetailsService {      @Autowired     private UserRepository userRepository;      @Override     public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException {         return (UserDetails) userRepository.findByEmail(email)                 .orElseThrow(() -&gt; new UsernameNotFoundException(\"사용자를 찾을 수 없습니다.\"));     } }    위 코드는 이번 프로젝트에서 사용한 UserDetailsService 인터페이스의 일부이다.   2-3. AuthenticationProvider  AuthenticationProvider 인터페이스는        사용자가 입력한 로그인 정보와 DB에서 가져온 사용자의 정보를 비교해주는 인터페이스이다.   해당 인터페이스에 오버라이드되는 authenticate() 메소드는  화면에 사용자가 입력한 로그인 정보를 담고있는 Authentication 객체를 갖고 있다.   authenticate() 메소드에서 로그인 인증을    성공하면 Authentication 객체를 리턴하고     실패하면 그에 맞는 Exception을 던진다.   2-4. AuthenticationFailureHandler  spring security에서 로그인 실패를 담당하는 인터페이스아다.     SecurityConfig에서 formLogin()에 설정하면 로그인이 실패했을 떄 호출되며 이에 대한 처리를 수행한다.   사용자가 왜 로그인할 수 없는지 자세한 에러 메시지를 출력해주고 싶어서         AuthenticationFailureHandler를 구현했다.   @Override     public void onAuthenticationFailure(HttpServletRequest httpServletRequest,                                         HttpServletResponse httpServletResponse,                                         AuthenticationException e) throws IOException, ServletException {          if(e instanceof ValidationFailedException){             httpServletResponse.sendRedirect(\"/users/signin?error=0\");         }         else if(e instanceof UsernameNotFoundException){             httpServletResponse.sendRedirect(\"/users/signin?error=1\");         }         else if(e instanceof DisabledException) {             httpServletResponse.sendRedirect(\"/users/signin?error=2\");         }         else {             httpServletResponse.sendRedirect(\"/users/signin?error=3\");         }      }    위 코드는 이번 프로젝트에서 사용한 AuthenticationFailureHandler 인터페이스의 일부이다.   Validation으로 에러를 출력해주고 싶은데  spring security로 로그인 로직을 처리하려고 하니까   spring boot가 접근을 못해서 에러 메시지가 출력되지 않았다.   그래도 사용자에게 자세히 에러 메시지를 출력해주고 싶어서   ValidationFailedException을 생성해 sendRedirect로 파라미터에 에러 코드를 전달했다.   public Authentication authenticate(String email, String password) throws AuthenticationException {         UserSigninDto userSigninDto = UserSigninDto.builder()                 .email(email)                 .password(password)                 .build();          // 사용자가 입력한 form data 형식이 맞는지 검사         ValidatorFactory factory = Validation.buildDefaultValidatorFactory();         Validator validator = factory.getValidator();          validator.validate(userSigninDto).stream().forEach(x -&gt; {             throw new ValidationFailedException(x.getMessage());         });          CustomUserDetails user = (CustomUserDetails) userDetailsService.loadUserByUsername(email);   위 코드는 Validation 을 위한 authenticate 메소드의 일부이다.   userSigninDto).stream().forEach(x -&gt; {   이 부분에서 어떤 Validation 에러 인지 전달하고 싶었는데        여러 에러가 발생하는 경우, 여러 메시지를 전달하는건       이 메소드 안에서 해결할 수 없어서 일단 사용자에게 입력 형식이 잘못되었다는      메시지만 전달하려고 한다.   3. Spring Security 예외          BadCredentialException - 비밀번호가 일치하지 않을 때 던지는 예외            InternalAuthenticationServiceException - 존재하지 않는 아이디일 때 던지는 예외            AuthenticationCredentialNotFoundException - 인증 요구가 거부됐을 때 던지는 예외            LockedException - 인증 거부 (잠긴 계정)            DisabledException - 인증 거부 (계정 비활성화)            AccountExpiredException - 인증 거부 (계정 유효기간 만료)            CredentialExpiredException - 인증 거부 (비밀번호 유효기간 만료)       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-17/0417/",
        "teaser": null
      },{
        "title": "Jenkins 사용하기",
        "excerpt":"젠킨스를 사용하려면?  1. 프로젝트 서버에 docker로 jenkins를 설치한다.   docker run -d -p 8000:8080 -v /home/jenkins_home:/var/jenkins_home --name jenkins -u root jenkins   docker image를 pull 받은 후 docker run해도 되는데   image가 없는 상태에서 docker run 명령어를 사용해도   image를 pull 해주기 때문에 괜찮다.   port를 8000으로 설정했기 때문에   docker container를 띄우고 나서   http://서버IP:8000/ 여기로 들어가면 젠킨스를 설정할 수 있다.       2. 플러그인 설치 및 플러그인 설치      위 화면이 첫 화면인데  cat /var/jenkins_home/secrets/initialAdminPassword    위 명령어를 통해 password를 얻을 수 있다.  (주의할 점은 -v 볼륨을 다르게 설정 했다면 위 명령어를 그대로 사용하면 안된다.)          Install suggested plugins 를 클릭해서 플러그인을 설치한다.          젠킨스 최신 버전을 설치하지 않으면 위 사진 처럼 플러그인 설치가 자동으로 잘 안된다.       3. 계정 생성     앞으로 젠킨스 설정을 하기 위해 이 계정으로 로그인해야 한다.       4. 로그인     로그인하면 위와 같은 화면으로 넘어간다.       5. 배포를 위한 설정  git에 올려둔 프로젝트가 업데이트될 때마다   젠킨스를 통해 서버에 배포하려면 몇가지 작업이 필요하다.      maven   JDK   Git 연동   쉘스크립트 작성     (docker로 배포하려고 쉘 스크립트로 배포하는 방식을 선택했다.)   jdk는 jenkins를 docker로 설치하면서    설치되었고 (open jdk 8)   나머지는 jenkins 서버 안으로 들어가서 설치해줬다.     아래 명령어로 접속..  docker exec -it jenkins /bin/bash       ** 아직 쉘스크립트 작성이 완성되지 않아 이후 설정은 나중에 업로드..      ","categories": ["Spring","Docker","Jenkins"],
        "tags": ["spring","jenkins","docker"],
        "url": "/2020-04-21/0421/",
        "teaser": null
      },{
        "title": "Jenkins & Redis",
        "excerpt":"1. jenkins 자동 배포 마무리  젠킨스를 도커로 설치해서 젠킨스 서버에서 프로젝트를 배포하고 싶은 서버로     ssh 명령어로 배포하려고 한다.   비밀번호 없이 ssh 명령어를 사용하기 위해       SSH Key를 생성하고 등록해야 한다.      SSH key 생성      우선 클라이언트 서버(젠킨스 서버)에서 아래 명령어로 SSH key를 생성한다.   ssh-keygen            키 페어를 만들려면 OpenSSH에 포함되어 있는 ssh-keygen 유틸리티를 사용한다.     디폴트로 2048-bit RSA 키 페어를 만들게 되어 있다.   위 명령어를 입력하면 키 생성 위치와 비밀번호를 물어보는데    따로 설정하지 않아도되서 Enter 누르고 넘어갔다.   모두 완료하면 private 키와 public 키 쌍이 생성된다.          서버에 key copy       public키를 서버에 넣어줘야 SSH key를 인증에 사용할 수 있다.   ssh-copy-id USER@HOST   위 명령어를 사용해 키를 복사할 수 있다.   이제 젠킨스에서 ssh로 프로젝트 서버에 접속할 수 있다.          Shell Script 작성      application.yml 파일을 git에 올릴 수 없어서     서버에 올려두고 cp 명령어로 복사해줬다..   ssh litebook@20.41.76.24 \"sudo docker build -t litebook:latest /home/jenkins_home/build\" ssh litebook@20.41.76.24 \"sudo docker stop litebook\" ssh litebook@20.41.76.24 \"sudo docker rm litebook\" ssh litebook@20.41.76.24 \"sudo docker run -d -p 8080:8080 --name litebook litebook:latest\"      ssh 접속으로 Docker image를 만들고 container 실행까지 완료했다.   2. Redis password 설정  redis 접속 password를 설정하고 싶으면 redis.conf 파일을 생성해야 한다.      redis.conf   requirepass PASSWORD            Docker로 설치 &amp; 설정   sudo docker run -v /home/litebook:/var/litebook/redis --name redis -d -p 6379:6379 redis redis-server /var/litebook/redis/redis.conf        docker로 위 처럼 레디스 설정파일을 지정해줄 수 있다.          RedisConfig.java       private RedisProperties redisProperties;      @Autowired     public RedisConfig(RedisProperties redisProperties){         this.redisProperties = redisProperties;     }      @Bean     public RedisConnectionFactory redisConnectionFactory() {         RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration();         redisStandaloneConfiguration.setPassword(redisProperties.getRedisPassword());         redisStandaloneConfiguration.setHostName(redisProperties.getRedisHost());         redisStandaloneConfiguration.setPort(redisProperties.getRedisPort());         LettuceConnectionFactory lettuceConnectionFactory = new LettuceConnectionFactory(redisStandaloneConfiguration);         return lettuceConnectionFactory;     }   RedisConnectionFactory도 수정해줬다.   ","categories": ["Spring","Docker","Jenkins","Redis"],
        "tags": ["spring","jenkins","docker","redis"],
        "url": "/2020-04-24/0424/",
        "teaser": null
      },{
        "title": "Spring boot + JSP = 404 ?",
        "excerpt":"404 Not Found   계속 jsp 파일을 찾지 못하는 에러 메시지가 뜬다..   jar 파일을 만들어 docker로 배포했었는데   war 파일로 변경한 후 이를 해결할 수 있었다.       jar &amp; war           jar(Java Archive)       .jar 확장자 파일에는 Class와 같은 Java 리소스와 속성 파일,      라이브러리 및 액세서리 파일이 포함되어 있다.       쉽게 Java 어플리케이션이 동작할 수 있도록      자바 프로젝트를 압축한 파일이라고 할 수 있다.           path등의 경로를 유지하기 때문에 jar파일을 사용하는 사용자들은       각 파일들에 대한 path문제에서 벗어날 수 있다.       ex) ojdbc14.14, servlet-api, jar 등            war(Web Application Archive)           .war 확장자 파일은 servlet/jsp 컨테이너에 배치할 수 있는      웹 어플리케이션 압축 파일 포맷이다.         JSP, Servlet, jar, class, xml, html 등     Servlet Context 관련 파일들로 패키징되어 있다.       (jar과 같은 맥락으로 servlet context 접근을 위해 관련된 모든 파일들을 패키지화)                        웹 어플리케이션에 관련된 파일들을 포함한다.      ex) jsp, servlet 파일 등           war는 jar와 달리 WEB-INF 및 META-INF 디렉토리로 사전 정의 된 구조를 사용하고,                war를 실행하려면 Tomcat, Weblogic, Websphere 등      웹 서버 또는 웹 컨테이너가 필요하다.           결론 : war로 바꾸자 !   jar를 생성했을 때 jar에 jsp 파일이 포함되지 않아서       계속 404 not found 에러가 발생했었다.   war를 생성하니까 jsp와 css가 포함되어     배포했을 때 정상적으로 파일을 찾았다.   war 생성을 위해 아래 파일들을 변경해줘야 한다.          change package      위 처럼 jsp와 css의 경로를 다시 설정해줬다.          application.yml   spring:   profiles:     active: local   session:     store-type: redis   mvc:     view:       prefix: /jsp/       suffix: .jsp   spring.mvc.view.prefix 설정 변경          Dockerfile   FROM openjdk:8-jdk-alpine ADD litebook-0.0.1-SNAPSHOT.war litebook.war EXPOSE 8080  ENTRYPOINT [\"java\",\"-jar\",\"litebook.war\"]              pom.xml          ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-04-26/0426/",
        "teaser": null
      },{
        "title": "JPA 연관관계",
        "excerpt":"연관관계 매핑 기초   엔티티들은 대부분 다른 엔티티와 연관관계가 있다.     그런데 객체는 참조(주소)를 사용해서 관계를 맺고 테이블은 외래키를 사용해서 관계를 맺는다.      방향            단방향 : 한 쪽만 참조       양방향 : 양쪽 모두 서로 참조  방향은 객체 관계에서만 존재하고 테이블 관계에서는 항상 양방향이다.                다중성      다대일, 일대다, 일대일, 다대다 다중성이 있다.       연관관계의 주인     객체를 양방향 연관관계로 만들면 연관관계의 주인을 정해야 한다.   1. 단방향 연관관계  1-1 다대일(N:1) 단방향 관계  예) Member —(N, 1)— Team           객체 연관관계와 테이블 연관관계의 가장 큰 차이    참조를 통한 연관관계는 언제나 단방향이다. 객체간에 연관관계를 양방향으로 만들고 싶으면   반대쪽에도 필드를 추가해서 참조를 보관해야 한다. 결국 연관관계를 하나 더 만들어야 한다.   하지만 이는 서로 다른 반방향 관계 2개라고 할 수 있다.              반면에 테이블은 외래키 하나로 양방향으로 조인할 수 있다.            객체 연관관계 vs 테이블 연관관계              객체 연관관계는 데이터를 조회할 때         객체는 참조(주소)를 사용하지만 테이블은 조인(JOIN)을 사용한다.                  참조를 사용하는 객체의 연관관계는 단방향이다.       객체를 양방향으로 참조하려면 단방향 연관관계를 2개 만들어야 한다.               A -&gt; B (a.b)            B -&gt; A (b.a)          외래 키를 사용하는 테이블의 연관관계는 양방향이다.                               A JOIN B 가 가능하면 반대로 B JOIN A 도 가능하다.                예제 코드       // Member.java    @ManyToOne  @JoinColumn(name=\"TEAM_ID\") private Team team;  // Team.java  @OneToMany  private List&lt;Member&gt; members;   @ManyToOne  다대일 관계라는 매핑 정보이다.    연관관계를 매핑할 때 이렇게 다중성을 나타내는 어노테이션을 필수로 사용해야 한다.   @JoinColumn(name=\"TEAM_ID\")  조인 컬럼은 외래 키를 매핑할 때 사용한다.   name 속성에는 매핑할 외래 키 이름을 지정한다.   이 어노테이션은 생략할 수 있다.   2. 양방향 연관관계  회원에서 팀으로 접근하고 반대 방향인 팀에서도 회원으로 접근할 수 있도록 양방향 연관관계로 매핑해보자.   객체 연관관계  일대다 관계는 여러 건과 연관관계를 맺을 수 있으므로 컬렉션을 사용해야 한다.    Team.members를 List 컬렉션으로 추가할 수 있다.   객체 연관관계를 정리하면 다음과 같다.     회원 -&gt; 팀 (Member.team)   팀 -&gt; 회원 (Team.members)   테이블 연관관계  데이터베이스 테이블은 외래 키 하나로 양방향으로 조회할 수 있다.      예제 코드   // Member.java    @ManyToOne  @JoinColumn(name=\"TEAM_ID\") private Team team;  public void setTeam(Team team){ // 연관관계 설정        this.team = team; }  // Team.java  @OneToMany(mappedBy = \"team\") private List&lt;Member&gt; members = new ArrayList&lt;Member&gt;();   팀과 회원은 일대다 관계이기 때문에 팀 엔티티에 컬렉션인 List&lt;Member&gt; members를 추가했다.    mappedBy 속성은 양방향 매핑일 때 사용하는데 반대쪽 매핑의 필드 이름을 값으로 주면 된다.   이렇게 양방향 매핑을 완료하면 팀에서 회원 컬렉션으로 객체 그래프를 탐색할 수 있다.   3. 연관관계의 주인  `mappedBy’는 왜 필요할까?   객체에는 양방향 연관관계라는 것이 없다.      테이블 연관관계는 다음과 같이 양방향 연관관계가 가능하다.    회원 &lt;-&gt; 팀   엔티티를 양방향 연관관계로 설정하면 객체의 참조는 둘인데 외래 키는 하나다.   그렇다면 둘 중 어떤 관계를 사용해서 외래 키를 관리해야 할까?       =&gt; 둘 사이에 차이가 발생   JPA에서는 두 객체 연관관계 중 하나를 정해서 테이블의 외래 키를 관리해야 하는데           이것을 연관관계의 주인이라고 한다.   (1) 양방향 매핑의 규칙 : 연관관계의 주인     방향 연관관계 매핑 시 지켜야할 규칙            두 연관관계 중 하나를 연관관계의 주인으로 정해야 한다.       주인만이 데이터베이스 연관관계와 매핑되고 외래 키를 관리(등록, 수정, 삭제)할 수 있다.       주인이 아닌 쪽은 읽기만 가능하다.       주인이 아닌 쪽에서 mappedBy 속성을 사용해서 연관관계의 주인을 지정한다.       주인은 mappedBy 속성을 사용하지 않는다.           ","categories": ["Spring","JPA"],
        "tags": ["spring","jpa"],
        "url": "/2020-05-06/0506/",
        "teaser": null
      },{
        "title": "DB를 사용하면서 발생 가능한 문제점",
        "excerpt":"    자바 기반 애플리케이션의 성능을 진단해 보면, 응답 속도를 지연시키는 대부분의 요인은 DB 쿼리 수행 시간과 결과를 처리하는 시간이다.   이 책의 저자는 애플리케이션에서의 DB 접속 관련 공지가 있었다고 한다.     주된 내용은 다음과 같다.           DB Connection을 할 경우에는 반드시 공통 유틸리티를 사용할 것.            각 모듈별 DataSource를 사용하여 리소스가 부족한 현상이 발생하지 않아도록 할 것.            반드시 Connection, Statement 관련 객체, ResultSet을 close할 것.            페이지 처리를 하기 위해서 ResultSet객체.last() 메서드를 사용하지 말 것.       왜 위와 같은 조치를 취해야 하는지 알아보자.       DB Connection 과 Connection Pool, DataSource  일반적으로 DB에 연결하여 사용하는 방법에서 가장 느린 부분은 Connection 객체를 얻는 부분이다.   DB와 WAS 사이에는 통신을 해야 하기 때문이다.   사용자가 갑자기 증가하면 Connection 객체를 얻기 위한 시간이 엄청나게 소요될 것이며, 많은 화면이 예외를 발생시킬 것이다.   이러한 부담을 줄이기 위해 사용하는 것이 DB Connection Pool이다.   가능하면 안정되고 검증된 WAS에서 제공하는 DB Connection Pool이나 DataSource를 사용하자.   Statement와 거의 동일하게 사용할 수 있는 Statement 인터페이스의 자식 클래스로 PreparedStatement가 있다.   그리고 PL/SQL을 처리하기 위해서 사용하는 PreparedStatement의 자식 클래스로 CallableStatement가 있다.       Statement VS. PreparedStatement  이 둘의 가장 큰 차이점은 캐시(cache) 사용 여부이다.   이 둘을 사용할 때는 다음과 같은 프로세스를 거친다.      쿼리 문장 분석   컴파일   실행   Statement를 사용하면 매번 쿼리를 수행할 때마다 1~3 단계를 거치고   PreparedStatement는 처음 한 번만 세 단계를 거친 후 캐시에 담아서 재사용 한다는 것이다.   만약 같은 쿼리를 반복적으로 수행한다면 PreparedStatement가 DB에 훨씬 적은 부하를 주며, 성능도 좋다.               DB를 사용할 때 닫아야 하는 것들  일반적으로 각 객체를 얻는 순서는 Connection, Statement, ResultSet 순이며,    객체를 닫는 순서는 ResultSet, Statement, Connection 순이다.   먼저 ResultSet 객체가 닫히는 경우는 다음과 같다.      close() 메서드 호출   GC의 대상이 되어 GC되는 경우   관련된 Statement 객체의 close() 메서드가 호출되는 경우       그렇다면 왜 굳이 close() 를 해야 하는가?   Connection, Statement 관련 인터페이스, ResultSet 인터페이스에서 close() 메서드를 호출하는 이유는   자동으로 호출되기 전에 관련된 DB와 JDBC 리소스를 해제하기 위함이다.   Statement 객체는 Connection 객체를 close() 한다고 자동으로 닫히지 않는다.   다음 두 경우에만 닫히므로, 반드시 close() 메서드를 호출해야 한다.      close() 메서드 호출   GC의 대상이 되어 GC되는 경우   가장 문제가 되는 Connection 인터페이스의 객체에 대해 알아보자.    다음 세 가지 경우에 닫힌다.      close() 메서드 호출   GC의 대상이 되어 GC되는 경우   치명적인 에러가 발생하는 경우   더 이상 사용할 수 있는 연결이 없으면, 여유가 생길 때까지 대기한다.   그러다가 어느 정도 시간이 지나면 오류가 발생한다.   GC가 될 때까지 기다리면 Connection Pool이 부족해지는 것은 시간 문제다.       아래와 같은 방법으로 이를 해결할 수 있다.   try {      . . .  } catch(Exception e) {      . . .  } finally {     try{rs.close();}catch(Exception rse){}     try{ps.close();}catch(Exception pse){}     try{con.close();}catch(Exception cone){} }  위 예는 throws 예외 구문이 있다는 가정 하에 작성되었다.   무엇보다도 가장 좋은 방법은 DB와 관련된 처리를 담당하는 관리 클래스를 만드는 것이다.   보통 DBManager 이라는 이름의 클래스를 많이 사용한다.               JDK 7 에서 등장한 AutoClosable 인터페이스   JDK 7부터 등장한 java.lang 패키지에 AutoClosable이라는 인터페이스가 있다.   AutoClosable 인터페이스에는 리턴 타입이 void인 close() 메서드 단 한 개만 선언되어 있다.   close() 메서드의 설명은 다음과 같다.      try-with-resources 문장으로 관리되는 객체에 대해서 자동적으로 close() 처리를 한다.   InterruptedException을 던지지 않도록 하는 것을 권장한다.   이 close() 메서드를 두 번 이상 호출할 경우 뭔가 눈에 보이는 부작용이 나타나도록 해야 한다.       가장 중요한 것은 try-with-resources 이다.   try 블록이 시작될 때 소괄호 안에 close() 메서드를 호출하는 객체를 생성해 주면   별도로 finally 블록에서 close() 메서드를 호출할 필요가 없어졌다는 의미다.               ResultSet.last() 메서드  이 메서드는 “ResultSet 객체가 갖고 있는 결과의 커서(Corsor)를 맨 끝으로 옮겨라” 라는 지시를 하는 메서드이다.   rs.next()가 다음 커서로 옮기는 것과 비교하면 이해하기가 쉬울 것이다.   이 메서드를 수행하는 이유가 뭘까?       대부분의 이유는 다음과 같이 사용하기 위해서이다.   rs.last();   int totalCount = rs.getRow();   ResultArray[] result = new ResultArray[totalCount];     전체 데이터 개수를 확인하고 배열에 담아서 사용하기 위해서라면 양호한 편..       배열을 Vector로 변경하고 사용하면 되기 때문이다.        하지만 게시판과 같은 화면을 구성할 때 전체 수를 확인하기 위해서라면      select count(*) from ... 과 같은 쿼리를 한 번 더 던져서 확인하는 것이 훨씬 빠르다.   그럼 rs.last() 에는 문제가 있을까?    rs.last() 메서드의 수행 시간은 데이터의 건수 및 DB와의 통신 속도에 따라서 달라진다.   건수가 많으면 많을 수록 대기 시간이 증가하기 때문에 rs.next()를 수행할 때와 비교할 수 없을 정도로 속도 차이가 나기 때문에,   이 메서드의 사용은 자제해야 한다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-DB/",
        "teaser": null
      },{
        "title": "JVM은 어떻게 구동될까?",
        "excerpt":"    웹 기반 시스템을 배포할 때 그냥 재시작만 한다면,         배포 직후 시스템 사용자들은 엄청나게 느린 응답 시간과 함께 시스템에 대한 많은 불만을 갖게 될 수도 있다.         즉, warning up이 필요한데 왜 이런 작업이 필요할까?    왜 WAS을 재시작하면 성능이 느린지 알아보자.       다음은 반드시 성능과 관련있는 부분은 아니지만 아래 내용은 알아두면 좋다.      HotSpot VM 구조   JIT 옵티마이저   JVM의 구동 절차   JVM의 종료 절차   클래스 로딩의 절차   예외 처리의 절차       HotSpot VM 은 어떻게 구성되어 있을까?   자바의 성능을 개선하기 위해 Just In Time(JIT) 컴파일러를 만들었고, 이름을 HotSpot이라고 지었다.   JIT 컴파일러는 프로그램의 성능에 영향을 주는 지점에 대해서 지속적으로 분석한다.    분석된 지점은 부하를 최소화하고, 높은 성능을 내기 위한 최적화의 대상이 된다.   JIT를 사용한다는 것은 언제나 자바 메서드가 호출되면      바이트 코드를 컴파일하고 실행 가능한 네이티브 코드로 변환한다는 의미다.      하지만 매번 JIT로 컴파일을 하면 성능 저하가 심하므로, 최적화 단계를 거치게 된다.       HotSpot VM 아키텍처는 다음과 같다.          HotSpot VM 런타임에 GC 방식과 JIT 컴파일러를 끼워 맞춰 사용할 수 있다.      이를 위해 VM 런타임은 JIT 컴파일러용 API와 가비지 컬렉터용 API를 제공한다.     JVM을 시작하는 런처와 스레드 관리, JNI 등도 VM 런타임에서 제공한다.             JIT Optimizer라는 게 도대체 뭘까?     HotSpot VM JIT 컴파일러에 대해서 이야기하기 전에   Client 버전과 Server 버전으로 나뉜다는 것을 기억하자. client는 스타트업 시간과 메모리공간에 대한 최적화에 중점을 두고 있고,      server는 시작시간은 좀 걸리더라도 다수의 request를 빠르게 처리하는데에 중점을 맞추고 있다.        javac 컴파일러는 소스코드를 바이트코드로 된 class 파일로 변환시켜준다.           자바 프로그램을 실행할 때 JVM은 항상 바이트코드로 시작, 동적으로 기계에 의존적인 코드로 변환한다.   JIT은 애플리케이션에서 각각의 메서드를 컴파일할 만큼 시간적 여유가 없어서        모든 코드는 초기에 인터프리터에 의해서 시작되고 해당 코드가 충분히 많이 사용될 경우에 컴파일할 대상이 된다.          • 인터프리터       자바 인터프리터는 JAVAC 명령으로 자바 프로그램을 중간 형태인 자바 바이트코드로 컴파일하고,          이를 자바 인터프리터가 한 줄씩 해석하여 기계어로 번역한다.     • 컴파일      고급언어로 작성된 프로그램을 목적프로그램으로 번역 후 링킹(Linking) 작업을 통해 실행 프로그램을 생성한다.         자바는 javac로 컴파일 하고 java로 실행시 중간언어(클래스파일)를 한줄 씩    자바 인터프로터가 번역하므로 컴파일 언어이면서 인터프리터 언어이다.     • 왜 컴파일과 인터프리터 방식을 병행할까?      원래 자바의 JVM에서는 인터프리터 방식만 사용했었다.     하지만 성능의 문제가 발생으로 JIT Compiler를 추가해서 성능의 효율을 끌어올렸다.    이로 인해 자바는 컴파일과 인터프리터 방식을 병행해서 사용하게 됐다.        HotSpot VM에서 이 작업은 각 메서드에 있는 카운터를 통해서 통제되며,      메서드에는 두 개의 카운터가 존재한다.      수행 카운터 (invocation counter): 메서드를 시작할 때마다 증가.   백에지 카운터 (backedge counter): 높은 바이트 코드 인덱스에서 낮은 인텍스로 컨트롤 흐름이 변경될 때마다 증가,         메소드에 루프가 존재하는지 확인할 때 사용된다.        backedge counter는 invocation counter보다 컴파일 우선순위가 더 높다.   이 카운터들이 인터프리터에 의해 증가될 때마다 그 값들이 한계치에 도달했는지 확인하고   도달했을 경우 인터프리터는 컴파일을 요청한다.   컴파일이 요청되면 컴파일 대상 목록의 큐에 쌓이고, 하나 이상의 컴파일러 스레드가 이 큐를 모니터링한다.   컴파일러 스레드가 바쁘지 않을 때는 큐에서 대상을 빼내서 컴파일을 시작한다.        HotSpot VM은 OSR(On Stack Replacement) 이라는 특별한 컴파일도 수행한다.         이 OSR은 인터프리터에서 수행한 코드 중 오랫동안 루프가 지속되는 경우,          중간에 컴파일해야 남은 반복을 빠르게 수행할 수 있기 때문에 사용된다.   최적화되지 않은 코드가 수행되고 있는 것을 발견하면 인터프리터에 두지 않고, 컴파일된 코드로 변경한다.           루프가 끝나지 않고 지속적으로 수행되고 있을 경우에 큰 도움이 된다.           SUN에서 개발한 HotSpot VM을 제외하고도 BAE 시스템에서 개발한 JRockit,      IBM에서 개발한 IBM JVM의 JIT 컴파일 방식이 있다.      JVM에 대한 더 많은 내용을 다음 글을 참고하면 좋을 것이다. JVM 에 대한 Naver D2 글                   JVM 시작 절차  (1) java 명령어 줄에 있는 옵션 파싱   (2) 자바 힙 크기 할당 및 JIT 컴파일러 타입 지정 (명령줄에 지정되지 않았을 경우)   (3) CLASSPATH와 LD_LIBRARY_PATH 같은 환경 변수를 지정한다.   (4) 자바의 Main 클래스가 지정되지 않았으면, Jar 파일의 mainfest 파일에서 Main 클래스를 확인한다.   (5) JNI의 표준 API인 JNI_CreateJavaVM를 사용하여 새로 생성한 non-primordial이라는 스레드에서 HotSpot VM을 생성한다.   (6) HotSpot VM이 생성되고 초기화되면, Main 클래스가 로딩된 런처에서는 main() 메서드의 속성 정보를 읽는다.   (7) CallStaticVoidMethod는 네이티브 인터페이스를 불러 HotSpot VM에 있는 main() 메서드가 수행된다.   이떄 자바 실행 시 Main 클래스 뒤에 있는 값들이 전달된다.              JVM 종료 절차  VM이 시작할 때 오류가 있어 시작을 중지할 때나, JVM에 심각한 에러가 있어서 중지할 필요가 있을 때는   DestroyJavaVM이라는 메서드를 HotSpot 런처에서 호출한다.   HotSpot VM의 종료는 다음의 DestroyJavaVM 메서드의 종료 절차를 따른다.   (1) HotSpot VM이 작동중인 상황에서는 단 하나의 데몬이 아닌 스레드가 수행될 때까지 대기한다.   (2) java.lang 패키지에 있는 Shutdown 클래스의 shutdown() 메서드가 수행된다.   이 메서드가 수행되면 자바 레벨의 shutdown hook이 수행되고,   finalization-on-exit 이라는 값이 true일 경우에 자바 객체 finalizer를 수행한다.   (3) HotSpot VM 레벨의 shutdown hook을 수행함으로써 HotSpot VM의 종료를 준비한다.   이 작업은 JVM_OnExit() 메서드를 통해서 지정된다.   그리고, HotSpot VM의 profiler, stat sampler, watcher, garbage collector 스레드를 종료시킨다.   이 작업들이 종료되면 JVMTI를 비활성화하며, Signal 스레드를 종료시킨다.   (4) HotSpot의 JavaThread::exit() 메서드를 호출하여 JNI 처리 블록을 해제한다.    그리고, guard pages, 스레드 목록에 있는 스레드들을 삭제한다.    이 순간부터는 HotSpot VM에서는 자바 코드를 실행하지 못한다.   (5) HotSpot VM 스레드를 종료한다.  이 작업을 수행하면 HotSpot VM에 남아 있는 HotSpot VM 스레드들을 safepoint로 옮기고, JIT 컴파일러 스레드들을 중지시킨다.   (6) JNI, HotSpot VM, JVMTI barrier에 있는 추적 기능을 종료시킨다.   (7) 네이티브 스레드에서 수행하고 있는 스레드들을 위해서 HotSpot의 “vm exited” 값을 설정한다.   (8) 현재 스레드를 삭제한다.   (9) 입출력 스트림을 삭제하고, PerfMemory 리소스 연결을 해제한다.   (10) JVM 종료를 호출한 호출자로 복귀한다.               클래스 로딩 절차  (1) 주어진 클래스의 이름으로 클래스 패스에 있는 바이너리로 된 자바 클래스를 찾는다.   (2) 자바 클래스를 정의한다.   (3) 해당 클래스를 나타내는 java.lang 패키지의 Class 클래스의 객체를 생성한다.   (4) 링크 작업이 수행된다. 이 단계에서 static 필드를 생성 및 초기화하고, 메서드 테이블을 할당한다.   (5) 클래스의 초기화가 진행되며, 클래스의 static 블록과 static 필드가 가장 먼저 초기화 된다.    해당 클래스가 초기화 되기 전에 부모 클래스의 초기화가 먼저 이루어진다.              내부 클래스 로딩 데이터의 관리  HotSpot VM은 클래스 로딩을 추적하기 위해 다음 3개의 해시 테이블을 관리한다.      SystemDictionary            로드된 클래스를 포함한다.       클래스 이름과 초기화한 로더의 정보, 클래스 일므과 정의한 로더의 정보도 포함한다.           PlaceholderTable            현재 로딩된 클래스에 대한 정보를 관리한다.       이 테이블은 ClassCircularityError를 체크할 때 사용       다중 스레드에서 클래스를 로딩하는 클래스 로더에서도 사용된다.           LoaderConstraintTable            타입 체크시의 제약 사항을 추정하는 용도로 사용된다.                     예외는 JVM에서 어떻게 처리될까?  JVM은 자바 언어의 제약을 어겼을 때 예외(exception)라는 시그널로 처리한다.     HotSpot VM 인터프리터, JIT 컴파일러, 다른 HotSpot VM 컴포넌트는 예외 처리와 모두 관련되어 있다.   일반적인 예외 처리 경우는 아래 두 가지 경우다.     예외를 발생한 메서드에서 잡을 경우   호출한 메서드에 의해서 잡힐 경우   후자의 경우에는 보다 복잡하며, 스택을 뒤져서 적당한 핸들러를 찾는 작업을 필요로 한다.       VM이 예외가 던져졌다는 것을 알아차렸을 때, 해당 예외를 처리하는 가장 가까운 핸들러를 찾기 위해서   HotSpot VM 런타임 시스템이 수행된다.   핸들러를 찾기 위해 다음 3가지 정보가 사용된다.     현재 메서드   현재 바이트 코드   예외 객체   만약 현재 메서드에서 핸들러를 찾지 못하면 현재 수행되는 스택 프레임을 통해   이전 프레임을 찾는 작업을 수행한다.      적당한 핸들러를 찾으면 HotSpot VM 수행 상태가 변경되며 HotSpot VM은 핸들러로 이동하고 자바 코드 수행은 계속된다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-JVM/",
        "teaser": null
      },{
        "title": "Collection과 Map",
        "excerpt":"어디에 담아야 하는지?   배열은 처음부터 크기를 지정해야 하지만,      Collection의 객체 대부분은 그럴 필요 없이 객체들이 채워질 때마다 자동으로 크기가 증가된다.           Collection 및 Map 인터페이스의 이해           Collection : 가장 상위 인터페이스이다.            Set : 중복을 허용하지 않는 집합을 처리하기 위한 인터페이스이다.            SortedSet : 오름차순을 갖는 Set 인터페이스이다.            List : 순서가 있는 집합을 처리하기 위한 인터페이스이기 때문에 인덱스가 있어 위치를 지정하여 값을 찾을 수 있다.   중복을 허용하며, List 인터페이스를 상속받는 클래스 중에 가장 많이 사용하는 것으로 ArrayLIst가 있다.            Queue : 여러 개의 객체를 처리하기 전에 담아서 처리할 때 사용하기 위한 인터페이스이다.        이 객체는 중복되는 키를 허용하지 않는다. 기본적으로 FIFO를 따른다.            SortedMap : 키를 오음차순으로 정렬하는 Map 인터페이스이다.           Set 인터페이스          HashSet : 데이터를 해쉬 테이블에 담는 클래스로 순서 없이 저장된다.            TreeSet: red-black 이라는 크리에 데이터를 담는다.   값에 따라 순서가 정해진다.    데이터를 담으면서 동시에 정렬을 하기 떄문에 HashSet보다 성능상 느리다.            LinkedHashSet : 해쉬 테이블에 데이터를 담는데, 저장된 순서에 따라서 순서가 결정된다.             HashSet과 LinkedHashSet의 성능이 비슷하고, TreeSet의 순서로 성능 차이가 발생한다.     (LinkedHashSet &gt; HashSet &gt; TreeSet)   TreeSet은 데이터를 저장하면서 정렬한다.   데이터를 순서에 따라 탐색해야 하는 경우에는 TreeSet을 사용하는 것이 좋다.   하지만 그럴필요가 없을 때는 HashSet이나 LinkedHashSet을 사용하는 것을 권장한다.       List 인터페이스  구현된 클래스에는 ArrayList와 Linked-List 클래스가 있으며, 원조 클래스 격인 Vector 클래스가 있다.           Vector : 객체 생성시에 크기를 지정할 필요가 없는 배열 클래스이다.            ArrayList : Vector과 비슷하지만, 동기화 처리가 되어 있지 않다.            LinkedList : ArrayList와 동일하지만, Queue 인터페이스를 구현했기 때문에 FIFO 큐 작업을 수행한다.           (1) 데이터를 넣는 속도 비교   데이터를 넣은 것은 어떤 클래스든 큰 차이가 없다.       (2) 순차적으로 결과를 받아오는 속도 비교 (list.get(index))                 ArrayList가 가장 빠르고, Vector과 LinkedList는 속도가 매우 느리다.          LinkedList가 Queue 인터페이스를 상속받기 때문이다.                             이를 수정하기 위해서는 순차적으로 결과를 받아오는 peek()나 poll() 메서드를 사용해야 한다.   수정 후, 테스트를 다시 해보면    ArrayList, LinkedList, Vector 순으로 빠르게 바뀐다.         Q. ArrayList와 Vector의 성능 차이는 왜 이렇게 큰가?    A. Vector은 여러 스레드에서 접근할 경우를 방지하기 위해서     get() 메서드에 synchronized가 선언되어 있다.      그래서 성능 저하가 발생할 수밖에 없다.     ArrayList는 여러 스레드에서 접근할 경우 문제가 발생할 수 있다.        (3) 데이터를 삭제하는 시간 비교     첫 번째 값 삭제와 마지막 값 삭제 속도의 차이가 크다.   LinkedList는 별 차이가 없지만, ArrayList나 Vector은 실제로 그 안에 배열을 사용한다.   그래서 ArrayList와 Vector의 첫번째 값을 삭제하면 느릴 수 밖에 없다.       Map 인터페이스  Map은 key-value 쌍으로 저장되는 구조체이다.     그래서 Map은 단일 객체만 저장하는 다른 Collection API들과는 다르게 따로 분리되어 있다.   구현한 클래스들은 HashMap, TreeMap, LinkedHashMap 세 가지와    원조 클래스 격인 Hashtable 클래스가 있다.           Hashtable : 데이터를 해쉬 테이블에 담는 클래스이다. 내부에서 관리하는데 해쉬 테이블 객체가 동기화되어 있으므로,   동기화가 필요한 부분에서는 이 클래스를 사용하기 바란다.            HashMap : 데이터를 해쉬 테이블에 담는 클래스이다.   Hashtable 클래스와 다른 점은 null 값을 허용한다는 것과 동기화되어 있지 않다는 것이다.            TreeMap : red-blak 트리에 데이터를 담는다.   TreeSet과 다른 점은 키에 의해서 순서가 정해진다는 점이다.            LinkedHashMap : HashMap과 거의 동일하며 이중 연결 리스트라는 방식을 사용하여 데이터를 담는다는 점만 다르다.           대부분의 클래스가 동일하지만,     트리 형태로 처리하는 TreeMap 클래스가 가장 느리다.       Queue 인터페이스  Queue는 데이터를 담아 두었다가 먼저 들어온 데이터부터 처리하기 위해서 사용된다.   List의 큰 단점은 데이터가 많은 경우 처리 시간이 늘어난다는 점이다.   가장 앞에 있는 데이터를 지우면 한 칸씩 옮기는 작업을 수행해야 하므로 느리다.   Queue 인터페이스를 구현한 클래스는 두 가지로 나뉜다.     java.util 패키지에 속하는 LinkedList와 PriorityQueue -&gt; 일반적인 목적의 큐 클래스   java.util.concurrent 패키지에 속하는 클래스들 -&gt; 컨커런트 큐 클래스         Queue 구현 클래스          Priority Queue : 큐에 추가된 순서와 상관없이 먼저 생성된 객체가 먼저 나오도록 되어 있는 큐다.            LinkedBlockingQueue : 저장할 데이터의 크기를 선택적으로 정할 수도 있는 FIFO 기반의 링크 노드를 사용하는 블로킹 큐다.            ArrayBlockingQueue : 저장되는 데이터의 크기가 정해져있는 FIFO 기반의 블로킹 큐다.            PriorityBlockingQueue : 저장되는 데이터의 크기가 정해져 있지 않고, 객체의 생성순서에 따라서 순서가 저장되는 블로킹 큐다.            DelayQueue : 큐가 대기하는 시간을 지정하여 처리하도록 되어 있는 큐다.            SynchronousQueue : put() 메서드를 호출하면, 다른 스레드에서 take() 메서드가 호출될 때까지 대기하도록 되어 있는 큐다.   이 큐에는 저장되는 데이터가 없다. API에서 제공하는 대부분의 메서드는 0이나 Null을 리턴한다.                블로킹 큐(blocking queue)란 크기가 지정되어 있는 큐에 더 이상 공간이 없을 때,   공간이 생길 때까지 대기하도록 만들어진 큐를 의미한다.        Collection 관련 클래스의 동기화  HashSet, TreeSet, LinkedHashSet, ArrayList, LinkedList,      HashMap, TreeMap, LinkedHashMap은 동기화되지 않은 클래스이다.    (JDK 1.2 버전 이후에 만들어짐)   동기화되어 있는 클래스로는 Vector와 Hashtable이 있다.    (JDK 1.0 버전에 만들어짐)   Collection 클래스에는 최신 버전 클래스들의 동기화를 지원하기 위한 synchronized로 시작하는 메서드들이 있다.    synchronized: 현재 데이터를 사용하고 있는 해당 스레드를 제외하고          나머지 스레드들은 데이터에 접근할 수 없도록 막는 개념   synchronized 키워드를 너무 남발하면 오히려 성능 저하를 일으킬 수 있다.          자바 내부적으로 blocking, non-blocking 처리를 하기 때문이다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-collection/",
        "teaser": null
      },{
        "title": "JSON도 잘 쓰자",
        "excerpt":"JSON과 파서들   JSON 데이터는 다음과 같은 두 가지의 구조를 기본으로 하고 있다.      name/value 형태의 쌍으로 collection 타입   값의 순서가 있는 목록 타입   JSON도 많은 CPU와 메모리를 점유하며 응답 시간도 느리다.   많은 종류의 자바 기반 JSON 파서들이 존재하는데, 가장 많이 사용되는 JSON 파서로는 Jackson JSON과 google-gson 등이 있다.       Jackson JSON 에 대해 알아보자.   JSON을 파싱하는 코드의 성능 비교 결과를 보면 XML 파싱이 JSON 보다 매우 느리다고 생각할 수 있지만,  데이터를 전송하기 위해서 XML 및 JSON 데이터를 Serialize와 Deserialize 할 경우도 있다.   그런데 JSON 데이터는 Serialize와 Deserialize를 처리하는 성능이 좋지 않다.   XML 파서보다 JSON 파서가 느린 경우가 대부분이다.          JSON 데이터를 자바로 파싱하는 라이브러리들의 성능을 비교하는 여러 글을 읽어봤는데         대용량 환경에서는 Jackson을 마이크로 서비스와 분산아키텍처 설정등과 같이 작은 용량의 많은             json 파일을 처리하는 환경이라면 GSON을 사용하는 것이 좋다는 결론이 많았다.        정리  XML 이나 JSON을 데이터 처리 기준으로 선정한다면, 메모리 및 CPU 사용량 손실을 반드시 염두에 둬야한다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-json/",
        "teaser": null
      },{
        "title": "클래스와 메서드의 정보를 확인할 수 있는 API",
        "excerpt":"클래스 정보, 어떻게 알아낼 수 있나?  자바에는 클래스와 메서드의 정보를 확인할 수 있는 API가 있다.         reflection 관련 클래스들  자바 API에는 reflection 이라는 패키지가 있다.    이 패키지에 있는 클래스들을 사용하면 JVM에 로딩되어 있는 클래스와 메서드 정보를 읽어 올 수 있다.       Class 클래스  Class 클래스는 클래스에 대한 정보를 얻을 때 사용하기 좋고, 생성자는 따로 없다.   ClassLoader 클래스의 defineClass() 메서드를 이용해서 클래스 객체를 만들 수도 있지만, 좋은 방법은 아니다.     그보다는 Object 클래스에 있는 getClass() 메서드를 사용하는 것이 일반적이다.       Method 클래스  Method 클래스를 사용하면 메서드에 대한 정보를 얻을 수 있다.   하지만 Method 클래스에는 생성자가 없으므로 Method 클래스의 정보를 얻기 위해서   Class 클래스의 getMethod() 메서드를 사용하거나 getDeclaredMethod() 메서드를 써야 한다.       Field 클래스  Field 클래스는 클래스에 있는 변수들의 정보를 제공하기 위해서 사용한다.    Method 클래스와 마찬가지로 생성자가 존재하지 않으므로 Class 클래스와 함께 사용해야 한다.       reflection 클래스를 잘못 사용한 사례  일반적으로 로그를 프린트할 때 클래스 이름을 알아내기 위해 다음과 같은 Class 클래스를 많이 사용한다.   this.getClass.getName()          이 방법은 getClass() 메서드를 호출할 때 Class 객체를 만들고,           그 객체의 이름을 가져오는 메서드를 수행하는 시간과 메모리를 사용할 뿐이다.   응답 속도에 그리 많은 영향을 주지는 않지만, 많이 사용하면 필요 없는 시간을 낭비하게 된다.       정리   reflection 관련 클래스를 사용하면 클래스의 정보 및 여러 가지 세부 정보를 알 수 있어 매우 편리하다.   하지만 로그에서 사용하기 위해서라면, instanceof를 사용하는 것이 클래스의 이름으로 해당 객체의 타입을 비교하는 방법보다 낫다.   추가적으로 클래스의 메타 데이터 정보는 JVM의 Perm 영역에 저장된다.            만약 Class 클래스를 사용하여 엄청나게 많은 클래스를 동적으로 생산하는 일이 벌어지면          Perm 영역이 더 이상 사용할 수 없게 되어 OutOfMemoryError가 발생할 수도 있어 조심해야 한다.  ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-reflection/",
        "teaser": null
      },{
        "title": "JSP와 서블릿, Spring에서 발생할 수 있는 문제점",
        "excerpt":"JSP와 Servlet의 기본적인 동작원리를 알아보자.    일반적으로 JSP와 같은 웹 화면단을 처리하는 부분에서 소요되는 시간은 많지 않다.    JSP의 경우 가장 처음에 호출되는 경우에만 시간이 소요되는 이후에는 컴파일된 서블릿 클래스가 수행되기 때문이다.        JSP 라이프 사이클  (1) JSP URL 호출         (2) 페이지 번역            (3) JSP 페이지 컴파일           (4) 클래스 로드          (5) 인스턴스 생성          (6) jspInit 메서드 호출          (7) _jspService 메서드 호출          (8) jspDestory 메서드 호출              해당 JSP 페이지가 이미 컴파일되어 있고 클래스 로드되어 있고             JSP 파일이 변경되지 않았다면 가장 많은 시간이 소요되는 (2)~(4) 프로세스는 생략된다.       서블릿 라이프 사이클  WAS의 JVM이 시작한 후에는,   Servlet 객체가 자동으로 생성되거나 초기화 되거나   사용자가 해당 Servlet을 처음으로 호출했을 때 생성되고 초기화 된다.              그 다음 계속 사용 가능 상태로 대기한다.      중간에 예외가 발생하면 사용 불가능 상태로 빠졌다가 다시 사용 가능 상태로 변환되기도 한다.      해당 서블릿이 더 이상 필요 없을 때는 파기 상태로 넘어간 후 JVM에서 제거 된다.   서블릿은 JVM에 여러 객체로 생성되지 않는다.    다시 말해 WAS가 시작하고, 사용 가능 상태가 된 이상 대부분의 서블릿은 JVM에 살아있고,      여러 스레드에서 해당 서블릿의 service() 메서드를 호출하여 공유한다.   만약 서블릿 클래스이 메서드 내에 선언한 지역 변수가 아닌 멤버 변수 (인스턴스 변수)를 선언하여    service() 메서드에서 사용하면 어떤 일이 벌어질까?   static을 사용하는 것과 거의 동일한 결과를 나타낸다.    service() 메서드를 구현할 때는 멤버 변수나 static한 클래스 변수를 선언하여   지속적으로 변경하는 작업은 피해야한다.       - 스프링 프레임워크 간단 정리   스프링 프레임워크는 데스크톱과 웹 어플리케이션, 작고 간단한 애플리케이션부터            여러 서버와 연동하여 동작해야 하는 엔터프라이즈 애플리케이션도 범용적인 애플리케이션 프레임워크이다.   Spring의 가장 큰 특징은 복잡한 애플리케이션도 POJO(Plain Old Java Object)로 개발할 수 있다는 점이다.   서블릿을 개발하려면 반드시 HttpServlet이라는 클래스를 상속해야 한다.   하지만 스프링을 사용하면 HttpServlet을 확장하지 않아도 웹 요청을 처리할 수 있는 클래스를 만들 수 있다.       스프링의 핵심 기술  Dependency Injection,   Aspect Oriented Programming,   Portable Service Abstraction 으로 함축할 수 있다.       (1) Dependency Injection     ‘의존성 주입’ 이라고 한다.    객체간의 관계를 관리하는 기술로 생각하면 된다.     어떤 객체가 필요로 하는 객체를 자기 자신이 직접 생성하여 사용하는 것이 아니라    외부에 있는 다른 무언가로부터 필요로 하는 객체를 주입 받는 기술이다.   (2) AOP (Aspect Oriented Programming)    ‘관점 지향 프로그래밍’ 이라고 부른다.   대부분은 비슷한 코드가 중복되고 코드를 읽는 데 방해가 된다.   이런 코드를 실제 비즈니스 로직과 분리할 수 있도록 도와주는 것이 바로 AOP이다.   자바에서 가장 유명한 AOP 프레임워크로는 AspectJ가 있다.   (3) PSA (Portable Service Abstraction)    스프링은 비슷한 기술을 모두 아우를 수 있는 추상화 계층을 제공하여, 사용하는 기술이 바뀌더라도   비즈니스 로직의 변화가 없도록 도와준다.       스프링 프레임워크를 사용하면서 발생할 수 있는 문제점들   스프링 프레임워크를 사용할 때 성능 문제가 가장 많이 발생하는 부분은 프록시(proxy) 와 관련이 있다.   스프링 프록시는 기본적으로 실행 시에 생성된다.     따라서 요청량이 많은 운영 상황으로 넘어가면 문제가 나타날 수 있다.   스프링이 프록시를 사용하게 하는 주요 기능은 트랜잭션이다.    @Transaction 어노테이션을 사용하면 해당 어노테이션을 사용한 클래스의 인스턴스를 처음 만들 때 프록시 객체를 만든다.   개발자가 직접 스프링 AOP를 사용해서 별도의 기능을 추가하는 경우에도 프록시를 사용하는데,   이 부분에서 문제가 많이 발생한다.   따라서, 간단한 부하 툴을 사용해서라도 성능적인 면을 테스트해야만 한다.   추가로, 스프링이 내부 매커니즘에서 사용하는 캐시도 조심해야 한다.   예를들어 스프링 MVC에서 작성하는 메서드의 리턴 타입으로 다음과 같은 문자열을 사용할 수 있다.   이 때 매번 동일한 문자열에 대한 뷰 객체를 새로 찾기 보다는 이미 찾아본 뷰 객체를 캐싱해두면      다음에도 동일한 문자열이 반환됐을 때 훨씬 빠르게 뷰 객체를 찾을 수 있다.   스프링이 제공하는 ViewResolver 중에 자주 사용되는 InternalResourceViewResolver에는 그러한 캐싱 기능이 내장되어 있다.   (ViewResolver는 뷰 이름과 지역화를 위한 Locale을 파라미터로 전달받으며,        매핑되는 View 객체를 리턴한다. 만약, 매핑되는 View 객체가 존재하지 않으면 null을 리턴한다.)   만약 매번 다른 문자열이 생성될 가능성이 높고, 상당히 많은 수의 키 값으로 캐싱 값이 생성될 여지가 있는 상황에서는   문자열을 반환하는 게 메모리에 치명적일 수 있다.   이런 상황에서는 뷰 이름을 문자열로 변환하기보다는 뷰 객체 자체를 반환하는 방법이 메모리 릭을 방지하는 데 도움이 된다.   @GetMapping(\"/members/{id}\") public View hello(@PathVariable int id) {     return new RedirectView(\"/members/\" + id); }           ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-spring/",
        "teaser": null
      },{
        "title": "static 잘 활용하기",
        "excerpt":"    자바 프로그래밍에서 성능을 향상시키는 방법 중 하나는 static을 사용하는 것이다.        그러나 잘 모르고 사용하면 더 느려지거나 오류가 발생할 수 있다.       static의 특징   자바에서 static으로 지정한 것은 해당 메서드나 변수가 정적이라는 의미다.   static으로 선언한 변수 = 클래스 변수           하나의 JVM이나 WAS 인스턴스에서 동일한 주소 값을 참조한다.            GC의 대상이 되지 않는다.           static 잘 활용하기   (1) 자주 사용하고 절대 변하지 않는 변수는 final static으로 선언하자.  자주 변경되지 않고, 경우의 수가 단순한 쿼리 문장이 있다면 final static이나 static으로 선언하여 사용하자.          (2) 설정 파일 정보도 static으로 관리하자.  클래스의 객체를 생성할 때마다 설정 파일을 로딩하면 엄청난 성능 저하가 발생하게 된다.         이럴 때는 반드시 static으로 데이터를 읽어서 관리해야 한다.        (3) 코드성 데이터는 DB에서 한 번만 읽자.  부서가 적은 회사의 코드나, 건수가 그리 많지 않되 조회 빈도가 높은 코드성 데이터는     DB에서 한 번만 읽어서 관리하는 것이 성능 측면에서 좋다.         만약 코드가 수정되었을 때는 updateCodes() 같은 메소드를 호출해서 코드 정보를 다시 읽으면 된다.        그런데 만약 서버 인스턴스가 하나만 있다면 코드가 변경되는 것을 걱정하지 않아도 된다.       하지만 서로 다른 JVM에 올라가 있는 코드 정보는 수정된 코드와 상이하므로 그 부분에 대한 대책을 마련해 놓아야 한다.   이러한 JVM 간에 상이한 결과가 나오는 것을 방지하기 위해서 요즘에는 mem-cached, EhCache 등의 캐시를 많이 사용한다.       static을 잘 못 사용한 경우  (1) 쿼리 관리용 클래스에서 사용한 static String queryURL = ...;  여러 화면에서 호출하는 경우 queryURL이 그때 그때 바뀌게 된다.     모든 스레드에서 동일한 주소를 가리키게 되어 문제가 발생한다.        (2) private static boolean successFlag;  성공 여부를 담기 위해 successFlag를 만들었다.    개발자 PC에서 테스트 하거나 성능, 통합 테스트를 할 때 문제점을 발견하지 못할 수도 있다.     수십명이 동시에 정보 확인을 위해 위 서블릿을 호출하면   다른 사용자에 의해 나의 정보가 바뀔 수 있다.       static과 메모리 릭  static으로 선언한 부분은 GC가 되지 않는다.   그럼 만약 어떤 클래스에 데이터를 Vector나 ArrayList에 담을 때     해당 Collection 객체를 static으로 선언하면 어떻게 될까?   만약 지속적으로 해당 객체에 데이터가 쌓이는데 GC가 되지 않으면 시스템은 OutOfMemoryError를 발생시킨다.   이렇게되면 시스템을 재시작해야 하고 해당 인스턴스는 더 이상 서비스할 수 없다.   더 이상 사용 가능한 메모리가 없어지는 현상을 메모리 릭(Memory Leak)이라고 하는데, static과 Collection 객체를 잘못 사용하면 메모리 릭이 발생한다.   ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-static/",
        "teaser": null
      },{
        "title": "왜 String을 쓰지 말라는 걸까?",
        "excerpt":"    Stringbuffer 클래스와 StringBuilder 클래스   StringBuffer 클래스나 StringBuilder 클래스에서 제공하는 메서드는 동일하다.   차이점은 무엇일까?   StringBuffer 클래스는 스레드에 안전하게 설계 되어 있으므로,        여러 개의 스레드가 하나의 StringBuffer 객체를 처리해도 전혀 문제가 되지 않는다.   하지만 StringBuilder는 단일 스레드에서의 안전성만 보장한다.     그렇기 때문에 여러 개의 스레드에서 하나의 StringBuilder 객체를 처리하면 문제가 발생한다.       String VS. StringBuffer VS. StringBuilder           String      Stirng은 짧은 문자열을 더할 경우 사용한다.                StirngBuffer       StringBuffer은 스레드에 안전한 프로그램이 필요할 때나,       개발 중인 시스템의 부분이 스레드에 안전한지 모를 경우 사용하면 좋다.               만약 클래스에 static으로 선언한 문자열을 변경하거나, singleton으로 선언된 클래스  (JVM에 객체가 하나만 생성되는 클래스)에 선언된 문자열일 경우에는 이 클래스를 사용해야만 한다.                StringBuilder     StringBuilder는 스레드에 안전한지의 여부와 관계 없는 프로그램을 개발할 때 사용하면 좋다.   만약 메서드 내에서 변수를 선언했다면, 해당 변수는 그 메서드 내에서만 살아있기 때문에 StringBuilder를 사용하면 된다.           정리  메모리를 가장 많이 차지하고 응답 시간에 많은 영향을 주는 것은 String 클래스이다.                   String 클래스를 쓰는 대신 스레드와 관련이 있으면 StringBuffer를,                    스레드 안전 여부와 상관이 없으면 StringBuilder를 사용하는 것을 권장한다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-string/",
        "teaser": null
      },{
        "title": "제대로 알고 써야하는 synchronized",
        "excerpt":"자바에서 스레드는 어떻게 사용하나?  WAS는 여러 개의 스레드가 동작하도록 되어 있다. synchronized를 자주 사용한다.             synchronized를 쓴다고 무조건 안정적인 것은 아니며 성능에 영향을 미치는 부분도 있다.       프로세스와 스레드  클래스를 하나 수행시키거나 WAS를 기동하면 서버에 자바 프로세스가 하나 생성된다.      하나의 프로세스에는 여러 개의 스레드가 생성된다.      단일 스레드가 생성되어 종료될 수도 있고, 여러 개의 스레드가 생성되어 수행될 수도 있다.      프로세스와 스레드의 관계는 1:N 관계라고 보면 된다.   스레드는 가벼운 프로세스라고도 하며, 프로세스에서 만들어 사용하고 있는 메모리를 공유한다.          그래서 별개의 프로세스가 하나씩 뜨는 것보다는 성능이나 자원 사용에 있어서 많은 도움이 된다.       Synchronized를 이해하자.  웹 기반의 시스템에서 스레드 관련 부분 중 가장 많이 사용하는 것은 synchronized일 것이다.     synchronized는 동시에 처리한다는 의미로 하나의 객체에 여러 객체가 동시에 접근하여 처리하는 상황에 사용한다.     하나의 객체에 여러 요청이 동시에 들어오면 한 명씩 들어오라고 해당 메서드나 블록에서 제어하게 된다.   synchronized와 static을 연결해서 생각하면 더욱 복잡해진다.     synchronized는 절대로 생성자의 식별자로는 사용할 수 없다는 점을 기억하자.   public synchronized void sampleMethod() {     // 생략 }  private Object obj = new Object(); public void sampleBlock() {     synchronized(obj) {         // 생략     } }   간단하게 synchronized라는 식별자로 동기화할 수 있다.           그럼 언제 동기화를 사용해야 할까?   (1) 하나의 객체를 여러 스레드에서 동시에 사용할 경우              (2) static으로 선언한 객체를 여러 스레드에서 동시에 사용할 경우   위의 경우가 아니면 동기화를 할 필요가 없다.                동기화 사용법: (1) 동일 객체 접근 시  예를들어, 여러 기부자가 어떤 기부금을 처리하는 단체에 기부금을 낸다고 가정하자.      총 기부금 : amount   기부자 : Contributor   기부단체 : Contribution   기부금 받는 창구 : donate()       public class Contribution {     private int amount = 0;          public void donate() {         amount++;     }          public int getTotal() {         return amount;     } }  public class Contributor extends Thread {     private Contribution myContribution;     private String myName;          . . .      }       동기화하기 전 기부단체 10개 (1000원씩 출력)  1인당 1원씩 1,000번 기부하고 기부가 완료되면 전체 기부금을 프린트한다.   public static void main(String[] args) {     Contributor[] cts = new Contributor[10];          // 기부자, 단체 초기화      for(int i = 0; i &lt; 10; ++i) {         Contribution group = new Contribution();         crs[i] = new Contributor(group, \"Contributor \" + i);     }          // 기부 실행      for(int i = 0; i &lt; 10; ++i) {         crs[i].start();     } }   위 코드에서 기부금을 받는 단체인 group 객체를 매번 생성했기 때문에       10명의 객체가 각기 다른 단체에 기부하게 된다.       동기화하기 전 기부 단체 1개 (10,000원 출력 X)  기부 단체가 하나인 경우 어떻게 될까?   Contribution group = new Contribution();  for(int i = 0; i &lt; 10; ++i) {     crs[i] = new Contributor(group, \"Contributor \" + i); }   총 기부금 금액은 10,000원이 출력되어야 하는데 예상대로 출력되지 않는다.       예상대로 출력되지 않는 이유는?  예상대로라면 1000원씩 기부했기 때문에 총 10,000원이 프린트되어야 하는데    대부분 10,000원이 프린트되지 않는다.   그 이유는 10개의 Contributor 객체에서 하나의 Contribution 객체의 donate() 메서드를     동시에 접근할 수 있도록 되어 있기 때문이다.           이 오류를 수정하기 위해 donate() 메서드에 synchronized를 써서 동기화 식별자를 추가해야 한다.   위 예제들을 성능 테스트해보면 필요 없는 부분에 synchronized를 사용하면 약간이지만 성능에 영향을 준다.                동기화 사용법: (2) static 사용 시  앞 예제에서 amount를 static으로 선언하고 synchronized를 사용하면 어떻게 될까?          동기화 전: 기부 단체 10개에 기부하는 경우 (synchronized 사용 X)  총 10,000원이 출력되어야 하는데 원하는 결과가 안나온다.    각 단체에 기부하는 케이스라 하더라도 amount를 static으로 선언하면   각 기부 단체에 따로 기부하는 것은 불가능하다.       donate() 메서드 동기화: 기부 단체 10개에 기부하는 경우 (synchronized 사용 O)  이번에도 원하는 결과가 나오지 않는다.    synchronized는 각각의 객체에 대한 동기화를 하는 것이기 때문에    각각의 단체에 대한 동기화는 되었지만 amount에 대한 동기화는 되지 않는다.       donate() 메서드 동기화, static 추가  amount는 클래스의 변수이지 객체의 변수가 아니다.   public static synchronized void donate() {     amount++; }   이제 원하는 대로 결과가 나왔다.       항상 변하는 값에 대해서 static으로 선언하여 사용하면 위험하다.    synchronized도 꼭 필요할 때만 사용해야 한다.       동기화를 위해서 자바에서 제공하는 것들   JDK 5.0부터 추가된 java.util.concurrent 패키지에 대해서 간단히 알아보자.     이 패키지에 주요 개념 4가지가 포함되어 있다.   (1) Lock : 실행 중인 스레드를 간단한 방법으로 정지시켰다가 실행시킨다. 상호참조로 인해 발생하는 데드락을 피할 수 있다.   (2) Execute : 스레드를 더 효율적으로 관리할 수 있는 클래스들을 제공한다.   (3) Concurrent 콜렉션 : 앞서 살펴본 콜렉션의 클래스들을 제공한다.   (4) Atomic 변수 : 동기화가 되어 있는 변수를 제공한다. 이 변수를 사용하면, synchronized 식별자를 메서드에 지정할 필요가 없이 사용할 수 있다.       정리  동일한 객체를 공유하거나, static을 사용한 변수를 공유할 경우 반드시 synchronized를 사용해야 한다.     synchronized는 여러 스레드에서 접근하는 것을 막아주는 장점이 있지만,   성능 저하가 발생한다는 단점이 있다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-synchronized/",
        "teaser": null
      },{
        "title": "서버를 어떻게 세팅해야 할까?",
        "excerpt":"설정해야 하는 대상   개발하는 것만큼 중요한 것이 서버의 세팅이다. 개발된 프로그램이 0.1초 걸린다고 해도 서버 세팅을 잘못하면 1초가 걸릴 수도 있다.            이러한 문제를 진단하는 가장 좋은 방법은 성능 테스트를 통해서 병목 지점을 미리 파악하는 것이다.   무조건 애플리케이션 위주로 병목을 찾는 것보다, 일단 문제가 될만한 세팅 값을 먼저 진단하는 것이 가장 효율적이다.         웹 기반의 시스템에서 성능에 영향을 줄만한 세팅을 나열해 보면 다음과 같다.      웹 서버 세팅   WAS 서버 세팅   DB 서버 세팅   장비 세팅       아파치 웹 서버의 설정   웹 서버는 반드시 WAS 앞에 두어야 한다.   웹에서 사용하는 어플리케이션 서버이지 웹 서버가 아니다. 정적인 부분은 웹 서버에서 처리해야 한다.       웹 서버의 Keep Alive  웹 서버와 웹 브라우저가 연결이 되었을 때 KeepAlive 기능이 켜져 있지 않으면, 매번 HTTP 연결을 맺었다 끊었다 하는 작업을 반복한다.   KeepAlive 기능이 켜져 있으면 두 개 정도의 연결을 열어서 끊지 않고, 연결을 계속 재사용한다.   KeepAlive 설정을 할 때 반드시 같이 해야 하는 설정이 있다.   KeepAlive-Timeout 설정이다.          마지막 연결이 끝난 이후에 다음 연결이 될 때까지 얼마나 기다릴지를 설정한다.   하지만 무조건 KeepAlive 옵션을 켜야 성능이 좋게 나오는 것은 아니다. 상황에 맞게 사용해야 한다.       DB Connection Pool 및 스레드 개수 설정  DB Connection Pool 과 스레드 개수에 대해서 알아보자.    이 두 항목의 개수는 메모리와 관련이 있다.   많이 사용할수록 메모리를 많이 점유하게 된다.     그렇다고 메모리를 위해서 DB Connection Pool 과 스레드 개수를 적게 지정하면,       서버에서는 많은 요청을 처리하지 못하고 대기할 수밖에 없다.   대부분의 WAS에서 DB Connection Pool의 개수를 최소치, 증가치, 최대치 등으로 지정할 수 있다.     최소치는 서버가 기동될 때 연결을 수행하는 개수이다.       최소 개수가 많으면 많을수록 서버 기동하는 시간이 오래 소요된다.   운영 중에는 최소 및 최대 값을 동일하게 하는 것이 좋다.   대부분 DB Connection Pool 보다 스레드 개수를 10개 정도 더 지정하는데,   이유는 스레드 개수가 DB Connection Pool 의 개수보다 적으면 적은 수만큼의 연결은 필요 없기 때문이다.   쉽게 스레드는 입구이고 DB Connection Pool은 출구라고 생각하면 된다.       ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-07/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-%EC%84%9C%EB%B2%84%EC%84%B8%ED%8C%85/",
        "teaser": null
      },{
        "title": "GC는 언제 발생할까?",
        "excerpt":"    GC란?   자바에서 메모리 관리를 누가 해야 하는가에 대한 생각을 해보자.     자바에서 메모리를 GC라는 알고리즘을 통하여 관리하기 때문에,   개발자가 메모리를 처리하기 위한 로직을 만들 필요가 없고 만들어서는 안된다.   Garbage Collection 은 말그대로 쓰레기를 정리하는 작업이다.       자바 프로그래밍을 할 때 쓰레기란 어떤 것일까?     자바에서 쓰레기는 객체이다. 하나의 객체는 메모리를 점유하고, 필요하지 않으면 메모리에서 해제되어야 한다.           메로리 점유는 다음과같이 쉽게 할 수 있다.     이러한 코드에서는 a라는 객체가 만들어쟈 메모리의 한 부분을 점유하게 된다.   String a = new String();        그럼 다음의 코드를 보자.   public String makeQuery(String code) {     String queryPre = \"Select * from table_a where a='\";     String queryPost = \"' order by c\";     return queryPre + code + queryPost; }   이 메서드를 호출한 후 수행이 완료되면 queryPre 객체와 queryPost 객체는 더 이상 필요가 없는 객체,   즉 쓰레기가 된다.     이 쓰레기 객체를 효과적으로 처리하는 작업을 GC라고 한다.                자바의 Runtime data area는 이렇게 구성된다.      PC 레지스터   JVM 스택   힙(Heap)   메서드 영역   런타임 상수(constant) 풀   네이티브 메서드 스택   이 영역 중에서도 GC가 발생하는 부분이 바로 힙 영역이다.      거꾸로 말하면, 나머지는 GC 대상이 아니라는 것이다.   다음은 이 영역들을 그림으로 나타낸 것이다.                         클래스 로더 서브 시스템 : 클래스나 인터페이스를 JVM으로 로딩하는 기술을 수행   실행 엔진 : 로딩된 클래스의 메서드들에 포함되어 있는 모든 인스트럭션 정보를 실행한다.   그림은 복잡해 보이지만, 자바의 메모리 영역은 단순하게 ‘Heap 메모리’와 ‘Non-heap 메모리’로 나뉜다.                 Heap 메모리   클래스 인스턴스, 배열이 이 메모리에 쌓인다.   이 메모리는 ‘공유 메모리’라고도 부르며 여러 스레드애서 공유하는 데이터들이 저장되는 메모리다.                   Non-heap 메모리    이 메모리는 자바의 내부 처리를 위해서 필요한 영역이다.   주된 영역이 바로 메서드 영역이다.          메서드 영억: 메서드 영억은 모든 JVM 스레드에서 공유한다.           이 영역에서 공유되는 데이터들은 다음과 같다.             런타임 상수 풀, 필드 정보에는 메서드 데이터, 메서드와 생성자 코드가 있다.       JVM 스택       스레드가 시작할 때 JVM 스택이 생성된다.       이 스택에는 메서드가 호출되는 정보인 프레임이 저장된다.    지역변수와 임시 결과, 메서드 수행과 리턴에 관련된 정보들도 포함된다.           네이티브 메서드 스택     자바 코드가 아닌 다른 언어로된 코드들이 실행하게 될 때의 스택 정보를 관리한다.          PC 레지스터       자바의 스레드들은 각각의 pc(Program Counter) 레지스터를 갖는다.   네이티브한 코드를 제외한 모든 자바 코드들이 수행될 때 JVM의 인트럭션 주소를 pc 레지스터에 보관한다.   여기서 Heap 영역과 메서드 영역은 JVM이 시작될 때 생성된다.                  GC의 원리  GC 작업을 하는 가비지 콜렉터는 다음의 역할을 한다.      메모리 할당   사용 중인 메모리 인식   사용하지 않는 메모리 인식   사용하지 않는 메모리를 인식하는 작업을 수행하지 않으면,   할당한 메모리 영역이 꽉 차서 JVM에 행(Hang)이 걸리거나 더 많은 메모리를 할당하려는 현상이 발생할 것이다.   JVM의 메모리는 여러 영역으로 나뉘는데, GC와 관련된 부분은 힙이다.      따라서 가비지 콜렉터가 인식하고 할당하는 자바의 힙 영역에 대해서 알아보자.   힙 영역 구조 참고      Young 영역에서 Old 영역으로 넘어가는 객체 중에서 Survivor 영억을 거치지 않고 바로 Old 영역으로 이동하는 객체가 있을 수 있는데,  객체의 크기가 아주 큰 경우이다.    Survivor 영역의 크키가 16MB 라고 가정했을 때 20MB를 점유하는 객체는 Survivor 영역으로 옮겨갈 수 없다.    이런 객체들은 바로 Old 영역으로 이동하게 된다.                GC의 종류  크게 두 가지 타입으로 나뉜다.      마이너GC : Young 영역에서 발생하는 GC   메이저GC : Old 영역이나 Perm 영역에서 발생하는 GC   이 두 가지 GC가 어떻게 상호작용하느냐에 따라서 GC 방식에 차이가 나며, 성능에도 영향을 준다.          GC가 발생하거나 객체가 각 영역에서 다른 영역으로 이동할 때 애플리케이션의 병목이 발생하면서 성능에 영향을 주게 된다.    그래서 핫 스팟 JVM 에서는 스레드 로컬 할당 버퍼라는 것을 사용한다.   이를 통하여 각 스레드별 메모리 버퍼를 사용하면 다른 스레드에 영향을 주지 않는 메모리 할당 작업이 가능해 진다.                5가지 GC 방식  JDK 7 이상에서 지원하는 GC 방식에는 다섯 가지가 있다.   Java VM(Virtual Machine) 내부에서 garbage collection 작업을 수행하는 엔진을 garbage collector라고 부른다.     Java VM 내부에 garbage collector가 여러 개 구현되어 있고,      Java VM을 실행할 때 command line parameter로 garbage collector를 선택할 수 있다.   [참고]                     5가지 방식 자세한 설명 : https://hyerin6.github.io/2020-03-23/GC(2)/        GC 과정에 대한 Naver D2 글 : https://d2.naver.com/helloworld/1329       1. Serial GC 시리얼 콜렉터  mark-sweep-compact 알고리즘을 사용해 Old 영역의 GC를 수행한다.   첫 단계에서 Old 영역에 살아있는 객체를 식별하고 힙의 앞부분부터 확인하여 살아있는 객체는 남긴다.   마지막 단계에서 각 객체가 연속되게 쌓이도록 살아있는 객체들을 한 곳으로 모은다.   적은 메모리와 CPU 코어 개수가 적을 때 적합한 방식이다.              그러나 운영 서버에서 절대 사용하면 안 되는 방식이 Serial GC다.           Serial GC는 데스크톱의 CPU 코어가 하나만 있을 때 사용하기 위해서 만든 방식이다.           Serial GC를 사용하면 애플리케이션의 성능이 많이 떨어진다.       2. Parallel GC 패러랠 콜렉터 (병렬 콜렉터)  스루풋 콜렉터(throughtput collector)라고도 부른다.      시리얼 콜렉터와 기본적인 알고리즘은 같은데 이 방식은 Young 영역을 병렬로 처리한다.   이 방식의 목표는 다른 CPU가 대기 상태로 남아있는 것을 최소화하는 것이다.   시리얼 GC는 GC를 처리하는 스레드가 하나이지만, Parallel GC는 여러개이기 때문에    Parallel GC는 GC의 부하를 줄이고 빠르게 처리량을 증가시킬 수 있다.   메모리가 충분하고 코어 개수가 많을 때 유리하다.       3. Parallel Old GC  Parallel GC와는 Old 영역의 GC 과정만 다르다.          이 방식은 Mark-Summary-Compact 단계를 거친다.      Summary 단계는 앞서 GC를 수행한 영역에 대해서                 별도로 살아있는 객체를 식별한다는 점에서 Mark-sweep-Compact 알고리즘의 sweep 단계와 다르게 조금 더 복잡하다.   병렬 콜렉터와 동일하게 이 방식도 여러 CPU를 사용하는 서버에 적합하다.       4. CMS GC  로우 레이턴시 콜렉터(low-latency-collector)로도 알려져 있다.   힙 메모리 영역이 클 때 적합하다.   Young 영역에 대한 GC는 병렬 콜렉터와 동일하다.       old 영역에 대한 GC는 다음과 같다.           초기 Initial Mark 단계에서는 클래스 로더에서 가장 가까운 객체 중 살아있는 객체만 찾고 끝낸다.    이는 대기 시간이 매우 짧다.            Concurrent Mark 단계에서는 방금 살아있다고 확인한 객체에서 참조하는 있는 객체들을 따라가면서 확인한다.   특징은 다른 스레드가 실행중인 상태에서 동시에 실행된다는 것이다.            Remark 단계에서는 새로 추가 되거나 참조가 끊긴 객체를 확인한다.            Concurrent Sweep 단계에서는 쓰레기를 정리하는 단계이다.       특징은 Concurrent Mark 단계와 마찬가지로 다른 스레드가 실행하는 동시에 실행된다는 것이다.       CMS GC는 stop-the-world 시간이 짧다는 장점에 반해 다음과 같은 단점이 존재한다.           다른 GC 방식보다 메모리와 CPU를 더 많이 사용한다.            Compaction 단계가 기본적으로 제공되지 않는다.    조각난 메모리가 많아 Compaction 작업을 실행하면          다른 GC 방식의 stop-the-world 시간보다 stop-the-world 시간이 더 길기 때문에         Compaction 작업이 얼마나 자주, 오랫동안 수행되는지 확인해야 한다.       이 방식은 2개 이상의 프로세서를 사용하는 서버에 적당하다. (예 - 웹 서버)                    Young 영역의 GC를 더 잘게 쪼개서 대기 시간을 줄일 수 있다.                 모든 애플리케이션의 응답 속도가 매우 중요할 경우에 사용한다.       5. G1 GC  Garbage First 는 지금까지의 GC(Young, Old)와는 다른 영역으로 구성되어 있다.   G1 GC의 Young GC    (1) 몇 개의 구역을 선정하여 Young 영역으로 지정한다.   (2) 이 Linear 하지 않은 구역에 객체가 생성되면서 데이터가 쌓인다.    (3) Young 영역으로 할당된 구역에 데이터가 꽉차면 GC를 수행한다.   (4) 살아남은 객체는 Sirvivor 구역으로 이동한다.   Old 영역 GC는 CMS GC 와 비슷하게 진행되며 여섯 단계로 나뉜다.   여기서 STW라고 표시된 단계는 모두 Stop the world가 발생한다.       G1 GC의 Old GC     (1) 초기 표시 (STW) : Old 영역에 있는 객체에서 Survivor 영역의 객체를 참조하고 있는 객체들을 표시한다.   (2) 기본 구역 스캔 단계 : Old 영역 참조를 위해서 Survivor 영역을 훑는다.              참고로 이 작업은 Young GC가 발생하기 전에 수행 된다.   (3) 컨커런트 표시 단계 : 전체 힙 영역에 살아있는 객체를 찾는다.              만약 이때 Young GC가 발생하면 잠시 멈춘다.   (4) 재표시 단계 (STW) : 힙에 살아있는 객체들의 표시 작업을 완료한다.              이 떄 snapshot-at-the-beginning(SATB)라는 알고리즘을 사용하며, 이는 CMS GC에서 사용하는 방식보다 빠르다.   (5) 청소 단계 (STW) : 살아있는 객체와 비어 있는 구역을 식별하고, 필요 없는 객체들을 지운다.  그리고 비어 있는 구역은 초기화한다.   (6) 복사 단계 (STW) : 살아있는 객체들을 비어 있는 구역으로 모은다.   G1은 CMS GC의 단점을 보완하기 위해 만들어졌으며 성능도 매우 빠르다.            GC가 어떻게 수행되고 있는지 보고 싶다면   시스템을 분석하려면 관련된 툴을 사용해야 한다.   여러 방법이 있는데 jstat 이라는 명령을 사용하여 실시간으로 보거나 verbosegc 옵션을 사용하여 로그를 남길 수도 있다.          자바 인스턴스 확인을 위한 jps  jps는 해당 머신에서 운영 중인 JVM의 목록을 보여준다.       JDK의 bin 디렉터리에 있으며, 사용법이 매우 간단하다.   jps [-q] [-mlvV] [-Joption] [&lt;hostid&gt;]            GC 상황을 확인하는 jstat  jstat는 GC가 수행되는 정보를 확인하기 위한 명령어이다.   jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]          Garbage Collection 모니터링 방법 Naver D2 글 : https://d2.naver.com/helloworld/6043             GC 튜닝을 항상 할 필요는 없다.   결론부터 이야기하면 모든 Java 기반의 서비스에서 GC 튜닝을 진행할 필요는 없다.   GC 튜닝이 필요 없다는 이야기는 운영 중인 Java 기반 시스템의 옵션과 동작이 다음과 같다는 의미이다.           -Xms 옵션과 –Xmx 옵션으로 메모리크기를 지정했다.            -server 옵션이 포함되어있다.            시스템에 Timeout 로그와찍 같은 로그가 남지않는다.       (여기서 타임아웃이란 DB 작업과 관련된 타임아웃, 다른 서버와의 통신시 타임아웃)   즉, JVM 메모리 크기도 지정하지 않았고 Timeout 로그가 수도 없이 많이 출력되었다면 GC 튜닝을 하는 것이 좋다.   그러나 한 가지 명심해야 할 것은 GC 튜닝은 가장 마지막에 하는 작업이라는 것이다.         GC 튜닝을 하는 이유가 무엇인지 근본적인 원인을 생각해 보자.            Java에서 생성된 객체는 가비지 컬렉터(Garbage Collector)가 처리해서 지운다.            생성된 객체가 많으면 많을수록 가비지 컬렉터가 가 처리해야 하는 대상도 많아지고, GC를 수행하는 횟수도 증가한다.            즉, 여러분이 운영하고 만드는 시스템이 GC를 적게 하도록 하려면 객체 생성을 줄이는 작업을 먼저 해야 한다.                운영하고 만드는 시스템이 GC를 적게 하도록 하려면 객체 생성을 줄이는 작업이 먼저 필요하다.   예를 들어, 이 책의 본문에 나오는 대부분의 내용을 지키면 된다.      String 대신 StringBuilder 나 StringBuffer 사용하거나,      로그를 최대한 적게 쌓도록 하는 등 임시 메모리를 적게 사용하도록 하는 작업은 중요하다.   만약 애플리케이션 메모리 사용도 튜닝을 많이 해서        어느 정도 만족할 만한 상황이 되었다면, 본격적으로 GC 튜닝을 시작하면 된다.   GC 튜닝의 목적을 두 가지로 나눠보자.     Old 영역으로 넘어가는 객체의 수 최소화하기   Full GC의 실행 시간을 줄이기       (1) Old 영역으로 넘어가는 객체의 수 최소화하기   Old 영역의 GC는 New 영역의 GC에 비하여 상대적으로 시간이 오래 소요되기 때문에   Old 영역으로 이동하는 객체의 수를 줄이면 Full GC가 발생하는 빈도를 많이 줄일 수 있다.   객체를 New 영역에만 남긴다는 것은 아니고,       New 영역의 크기를 잘 조절함으로써 큰 효과를 볼 수 있다는 것이다.       (2) Full GC 시간 줄이기  Full GC 수행 시간은 상대적으로 Young GC에 비하여 길다.   그래서 Full GC 실행에 오랜 시간이 소요되면 연계된 여러 부분에서 타임아웃이 발생할 수 있다.   하지만 Old 영역의 크기를 줄여버리면 OutOfMemoryError가 발생하거나 Full GC 횟수가 늘어난다.    반대로 크기를 늘리면 Full GC 횟수는 줄어들지만 실행 시간이 늘어난다.     Old 영역의 크기를 적절하게 잘 설정해야 한다.           GC의 성능을 결정하는 옵션들   이런 저런 옵션을 많이 설정한다고 시스템의 GC 수행 속도가 월등히 빨라지진 않는다.        오히려 더 느려질 확률이 높다. 두 대 이상의 서버에 GC 옵션을 다르게 적용해서 비교해 보고,         옵션을 추가한 서버의 성능이나 GC 시간이 개선된 때에만 옵션을 추가하는 것이 GC 튜닝의 기본 원칙다.         절대로 잊지 말자!   -Xms 옵션(JVM 시작 시 힙 영역 크기)과 -Xmx 옵션(최대 힙 영역 크기)은 필수로 지정해야 하는 옵션이다.          그리고 NewRatio 옵션(New영역과 Old 영역의 비율)을 어떻게 설정하느냐에 따라서 GC 성능에 많은 차이가 발생한다.   GC 방식 중에서 특별히 신경쓸 필요가 없는 방식은 Serial GC다.       Serial GC는 클라이언트 장비에 최적화되어 있기 때문이다.                GC 튜닝의 절차   (1) GC 상황 모니터링   GC 상황을 모니터링하며 현재 운영되는 시스템의 GC 상황을 확인해야 한다.   (2) 모니터링 결과 분석 후 GC 튜닝 여부 결정      분석한 결과를 확인했는데 GC 수행에 소요된 시간이 0.1~0.3초 밖에 안 된다면 굳이 GC 튜닝에 시간을 낭비할 필요는 없다.   하지만 GC 수행 시간이 1~3초, 심지어 10초가 넘는 상황이라면 GC 튜닝을 진행해야 한다.   그런데 만약 Java의 메모리를 10GB 정도로 할당해서 사용하고 있고 메모리의 크기를 줄일 수 없다면      방법은 없을 것 같다.   GC 튜닝 전에 시스템의 메모리를 왜 높게 잡아야 하는지에 생각해 봐야 한다.   튜닝 여부 결정에 대한 자세한 내용은 책을 한번 더 확인…   (3) GC 방식 / 메모리 크기 지정   GC 튜닝을 진행하기로 결정했다면 GC 방식을 선정하고 메모리의 크기를 지정한다.   이때 서버가 여러 대이면 서버에 GC 옵션을 서로 다르게 지정해서 GC 옵션에 따른 차이를 확인하는 것이 중요하다.   (4) 결과 분석      운이 좋으면 해당 시스템에 가장 적합한 GC 옵션을 찾을 수 있지만 그렇지 않다면   로그를 분석해 메모리가 어떻게 할당되는지 확인해야 한다.   그 다음에 GC 방식 / 메모리 크기를 변경해 가면서 최적의 옵션을 찾아 나간다.   (5) 결과가 만족스러울 경우 전체 서버에 반영 및 종료                1, 2 단계 : GC 상황 모니터링 및 결과 분석하기   다음의 조건에 모두 부합한다면 GC 튜닝이 필요 없다.      Minor GC의 처리 시간이 빠르다.   Minor GC 주기가 빈번하지 않다.   Full GC의 처리 시간이 빠르다.   Full GC 주기가 빈번하지 않다.   주의할 점은 GC 상황을 확인할 때 시간만 보면 안 된다는 점이다.   GC 가 수행되는 횟수도 확인해야 한다.       3.1 단계 : GC 방식 지정   Serial GC는 운영에서 사용하지 못해 제외되고, JDK 7이 아니면 G1 GC도 제외되어      Parallel GC, Parallel Compacting GC, CMS GC 중에서 하나를 선택해야 한다.   가장 좋은 방법은 세 가지 방식을 모두 적용해 보는 것이다.   일반적으로 CMS GC가 다른 Parallel GC 보다 작업 속도가 빠르다.   하지만 항상 빠른 것은 아니다.    Concurrent mode failure 이 발생하면 다른 Parallel GC 보다 느려진다.      Concurrent mode failure 이란?   Parallel GC와 CMS GC의 가장 큰 차이점은 압축(Compaction) 작업 여부이다.      압축 작업은 메모리 할당 공간 사이에 사용하지 않는 빈 공간이 없도록 옮겨서 메모리 단편화를 제거하는 작업이다.   CMS GC는 메모리에 빈 공간이 여기저기 생긴다. 그렇기 때문에 크기가 큰 객체가 들어갈 수 있는 공간이 없을 수도 있다.         예를들어, Old 영역에 남아 있는 크기가 300MB 인데도 10MB짜리 객체가 연속적로 들어갈 공간이 없을 수 있다.   그럴 때 Concurrent mode failure 라는 경고가 발생하면서 압축 작업을 수행한다.   그런데, CMS GC를 사용할 때는 압축 시간이 다른 Parallel GC 보다 더 오래 소요된다.   그래서 오히려 더 문제가 될 수 있다.                  3.2 단계 : 메모리 크기   메모리 크기와 GC 발생 횟수, GC 수행 시간의 관계는 다음과 같다.   - 메모리 크기가 크면,     GC 발생 횟수는 감소한다.   GC 수행 시간은 길어진다.   - 메모리 크기가 작으면,     GC 발생 시간는 짧아진다.   GC 수행 횟수는 증가한다.   메모리 크기를 크게 설정할 것인지, 작게 설정할 것인지에 대한 정답은 없다.                4단계 : GC 튜닝 결과 분석  분석할 때에는 다음의 사항을 중심으로 살펴보는 것이 좋다.      GC 옵션을 결정하는 데 가장 큰 비중을 차지하는 것은 1번 항목인 Full GC 수행 시간이다.      Full GC 수행시간   Minor GC 수행시간   Full GC 수행간격   Minor GC 수행간격   전체 Full GC 수행시간   전체 Minor GC 수행시간   전체 GC 수행시간   Full GC 수행횟수   Minor GC 수행횟수       운이 좋아서 한 번에 가장 적합한 GC 옵션을 찾으면 좋지만, 그렇지 못한 경우가 대부분이다.      한 번에 끝내려다가 잘못하면 서비스에 OutOfMemoryError가 발생할 수 있으니 조심해서 GC 튜닝을 진행하는 것이 좋다.                같이 보면 좋은 GC 관련 블로그 글     https://hyerin6.github.io/2020-03-23/GC/   https://hyerin6.github.io/2020-03-23/GC(2)/   ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-08/%EC%9E%90%EB%B0%94%EC%84%B1%EB%8A%A5%ED%8A%9C%EB%8B%9D-GC/",
        "teaser": null
      },{
        "title": "자바 객체지향의 원리와 이해 (1)",
        "excerpt":"OOP란?    Object Oriented Programming = 객체 지향 프로그래밍   컴퓨터 프로그램을 “객체(Object)”들의 모임으로 파악하고자 하는 프로그래밍의 패러다임 중에 하나이다.     각 “객체(Object)” 들은 서로 메시지를 주고 받을 수 있으며 데이터를 처리할 수 있다.   OOP 장점          프로그램을 유연하고 변경이 용이하게 만든다.            프로그램의 개발과 보수를 간편하게 만든다.            직관적인 코드 분석을 가능하게 한다.       자바와 절차적 / 구조적 프로그래밍   JVM의 존재와 역할을 아는 것이 자바 개발 환경을 이해하는 데 필수적이다. JVM은 이름 그대로 가상기계다.    현실 세계에서 컴퓨터를 구동하기 위해서는 물리적 컴퓨터인 하드웨어와 운영체제, 그리고 그 위에서 구동될 소프트웨어가 필요하다.   거기에 더해 소프트웨어를 개발할 수 있는 개발 도구가 필요하다. 자바의 가상 세계는 다음과 같이 현실 세계를 모방하고 있다.   현실 세계 -&gt; 가상 세계(자바 월드)             소프트웨어 개발 도구 -&gt; JDK : 자바 개발 도구     운영체제 -&gt; JRE : 자바 실행 환경     하드웨어(물리적 컴퓨터) -&gt; JVM : 자바 가상 기계   현실 세계에서 소프트웨어, 즉 프로그램은 개발자가 개발 도구를 이용해 개발하고 운영체제를 통해 물리적 컴퓨터인 하드웨어 상에서 구동된다.   자바가 만들어 주는 가상 세계도 이와 마찬가지다.   자바 개발 도구인 JDK를 이용해 개발된 프로그램은 JRE에 의해 가상의 컴퓨터인 JVM 상에서 구동된다.      JDK는 자바 소스 컴파일러인 java.exe를 포함하고 있고 JRE는 자바 프로그램 실행기인 java.exe를 포함하고 있다.          자바 개발자는 본인이 사용 중인 플랫폼에 설치된 JVM용으로 프로그램을 작성하고 배포하면         각 플랫폼에 맞는 JVM이 중재자로서 각 플랫폼에서 프로그램을 구동하는 데 아무 문제가 없게끔 만들어주는 것이다.   JDK: Java Development Kit / 자바 개발 도구    JRE: Java Runtime Environment / 자바 실행 환경     JVM: Java Virtual Machine / 자바 가상 기계   main() 메서드 : 메서드 스택 프레임  main() 메서드는 프로그램이 실행되는 시작점이다.   main() 메서드가 실행될 때 메모리, 특히 T 메모리에서 어떤 일이 일어날까?   JRE는 먼저 프로그램 안에 main() 메서드가 있는지 확인한다.   main() 메서드가 확인되면, JRE는 프로그램 실행을 위한 사전 준비에 착수한다.   JVM에 전원을 넣어 부팅하는 것이다.   JVM은 부팅되면 목적 파일을 받아 실행시킨다.   JVM이 맨 먼저 하는 일을 전처리 과정이라고 하는데,   모든 자바에 반드시 포함되는 패키지가 있다. java.lang   JVM은 가장 먼저 java.lang 패키지를 T 메모리의 스태틱 영역에 가져다 놓는다.   main() 메서드가 실행되기 전 JVM에서 수행하는 전처리 작업들은 다음과 같다.           java.lang 패키지 T 메모리의 스태틱 영역에 배치하기            import된 패키지를 T 메모리의 스태틱 영역에 배치하기            프로그램 상의 모든 클래스를 T 메모리의 스태틱 영역에 배치하기       main() 메서드가 끝나면 JRE는 JVM을 종료하고 JRE 자체도 운영체제 상의 메모리에서 사라진다.   T 메모리도 사라지게 된다.   T 메모리 소멸, JVM 기동 중지, JRE가 사용했던 시스템 자원 운영체제에 반납   T 메모리의 힙 영역은 다음에 같이 공부하기로 하자.   지역 변수와 메모리 : 스택 프레임이 갇혔어요 !   변수는 메모리에 있다.   지역 변수, 클래스 멤버 변수, 객체 멤버 변수로 다른 목적을 갖고 있는데   스태틱 영역, 스택 영역, 힙 영역 각각 있는 곳도 다르다.   클래스 멤버 변수는 스태틱 영영에 한번 자리 잡으로 JVM이 종료될 때까지 고정된(static)  상태로 그 자리를 지킨다.   객체 멤버 변수는 힙에서 일생을 보낸다.   객체와 함께 가비지 컬렉터라고 불리는 메모리 회수기에 의해 일생을 마치게 된다.   한 가지 기억할 결론은   외부 스택 프레임에서 내부 스택 프레임의 변수에 접근하는 것은 불가능하지만   그 역은 가능하다.   멀티 스레드 / 멀티 프로세스의 이해   멀티 스레드의 T 메모리 모델은 스택 영역을 스레드 개수만큼 분할해서 쓰는 것이다.      멀티 프로세스는 다수의 데이터 저장 영역, 즉 다수의 T 메모리를 갖는 구조이다.   멀티 프로세스는 각 프로세스마다 각자의 T 메모리가 있어   각자 고유의 공간이므로 서로 참조할 수 없다.     멀티 스레드는 하나의 T 메모리만 사용하는데 스택 영역만 분할해서 사용하는 구조이다.     그래서 하나의 스레드에서 다른 스레드의 스택 영역에는 접근할 수 없지만 스태틱 영역과 힙 영역은 공유해서 사용하는 구조다.   따라서 멀티 프로세스 대비 멀티 스레드는 메모리를 적게 사용할 수 있는 구조이다.   자바와 객체 지향   객체 지향의 4대 특성 - 캡! 상추다     캡슐화(Encapsulation) : 정보 은닉 (information hiding)   상속 : 재사용   추상화(Abstraction) : 모델링   다형성(Polymorphism) : 사용 편의   추상화는 모델링이다.  추상화란 구체적인 것을 분해해서 관찰자가 관심 있는 특성만 가지고 재조합하는 것이라고 정리할 수 있다.   중요한 부분만 적어보자.     OOP의 추상화는 모델링이다.   클래스 : 객체 = 펭귄 : 뽀로로   클래스 설계에서 추상화가 사용된다.   클래스 설계를 위해서는 애플리케이션 경계부터 정해야 한다.   객체 지향에서 추상화의 결과는 클래스이다.   추상화를 넓게 본다면 아래의 내용도 포함이다.     상속을 통한 추상화, 구체화   인터페이스를 통한 추상화   다형성을 통한 추상화   상속 : 재상용 + 확장  상속 관계에서 반드시 만족해야 할 문장이 있다.     하위 클래스는 상위 클래스다.   예를들어, 조직도와 분류도로 나눠 생각해보자.   조직도     아버지는 할아버지다??   아들은 아버지다??   위 예시는 이상하다.   분류도     포유류는 동물이다.   고래는 포유류다.   고래는 동물이다.   자연스러운 예시이다.   “하위 클래스는 상위 클래스다.” 라는 문장과 객체지향 설계 5원칙 중 LSP를 나타내는 말이다.   마지막으로 정리해보자.     객체 지향의 상속은 상위 클래스의 특성을 재사용하는 것이다.   객체 지향의 상속은 상위 클래스의 특성을 확장하는 것이다.   객체 지향의 상속은 is a kind of 관계 (-는 -의 한 분류이다.)를 만족해야 한다.   다중 상속과 자바  왜 자바는 다중 상속을 지원하지 않을까?   인어공주를 예로 들어보자.   인어는 사람과 물고기를 상속한다고 생각해보자.      물고기와 사람은 수영을 할 수 있다.     그런데 인어에게 “수영해!” 라고 했을 때, 인어는 팔과 다리로 헤엄칠까 아니면 지느러미로 헤엄칠까..?        어떤 부모의 헤엄 방법을 사용해야 하는지 충돌이 일어났다.   이와 같은 문제를 다중 상속의 다이아몬드 문제라고 한다.          결국 자바는 인터페이스를 도입해 다중 상속의 득은 취하고 실은 과감히 버렸다.   상속과 인터페이스  그럼 인터페이스는 왜 다중 상속이 가능할까?          인터페이스는 ‘무엇을 할 수 있는’ 이라는 표현의 형태로 만들어져   기능에 대한 선언만 있기 때문에 다중 상속에서 전혀 문제될게 없다.   그렇가면 아래의 문제들에는 어떤게 정답일까?     상위 클래스는 하위 클래스에게 물려줄 특성이 많을수록 좋을까? 적을수록 좋을까?   인터페이스는 구현을 강제할 메서드가 많을수록 좋을까? 적을수록 좋을까?   정답은,    상위 클래스는 물려줄 특성이 많으면 많을수록 좋고   인터페이스는 구현을 강제할 메서드의 수가 적은게 좋다.   상위 클래스가 풍성할수록 좋은 이유는 LSP 에 따른 이유이고,    인터페이스 메서드가 적을수록 좋은 이유는 ISP에 따른 이유라고 할 수 있다.   객체 지향 설계 5원칙 보러가기   캡슐화 : 정보 은닉  자바에서 정보 은닉이라고 하면 접근 제어자들이 생각난다.      private : 본인만 접근 가능   default : 같은 패키지 내의 클래스에서 접근 가능   protected : 상속, 같은 패키지 내의 클래스에서 접근 가능   public : 모두가 접근 가능   단순하게 마무리 해보자면,           객체 멤버의 접근 제어자   자신의 멤버가 아닌 다른 객체의 멤버에 접근하는 경우에 다른 객체를 생성한 후 접근해야 한다.            정적 멤버는 클래스명.정적멤버 형식으로 접근하는 것을 권장한다.       참조 변수의 복사   기본 자료형 변수를 복사하는 경우 Call By Value (값에 의한 호출)에 의해 그 값이 복사되며   두 개의 변수는 서로에게 영향을 주지 않는다.   그렇다면 기본 자료형이 아닌 객체를 저장하고 있는 객체 참조 변수를 복사하는 경우는 어떨까?   기본 자료형 변수는 저장하고 있는 값을 그 값 자체로 해석하는 반면,   객체 참조 변수는 저장하고 있는 값을 주소로 해석한다는 차이가 있다.   마지막으로 정리해보면,     기본 자료형 변수는 값을 값 자체로 판단한다.   참조 자료형 변수는 값을 주소로 판단한다.   기본 자료형 변수를 복사할 때, 참조 자료형 변수를 복사할 때 일어나는 일은 같다.   즉, 가지고 있는 값을 그대로 복사해서 넘겨 준다.   ","categories": ["Spring","Java"],
        "tags": ["java","spring"],
        "url": "/2020-06-09/%EC%8A%A4%ED%94%84%EB%A7%81%EC%9E%85%EB%AC%B8%EC%9D%84%EC%9C%84%ED%95%9C(1)/",
        "teaser": null
      },{
        "title": "자바 객체지향의 원리와 이해 (2)",
        "excerpt":"자바가 확장한 객체 지향   abstract 키워드 - 추상 메서드와 추상 클래스   동물 클래스가 있고 동물의 울음소리를 출력하는 추상 메서드인 울어보세요() 라는 메소드가 있다고 하자.     오리, 말, 고양이, 강아지 등의 동물들은 동물 클래스를 상속받아서 울음소리를 출력해야 한다.   우리에게는 두 문제가 있다.     동물 객체는 어떻게 울어야 하지? / 누가 실수로 동물 객체를 만들면 어떡하지?   동물 참조 변수 배열로 모든 동물을 울게 하려면 하위 클래스에서 오버라이딩할 울어보세요() 메서드가 동물 클래스에 필요한데..   이 두 문제가 추상 메서드와 추상 클래스로 한 번에 해결된다.    그뿐만 아니라 만약 동물을 상속한 하위 클래스가 울어보세요() 메서드를 오버라이딩하지 않으면   컴파일 시점에서 에러가 발생한다.   abstract 키워드에 대한 내용을 정리하면 다음과 같다.           추상 클래스는 인스턴스, 즉 객체를 만들 수 없다.            추상 메서드는 하위 클래스에게 메서드의 구현을 강제한다. 오버라이딩 강제            추상 메서드를 하나라도 포함하고 있는 클래스는 반드시 추상 클래스여야 한다.       생성자   클래스의 인스턴스, 즉 객체를 만들 때마다 new 키워드를 사용한다.      우선 기억해야 할 자바의 특징이 있다.      개발자가 아무런 생성자도 만들지 않으면 자바는 인자가 없는 기본생성자를 자동으로 만들어준다.   인자가 있는 생성자를 하나라도 만들면 자바는 기본 생성자를 만들어주지 않는다.   생성자는 개발자가 필요한 만큼 오버로딩해서 만들 수 있다.          또한, 우리는 생성자라고 줄여서 부르지만 정확히는 객체 생성자 메서드임을 잊지 말자.   클래스 생성 시의 실행 블록, static 블록   객체가 생성자가 있는 것이지 클래스 생성자는 없다.           그러나 클래스가 스태틱 영역에 배치될 때 실행되는 코드 블록이 있다. 바로 static 블록이다.   static 블록에서 사용할 수 있는 속성과 메서드는 당연하게 static 멤버 뿐이다.    예전에 작성한 게시글을 보면 이해할 수 있다.    T 메모리를 보면 객체 멤버에 접근할 방법이 없음을 알 수 있다.   객체 멤버는 클래스가 static 영역에 자리 잡은 후에 객체 생성자를 통해 힙에 생성된다.              클래스의 static 블록이 실행되고 있을 때는 해당 클래스의 객체는 하나도 존재하지 않기 때문에                 static 블록에서는 객체 멤버에 접근할 수 없다.   당연한 이야기지만 어떤 클래스에 static 블록이 있으면,       그 블록은 객체가 생성될 때 실행되고 인스턴스 여러 개가 만들어져도 static 블록은 한 번만 실행된다.   클래스가 제일 처음 사용될 떄는 다음 중 하나이다.     클래스의 정적 속성을 사용할 때   클래스의 정적 메서드를 사용할 때   클래스의 인스턴스를 최초로 만들 때   왜 프로그램이 실행될 때 바로 클래스들의 정보를 T 메모리의 static 영역에 로딩하지 않고   해당 클래스가 처음 사용될 때 로딩할까?     스태틱 영역도 메모리이기 때문이다. 메모리는 최대한 늦게 사용을 시작하고 최대한 빨리 반환하는 것이 정석이다.   final 키워드   final 키워드가 나타날 수 있는 곳은 딱 세 군데다.   클래스, 변수, 메서드           final과 클래스   상속을 허락하지 않겠다는 의미다.            final과 변수   변경 불가능한 상수이다.            final과 메서드  재정의, 즉 오버라이딩을 금지한다.       interface 키워드와 implements 키워드   인터페이스는 public 추상 메서드와 public 정적 상수만 가질 수 있다.   그래서 인터페이스는 메서드에 public과 abstract,       속성에 public과 static, final을 붙이지 않아도 자동으로 자바가 알아서 붙여준다.   this 키워드   this는 객체가 자기 자신을 지칭할 때 쓰는 키워드다.       아래 내용을 기억해두자.           지역 변수와 속성의 이름이 같은 경우 지역 변수가 우선이다.            객체 변수와 이름이 같은 지역 변수가 있는 경우 객체 변수를 사용하려면 this를 접두사로 사용한다.            정적 변수와 이름이 같은 지역 변수가 있는 경우 정적 변수를 사용하려면 클래스명을 접두사로 사용한다.       super 키워드   바로 위 상위 클래스의 인스턴스를 지칭하는 키워드다.   super 키워드로 바로 위의 상위 클래스 인스턴스에만 접근할 수 있다.   super.super 과 같은 형태는 안된다.   클래스명.객체메서드명()   객체 메서드를 호출할 때 스택 정보를 보면     객체명.객체메서드명()이 아닌 클래스명.객체메서드명()임을 확인할 수 있다.   만약 객체가 a[100] 처럼 요소가 100개인 배열이라면 힙 영역에 생기는 객체는 100개가 되고   메서드도 각 객체에 따라 100개가 만들어져야 한다.   하지만 메서드가 객체에 따라 달라지는 것은 아니다. 객테 멤버 메서드에서 사용하는 객체 멤버 속성의 값만 다를 뿐이다.   메서드를 힙 영역에 100개나 만드는 것은 심각한 메모리 낭비라고 할 수 있다.   그래서 JVM은 객체 멤버 메서드를 스태틱 영역에 단 하나만 보유한다.   그리고 눈에 보이지는 않지만 메서드를 호출할 때 객체 자신을 나타내는 this 객체 참조 변수를 넘긴다.   ","categories": ["Spring","Java"],
        "tags": ["java","spring"],
        "url": "/2020-06-09/%EC%8A%A4%ED%94%84%EB%A7%81%EC%9E%85%EB%AC%B8%EC%9D%84%EC%9C%84%ED%95%9C(2)/",
        "teaser": null
      },{
        "title": "Java8: optional, interface, lambda, stream",
        "excerpt":"Lambda   자바 8은 많은 변화를 맞이했다.   특히 함수형 프로그래밍 지원을 위한 람다의 도입이 두드러진다.       람다가 도입된 이유   핫해진 용어 가운데 빅데이터가 있다.    프로그래머들에게 빅데이터를 프로그램적으로 다룰 수 있는 방법이 필요해졌다.       그래서 멀티 코어를 활용한 분산 처리 즉, 병렬화 기술이 필요해졌다.   하나의 CPU안에 다수의 코어를 삽입하는 멀티 코어 프로세서들이 등장하면서   프로그래머들에게 병렬화 프로그래밍에 대한 필요성이 생기기 시작했다.   자바 8에서는 병렬화를 위해 컬렉션(배열, List, Map, Set)을 강화했고,   이러한 컬렉션을 더 효율적으로 사용하기 위해 스트림(Stream)을 강화했다.   또 스트림을 효율적으로 사용하기 위해 함수형 프로그래밍이,   다시 함수형 프로그래밍을 위해 람다가, 람다를 위해 인터페이스의 변화가 수반됐다.   람다를 지원하기 위한 인터페이스를 함수형 인터페이스라고 한다.   (위 설명에서 ‘~를 위해 ~가 생겼다.’ 가 무조건 그렇다는 것은 아니다.)       Lambda 람다란 무엇인가?   코드 블럭을 변수처럼 사용할 수 있다는 것이다.   별도의 클래스 정의 없이 코드 블록인 메서드를 사용하고자 할 때 많이 사용되던 익명 객체를 사용하는 방법이다.   자바 8에서는 익명 객체조차 없이 바로 코드 블록만 사용하면 된다.   class myTest implements Runnable {             public void run() {         System.out.println(\"Hello Lambda!\");     }        }                   기존 방식으로 Runnable 인터페이스 구현체를 사용하는 코드이다.   main 메서드에서 MyTest 클래스 객체를 생성하여 run() 메서드를 호출한다.       기존 방식의 코드 블록을 사용해보자. - 익명 객체 생성   public static void main(String[] args) {     Runnable r = new Runnable() {         public void run() {             System.out.println(\"Hello Lambda!\");         }        };          r.run(); }   별도의 클래스 정의 없이 코드 블록인 메서드를 사용하고자 할 때 많이 사용되던 익명 객체를 사용하는 방법이다.    자바 8에서는 더 나은 방법을 사용할 수 있다.   즉, 익명 객체조차 없이 바로 코드 블록만 사용하면 된다.       새로운 방식의 코드 블록 사용 - lambda   Runnable r = () -&gt; {        System.out.println(\"Hello Lambda!\");     }     Runnable 타입으로 참조 변수 r을 만들고 있으니 new Runnable()은 컴파일러가 알아낼 수 있다.   굳이 코드로 작성할 필요가 없다.   마지막으로 화살표 기호 -&gt;   이는 람다의 구조가 다음과 같기 때문에 추가되었다.   (인자목록) -&gt; { 로직 }       함수형 인터페이스  추상 메서드를 하나만 갖는 인터페이스를 자바 8부터 함수형 인터페이스라고 한다.   함수형 인터페이만 람다식으로 변경할 수 있다.   main.java   MyFunctionalInterface mfi = (int a) -&gt; { return a * a; };   MyFunctionalInterface.java   @FunctionalInterface   interface MyFunctionalInterface {      public abstract int runSomething(int count); }   @FunctionalInterface 어노테이션을 붙이는 것은 옵션이다.   이 어노테이션이 붙은 경우 컴파일러는   인터페이스가 함수형 인터페이스의 조건에 맞는지 검사한다.   즉, 단 하나의 추상 메서드만 갖고 있는지 확인한다.   가장 간단하게 구현하는 방법은 다음과 같다.   MyFunctionalInterface mfi = a -&gt; a * a;        메서드 호출 인자로 람다 사용   람다식을 변수에 저장하는 것이 가능하다면 당연히 메서드의 인자로도 사용할 수 있다.   람다식을 단 한번만 사용한다면 굳이 변수에 할당할 필요도 없이   인자로 넘겨주면 된다.   doIt(a -&gt; a*a);       메서드 반환값으로 람다 사용   public static MyFunctionalInterface todo() {     reutrn num -&gt; num * num; }       컬렉션 스트림에서 람다 사용   람다는 다양한 용도가 있지만 그 중에서도 컬렉션 스트림을 위한 기능에 크게 초점이 맞춰져 있다.   컬렉션 스트림과 람다를 통해 더 적은 코드로 더 안정적인 코드를 만들어 보자.   예제 : 컬렉션 스트림을 활용해서, age 배열에서 20세 미만인 사람들을 거르는 상황을 구현해보자.   Arrays.stream(ages)       .filter(age -&gt; age &lt; 20)       .forEach(age -&gt; System.out.fomat(\"Age %d ! Can't enter\\n\", age));   예제에서 기존 for, if를 사용하는 것보다 좋아진 점은 How가 아닌 What을 지정했다는 것이다.   함수형 프로그래밍의 장점인 선언적 프로그래밍을 활용하는 것이다.     ‘어떻게 하라’를 명령하는게 아니라 ‘무엇을 원한다’라고 선언하는 것과 같다.   또한 스트림은 메서드 체인 패턴을 이용해 최종 연산이 아닌 모든 중간 연산은 다시 스트림으로 반환해   코드를 간략하게 작성할 수 있게 지원한다.       메서드 레퍼런스와 생성자 레퍼런스   위 스트림, 람다 예제에서 아래 코드로도 구현할 수 있다.   Arrays.stream(ages)       .sorted()       .forEach(System.out:println);   이 코드를 람다식으로 표현하면 다음과 같다.   Arrays.stream(ages)       .sorted()       .forEach(age -&gt; System.out.println(age));   위 람다식은 인자를 아무런 가공없이 그대로 출력한다.   이런 코드를 사용할 때 메서드 레퍼런스라고 하는 간략한 형식을 사용할 수 있다.     메서드 레퍼런스에는 다음과 같은 세 가지 유형이 있다.           인스턴스::인스턴스메서드    람다식의 인자는 인스턴스 메서드의 인자가 된다.            클래스::정적메서드   람다식의 인자는 정적 메서드의 인자가 된다.            클래스::인스턴스메서드   람다의 첫 번째 인자는 인스턴스가 되고        그 다음 인자(들)은 인스턴스 메서드의 인자(들)가 된다.       마지막으로 메서드 레퍼런스와 유사한 생성자 레퍼런스가 있다.   클래스::new   예제를 통해 사용법을 알아보자.   B016 b = B016::new; // ERROR  Supplier&lt;B016&gt; factory = B016::new; // OK      첫 번째 코드에서 ERROR가 발생하는 이유는          생성자 레퍼런스로 생성한 것은 B016 클래스의 객체가 아니라         함수형 인터페이스 구현 객체이기 때문이다.   기본 생성자(인자가 없는 생성자)이기에              이를 만족하는 Supplier 함수형 인터페이스를 사용해 생성자 자체에 대한 참조가 만들어진다.       인터페이스의 디폴트 메서드와 정적 메서드   자바 8 이전에는 인터페이스가 가질 수 있는 멤버는 다음과 같다.     정적 상수   추상 인스턴스 메서드   그런데 자바 8에서는 인터페이스에 큰 변화가 있었다.   자바 8에서 인터페이스가 가질 수 있는 멤버는 다음과 같다.     정적 상수   추상 인스턴스 메서드   구체 인스턴스 메서드 - 디폴트 메서드   (구체) 정적 메서드   이제 인터페이스도 몸체를 가진 인스턴스 메서드를 가질 수 있게 됐다.   이를 디폴트 메서드라고 하고 default 키워드를 메서드 정의에 사용한다.   또한, (구체) 정적 메서드를 가질 수 있게 되었고 static 키워드를 메서드 정의에 사용하면 된다.       자바 8에서 언어적으로 가장 큰 변화를 꼽으라면 바로 인터페이스의 스펙 변화를 꼽을 수 있다.   이로 인해 람다가 가능해졌고, 연쇄적으로 더 강화된 컬렉션 API를 사용할 수 있게 됐을뿐만 아니라       함수형 프로그래밍이 가능해졌기 때문이다.   그럼 왜 인터페이스에 디폴트 메서드와 정적 메서드를 추가한걸까?   컬렉션 API를 강화하면서 컬렉션의 공통 조상인 Collection의 슈퍼 인터페이스인 스 Iterable 인터페이스에는 많은 변화가 필요했다.   한 예로 내부 반복을 가능하게 하는 forEach의 도입이 있다.  그런데 인터페이스에 변화를 주게 되면,     즉 새로운 추상 인스턴스 메서드를 추가하게 되면      기존에 해당 인터페이스를 구현한 모든 사용자 정의 클래스는 이를 추가적으로 구현해야만 한다.   이전 JDK를 기반으로 작성된 프로그램도 자바 8 JVM에서 구동될 수 있게       디폴트 메서드라고 하는 새로운 개념을 인터페이스 스펙에 추가한 것이다.       Stream   간결하게 컬렉션의 데이터를 처리하는 기능이다.   // Before       List&lt;Shape&gt; list = new ArrayList&lt;Shape&gt;();            for (Shape s : shapes) { \tif (s.getColor() == RED) { \t\tlist.add(s); \t} }   // After shapes.stream().filter(s -&gt; s.getColor() == Red).collect(toList());                  Stream API : 병렬 연산을 지원하는 스트림이라는 새로운 API           스크림이란 한번에 한개씩 만들어지는 연속적인 데이터 항목들의 모임이다.            스트림 파이프라인을 이용해서 입력부분을 여러 CPU 코어에 쉽게 할당할 수 있다.       (Thread Safe한 병렬성을 얻을 수 있다.)           Parallel Stream     Stream을 병렬로 처리가능하도록 하는 기능이다.   여러 쓰레드에서 처리할 수 있도록 분할한 Stream 이다.   shapes.parallelStream().forEach(s -&gt; doSomething());         Optional   간단하게 아래와 같이 설명할 수 있다.     값을 Optional로 캡슐화하여 NullPointerException을 막는다.   값이 존재한다면 Optional 클래스는 값을 감싼다.   값이 없다면 Optional.empty 메서드로 Optional을 리턴한다.   변수의 값이 null인지 아닌지 확인하는 것을 더 간결하게 구현하고자   자바 8에서는 Optional 인터페이스가 추가되었다.   JPA Repository의 findOne, findById 등 메소드의 리턴타입이       엔터티 클래스이어도 되고, Optional 이어도 된다.   Student findOne(int id); Optional&lt;Student&gt; findById(int id);   리턴 값이 Student 인 경우에, 해당 학생이 존재하지 않을 경우에, null 이 리턴된다.   리턴 값이 Optional인 경우에, 해당 학생이 존재하지 않을 경우에는,         내부 값이 비어있는 Optional 객체가 리턴된다.         내부 값이 비어 있는 경우에, Optional 객체의 ifPresent() 메소드는 false를 리턴한다.        내부 값이 들어있는 경우에, Optional 객체의 get() 메소드는 그 값을 리턴한다.   Optional - 오라클 공식 문서 보러가기       @RequestMapping(\"findOne/{id}\")   public Music findOne(@PathVariable(\"id\") String id) {       Optional&lt;Music&gt; result=musicService.findById(id);            return result.orElse(new Music());       }   만약 findById 메소드의 리턴 타입이 다음과 같았다면,            Music findById(Stirng id);   액션 메소드의 마지막 return 문은 다음과 같아야 한다.            return result == null ? new Misuc() : result;   위와 같이, null 인지 아닌지 검사하는 코드를 간결하게 구현하기 위해서,              Optional 을 사용한다.   JPA Repository   Student findById(int id); Optional&lt;Student&gt; findById(int id); // 최신 버전  Student findOne(int id); Optional&lt;Student&gt; findOne(int id); // 최신 버전   서비스나 컨트롤러에서   Student student = studentRepository.findOne(id); // 과거 코드  Optional&lt;Student&gt; result = studentRepository.findOne(id); // 최신 코드 Student student = result.orElse(new Student()); // 최신 코드   model.addAttribute(\"student\", studentRepository.findOne(id)); // 과거 model.addAttribute(\"student\", studentRepository.findOne(id).orElse(new Student())); // 최신   // StudentService.java public Student findById(int id) {     return studnetRepository.findById(id).orElse(new Student()); }  // StudentController.java  model.addAttribute(\"studnet\", studentService.findById(id));   ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-10/java8/",
        "teaser": null
      },{
        "title": "자바 객체지향의 원리와 이해 (3)",
        "excerpt":"Ioc/DI : 제어의 역전/의존성 주입      의존성은 new 이다.   전체가 부분에 의존한다.   자동차가 생성되고 내부적으로 타이어를 생산한다고 가정하자.   자동차 클래스 내부에 Tire 속성이 있다.      자동차 클래스의 생성자에서 타이어를 생산한다.     new Tire() 에서 타이어를 생산하는 new 부분에서 의존 관계가 일어나고 있다.   결론은 다음과 같다.     자동차는 타이어에 의존한다.   운전자는 자동차를 사용한다.   운전자는 자동차에 의존한다고 할 수 있다.       스프링 없이 의존성 주입하기 1 - 생성자를 통한 주입   운전자가 자동차를 생산하면서 타이어를 장창한다고 가정하자.    Car car = new Car(tire);   주입이란, 외부에서라는 말을 내포하고 있다.    외부에서 생산된 타이어를 자동차에 장착하는 작업이 주입이다.   앞서 Car 객체가 Tire를 직접 생산하는 것은            Tire에 대한 의존성을 자체적으로 해결하는 방식이었다.   이번에는 외부에서 생산된 tire 객체를 자동차 생성자의 인자로 주입(장착)하는 형태로 구현해보자.   달라지는 것은 자동차의 생성자에 인자가 생기는 것이다.   변경된 코드에서의 장점은     기존에는 Car가 구체적으로 한국 타이어를 생산할지 미국 타이어를 생산할지 결정했다.   그러면 코드는 유연성이 떨어진다.   Car는 한국 타이어와 미국 타이어에 대해 정확히 알고 있어야만 그에 해당하는   객체를 생성할 구 있었다.   의존성 주입을 적용할 경우, 그저 Tire 인터페이스를 구현한 어떤 객체가 들어오면 정상적으로 작동된다.   의존성을 주입할 경우 확장성도 좋아지는데, Car.java 코드를 변경할 필요도 없어진다.   실제 제품화하게 되면 더 많은 코드를 재배포할 필요가 없도록 구성해야 코드 재컴파일과 재배포에 대한 부담을 줄일 수 있다.   이것은 인터페이스를 구현(준수)했기에 얻는 이점이라고 볼 수 있다.   표준화했다고 이해하면 될것이다.       스프링 없이 의존성 주입하기2 - 속성을 통한 의존성 주입   자바로 표현 - 속성 접근자 메서드 사용   Tire tire = new KoreaTire();   Car car = new Car();   car.setTire(tire);       생성자를 통해 의존성을 주입하는 것은 교체의 방법이 없다.   이러한 문제점을 해결하기 위해 속성을 통한 의존성 주입이 필요하다.   그러나 최근 속성을 통한 의존성 주입보다 생성자를 통한 의존성 주입을 선호하는 사람들이 많은데,    이는 프로그램에서는 한번 주입된 의존성을 계속 사용하는 경우가 더 일반적이기 때문이다.       스프링을 통한 의존성 주입 - XML 파일 사용   다음과 같은 시나리오를 갖는다고 가정하자.     운전자가 종합 쇼핑몰에서 타이어를 구매한다.   운전자가 종합 쇼핑몰에서 자동차를 구매한다.   운전자가 자동차에 타이어를 장착한다.   스프링을 통한 의존성 주입은 생성자를 통한 의존성 주입과 속성을 통한 의존성 주입을 모두 지원하는데   속성을 통한 의존성 주입만 살펴보자.   스프링을 도입해서 달라지는 것은 Driver.java 클래스와 스프링 설정 파일 하나를 추가해 주는 것 뿐이다.   종합 쇼핑몰의 역할이 스프링 프레임워크라고 생각하면 된다.       그래서 Driver.java 에 상품을 구매할 종합 쇼핑몰에 대한 정보가 필요한 것이다.   XML 파일에 상품을 등록해놓는데.    상품을 등록할 때 bean 태그를 이용해 등록한다.   각 상품을 구분하기 위한 id 속성과 그 상품을 어떤 클래스를 통해        생산(인스턴스화) 해야 할지 나타내는 class 속성을 함께 지정하면 된다.   KoreaTire.java가 XML 파일에서 id=tire인 bean 태그와 연결돼 있고,   Driver.java 의 main() 메서드에서 아래 코드로 연결돼 있는 것을 볼 수 있다.   context.getBean(\"tire\", Tire.class);        위 코드는 아래와 같이 해석된다.    “KoreaTire라고 하는 상품이 tire라는 이름으로 진열돼 있고, 구매(getBean)할 수 있다.”   스프링을 도입해서 얻는 이득은 무엇일까?          가장 큰 이득은 자동차의 타이어 브랜드를 변경할 때        그 무엇도 재컴파일/재배포하지 않아도 XML 파일만 수정하면 프로그램의 실행 결과를 바꿀 수 있다는 것이다.       스프링을 통한 의존성 주입 - 스프링 설정 파일(XML)에서 속성 주입   XML 파일에 property 속성을 사용해보자.   자바에서 접근자 및 설정자 메서드를 속성 메서드라고 하는데 영어로 속성은 property다.   결국 car.setTire(tire)라고 하던 부분을 XML 파일의 property 태그를 이용해 대체하는 것이다.   그래서 Driver.java 에는 Car car = context.getBean(\"car\", Car.class); 코드만 남는다.       스프링을 통한 의존성 주입 - @Autowired 를 통한 속성 주입   반드시 설정자 메서드를 통해서 Tire 값을 주입해야 하는 걸까?     스프링의 속성 주입 방법 가운데 @Autowired를 이용하는 방법을 살펴보자.   @Autowired의 의미를 이해해보자.    이것은 스프링 설정 파일을 보고 자동으로 속성의 설정자 메서드에 해당하는   역할을 해주겠다는 의미이다.   이렇게 구현하면 XML 설정 파일에서 property 태그가 필요없다.    @Autowired를 통해 자동으로 엮어줄 수 있기(의존성 주입) 때문이다.   (1) 그렇가면 AmericaTire로 변경해서 사용하려면 어떻게 해야할까?    bean 태그의 class 속성을 AmericaTire로 변경한다.   (2) KoreaTire 부분을 완전히 삭제하고, AmaricaTire의 bean 태그에서 id를 삭제하면 어떻게 될까?    정상적으로 구동된다.   빈의 id 속성이 없는데 어떻게 매칭된걸까?   @Autowired는 type 기준 매칭이 우선되기 때문이다.       만약 같은 타입으로 구현한 클래스가 여러 개 있다면 그때 빈 태그의 id로 구분하여 매칭한다.             type을 구현한 빈이 있고 하나라면 그 유일한 빈을 객체에 할당한다.       스프링을 통한 의존성 주입 - @Resource를 통한 속성 주입   @Resource 는 자바 표준 어노테이션이다.   매칭 우선순위는 @Autowired 다르게 id가 더 높다.       마무리     변수에 값을 할당하는 모든 곳에 의존 관계가 생긴다.   의존 대상이 내부에 있을 수도, 외부에 있을 수도 있다.   DI는 외부에 있는 의존 대상을 주입하는 것을 말한다.   의존 대상을 구현하고 배치할 때 SOLID 와 응집도는 높이고 결합도는 낮추라는 기본 원칙에 충실해야 한다.   그래야 프로젝트의 구현과 유지보수가 수월해진다.       AOP - Aspect? 관점? 핵심 관심사? 횡단 관심사?   AOP 글 보러가기       PSA (Potable Service Abstraction) 일관성있는 서비스 추상화   PSA는 일관성 있는 추상화이다.   서비스 추상화의 예로 JDBC를 들 수 있다. JDBC라고 하는 표준 스펙이 있기 때문에 오라클을 사용하든, MySQL을 사용하든,       Connection, Statement, ResultSet을 이용해 공통된 방식으로 코드를 작성할 수 있다.     데이터베이스 종류에 관계없이 같은 방식으로 제어할 수 있는 이유는 어댑터 패턴을 활용했기 때문이다.     이처럼 어댑터 패턴을 적용해 같은 일을 하는 다수의 기술을 공통의 인터페이스로 제어할 수 있게한 것을 서비스 추상화라고 한다.   스프링은 ORM, 캐시, 트랜잭션 등 다양한 기술에 대한 PSA를 제공한다.      ","categories": ["Spring","Java"],
        "tags": ["java","spring"],
        "url": "/2020-06-10/%EC%8A%A4%ED%94%84%EB%A7%81%EC%82%BC%EA%B0%81%ED%98%95/",
        "teaser": null
      },{
        "title": "Process & Thread",
        "excerpt":"프로세스와 스레드                      멀티 스레드                동기와 비동기의 차이                  synchronized &amp; volatile   프로세스와 스레드   프로세스   일반적으로 CPU에 의해 처리되는 사용자 프로그램, 시스템 프로그램 즉 실행중인 프로그램을 의미하며,  작업(Job) 태스크(Task)라고도 한다.   즉 프로세스는 운영체제로부터 자원을 할당받는 작업이 단위이다.   프로그램에서 프로세스로 메모리에 올라올 때 운영체제로부터 프로세스를 운영하기 위해   필요한 주소 공간, 메모리(Text, Data, Heap, Stack 공간)을 부여 받는다.   스레드   한 프로세스 내에서 동작되는 여러 실행의 흐름으로,         프로세스 내의 주소 공간이나 자원들을 같은 프로세스 내의 스레드끼리 공유하며 실행된다.   스레드는 프로세스 내에서 각각의 스택 공간을 제외한 나머지 공간과 시스템 자원을 공유한다.   프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모도 현격히 줄어들게 된다.   하나의 프로세스에서 여러 스레드가 존재하게 되니 스레드 간의 통신이 필요한 경우 별도의 자원을 이용하는 것이 아니라   메모리 공간을 공유하므로 데이터 세그먼트, 즉 전역 변수를 이용하여 구현한다.   그런데 전역 변수를 여러 스레드가 함께 사용하게 되면 충돌이 발생하게 되서 동기화 문제를 해결해야 한다.   스레드 사용 이유   하나의 프로세스에 1 ~ N 개의 스레드가 생성된다.       스레드는 가벼운 프로세스라고도 불리고 프로세스에서 만들어 사용하고 있는 메모리를 공유한다.   멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행하게 되면 프로세스를 생성하여 자원을 할당하는 과정도 줄어들 뿐더러      프로세스를 컨텍스트 스위칭(Context Switching)하는 것 보다 오버헤드를 더 줄일 수 있게 된다.   뿐만 아니라 프로세스간의 통신 비용보다 하나의 프로세스 내에서 여러 스레드간의 통신 비용이 훨씬 적으므로         작업들 간의 통신 부담을 줄일 수 있게 된다.   프로세스와 스레드의 차이   프로세스와 스레드의 근본적인 차이는 프로세스는 운영체제로부터 독립된 시간, 공간 자원을 할당 받아 실행된다는 점이고,       스레드는 한 프로세스 내에서 많은 자원을 공유하면서 병렬적으로(Concurrently) 실행된다는 것이다.        다른 차이는 모두 이 근본적인 차이에서 비롯된다.   프로세스 / 스레드           자원 할당 여부 : 실행 시마다 새로운 자원을 할당\t/ 자신을 실행한 프로세스의 자원을 공유            자원 공유 여부 : 일반적으로 자원을 공유하지 않는다. 같은 프로그램의 프로세스일 경우 코드를 공유하기는 한다. /        같은 프로세스 내 스레드들은 스택을 제외한 나머지 세 영역을 공유한다.            독립성 여부 : 일반적으로 독립적 / 일반적으로 프로세스의 하위 집합            주소 소유 여부 : 별개의 주소 공간을 갖는다 / 주소 공간을 공유한다.            통신 여부 : 오직 시스템이 제공하는 IPC 방법으로만 통신 / 공유 변수 수정 등 자유롭게 다른 스레드와 소통            Context Switch :  일반적으로 프로세스보다 스레드의 Context Switching이 더 빠를 수 있다.     하지만 상황에 따라 그렇지 않을 수 있다.           멀티 스레드   멀티 스레드는 하나의 프로세스 내에서 둘 이상의 스레드가 동시에 작업을 수행하는 것을 의미한다.          멀티 프로세스(multi process)는 여러 개의 CPU를 사용하여 여러 프로세스를 동시에 수행하는 것을 의미합니다.   멀티 스레드와 멀티 프로세스 모두 여러 흐름을 동시에 수행한다는 공통점이 있다.            그러나 멀티 프로세스는 각 프로세스가 독립적인 메모리를 가지고 별도로 실행되지만,            멀티 스레드는 각 스레드가 자신이 속한 프로세스의 메모리를 공유한다는 점이 다릅니다.      문맥 교환(context switching)   컴퓨터에서 동시에 처리할 수 있는 최대 작업 수는 CPU의 코어(core) 수와 같습니다.               만약 CPU의 코어 수보다 더 많은 스레드가 실행되면,      각 코어가 정해진 시간 동안 여러 작업을 번갈아가며 수행하게 됩니다.   이때 각 스레드가 서로 교체될 때 스레드 간의 문맥 교환(context switching)이라는 것이 발생합니다.      문맥 교환이란 현재까지의 작업 상태나 다음 작업에 필요한 각종 데이터를 저장하고 읽어오는 작업을 가리킵니다.   이러한 문맥 교환에 걸리는 시간이 커지면 커질수록, 멀티 스레딩의 효율은 저하됩니다.      오히려 많은 양의 단순한 계산은 싱글 스레드로 동작하는 것이 더 효율적일 수 있습니다.   따라서 많은 수의 스레드를 실행하는 것이 언제나 좋은 성능을 보이는 것은 아니라는 점을 유의해야 합니다.       동기와 비동기   동기 (synchronous)   동시에 일어난다는 뜻으로 요청과 그 결과가 동시에 일어난다는 것이다.   시간이 얼마가 걸리던지 요청한 자리에서 결과가 주어져야 한다.   요청한 결과가 한 자리에서 동시에 일어난다.  = A노드와 B노드 사이의 작업 처리 단위(transaction)을 동시에 맞춘다.   예를들어,            어떤 객체 또는 함수 내부에서 다른 함수를 호출했을 때          이 함수의 결과를 호출한 쪽에서 처리하면 동기입니다.   일반적으로 싱글 스레드를 사용한 처리방식이 이에 해당한다.   비동기 (Asynchronous)   동시에 일어나지 않는다를 의미한다. 요청과 결과가 동시에 일어나지 않는다.   요청한 그 자리에서 결과가 주어지지 않음   = 노드 사이의 작업 처리 단위를 동시에 맞추지 않아도 된다.   예를들어,           어떤 객체 또는 함수 내부에서 다른 함수를 호출했을 때        이 함수의 결과를 호출한 쪽에서 처리하지 않으면 비동기입니다.   동기와 비동기의 차이   동기방식은 매우 설계가 간단하고 직관적이지만     결과가 주어질 때까지 아무것도 못하고 대기해야 한다는 단점이 있다.   비동기방식은 좀 더 복잡하지만 결과가 주어지는 시간이 길어져도 그 시간 동안 다른 작업을 할 수 있어서  좀 더 효율적으로 자원을 사용할 수 있는 장점이 있다.   작업 요청한 스레드가 결과를 받을 때까지 멈추느냐 아니냐의 차이가 있다.      단, 싱글 스레드의 경우 작업을 요청한 스레드에서 처리해야 하므로 스레드가 멈추지는 않는다.   블로킹 (Blocking)   네트워크 통신에서 요청이 발생하고 완료될 때까지 모든 일을 중단한 상태로   대기해야 하는 것을 블로킹 방식이라고 한다.   자신의 수행결과가 끝날 때까지 제어권을 갖고 있는 것을 의미한다.   작업이 끝날 때까지 대기했다가 결과를 반환 받아서 처리한다.   논블로킹 (Non-blocking)   자신이 호출되었을 때 제어권을 바로 자신을 호출한 쪽으로 넘겨  자신을 호출한 쪽에서 다른 일을 할 수 있도록 하는 것이다.   예를들어, setTimeout(hyerin, 300) 함수를 호출했을 떄   3초 후에 hyerin() 함수가 호출되는데 제어권을 반납했기 떄문에    3초 동안 다른 일을 수행할 수 있다.   네트워크 통신이 완료될 때까지 기다리지 않고 다른 작업을 수행할 수 있어        경우에 따라 효율이나 반응속도가 뛰어나다.         반면 설계가 복잡해진다는 단점이 있다.       synchronized &amp; volatile   synchronized   하나의 객체에 여러 객체가 동시에 접근하여 처리하는 상황이 발생할 때 사용한다.      생성자의 식별자로는 사용할 수 없다.   하나의 객체를 여러 스레드에서 동시에 사용할 경우   static으로 선언한 객테를 여러 스레드에서 동시에 사용할 경우   JVM 내에서 synchronization은 어떻게 동작할까?   자바의 HotSpot VM은 ‘자바 모니터’를 제공함으로써 스레드들이 ‘상호 배제 프로토콜’에 참여할 수 있도록 돕는다.   자바 모니터는 잠긴 상태(lock)나 풀림(unlocked) 중 하나이며, 동일한 모니터에 진입한 여러 스레드들 중에서   한 시점에서 단 하나의 스레드만 모니터를 가질 수 있다.   모니터를 가진 스레드만 모니터에 의해서 보호되는 영역에 들어가서 작업을 할 수 있다.       여기서 보호된 영역이란 앞서 설명한 synchronized 로 감싸진 블록들을 의미한다.   모니터를 보유한 스레드가 보호 영역에서의 작업을 마치면, 모니터는 다른 대기중인 스레드에게 넘어간다.   volatile   volatile 키워드는 java 변수를 메인 메모리에 저장하겠다는 것을 명시하는 것이다.   매번 변수의 값을 read할 때마다 CPU cache에 저장한 값이 아닌 메인 메모리에서 읽는 것이다.   또한 write 할 때도 메인 메모리에 작성한다.   Q. 왜 volatile 키워드가 필요할까?   volatile 변수를 사용하고 있지 않은 멀티 스레드 어플리케이션에서는 Tack를 수행하는 동안   성능 향상을 위해 메인 메모리에서 읽은 변수 값을 CPU cache에 저장하게 된다.   만약에 멀티 스레드 환경이라면 스레드가 변수 값을 읽어올 때   각각의 CPU cache에 저장된 값이 다르기 때문에 변수 값 불일치 문제가 발생하게 된다.   volatile 키워드를 추가하게 되면 메인 메모리에 저장하고 읽어오기 때문에         변수 값 불일치 문제를 해결할 수 있다.   Q. 언제 volatile이 적합할까?   멀티 스레드 환경에서 하나의 스레드만이 read&amp;write하고 나머지 스레드가 read하는 상황에서   가장 최신의 값을 보장해야 할 때 volatile를 사용해야 한다.   여러 스레드가 write 하는 상황에서는     synchronized 를 통해 변수 read&amp;write의 원자성을 보장해야 한다.   Q. volatile는 성능에 어떤 영향이 있을까?   volatile는 변수의 read와 write를 메인 메모리에서 진행하게 된다.       CPU cache보다 메인 메모리가 비용이 더 크기 때문에       변수 값 일치를 보장해야 하는 경우에만 volatile를 사용하는 것이 좋다.   ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2020-06-12/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80%EC%8A%A4%EB%A0%88%EB%93%9C/",
        "teaser": null
      },{
        "title": "토비의 스프링 (4)",
        "excerpt":"예외의 종류와 특징   예외를 어떻게 다뤄야 할까?    가장 큰 이슈는 체크 예외라고 불리는 명시적인 처리가 필요한 예외를 사용하고 다루는 방법이다.   자바에서 throw를 통해 발생시킬 수 있는 예외는 크게 세 가지가 있다.          Error   첫째는 java.lang.Error 클래스의 서브클래스들이다. 에러는 시스템에 뭔가 비정상적인 상황이 발생했을 경우에 사용된다.   주로 자바 VM에서 발생시키는 것이고 애플리케이션 코드에서 잡으려고 하면 안 된다.   OutOfMemoryError나 ThreadDeath같은 에러는 catch 블록으로 잡아봤자 아무런 대응 방법이 없기 때문이다.   따라서 시스템 레벨에서 특별한 작업을 하는 게 아니라면 애플리케이션에서는 이런 에러에 대한 처리는 신경 쓰지 않아도 된다.          Exception과 체크 예외   java.lang.Exception 클래스와 그 서브클래스로 정의되는 예외들은 에러와 달리   개발자들이 만든 애플리케이션 코드의 작업 중에 예외상황이 발생했을 경우에 사용된다.   Exception 클래스는 다시 체크 예외와 언체크 예외로 구분된다.   전자는 Exception 클래스의 서브클래스이면서 RuntimeException 클래스를 상속하지 않은 것들이고,   후자는 RuntimeException을 상속한 클래스들을 말한다.   RuntimeException은 Exception의 서브클래스이므로 Exception의 일종이긴 하지만  자바는 이 RuntimeException과 그 서브클래스는 특별하게 다룬다.   일반적으로 예외라고 하면 Exception 클래스의 서브클래스 중에서 RuntimeException을 상속하지 않은 것만을 말하는   체크 예외라고 생각해도 된다.   체크 예외가 발생할 수 있는 메소드를 사용할 경우 반드시 예외를 처리하는 코드를 함께 작성해야 한다.   그렇지 않으면 컴파일 에러가 발생한다.          RuntimeException과 언체크/런타임 예외   java.lang.RuntimeException 클래스를 상속한 예외들은   명시적인 예외처리를 강제하지 않기 때문에 언체크 예외라고 불린다.   또는 대표 클래스 이름을 따서 런타임 예외라고도 한다.   에러와 마찬가지로 이 런타임 예외는 catch 문으로 잡거나 throws로 선언하지 않아도 된다.   물론 명ㅁ시적으로 잡거나 throws로 선언해도 상관없다.   런타임 예외는 주로 프로그램의 오류가 있을 떄 발생하도록 의도된 것들이다.   대표적으로 오브젝트를 할당하지 않은 레퍼런스 변수를 사용하려고 시도했을 때 발생하는 NullException이나,   허용되지 않는 값을 사용해서 메소드를 호출할 때 발생하는 IllegalArgumentException 등이 있다.   이런 예외는 코드에서 미리 조건을 체크하도록 주의 깊게 만든다면 피할 수 있다.     피할 수 있지만 개발자가 부주의해서 발생할 수 있는 경우에 발생하도록 만든 것이 런타임 예외이다.   따라서 런타임 예외는 예상하지 못했던 예외상황에서 발생하는 게 아니기 때문에        굳이 catch나 throws를 사용하지 않아도 되도록 만든 것이다.       예외처리 방법      예외 복구   첫 번째 예외처리 방법은 예외상황을 파악하고 문제를 해결해서 정상 상태로 돌려놓는 것이다.   사용자에게 상황을 알려주고 다른 작업 흐름으로 자연스럽게 유도해서 예외상황을 해결하는 방법이다.   네트워크가 불안해서 가끔 서버에 접속이 잘 안되는 열악한 환경에 있는 시스템이라면   원격 DB 서버에 접속하다 실패해서 SQLException이 발생하는 경우에 재시도를 해볼 수 있다.   네트워크 접속이 원활하지 않아서 예외가 발생했다면 일정 시간 대기했다가 다시 접속을 시도해보는 방법을 사용해서   예외상황으로부터 복구를 시도할 수 있다.    물론 정해진 횟수만큼 재시도해서 실패했다면 예외 복구는 포기한다.          예외처리 회피   두 번째 방법은 예외처리를 자신이 담당하지 않고 자신을 호출한 쪽으로 던져버리는 것이다.   throws 문으로 선언해서 예외가 발생하면 알아서 던져지게 하거나 catch 문으로 일단 예외를 잡은 후에   로그를 남기고 다시 예외를 던지는 것이다.   빈 catch 블록으로 잡아서 예외가 발생하지 않은 것처럼 만드는 경우는, 드물지만 특별한 의도를 가지고 예외를 복구했거나   아무 개념이 없어서 그런 것이지 회피한 것은 아니다.   예외처리를 회피하려면 반드시 다른 오브젝트나 메소드가 예외를 대신 처리할 수 있도록 던져줘야 한다.   예외를 회피하는 것은 예외를 복구하는 것처럼 의도가 분명해야 한다.   콜백/템플릿처럼 긴밀한 관계에 있는 다른 오브젝트에게 예외처리 책임을 분명히 지게 하거나,   자신을 사용하는 쪽에게 예외를 다루는 게 최선의 방법이라는 분명한 확신이 있어야 한다.          예외 전환   마지막으로 예외를 처리하는 방법은 예외 전환을 하는 것이다.   예외 회피와 비슷하게 예외를 복구해서 정상적인 상태로는 만들 수 없기 때문에 예외를 메소드 밖으로 던지는 것이다.   하지만 에외회피와는 달리 발생한 예외를 그대로 넘기는 게 아니라 적절한 예외로 전환해서 던진다는 특징이 있다.   보통 두 가지 목적으로 사용된다.   (1) 내부에서 발생한 예외를 그대로 던지는 것이 그 예외상황에 대한 적절한 의미를 부여해주지 못하는 경우,   의미를 분명하게 해줄 수 있는 예외로 바꿔주기 위해서이다.   보통 전환하는 예외에 원래 발생한 예외를 담아서 중첩 예외로 만드는 것이 좋다.   (2) 예외를 처리하기 쉽고 단순하게 만들기 위해 포장하는 방법이 있다.    중첩 예외를 이용해 새로운 예외를 만들고 원인이 되는 예외를 내부에 담아서 던지는 방식은 같다.   하지만 의미를 명확하게 하려고 전환하는 것이 아니다.   주로 예외처리를 강제하는 체크 예외를 언체크 에외인 런타임 예외로 바꾸는 경우에 사용한다.   대표적으로 EJBException을 들 수 있다. EJB 컴포넌트 코드에서 발생하는 대부분의 체크 예외는   비즈니스 로직으로 볼 때 의미 있는 예외이거나 복구 가능한 예외가 아니다.   이런 경우에는 런타임 예외인 EJBException으로 포장해서 던지는 편이 낫다.   RuntimeException클래스를 상속한 런타임 예외라서   런타임 예외로 만들어서 전달하면 EJB는 이를 시스템 익셉션으로 인식하고 트랜잭션을 자동으로 롤밷해주기 때문이다.   반대로 애플리케이션 로직상에서 예외조건이 발견되거나 예외상황이 발생할 수도 있다.   이런 것은 API가 던지는 예외가 아니라 애플리케이션 코드에서 의도적으로 던지는 예외이다.   이때는 체크 예외를 사용하는 것이 적절하다.      비즈니스적인 의미가 있는 예외는 이에 대한 적절한 대웅이나 복구 작업이 필요하기 때문이다.       예외처리의 전략      런타임 예외의 보편화   일반적으로 체크 예외가 일반적인 예외를 다루고, 언체크 예외는 시스템장애나 프로그램상의 오류에 사용된다고 했다.   문제는 체크 예외는 복구할 가능성이 조금이라도 있는 예외적인 상황이기 때문에 자바는 이를 처리하는 catch 블록이나   throws 선언을 강제하고 있다는 것이다.   하지만 자바 엔터프라이즈 서버환경에서 수만은 사용자가 동시에 요청을 보내고 각 요청이 독립적인 작업으로 취급된다.      하나의 요청을 처리하는 중에 예외가 발생했다면 해당 작업만 중지시키면 되지만,    서버의 특정 계층에서 예외가 발생할 때 작업을 일시 중지하고 사용자와 바로 커뮤니케이션하면서 예외상활을 복구할 수 있는 방법이 없다.   차라리 애플리케이션 차원에서 예외상황을 미리 파악하고, 예외가 발생하지 않도록 차단하는 것이 좋다.   자바의 환경이 서버로 이동하면서 체크 예외의 활용도와 가치는 점점 떨어지고 있다.   자칫하면 throws Exception으로 아무런 의미도 없는 메소드들을 낳을 뿐이다.   그래서 대응이 불가능한 체크 예외라면 빨리 런타임 예외로 전환해서 던지는 게 낫다.          애플리케이션 예외   시스템 또는 외부의 예외상황이 아니라 애플리케이션 자체의 로직에 의해 의도적으로 발생시키고,   반드시 catch 해서 무엇인가 조치를 취하도록 요구하는 예외도 있다.   이런 예외들을 일반적으로 애플이케이션의 예외라고 한다.   예를들어, 사용자가 요청한 금액을 계좌에서 출금하는 기능을 가진 메서드를 구현한다고 생각해보자.  계좌에 남아있는 금액보다 더 큰 금액을 출금하려고 한다면 출금 작업은 중단되어야 한다.   이런 기능을 담은 메소드를 설계하는 방법 두 가지가 있다.   1. 정상적인 출금처리를 했을 경우와 잔고 부족이 발생했을 경우에 각각 다른 종류의 리턴 값을 돌려주는 것   이렇게 리턴 값으로 결과를 확인하고 예외상황을 체크하면 불편한 점이 있다.   우선 예외상황에 대한 리턴 값을 명확하게 코드화하고 잘 관리하지 않으면 혼란이 생길 수 있다.   사전에 상수로 정의해둔 표준 코드를 사용하지 않는다면 자칫 개발자 사이의 의사소통 문제로 인해 제대로 작동하지 않을 위험이 있다.   또 한가지 문제는 조건문이 너무 자주 등장한다는 것이다.   코드는 지저분해지고 흐름을 파악하고 이해하기가 힘들어질 것이다.   2. 정상적인 흐름을 따르는 코드는 두고, 잔고 부족과 같은 예외 상황에서는 비즈니스적인 의미를 띤 예외를 던지도록 만드는 것이다.   잔고 부족인 경우라면 InsufficientBalanceException 등을 던진다.   예외상황을 처리하는 catch 블록을 메소드 호출 직후에 둘 필요는 없다.     정상적인 흐름을 따르지만 예외가 발생할 수 있는 코드를 try 블록 안에 깔끔하게 정리해두고     예외상황 처리는 catch 블록에 모아둘 수 있기 떄문에 코드를 이해하기도 편하다.   이때 사용하는 예외는 의도적으로 체크 예외로 만든다.    그래서 개발자가 잊지 않고 자주 발생 가능한 예외상황에 대한 로직을 구현할 수 있도록     강제해주는 게 좋다.   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-06-13/exception/",
        "teaser": null
      },{
        "title": "토비의 스프링 (3)",
        "excerpt":"3장 템플릿   확장에는 자유롭게 열려 있고 변경에는 굳게 닫혀 있다는 객체지향 설계의 핵심 원칙인   개방 폐쇄 원칙을 다시 생각해보자.   이 원칙은 코드에서 어떤 부분은 변경을 통해 그 기능이 다양해지고 확장하려는 성질이 있고,   어떤 부분은 고정되어 있어 변하지 않으려는 설징이 있음을 말해준다.   변화의 특성이 다른 부분을 구분해주고, 각각 다른 목적과 다른 이유에 의해 다른 시점에 독립적으로 변경될 수 있는         효율적인 구조를 만들어주는 것이 바로 이 개방 폐쇄 원칙이다.   템플릿이란 이렇게 바뀌는 성질이 다른 코드 중에서 변경이 거의 일어나지 않으며 일정한 패턴으로   유지되는 특성을 가진 부분을 자유롭게 변경되는 성질을 가진 부분으로부터 독립시켜   효과적으로 활용할 수 있도록 하는 방법이다.       분리와 재상용을 위한 디자인 패턴 적용   다음은 개선할 deleteAll() 메서드이다.   Connection c = null; PreparedStatement ps = null;     try {     c = dataSource.getConnection();      ps = c.prepareStatement(\"delete from users\"); // 변하는 부분       ps.executeUpdate(); } catch (SQLException e) {     throw e; } finally {     if(ps != null) { try { ps.close(); }  catch (SQLException e) {} }     if(c != null) { try { c.close(); }  catch (SQLException e) {} } }   변하는 부분을 재외하면 나머지 코드는 변하지 않는다.   이 로직에 따라 변하는 부분을 변하지 않는 나머지 코드에서 분리하는 것이 어떨까?     변하지 않는 부분을 재사용할 수 있는 부분이 있지 않을까?       메소드 추출   먼저 생각해볼 수 있는 방법은 변하는 부분을 메소드로 빼는 것이다.   자주 바뀌는 부분을 메서드로 독립시키는 것은 별 이득이 없어 보인다.   왜냐면 보통 메소드 추출 리팩토링을 적용하는 경우에는 분리시킨 메서드를 다른 곳에서 재사용할 수 있어야 하는데   반대로 분리시키고 남은 메서드가 재사용이 필요한 부분이기 때문이다.           분리된 메서드는 DAO 로직마다 새롭게 만들어서 확장돼야 하는 부분이기 때문에 뭔가 반대로 됐다.       템플릿 메소드 패턴의 적용   템플릿 메서드 패턴은 상속을 통해 기능을 확장해서 사용하면 된다.   변하는 부분을 추상 메서드로 정의해두고 서브클래스에서 재정의하여 사용하면 된다.   하지만 템플릿 메서드 패턴으로서의 접근은 제한이 많다.   가장 큰 문제는 DAO 로직마다 상속을 통해 새로운 클래스를 만들어야 한다는 점이다.   만약 이런 방식으로 구현한다면 JDBC 메서드가 4개일 경우 4개의 서브 클래스를 만들어서 사용해야 한다.   두 번째 문제는 확장구조가 이미 클래스를 설계하는 시점에서 고정되어 버린다는 점이다.   변하지 않는 코드와 서브 클래스들(변하는 코드)이 이미 클래스 레벨에서 컴파일 시점에 이미 그 관계가 결정되어 있다.   따라서 그 관계에 대한 유연성이 떨어져 버린다.   상속을 통해 확장을 꾀하는 템플릿 패턴의 단점이 고스란히 드러난다.       전략 패턴 사용   개방 폐쇄 원칙을 잘 지키는 구조이면서도 템플릿 메서드 패턴보다 유연하고 확장성이 뛰어난 것이,    오브젝트를 아예 둘로 분리하고 클래스 레벨에서는 인터페이스를 통해서만 의존하도록 만드는 전략 패턴이다.   전략 패턴은 OCP 관점에 보면 확장에 해당하는      변하는 부분을 별도의 클래스로 만들어 추상화된 인터페이스를 통해 위임하는 방식이다.   c = dataSource.getConnection();  StatementStrategy strategy = new DeleteAllStatement(); ps = strategy.makePreparedStatement(c);   위 코드는 그럭저럭 전략 패턴을 적용한 것으로 볼 수 있다.   하지만 전략 패턴은 필요에 따라 컨텍스트는 그대로 유지되면서 전략을 바꿔쓸 수 있어야 한다.   이렇게 컨텍스트 안에서 이미 구체적인 전략 클래스인 DeleteAllStatement를 사용하도록 고정되어 있다면 뭔가 이상하다.    전략 패턴과 OCP에 잘 들어맞지 않는다.       DI 적용을 위한 클라이언트 / 컨텍스트 분리   문제를 해결하기 위해 전략 패턴의 실제적인 사용 방법을 더 살펴보자.   전략 패턴에 따르면 Context가 어떤 전략을 사용하게 할 것인지는 Context를 사용하는 앞단의 Client가 결정하는 게 일반적이다.      Client가 구체적인 전략의 하나를 선택하고 오브젝트를 만들어서 Context에 전달하는 것이다.   결국 전략 오브젝트 생성과 컨텍스트로의 전달을 담당하는 책임을 분리시킨 것이 바로 ObjectFactory이며   이를 일반화한 것이 이전 장에서 살펴봤던 의존관계 주입(DI)이었다.   DI란 이러한 전략 패턴의 장점을 일반적으로 활용할 수 있도록 만든 구조라고 볼 수 있다.   의존관계 주입(DI)은 다양한 형태로 적용할 수 있다.   가장 중요한 개념은 제 3자의 도움을 통해 두 오븢게트 사이의 유연한 관계가 설정되도록 만든다는 것이다.       전략과 클리이언트의 동거   지금까지 공부한 내용으로 구현한 코드에 더 개선할 부분이 있다.      DAO 메서드마다 새로운 StatementStrategy 구현 클래스를 만들어야 한다는 점이다.    이렇게 되면 기존 UserDao 때보다 클래스 파일의 개수가 더 늘어난다.   이래서는 런타임 시에 다이내믹하게 DI해준다는 점을 제외하면 로직마다 상속을 사용하는   템플릿 메서드 패턴을 적용했을 때보다 그다지 나을 게 없다.      DAO 메서드에서 StatementStrategy에 전달할 User와 같은 부가적인 정보가 있는 경우,                이를 위해 오브젝트를 전달받는 생성자와 이를 저장해둘 인스턴스 변수를 번거롭게 만들어야 한다는 점이다.   이 오브젝트가 사용되는 시점은 컨텍스트가 전략 오브젝트를 호출할 때라서 잠시라도 어딘가에 다시 저장해둘 수밖애 없다.   이 문제점들을 해결해보자.       로컬 클래스   클래스 파일이 많아지는 문제점은 간단하게 해결할 수 있다.   내부 클래스로 정의해버리는 것이다.   마치 로컬 변수를 선언하듯이 사용하면 된다.   로컬 클래스는 선언된 메서드 내에서만 사용할 수 있다.   메서드 안에서 클래스 생성 로직을 함께 볼 수 있어 코드를 이해하기 좋고,   내부 클래스이기 때문에 자신이 선언된 곳의 정보에 접근할 수 있다.   다만, 내부 클래스에서 외부의 변수를 사용할 때는 외부 변수는 반드시 final로 선언해야 한다.       익명 내부 클래스   더 욕심을 내보자면, 더 간결하게 클래스 이름도 제거할 수 있다.   new 인터페이스이름() { 클래스 본문 };         컨텍스트와 DI   JdbcContext의 분리   전략 패턴의 구조로 보자면 UserDao의 메소드가 클라이언트고, 익명 내부 클래스로 만들어지는 것이 개별적인 전략이고         JdbcContextWithStatementStrategy() 메서드는 컨텍스트이다.   컨텍스트 메서드는 UserDao 내의 PreparedStatement를 실행하는 기능울 가진 메서드에서 공유할 수 있다.   그런데 JdbcContextWithStatementStrategy()는 다른 DAO에서도 사용 가능하다.    밖으로 독립시켜 모든 DAO가 사용할 수 있게 해보자.   분리해서 만든 클래스는 JdbcContextfkrh gkwk.   JdbcContext에 UserDao에 있던 컨텍스트 메서드를 workWithStatementStrategy()라는 이름으로 옮겨놓는다.   JdbcContext가 DataSource에 의존하고 있으므로 DataSource 타입 빈을 DI 받을 수 있게 해줘야 한다.       빈 의존관계 변경   새롭게 변경된 의존관계를 살펴보자.   UserDao는 이제 JdbcContext에 외존한다. 그런데 JdbcContext는 인터페이스인 DataSource와는 달리 구체 클래스다.   스프링 DI는 기본적으로 인터페이스를 사에이 두고 의존 클래스를 바꿔서 사용할 수 있도록 하는 게 목적이다.          하지만 이 경우 JdbcContext는 그 자체로 독립적인 JDBC 컨텍스트를 제공해주는 서비스 오브젝트로서 의미가 있을 뿐이고         구현 방법이 바뀔 가능성은 없다.   따라서 인터페이스를 구현하도록 하지 않았고, UserDaodjl JdbcContext는 인터페이스를 사이에 두지 않고 DI를 적용하는 특별한 구조가 되었다.       스프링 빈으로 DI   JdbcContext를 UserDao와 DI 구조로 만들어야 할 이유를 생각해보자.           JdbcContext가 스프링 컨테이너의 싱글톤 레지스트리에서 관리되는 싱글톤 빈이 되기 때문이다.            JdbcContext가 DI를 통해 다른 빈에 의존하고 있기 때문이다.     JdbcContext는 dataSource 프로퍼티를 통해 DataSource 오브젝트를 주입받도록 되어 있다.   DI를 위해서는 주입되는 오브젝트와 주입받는 오브젝트 양쪽 모두 스프링 빈으로 등록돼야 한다.       스프링이 생성하고 관리하는 IoC 대상이어야 DI에 참여할 수 있기 떄문이다.      따라서 JdbcContext가 다른 빈을 받기 위해서라도 스프링 빈으로 등록돼야 한다.   왜 인터페이스를 사용하지 않았을까?   인터페이스가 없다는 건 UserDao와 JdbcContext가 매우 긴밀한 관계를 가지고          강하게 결합되어 있다는 것이다.   클래스는 구분되어 있지만 강한 응집도를 갖고 있다.   JDBC 방식 대신 JPA나 하이버네이트 같은 ORM을 사용해야 한다면 JdbcContext도 통쨰로 바뀌어야 한다.   이런 경우는 굳이 인터페이스를 두지 말고 강력한 결합을 가진 관계를 허용하면서 위에서 말한 두 가지 이유인,   싱글톤으로 만드는 것과 JdbcContext에 대한 DI 필요성을 위해 스프링의 빈으로 등록해서 UserDao에 DI되도록 만드는 것도 좋다.   단, 이런 클래스를 바로 사용하는 코드 구성을 DI에 적용하는 것은 가장 마지막 단계에서 고려해볼 사항이다.       템플릿과 콜백   전략 패턴은 바뀌지 않는 일정한 패턴을 갖는 작업 흐름이 존재하고 그중 일부분만 자주 바꿔서 사용해야 하는 경우에 적합한 구조다.         전략 패턴의 기본 구조에 익명 내부 클래스를 활용한 방식이다.    이런 방식을 스프링에서는 템플릿/콜백 패턴이라고 부른다.      전략 패턴의 컨텍스트를 템플릿이라 부르고, 익명 내부 클래스로 만들어지는 오브젝트를 콜백이라고 부른다.       템플릿/콜백의 동작원리   템플릿은 고정된 작업 흐름을 가진 코드를 재사용한다는 의미에서 붙인 이름이다.       콜백은 템플릿 안에서 값을 참조하기 위한 것이 아니라 특정 로직을 담는 것을 목적으로     호출되는 오브젝트를 말한다.   템플릿 메서드 패턴은 고정된 틀의 로직을 가진 템플릿 메소드를 슈퍼클래스에 두고,        바뀌는 부분을 서브 클래스의 메서드에 두는 구조로 이뤄진다.      템플릿/콜백의 특징   전략 패턴의 전략은 여러 개의 메소드를 가진 일반적인 인터페이스를 사용할 수 있다.   템플릿/콜백 패턴의 콜백은 보통 단일 메소드 인터페이스를 사용한다.   작업 흐름 중 특정 기능을 위해 한 번 호출되는 경우가 일반적이기 때문이다.   하나의 템플릿 안에서 여러 전략을 사용한다면 하나 이상의 콜백 오브젝트를 사용할 수도 있다.   콜백은 일반적으로 하나의 메서드를 가진 인터페이스를 구현한 익명 내부 클래스로 만들어진다고 보면된다.   콜백 인터페이스의 메서드에는 보통 파라미터가 있다.   이 파라미터는 템플릿의 작업 흐름 중에 만들어지는 컨텍스트 정보를 전달받을 때 사용된다.      템플릿/콜백의 작업 흐름           클아이언트의 역할은 템플릿 안에서 실행될 로직을 담은 콜백 오브젝트를 만들고,    콜백이 참조할 정보를 제공하는 것이다.   만들어진 콜백은 클라이언트가 템플릿의 메소드를 호출할 때 파라미터로 전달된다.            템플릿은 정해진 작업 흐름을 따라 작업을 진행하다가 내부에서 생성한 참조정보를 가지고 콜백 오브젝트의 메소드를 호출한다.   콜백은 클라이언트 메서드에 있는 정보와 템플릿이 제공한 참조정보를 이용해서 작업을 수행하고 그 결과를 다시 템플릿에 돌려준다.            템플릿은 콜백이 돌려준 정보를 사용해서 작업을 마저 수행한다.        경우에 따라 최종 결과를 클라이언트에 다시 돌려주기도 한다.       복잡한 과정같지만 DI 방식의 전략 패턴 구조로 보면 간단하다.   클라이언트가 템플릿 메소드를 호출하면서 콜백 오브젝트를 전달하는 것은 메소드 레벨에서 일어나는 DI이다.   일반적인 DI는 의존 오브젝트를 수정자 메서드로 받아서 사용할 것인데   템플릿/콜백 방식에서는 매번 메서드 단위로 사용할 오브젝트를 받는 것이 특징이다.   콜백 오브젝트가 내부 클래스로서 자신을 생성한 클라이언트 메소드 내의 정보를 직접 참조한다는 것도 템플릿/콜백의 고유한 특징이다.     클라이언트와 콜백이 강하게 결합된다는 면에서도 일반적인 DI와 조금 다르다.   이 패턴에 녹아있는 전략 패턴과 수동 DI 를 이해할 수 있어야 한다.       템플릿/콜백의 응용   고정된 작업 흐름을 갖고 있으면서 여기저기서 자주 반복되는 코드가 있다면,   중복되는 코드를 분리할 방법을 생각해보는 습관을 기르자.   먼저 메소드로 분리할 방법을 생각해보고,     그중 일부 작업을 필요에 따라 바꾸어 사용해야 하나면     인터페이스를 사이에 두고 분리해서 전략 패턴을 적용하고 DI로 의존관계를 관리하도록 만든다.   그런데 바뀌는 부분이 한 애플리케이션 안에서 동시에 여러 종류가 만들어질 수 있다면   템플릿/콜백 패턴을 적용하는 것을 고려해볼 수 있다.   가장 전형적인 템플릿/콜백 패턴의 후보는 try/catch/finally 블록을 사용하는 코드다.       정리           JDBC와 같은 예외가 발생할 가능성이 있으면 공유 리소스의 반환이 필요한 코드는 반드시 try/catch/finally 블록으로 관리해야 한다.            일정한 작업 흐름이 반복되면서 그중 일부 기능만 바뀌는 코드가 존재한다면 전략 패턴을 적용한다.   바뀌지 않는 부분은 컨텍스트로 바뀌는 부분은 전략으로 만들고 인터페이스를 통해 유연하게 전략을 변경할 수 있도록 구성한다.            같은 애플이케이션 안에서 여러 가지 종류의 전략을 다이내믹하게 구성하고 사용해야 한다면 컨텍스트를 이용하는   클라이언트 메서드에서 직접 전략을 제공하게 만든다.            클라이언트 메소드 안에 익명 내부 클래스를 사용해서 전략 오브젝트를 구현하면 코드도 간결해지고 메소드의 정보를 직접 사용할 수 있어서 편리하다.            컨텍스트가 하나 이상의 클라이언트 오브젝트에서 사용된다면 클래스를 분리해서 공유하도록 만든다.            컨텍스트는 별도의 빈으로 등록해서 DI 받거나 클라이언트 클래스에서 직접 생성해서 사용한다.   클래스 내부에서 컨텍스트를 사용할 때 컨텍스트가 의존하는 외부의 오브젝트가 있다면 코드를 이용해서 직접 DI 해줄 수 있다.            단일 전략 메소드를 갖는 전략 패턴이면서 익명 내부 클래스를 사용해서 매번 전략을 새로 만들어 사용하고,   컨텍스트 호출과 동시에 전략 DI를 수행하는 방식을 템플릿/콜백 패턴이라고 한다.            콜백의 코드에도 일정한 패턴이 반보된다면 콜백을 템플릿에 넣고 재활용하는 것이 편리하다.            템플릿과 콜백의 타입이 다양하게 바뀔 수 있다면 제네릭스를 이용한다.            탬플릿은 한 번에 하나 이상의 콜백을 사용할 수 있고, 하나의 콜백을 여러 번 호출할 수도 있다.            템플릿/콜백을 설계할 때는 템플릿과 콜백 사이에 주고받는 정보에 관심을 둬야 한다.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-06-13/template/",
        "teaser": null
      },{
        "title": "Transaction",
        "excerpt":"Transaction   1. 배경지식   (1) 트랜잭션이란?   트랜잭션이란 더 이상 나눌 수 없는 단위 작업을 말한다.   작업을 쪼개서 작은 단위로 만들 수 없다는 것은 트랜잭션의 핵심 속성인 원자성을 의미한다.   SQL 명령이 DB에서 실행되는 것을 트랜잭션이라고도 한다.     별도로 지정하지 않으면 SQL 명령 하나가 실행되는 것이 하나의 트랜잭션이 된다.   SQL 문장 여러개를 묶어서 하나의 트랜잭션을 만들수도 있다.  예를 들어서 운영체제에서 앱이 실행되는 것을 프로세스(process)라고 부르는 것처럼     DMBS에서 SQL 명령이 실행되는 것은 트랜잭션(transaction)이라고 부른다.   운영체제 프로세스에서 병렬성 문제, 데드락 문제가 발생하는 것과 유사하게   DB 트랜잭션에서도 병렬성 문제, 데드락 문제가 발생한다.       (2) 트랜잭션의 속성      원자성(Atomicity)   트랜잭션 내부 작업들이 부분 성공 부분 실패하는 일 없이, 전체 성공하거나 전체 실패하는 것이 보장된다.   예를들어, 자금 이체는 보내는 쪽에서 돈을 빼는 작업과 받는 쪽에 돈을 넣는 작업 중 하나라도 실패하면 안된다.          일관성(Consistency)   트랜잭션 실행이 성공적으로 완료되면, 데이터베이스 상태는 모순이 없는 상태가 (consistency) 유지됨이 보장된다.   즉 트랜잭션은 데이터베이스 상태를 모순이 있는 (inconsistent) 상태로 변경할 수 없다.          고립성(Isolation)   DB에서 여러 트랜잭션이 동시에 실행되지만, 트랜잭션이 서로 충돌하지 않고, 마치 혼자 실행되는 것과   같은 환경이 보장된다.   예를들어, 두 트랜잭션이 어떤 레코드를 동시에 쓰려고 할 때.   어떤 트랜잭션이 수정하고 있는 레코드를 다른 트랜잭션이 읽으려고 할 때   충돌 없이 여러 트랜잭션이 동시에 잘 실행될 수 있음이 보장된다.          지속성(Durability)   성공적으로 수행 종료된 트랜잭션이 저장한 데이터는 시스템 장애 등의 이유로 날아가는 일이 없이   계속 유지됨이 보장된다. 혹시 시스템에 장애가 발생하더라도 DBMS의 백업과 복구 기능을 활용하여,   장애 직전의 상태로 데이터를 전부 복구할 수 있음이 보장된다.       2. 구현   spring 기능을 활용하여 트랜잭션을 구현   (1) application.properties   spring.aop.proxy-target-class=true           스프링 트랜잭션 기능을 구현하기 위해서   @Transactional 어노테이션을 메소드나 클래스에 붙여줄 경우   그리고 어노테이션이 사용된 클래스가 부모 interface가 없을 때   위 설정이 필요하다.       Transaction Level   트랜잭션 전파 (propagation)   트랜잭션을 시작하거나 기존 트랜잭션에 참여하는 방법을 결정하는 속성이다.     기존 트랜잭션에 참여한다는 것은 현재 트랜잭션에서 다른 트랜잭션으로 이동할 때를 이야기 한다.   예를들어 AccountService에 트랜잭션이 걸려 있는데 OrderService 에서도 트랜잭션이 걸려 있는 것을 말한다.   같은 클래스는 해당 사항이 없다.   트랜잭션 경계의 시작 지점에서 트랜잭션 전파 속성을 참조해서 해당 범위의 트랜잭션을 어떤 식으로 진행시킬지 정할 수 있다.   다음과 같은 속성으로 설정이 가능하다.          REQUIRED   디폴트 속성이며 모든 트랜잭션 매니저가 지원한다.      미리 시작된 트랜잭션이 있으면 참여하고 없으면 새로 시작한다.   자연스럽고 간단한 트랜잭션 전파 방식이지만 사용해보면 매우 강력하고 유용하다는 사실을 알 수 있다.   하나의 트랜잭션이 시작된 후에 다른 트랜잭션 경계가 설정된 메소드를 호출하면 자연스럽게 같은 트랜잭션으로 묶인다.          SUPPORTS   이미 시작된 트랜잭션이 있으면 참여하고 그렇지 않으면 트랜잭션 없이 진행한다.   트랜잭션이 없긴 하지만 해당 경계 안에서 Connection이나 하이버네이트 Session 등을 공유할 수 있다.          MANDATORY   REQUIRED와 비슷하게 이미 시작된 트랜잭션이 있으면 참여한다.   반면에 트랜잭션이 시작된 것이 없으면 새로 시작하는 대신 예외를 발생시킨다.   혼자서는 독립적으로 트랜잭션을 진행하면 안 되는 경우에 사용한다.          REQUIRES_NEW   항상 새로운 트랜잭션을 시작한다. 이미 진행 중인 트랜잭션이 있으면 트랜잭션을 잠시 보류시킨다.   JTA 트랜잭션 매니저를 사용한다면 서버의 트랜잭션 매니저에 트랜잭션 보류가 가능하도록 설정되어 있어야 한다.          NOT_SUPPORTED   트랜잭션을 사용하지 않게 한다. 이미 진행중인 트랜잭션이 있으면 보류시킨다.          NEVER   트랜잭션을 사용하지 않도록 강제한다. 이미 진행 중인 트랜잭션도 존재하면 안된다.  만약 있다면 보류시킨다.          NESTED   이미 진행중인 트랜잭션이 있으면 중첩 트랜잭션을 시작한다.          중첩 트랜잭션은 트랜잭션 안에 다시 트랜잭션을 만드는 것이다.        하지만 독립적인 트랜잭션을 만드는 REQUIRES_NEW와는 다르다.   중첩된 트랜잭션은 먼저 시작된 부모 트랜잭션의 커밋과 롤백에는 영향을 받지만       자신의 커밋과 롤백은 부모 트랜잭션에게 영향을 주지 않는다.   중첩 트랜잭션은 JDBC 3.0 스펙의 저장포인트(savepoint)를 지원하는 드라이버와    DataSourceTransactionManager 를 이용할 경우에 적용 가능하다.     또는 중첩 트랜잭션을 지원하는 일부 WAS의 JTA 트랜잭션 매니저를 이용할 때도 적용할 수 있다.    유용한 트랜잭션 전파 방식이지만 모든 트랜잭션 매니저에 다 적용 가능한 건 아니므로,    적용하려면 사용할 트랜잭션 매니저와 드라이버, WAS의 문서를 참조해 보고,    미리 학습 테스트를 만들어서 검증해봐야 한다.       트랜잭션 격리 (isolation)   1. 데이터베이스의 Lock   (1) 데이터베이스에서 락이란?   동시에 실행되는 여러 트랜잭션이 서로 충돌하는 일이 벌어질 수 있다.      예를 들어 어떤 트랜잭션에서 UPDATE 명령이 실행되어 어느 레코드를 수정하는 도중에,   다른 트랜잭션에서 그 레코드를 DELETE 해버리면 문제가 발생할 것이다.     이런 충돌을 피하기 위해서, 트랜잭션에서 데이터를 읽고 쓸 때,    다른 트랜잭션이 방해하지 못하도록 그 데이터를 잠시 잠그는(lock) 것이 필요하다.      락(lock)에는 읽기 락과 쓰기 락이 있다   (2) 읽기 락 (Rread Lock)   트랙잭션이 데이터를 읽기 직전에 그 데이터에 읽기 락을 건다.   읽기 락은 여러 개가 중복될 수 있다.     그래서 동시에 여러 트랜잭션이 같은 데이터를 읽는 것은 가능하다.   읽기 락과 쓰기 락은 중복될 수 없다.     그래서 어떤 트랜잭션이 데이터를 읽는 중이라서 읽기 락이 걸려 있는 데이터를    다른 트랜잭션이 수정하는 것은 불가능하다.    데이터 읽기가 끝나고 읽기 락이 풀리면, 그때 쓰기 락을 걸고 수정하게 된다.   (3) 쓰기 락 (Write Lock)   트랜잭션이 데이터를 쓰기 직전에 그 데이터에 쓰기 락을 건다.   쓰기 락은 여러 개 중복될 수 없다.  그래서 동시에 여러 트랜잭션이 같은 데이터를 수정하는 것은 불가능하다.   읽기 락과 쓰기 락은 중복될 수 없다.  그래서 어떤 트랜잭션이 데이터를 수정하는 중이라서 쓰기 락이 걸려 있는 데이터를   다른 트랜잭션이 읽는 것은 불가능하다.   데이터 수정이 끝나고 쓰기 락이 풀리면, 그때 읽기 락을 걸고 읽게 된다.   (4) 쓰기 락의 범위   트랜잭션이 데이터를 수정할 때 먼저 그 데이터에 자동으로 쓰기 락이 걸리게 된다.       데이터 수정 전에 쓰기 락이 걸리는 것은 언제나 자동으로 일어난다.      언제나 트랜잭션이 종료될 때 쓰기 락이 풀린다 (unlock).   즉 쓰기 락은 데이터를 수정하기 직전에 언제나 자동으로 걸리고,   트랜잭션이 종료될 때 쓰기 락이 풀린다.   (5) 읽기 락의 범위   트랜잭션이 데이터를 읽을 때 먼저 그 데이터에 읽기 락이 자동으로 걸려야 한다.  그런데 읽기 락이 언제나 자동으로 걸리는 것은 아니다.   읽기 락을 하냐 마냐는 Transaction Isolation Level 설정에 따라 다르다.  읽기 락이 언제까지 유지할 것인지도 Transaction Isolation Level 설정에 따라 다르다.       2. Transaction Isolation Level   Transaction Isolation Level 설정에 따라,   트랜잭션이 데이터를 읽기 전에 읽기 락을 할지 말지 읽기 락을 언제까지 유지할지가 결정된다.   읽기 락을 많이 걸고 오래 유지할 수록 데이터의 안정성은 좋아지지만 성능은 나빠진다.   돈 거래와 같은 중요한 데이터라면 데이터 안정성이 중요하고,   게시판 덧글과 같이 별로 중요하지 않은 데이터라면 성능이 더 중요할 것이다.       (1) Transaction Isolation Level 설정 명령   SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED    SET TRANSACTION ISOLATION LEVEL READ COMMITTED    SET TRANSACTION ISOLATION LEVEL REPEATABLE READ    SET TRANSACTION ISOLATION LEVEL SERIALIZABLE    위 목록에서 아래의 명령일 수록 읽기 락을 좀 더 많이 건다.   Transaction Isolcation Level을 설정하는 명령을 실행하지 않았다면,   디폴트 상태는 다음과 같다.           Oracle : READ COMMITTED            SQL Server : READ COMMITTED            MySQL : REPEATABLE READ           (2) Read Uncommitted   읽기 락을 전혀 하지 않는다. 그래서 가장 빠르다.   Dirty Reads 문제 발생   읽기 락을 전혀 하지 않기 때문에, 다른 트랜잭션이 수정하고 있어서 쓰기 락이 걸려 있는 데이터도 읽을 수 있다.     그래서 게시글 본문이 반쯤 저장된 상태에서 그 게시글 레코드를 읽는 것이 가능하다.   이렇게 완전하지 않고 반쯤 수정된 데이터가 읽혀질 수 있는 문제를 Dirty Reads 문제라고 부른다.   읽기 락을 하지 않기 때문에, 어떤 트랜잭션이 읽고 있는 중인 데이터를   다른 트랜잭션이 쓰기 락을 걸고 수정하거나 삭제할 수도 있다.   Read Uncommitted 레벨에서는 Dirty Reads 문제가 발생할 수 있다.   이 문제를 피하려면, Transaction Isolation Level 을 다음 단계인 Read Committed로 올려야 한다.       (3) Read Committed   데이터를 읽기 직전에 언제나 읽기 락을 한다.      그리고 그 SQL 문장이 끝나자 마자 읽기 락을 푼다.      즉 읽기 락을 SQL 문장 하나 단위로만 유지한다.   읽기 락을 걸고 데이터를 읽기 때문에,    그리고 읽기 락이 걸려 있는 데이터에 쓰기 락을 걸 수는 없기 때문에,    읽는 중인 데이터를 다른 트랜잭션이 수정할 수 없다.    따라서 Dirty Reads 문제는 발생하지 않는다.   Transaction Isolcation Level을 설정하는 명령을 실행하지 않았다면,    이것이 디폴트 상태이다.   Non-repeatable Reads 문제 발생   Read Committed 단계에서는 Dirty Reads 문제는 해결 되었지만,  모든 문제가 다 해결된 것은 아니다.  미묘한 Non-repeatable Reads 문제가 남아있다.   하나의 트랜잭션에서 어떤 데이터를 처음 읽을 때와 나중에 읽을 때 값이 달라져서     문제가 되는 상황을 Non-Repeatable Reads 문제라고 부른다.   Non-Repeatable Reads 문제를 피하려면    다른 트랜잭션이 사이에 끼어 들어와서 데이터를 수정하지 못하게 막아야 한다.   그러러면 읽기 락을 좀 더 열심히 걸어야 한다.   Non-Repeatable Reads 문제를 피하려면   Transaction Isolation Level 을 다음 단계인 Repeatable Read 단계로 올려야 한다.       (4) Repeatable Read   데이터를 읽기 직전에 읽기 락을 건다.   그리고 읽기 락을 트랜잭션 끝날 때까지 유지해서   다른 트랜잭션이 사이에 끼어 들어와서 데이터를 수정하지 못하게 막는다.   Non-repeatable Reads 문제 해결   읽기 락이 걸려 있는 데이터에 다른 트랜잭션이 쓰기 락을 걸 수 없지만,      읽기 락을 건 바로 그 트랜잭션은, 자신이 걸었던 읽기 락을 쓰기 락으로 변경하는 것이 가능하다.   Phantom Reads 문제 발생   Repeatable Read 단계에서 Non-repeatable Reads 문제는 해결 되었지만  모든 문제가 다 해결된 것은 아니다.  아주 미묘한 Phantom Reads 문제가 남아있다.   예를 들어 수강 신청에서   절차1) 먼저 강좌의 수강 레코드 수를 조회하여 최대 수강 인원 수 보다 크거나 같다면,   그 강좌의 수강 인원이 꽉찬 것이므로 종료.   절차2) 그렇지 않다면 수강 레코드 삽입(insert)   위와 같은 순서로 구현했을 때,    절차1에서 읽은 수강 레코드들에 읽기 락이 걸리고 트랜잭션이 끝날 때가지 유지된다.   그 트랜잭션이 끝날 때가지 읽기 락이 걸려 있는 수강 레코들은 수정 될 수 없도록 보호되지만,   새 수강 레코드가 삽입되는 것은 가능하다.    그래서 절차1과 절차2 사이에 다른 트랜잭션이 그 강좌에 새 수강 레코드를 삽입할 수 있다.   절차1에서 강좌의 수강 레코드 수를 조회할 때는 최대 수강 인원 수 보다 작았는데,  막상 절차2를 실행할 때는 최대 수강 인원 수와 수강 레코드 수가 같을 수 있다.  절차1과 절차2 사이에 다른 트랜잭션이 수강 레코드를 등록할 수 있기 때문이다.   절차1과 절차2에서 조회한 수강 레코드 수가 동일하려면,     절차1과 절차2 사이에 다른 트랜잭션이 그 강좌에 수강 레코드를 등록하지 못하게 막아야 한다.   이렇게 막는 것은 조금 복잡한 읽기 락(lock)이 필요하다.   Phantom Reads 문제를 피하려면   좀 더 복잡한 읽기 락을 걸어야 한다.    Transaction Isolation Level 을 다음 단계인 Serializable 단계로 올려야 한다.       (5) Serializable   Phantom Reads 문제를 피하기 위해 좀 더 복잡한 읽기 락을 건다.    그리고 트랜잭션 끝날 때까지 읽기 락을 유지한다.   테이블에 읽기 락을 걸거나, 테이블 인덱스에 읽기 락을 걸거나,   WHERE 절 조건식으로 읽기 락을 걸기도 한다.   테이블에 읽기 락이 걸리면, 그 테이블에 대한 모든 수정(insert, update, delete)은 막힌다.      데이블 인덱스에 읽기 락이 걸리면, 그 인덱스에 변화를 초래하는 수정(insert, update, delete)은 막힌다.    WHERE 절 조건식으로 읽기 락이 걸리면, WHERE 절 조건식의 true/false 값이 변할 만한 수정(insert, update, delete)은 막힌다.   Phantom Reads 문제 해결   수강 신청에서 절차를 다시 생각해 보자.    절차1) 먼저 강좌의 수강 레코드 수를 조회하여 최대 수강 인원 수 보다 크거나 같다면,       그 강좌의 수강 인원이 꽉찬 것이므로 종료.   절차2) 그렇지 않다면 수강 레코드 삽입(insert)   강좌의 수강 레코드 수 조회 SQL 문은 다음과 같은 형태일 것이.   SELECT COUNT(*) FROM 수강 WHERE lectureId = #{lectureId}      절차1에서 읽은 강좌 레코드 수를 조회하는 WHERE 절의 조건식에 읽기 락이 걸린다.   위 WHERE 조건식의 값이, 어떤 명령의 실행 전과 후에 달라지다면, 락에 의해서 그 명령의 실행은 막힌다.    위 WHERE 조건식이 true인 레코드를 delete 하는 것도 막힌다.   위 WHERE 조건식이 true인 레코드를 insert 하는 것도 막힌다.   따라서 절차1과 절차2 사이에 다른 레코드가 끼어 들어와서 그 강좌에 새 수강 레코드를 삽입할 수 없다.   Serializable 단계는 모든 읽기 문제가 다 해결된 단계이다.       요약   read uncommitted   어떤 트랜잭션이 수정한 내용이 아직 commit 되기 전부터,   다른 트랜잭션들에게 그 값이 보임. (dirty read 문제)       read committed   어떤 트랜잭션이 수정한 내용이 commit 된 이후에만.   다른 트랜잭션들에게 그 값이 보임. (dirty read 해결됨)   어떤 트랜잭션이 한 번 읽은 레코드를, 트랜잭션 실행 도중 다시 읽었을 때,   그 사이에 다른 트랜잭션이 그 레코드를 수정하고 commit 했다면,   다시 읽은 값은 처음 읽은 값과 달라진다. (nonrepeatable read 문제)       repeatable read   어떤 트랜잭션이 한 번 읽은 레코드를, 트랜잭션 실행 도중 다시 읽었을 때,   그 사이에 다른 트랜잭션이 그 레코드를 수정하고 commit 했더라도,   처음 읽은 값과 다시 읽은 값이 동일함이 보장된다. (nonrepeatable read 해결됨)   어떤 트랜잭션이 아직 읽지 않은 레코드를,   다른 트랜잭션이 수정하는 것이 허용된다.   예를 들어, 어떤 소프트웨어공학과 학생 수를 세기 위해   소프트웨어공학과 학생 레코드들을 읽으면,   그 사이에 다른 트랜잭션이 그 레코드를 수정하고 commit 했더라도,   처음 읽은 값과 다시 읽은 값이 동일함이 보장된다.   하지만,   다른 트랜잭션이 소프트웨어공학과 학생 레코드가 새로 추가하고 commit 한 후에,   다시 소프트웨어공학과 학생 수를 세면, 처음 세었을 때 보다 1 증가했을 것이다.   (phantom read 문제)       serializable   phantom read 문제도 해결됨.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2020-06-13/transaction/",
        "teaser": null
      },{
        "title": "커서 기반 페이징 구현",
        "excerpt":"Cursor 기반 페이징 구현   타임라인 기능을 위해 무한 스크롤을 이용한 페이징 방식을 구현해보기로 했다.   스프링을 공부하면서 pagination을 공부하면서 Offset 기반의 페이징만 구현했는데,   SNS 같은 무한 스크롤에서 문제가 생길 수 있다고 한다.   1. Offset   SELECT * FROM POSTS ORDER BY ID DESC LIMIT 0, 10   SELECT * FROM POSTS ORDER BY ID DESC LIMIT 10, 10   SELECT * FROM POSTS ORDER BY ID DESC LIMIT 20, 10     실시간으로 많은 글이 올라오는 환경에서 위 쿼리는 다음고 같은 문제를 발생시킨다.     첫번째 쿼리가 실행되고 그 사이에 게시글 하나가 추가되면 두번째 쿼리를 조회할 때 중복될 수 있다.   2. Cursor   커서 기반 페이징은 조회할 때 내가 읽은 마지막 요소를 알려줘서 그 뒤의 값을 조회할 수 있도록 하는 것이다.   SELECT * FROM Post p WHERE p.user_id = :userId ORDER BY p.id DESC LIMIT 10 SELECT * FROM Post p WHERE p.user_id = :userId AND p.id &lt; :id ORDER BY p.id DESC LIMIT 10       위 쿼리는 litebook 프로젝트에서 사용한 쿼리이다.   최신 10개의 게시글을 조회하고 이전에 조회한 마지막 id 보다 작은 10개를 가져오라는 것이다.       REST API   litebook은 타임라인 기능을 중심으로 프론트까지 같이 개발했었는데        서버 위주로 개발하고 싶은 욕심이 생겨서 rest api로 댓글, 좋아요, 검색, 친구 추천 기능 등등                  기능을 더 추가해서 설계부터 다시 개발하기로 결심했다!   ","categories": ["Spring","JPA"],
        "tags": ["spring","jpa"],
        "url": "/2020-07-14/0714/",
        "teaser": null
      },{
        "title": "Lotto Game",
        "excerpt":"기본 템플릿: https://github.com/hyerin6/java-lotto/tree/master    내가 구현중인 코드: https://github.com/hyerin6/java-lotto       로또 게임을 만들어보자           로또 구입 금액을 입력하면 구입 금액에 해당하는 로또를 발급            수익률을 계산해 출력            자바 코드 컨벤션 참고            else 예약어 사용하지 않기            public/protected/private/package 접근 제어자 적절하게 사용            함수(메서드) 길이 10라인 넘기지 않기            indent(들여쓰기) depth 2 넘지 않기                  1. 일급 컬렉션   Collection을 Wrapping하면서 Wrapping한 Collection 외 다른 멤버변수가 없는 상태를 일급 컬렉션이라 한다.   Wrapping 함으로써 다음과 같은 이점을 갖는다.       (1) 비즈니스에 종속적인 자료구조              (2) Collection의 불변성을 보장              (3) 상태와 행위를 한 곳에서 관리              (4) 이름이 있는 컬렉션   자세한 설명은 아래 두 글을 참고  https://jojoldu.tistory.com/412  https://woowacourse.github.io/javable/2020-05-08/First-Class-Collection            2. getter 줄이기   지금까지 거의 모든 프로젝트에서 멤버 변수 접근 제한자를 private로 설정하고    getter/setter을 이용해서만 접근이 가능하도록 했다.   모든 멤버 변수에 lombok을 사용해 getter/settter을 사용했었다.       무조건 모든 멤버 변수에 getter을 사용하는 게 좋은 건 아니라고 해서 공부해보려고 한다.   객체에 메시지를 보내 객체가 로직을 수행하도록 하자   객체는 메시지를 받으면 그에 따른 로직을 수행한다.             -&gt; 객체지향 프로그래밍은 객체가 스스로 일을 하도록 하는 프로그래밍이다.   getter을 사용해 상태값을 꺼내 객체 외부에서 로직을 수행하거나 상태를 바꾸면     이는 객체스럽지 못한 것!    (Collection 인터페이스를 사용하는 경우 외부에서 getter메서드로 얻은 값을 통해 상태값을 변경할 수 있다.)   참고: https://woowacourse.github.io/javable/2020-04-28/ask-instead-of-getter               3. stream 사용   lotto game 구현에서 반복문은 전부 for문을 사용했는데   stream을 사용해보기로 했다.   우선 아래 부분만 수정해보자.          before   for(int i = 0; i &lt; size; ++i) {       profit += ranks.get(i).getWinningMoney();   }            after   private static double getProfit(List&lt;Rank&gt; ranks) {                  int profit = ranks.stream().mapToInt(Rank::getWinningMoney).sum();            \treturn profit;            }                    ","categories": ["Depromeet","Java","OOP"],
        "tags": ["java","oop"],
        "url": "/2020-07-25/lotto/",
        "teaser": null
      },{
        "title": "디프만 8기 4조 워밍업 프로젝트 : 꿀단지",
        "excerpt":"1차 회의 결과는 다음과 같다.      ","categories": ["Depromeet","OOP"],
        "tags": ["erd"],
        "url": "/2020-07-29/modeling/",
        "teaser": null
      },{
        "title": "git 브랜치 병합 전략 : rebase",
        "excerpt":"Git Rebase   두개의 브랜치에서 작업할 때 하나의 브랜치를 다른 브랜치로 합치기 위해서   git에서 두 가지 방법을 주로 사용한다.      merge   rebase   merge만 사용했었는데 이번 프로젝트에서 rebase에 대해 알아보고 사용해보기로 했다!       Rebase   브랜치의 공통 조상이 되는 base를 다른 브랜치의 커밋 지점으로 바꾸는 것이라고 할 수 있다.   기본 전략은 다음과 같다.      먼저 rebase하려는 브랜치 커밋들의 변경사항을 patch라는 것으로 만든 다음에      어딘가에 저장해 두고 이를 master 브랜치에 하나씩 적용하여 새로운 커밋을 만든다.   feature를 master 브랜치로 rebase하는 명령어를 살펴보자.       git checkout feature                       git rebase master                            git merge feature                   feature 브랜치로 checkout   master 브랜치로 rebase   feature 브랜치를 master로 fast-forward merge       참고 : https://velog.io/@godori/Git-Rebase  ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2020-08-09/git-rebase/",
        "teaser": null
      },{
        "title": "정규화",
        "excerpt":"정규화란?   테이블을 올바른 형태로 만들고 분리하는 데이터베이스의 설계를 재구성하는 테크닉이다.   정규화가 왜 필요할까?      불필요한 데이터(redundancy)를 제거 : 중복 데이터 제거(무결성)   데이터 저장을 논리적으로 한다.   결과적으로 데이터베이스 크기가 줄어들고 찾아야 할 데이터가 적어져 쿼리가 빨라진다.   정규화되지 않은 구조의 테이블          Update  여러 줄의 데이터를 갱신해야 하는데 이로인해 데이터의 불일치(inconsistency)가 발생할 수 있다.            Insert   특정 컬럼에 NULL이 포함될 수 있다.            Delete   데이터를 삭제하려고 했지만 테이블이 삭제될 수도 있다.       정규화가 제대로 되지 않은 테이블의 경우 갱신/삽입/삭제 시 다양한 문제가 발생할 수 있다.    이를 테이블의 구성을 논리적으로 변경하여 해결하고자 하는 것이 정규화이다.   정규화의 법칙(Normalization Rule)은 1차정규화, 2차정규화, 3차정규화, BCNF, 4차정규화, 5차정규화로 나눌 수 있다.   원자값: 더 이상 쪼갤 수 없는 조각 정보  속성값은 원자값을 가져야 한다.   예를 들어 주소는 [ 도 / 시 / 번지 / 아파트명 ]으로 나눠 저장하면 원자값일까?     배달 업체인 경우 주소를 [도 시 번지 아파트명] 한 번에 저장하는 것이 원자값이고       부동산 업체인 경우 [ 도 / 시 / 번지 / 아파트명 ] 따로 나눠 저장하는 것이 원자값이다.   각각의 목적에 따라 원자값이 달라질 수 있다.   원자적 데이터를 사용하면 쿼리 작성이 쉽고 수행 시간이 빨라 쿼리를 효율적으로 수행할 수 있고     저장 데이터가 대용량인 경우 더욱 효율적이다.      원자적 데이터로 구성된 열은 그 열에 같은 타입의 데이터를 여러 개 가질 수 없다.   원자적 데이터로 구성된 테이블은 같은 타입의 데이터를 여러 열에 가질 수 없다.   제1 정규형 (1NF)      각 행의 데이터들은 원자적 값을 가져야 한다.   각 행은 기본 키를 가지고 있어야 한다.   제2 정규형 (2NF)      테이블의 모든 컬럼이 완전 함수적 종속을 만족해야 한다.   행으로 중복되는 부분을 찾아내(부분 함수 종속성을 찾아내) 테이블 분할헤야 한다.   제3 정규형 (3NF)      기본 키 이외의 다른 컬럼이 그외 다른 컬럼을 결정할 수 없어야 한다.   기본 키 외에 중복되는 부분을 찾아내 분할해야 한다.   ","categories": ["MySQL","Database"],
        "tags": ["mysql","database"],
        "url": "/2020-09-14/%EC%A0%95%EA%B7%9C%ED%99%94/",
        "teaser": null
      },{
        "title": "Maven Wrapper, 상수화, 테스트",
        "excerpt":"디프만 파이널 프로젝트를 시작하면서 회원가입 기능을 구현해보며 코드리뷰를 했다.      SNS 로그인 기능을 사용하기로해서 처음 구현한 코드는 프로젝트에서 사용하지 않지만   코드리뷰를 다시 보면서 공부하기로 했다.   Maven Wrapper의 용도   Apache Maven은 자바 프로젝트 의존성 관리 도구이다.     이를 좀 더 쉽게 최신 버전을 유지하기 위해 Maven Wrapper가 나왔다.     Maven Wrapper(mvnw)가 설정된 프로젝트는 maven 설치 없이도 빌드가 가능하다.     즉 Apache Maven을 프로젝트에서 요구하는 버전으로 유지하기 위해 사용하는 도구이다.   실행   일반적으로 Maven은 다음 명령어로 실행한다.   mvn clean package      mvnw가 설정된 프로젝트는 다음 명령어로 실행한다.   ./mvnw clean package                항상 같은 값을 리턴하는 경우   return new ResponseEntity&lt;&gt;(HttpStatus.BAD_REQUEST);        Controller에서 위 코드를 반복하게 되었고, 상수화하면 불필요한 객체 생성을 줄일 수 있다는걸 알게 되었다.   private final static ResponseEntity BAD_REQUEST = new ResponseEntity(HttpStatus.BAD_REQUEST);                단위테스트 &amp; 통합테스트      단위 테스트 : 클래스를 하나씩 따로 테스트하는 것   통합 테스트 : 클래스들의 객체를 서로 연결하여 같이 테스트하는 것   Junit 테스트에 대한 것은 이미 블로그에 정리해둔 것이 있다.     Junit Test 블로그 보러가기       ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2020-10-14/code-review/",
        "teaser": null
      },{
        "title": "Spring webflux",
        "excerpt":"    회의 결과 카카오 로그인과 네이버 로그인을 사용하여 회원 인증을 하기로 했다.     나의 담당은 카카오 로그인이고 아직 프론트 개발자분들과 회의를 하기 전이라 자세한건 변경될 수 있지만   access token으로 사용자 정보를 가져오는 kakao api를 사용하는걸 미리 구현해봤다.       Spring webflux   Spring MVC는 기본적으로 블로킹이고 동기방식을 사용한다. 비동기 처리 기능이 스프링 프레임워크3에서 추가되었지만     서블릿은 응답을 기다리는 동안 pool의 스레드들은 여전히 지연시킬 수 있기 때문에 전체 stack이 reactive 해야 하는 요구를 충족시킬 수 없다.         이러한 문제를 해결할 수 있도록 스프링 프레임워크5에 도입된 대안적인 모듈이 webflux이다.   웹 요청을 reactive하게 다루는데에 초점이 맞춰져있다.   기존의 서블릿 기반의 spring boot는 tomcat을 기반으로 동작한다.   반면 spring boot webflux는 여러가지 고를 수 있는데 디폴트로 netty를 사용한다.      Tomcat - 하나의 요청에 하나의 스레드가 동작   Netty - 1개의 이벤트를 받는 스레드와 다수의 worker 스레드로 동작   위 내용은 webflux에 대해 알아보면서 메모한 것이고 다음 포스팅들을 참고했다.   라인 테크 블로그 - Reactive Streams와 놀자!    spring.io - webflux       구현      kakao api 중 사용자 정보 요청 (/v2/user/me)을 사용했는데 response가 조금 복잡해보인다.          우선 error response는 static inner class로 작성했고, kakao_account는 따로 클래스를 만들어주고 inner class로 Profile을 정의했다.   ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2020-10-14/login/",
        "teaser": null
      },{
        "title": "WebClient, Nested Class",
        "excerpt":"카카오 로그인 기능을 담당하게 되어 약 일주일 동안 기능 구현과 함께 코드리뷰를 받았다.   WebClient에서 요청을 날릴 때 exchange VS retrieve   retrieve는 바로 response body를 처리 할 수 있고   exchange는 상태값, 헤더 등 client response 자체를 전달해줘서 세밀하게 제어할 수 있는 차이가 있다.   그런데 exchange는 성공, exception, 예상치 못한 응담이라도 response를 처리하지 않으면 메모리 누수가 발생한다.     retrieve와 달리 4XX, 5XX와 같은 응답에 대한 자동 처리가 없어 상태 코드를 확인해야 하는데 그 과정에서 개발자가 실수하게 되면 메모리릭이 발생하기 때문에 retrieve 사용을 권장한다고 한다.   이번 프로젝트에서 kakao의 일부 api만 사용할 것이고 거의 대부분 문제가 되는 응답은 상태가 4XX이라 onStatus() 에서 에러를 처리가 가능해 retrieve를 사용했다.                 Nested Class   이펙티브 자바, 토비의 스프링 등을 읽으면서 inner class는 static으로 구현하라는 것을 많이 봤다.   inner class로 인해 메모리릭이 발생하는 경우는 (비동기) outer class와 inner class의 스레드가 돌아가는중에    outer class의 작업이 끝나면 inner class의 outer class 객체 참조로 인해 메모리가 해제되지 않아 생긴다~   static class는 외부 클래스의 객체 생성 없이 내부 클래스의 객체를 생성할 수 있고  암시적인 outer class 객체 참조를 하지 않는다~   위와 같은 이유로 static으로 구현하라는 것이었는데         단지 response로만 사용하는 경우에는 고려하지 않아도 될 문제였다.       그래도 inner class에 대해 다시 한 번 공부할 수 있는 계기가 되었다.   이참에 다시 정리해보자.           Nested Class        클래스 안에 클래스라는 의미로 이를 사용하는 이유는   외부 클래스의 멤버들을 쉽게 접근할 수 있고 외부에는 불필요한 클래스 파일을 감춰서(캡슐화) 코드의 복잡성을 줄일 수 있다는 점이다.          종류           인스턴스 클래스(instance class)      외부 클래스의 멤버변수 선언 위치에 선언                  스태틱 클래스(static class)    외부 클래스의 멤버변수 선언 위치에 선언                외부클래스명.내부클래스명 객체명 = new 외부클래스명.내부클래스명();    위와 같이 외부 클래스 객체 없이 내부 클래스 객체 생성이 가능하다.                         지역 클래스(local class)     외부 클래스의 메서드나 초기화 블럭에서 선언                    익명 클래스(anonymous inner class)        클래스의 선언과 객체 생성을 동시에 하는 이름이 없는 클래스           ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2020-10-17/review2/",
        "teaser": null
      },{
        "title": "Jenkins 테스트 자동화",
        "excerpt":"로그인 기능 개발을 시작하면서 젠킨스를 이용한 자동 배포와 테스트 자동화를 해보기로 했고 테스트 자동화(ci)를 담당하게 되었다.   우선 작업(job)을 새로 만들고 git repogitory와 연동했다.       1. Jenkins &amp; Git 연동   jenkins의 첫 화면에서 사람 &gt; user 선택 &gt; 설정 &gt; token 생성       위와 같은 경로로 들어가 jenkins에서 토큰을 만들어주고   git webhook에서 Payload URL을 다음과 같이 작성하면 된다.   http://&lt;jenkins_user_name&gt;:&lt;jenkins_token&gt;@&lt;jenkins_ip&gt;/job/&lt;jenkins_job&gt;/buildWithParameters?token=&lt;Authentication_Token&gt;   jenkins_user_name은 젠킨스 유저 ID,       jenkins_token은 젠킨스 유저 설정에서 생성한 token,       Authentication_Token은 젠킨스 job에서 빌드 유발을 빌드를 원격으로 유발 로 선택했을 때        내가\tAuthentication Token 에 적은 문자열이다.   다음 화면에서 원하는 문자열을 입력하면 된다.      git webhook에서 Pull request를 선택하고 저장하면        pr에 이벤트가 발생할 때 젠킨스에서 스크립트 실행이 가능해진다.            2. 젠킨스 설정   젠킨스에서 dangdang_ci라는 job을 만들고 git 연동까지 완료했다.       플러그인을 사용하지 않고 스크립트를 직접 작성하며 공부해보기로 했기 때문에   젠킨스에 특별한 설정은 필요없고 매개변수 설정이랑 스크립트 작성, 빌드 전 workspace(git clone 받은 것) 삭제 설정만 하면된다.   다만, pr 테스트 결과를 git에 다시 보내려면 git에서 token을 발급 받아야 한다. (한번만 보여주니까 저장해둬야함)    git 계정 Settings &gt; Developer settings &gt; Personal access tokens 에서 토큰을 생성해서      헤더에 다음과 같은 형식으로 보내주면 된다.   Authorization: token &lt;TOKEN&gt;   (url에 query string(access_token)으로 보내도 되는데 git에서 권장하지 않기 때문에 언제든지 작동하지 않을 수 있다는 메일이 날아온다.)                  3. Script   #!/bin/bash -li  #git pr 정보를 payload 매개변수로 받아 payload.txt 파일로 저장합니다.     echo $payload &gt; payload.txt   #pr 의 상태를 action 변수에 저장합니다. (ex. opened, closed) action='python -c 'import json, os; d = json.loads(open(\"payload.txt\").read()); print d[\"action\"]''   #pr의 상태가 opened이나 reopened, edited이 아니면 테스트를 진행하지 않습니다.    if [ $action != \"opened\" ] || [ $action != \"reopened\" ] || [ $action != \"edited\" ]; then exit ; fi  #ci 결과를 다시 git에 보내주기 위해 payload로 받은 정보를 파싱합니다.  pr_branch='python -c 'import json, os; d = json.loads(open(\"payload.txt\").read()); print d[\"pull_request\"][\"head\"][\"ref\"]''   #payload로 받은 statuses_url을 사용하여 pr 상태를 변경할 수 있다.    curl_url='python -c 'import json, os; d = json.loads(open(\"payload.txt\").read()); print d[\"pull_request\"][\"statuses_url\"]''   #pr branch의 코드만 가져옵니다.  git clone -b $pr_branch --single-branch https://github.com/depromeet/8th-final-team5-backend.git  cd 8th-final-team5-backend   #테스트 진행, 결과가 실패인지 result 변수에 저장합니다. (테스트 실패하면 result에 0이 저장됨) result=`echo \\`./mvnw test\\` | grep -q \"BUILD FAILURE\"; echo $?`  #$BUILD_NUMBER 는 jenkins에서 제공하는 변수다. git에서 detail 링크를 누르면 스크립트 결과를 바로 볼 수 있다.      #테스트 결과 성공하면 state를 success 실패하면 failure로 git에 전달    if [ $result == \"1\" ]; then \\ \tcurl \"${curl_url}\" \\   \t\t-H \"Content-Type: application/json\" \\   \t\t-H \"Authorization: token &lt;TOKEN&gt;\" \\   \t\t-X POST \\   \t\t-d \"{\\\"state\\\": \\\"success\\\",\\\"context\\\": \\\"continuous-integration/jenkins\\\", \\\"description\\\": \\\"Jenkins\\\", \\\"target_url\\\": \\\"http://20.194.0.141/job/dangdang_ci/$BUILD_NUMBER/console\\\"}\"; \\ else \\  \tcurl \"${curl_url}\" \\    \t\t-H \"Content-Type: application/json\" \\   \t\t-H \"Authorization: token &lt;TOKEN&gt;\" \\   \t\t-X POST \\   \t\t-d \"{\\\"state\\\": \\\"failure\\\",\\\"context\\\": \\\"continuous-integration/jenkins\\\", \\\"description\\\": \\\"Jenkins\\\", \\\"target_url\\\": \\\"http://20.194.0.141/job/dangdang_ci/$BUILD_NUMBER/console\\\"}\"; \\ fi               참고      https://git-scm.com/book/ko/v2/GitHub-GitHub-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8C%85   https://applitools.com/blog/how-to-update-jenkins-build-status-in-github-pull-requests-step-by-step-tutorial/   ","categories": ["Depromeet","Jenkins"],
        "tags": ["jenkins"],
        "url": "/2020-10-21/jenkins-ci/",
        "teaser": null
      },{
        "title": "탐색 알고리즘(DFS & BFS)",
        "excerpt":"2차원 지도 탐색   백준 2178 미로 탐색 문제   미로의 각 칸이 탐색 대상 노드이기 때문에 BFS로 풀어야 한다.           구현1            Location 객체를 HashSet에 보관하려면 hashCode, equals 메소드를 재정의해야 한다.            구현2           Node 객체를 만들어 Queue에 저장하며 조건에 맞는지 검사            구현3               모든 칸을 Node로 생성하여 Queue에 저장하지 않고 탐색해야 하는 칸만 Node 객체로 생성                 최장거리를 구현해보자.      구현4   촤장거리 탐색도 BFS로 구현해야 한다.   목적지에 도착하자마자 distance를 리턴하는게 아니다. 도착하자마자 리턴하면 최단 거리가 된다.           마지막 distance 값이 최대거리이기 때문에 queue가 empty가 될 때까지 탐색을 계속한 후      max 값을 리턴해야 한다.              반복문으로 DFS 구현      구현5   반복문으로 깊이 우선 탐색을 구현하라.  last in, first out =&gt; BFS  last in, last out =&gt; DFS  깊이 우선 탐색의 리턴값 distance는 최단거리가 아니다.              비숫한 문제 : 프로그래머스 카카오프렌즈 컬러링북      BFS 구현 코드      입력 예제를 직접 그려보면 영역은 이렇게 나타난다.   백준 문제를 풀고 이 문제를 풀어보니 쉽게 이해할 수 있었다.     목적지 없이 전부 탐색해야 한다는 점과 색이 같으면 Node를 생성해 Queue에 넣어준다는 점만 다르고 풀이 방식은 똑같다.                풀어볼 문제 목록      https://www.acmicpc.net/problem/7562   https://www.acmicpc.net/problem/6593   https://www.acmicpc.net/problem/2589   https://www.acmicpc.net/problem/7576   https://www.acmicpc.net/problem/7569   https://www.acmicpc.net/problem/3055   https://www.acmicpc.net/problem/4179   https://www.acmicpc.net/problem/2206   https://www.acmicpc.net/problem/10026   https://www.acmicpc.net/problem/2468   https://www.acmicpc.net/problem/2667   https://www.acmicpc.net/problem/2583   https://www.acmicpc.net/problem/2146   https://www.acmicpc.net/problem/2573   ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2020-11-12/search/",
        "teaser": null
      },{
        "title": "순열 permutation",
        "excerpt":"소수 찾기   한자리 숫자가 적힌 종이 조각이 흩어져있습니다.      흩어진 종이 조각을 붙여 소수를 몇 개 만들 수 있는지 알아내려 합니다.     각 종이 조각에 적힌 숫자가 적힌 문자열 numbers가 주어졌을 때,     종이 조각으로 만들 수 있는 소수가 몇 개인지 return 하도록 solution 함수를 완성해주세요.       ex. INPUT : \"17\" RETURN : 3         에라토스테네스의 체를 이용해서 소수인지 아닌지 검사하는 알고리즘은 예전에 풀어본 적이 있어          쉽게 떠올랐지만 문자열을 조합해서 숫자를 만드는 것은 쉽지 않았다.   먼저 순열 알고리즘을 공부해보자.       순열   순열이란 n개의 값 중에서 r개의 숫자를 모든 순서대로 뽑는 경우를 말한다.   예를들어 [1, 2, 3] 이라는 배열에서 길이가 2인 숫자를 만든다고 가정하면   [1, 2]    [1, 3]      [2, 1]    [2, 3]     [3, 1]    [3, 2]   총 6개의 숫자가 만들어진다.       swap을 이용한 순열   배열의 첫번째 값부터 하나씩 바꾸며 모든 값을 한번씩 swap 한다.   depth를 기준 인덱스로 depth 보다 작으면 고정, 크면 다시 swap 한다.   순서는 보장되지 않는다.   static void permutation(int[] arr, int depth, int n, int r) {       if (depth == r) {           print(arr, r);           return;       }         for (int i=depth; i&lt;n; i++) {           swap(arr, depth, i);           permutation(arr, depth + 1, n, r);            swap(arr, depth, i);         }   }     static void swap(int[] arr, int depth, int i) {       int temp = arr[depth];       arr[depth] = arr[i];       arr[i] = temp;   }         visited 배열을 이용한 순열   swap을 이용한 구현과는 다르게 사전식으로 순열을 구할 수 있다.      arr : r개를 뽑기 위한 n개의 값   output : 뽑힌 r개의 값   visited : 중복해서 뽑지 않기 위해 체크하는 값   DFS를 돌면서 모든 인덱스를 방문하여 output에 값을 넣는다.   이미 들어간 값은 visited를 true로 바꿔서 중복을 방지한다.   depth값은 output에 들어간 숫자의 길이이다.  depth의 값이 r만큼 되면 output에 들어있는 값을 출력하면 된다.   static void perm(int[] arr, int[] output, boolean[] visited, int depth, int n, int r) {         if (depth == r) {             print(output, r);             return;         }           for (int i=0; i&lt;n; i++) {             if (visited[i] != true) {                 visited[i] = true;                 output[depth] = arr[i];                 perm(arr, output, visited, depth + 1, n, r);                        visited[i] = false;;             }     } }       에라토스테네스의 체   public static boolean isPrime(int num){   \t\t// 에라토스테네스의 체를 이용   \t\tfor(int i = 2; i &lt;= Math.sqrt(num); i++){   \t\t\tfor(int j = 2; j * i &lt;= num ; j++){   \t\t\t\tNUMBER[j * i] = false;   \t\t\t}   \t\t}   \t\treturn NUMBER[num];   }       참고  https://bcp0109.tistory.com/14   ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2020-11-13/permutation/",
        "teaser": null
      },{
        "title": "ResponseEntity & Generic",
        "excerpt":"이미지 저장, 주소 저장, 인기 반려동물과 탐색 정렬 기준 등   회의해야 할 게 아직 많이 남았지만 간단하게 필요한 데이터와 관계를 정리해봤다.              ResponseEntity   ResponseEntity는 HttpEntity를 상속받아 HttpHeader와 body를 가질 수 있다.        status field를 가지기 때문에 상태 코드도 리턴해줘야 한다.   new ResponseEntity&lt;&gt;(\"success\", HttpStatus.OK); // 메시지(String)과 상태코드(200)를 리턴 new ResponseEntity&lt;&gt;(message, HttpStatus.INTERNAL_SERVER_ERROR); // 객체와 상태코드를 오류로 리턴          new ResponseEntity(HttpStatus.OK);  // 상태코드(200)만 리턴    new ResponseEntity(header, HttpStatus.OK);  // header와 상태코드(200) 리턴         참고  https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/http/ResponseEntity.html#ResponseEntity-T-org.springframework.util.MultiValueMap-org.springframework.http.HttpStatus-                Generic   이번 프로젝트에서도 클라이언트에 ResponseEntity로 응답하는데       제네릭이 사용되서 제네릭에 대해 공부해봐야 겠다는 생각이 들었고         먼저 ResponseEntity도 같이 가볍게 정리해봤다. 😊😊   제네릭을 검색해 본적이 많은데 프로그래밍에서 뜻이나 문법만 나와서   이펙티브 자바에 제네릭을 왜 사용하는지, 장단점이나 주의할 내용이 있는지 찾아봤더니 역시 관련된 내용이 있었다.     아직 2장을 읽는 중이라 몰랐는데 5장 전체가 제네릭에 관련된 내용이었다..     먼저 제네릭 부분부터 읽어보자.            1. 이왕이면 제네릭 타입으로 만들라.   다음은 단순한 스택 코드이다.   public class Stack {       private Object[] elements;                  . . .    }     이 클래스를 제네릭으로 바꾼다고 해도 클라이언트에는 아무런 해가 없다.   오히려 위 코드는 클라이언트가 스택에서 꺼낸 객체를 형변환해야 하는데, 이때 런타임 오류가 날 위험이 있다.   일반 클래스를 제네릭 클래스로 만드는 첫 단계는 클래스 선언에 타입 매개변수를 추가하는 일이다.   public class Stack&lt;E&gt; {     private E[] elements;     private static final int DEFAULT_INITIAL_CAPACITY = 16;      public stack() {         elements = new E[DEFAULT_INITIAL_CAPACITY];     } }   이 상태에서 컴파일하면 다음과 같은 오류가 밟생한다.   Stack.java:8: generic array creation      elements = new E[DEFAULT_INITIAL_CAPACITY];                 ^   E와 같은 실체화 불가 타입으로는 배열을 만들 수 없다.     배열을 사용하는 코드를 제네릭으로 만들려 할 때 이 문제가 항상 발목을 잡을 것이다.   해결책은 두 가지가 있다.   (1) 제네릭 배열 생성을 금지하는 제약을 대놓고 우회하는 방법   Object 배열을 생성한 다음 제네릭 배열로 형변환해보자.   컴파일러는 오류 대신 경고를 내보낼 것이다. (일반적으로) 타입 안전하지 않다.   Stack.java8: warning: [unchecked] unchecked cast  found: Object[], required: E[]   elements = (E[]) new Object[DEFAULT_INITIAL_CAPACITY];               ^     컴파일러는 타입 안전한지 증명할 방법이 없지만 우리는 할 수 있다.   따라서 이 비검사 형변환이 프로그램의 타입 안전성을 해치지 않음을 우리 스스로 확인해야 한다.   배열 elements는 private 필드에 저장되고, 클라이언트로 반환되거나 다른 메서드에 전달되는 일은 전혀 없다.   push 메서드를 통해 배열에 저장되는 원소의 타입은 항상 E다. 따라서 이 비검사 형변환은 확실히 안전하다.   비검사 형변환이 안전함을 직접 증명했다면 범위를 좁혀 @SuppressWarnings 어노테이션으로 해당 경고를 숨긴다.   @SuppressWarnings(\"unckecked\") public Stack() {     elements = (E[]) new Object[DEFAULT_INITIAL_CAPACITY];   }         (2) elements 필드의 타입을 E[] 에서 Object[]로 바꾸는 방법        이렇게 하면 첫 번째와는 다른 오류가 발생한다.   Stack.java:19: incompatible types  found: Object, required: E     E result = elements[--size];   배열이 반환한 원소를 E로 형변환하면 오류 대신 경고가 뜬다.   E는 실체화 불가 타입이므로 컴파일러는 런타임에 이뤄지는 형변환이 안전한지 증명할 방법이 없다.   이번에도 개발자가 직접 증명하고 경고를 숨길 수 있다.  pop 메서드 전체에서 경고를 숨기지 않고 비검사 형변환을 수행하는 할당문에서만 숨기는 것이다.   public E pop() {       if(size == 0)            throw new EmptyStackException();          @SuppressWarnings(\"unckecked\") E result = (E) elements[--size];      elements[size] = null; //  다 쓴 참조 해제       return result; }   첫 번째 방법은 가독성이 좋고 코드가 짧기 때문에 자주 사용되는 방법이지만     (E가 Object가 아닌 한) 배열의 런타임 타입이 컴파일타임 타입과 달라 힙 오염(heap pollution)을 일으킨다.   힙 오염이 맘에 걸리는 개발자는 두 번째 방법을 사용하기도 한다.   그러나 두 번째 방법은 배열에서 원소를 읽을 때마다 어노테이션을 붙여줘야 한다.       정리    클라이언트에서 직접 형변환해야 하는 타입보다 제네릭 타입이 더 안전하고 쓰기 편하다.    그러니 새로운 타입을 설계할 때는 형변환 없이도 사용할 수 있도록 하자.   그렇게 하려면 제네릭 타입으로 만들어야 할 경우가 많다. 기존 타입 중 제네릭이있어야 하는 게 있다면 제네릭 타입으로 변경하자.   기존 클라이언트에게 아무 영향을 주지 않으면서 새로운 사용자를 편하게 해줄 수 있다.           2. 이왕이면 제네릭 메서드로 만들라.   클래스와 마찬가지로 메서드도 제네릭으로 만들 수 있다.        매개변수화 타입을 받는 정적 유틸리티 메서드는 보통 제네릭이다.   다음은 두 집합의 합집합을 반환하는 문제가 있는 메서드다.   public static Set union(Set s1, Set s2) {     Set result = new HashSet(s1);     result.addAll(s2);     return result; }     컴파일은 되지만 경고가 두 개 발생한다.   HashSet(Collection&lt;? extends E&gt;) as a member of raw type HashSet      Set result = new HashSet(s1);                  ^  addAll(Collection&lt;? extends E&gt;) as a member of raw type Set     result.addAll(s2);                  ^    경고를 없애려면 이 메서드를 타입 안전하게 만들어야 한다.   메서드 선언에서의 세 집합(입력 2개, 반환 1개)의 원소 타입을 타입 매개변수로 명시하고,   메서드 안에서도 이 타입 매개변수만 사용하게 수정하면 된다.   (타입 매개변수들을 선언하는) 타입 매개변수 목록은 메서드의 제한자와 반환 타입 사이에 온다.   다음 코드에서 타입 매개변수 목록은 &lt;E&gt; 이고 반환 타입은 Set&lt;E&gt; 이다.   public static &lt;E&gt; Set&lt;E&gt; union(Set&lt;E&gt; s1, Set&lt;E&gt; s2) {     Set&lt;E&gt; result = new HashSet&lt;&gt;(s1);     result.addAll(s2);     return result; }   직접 형변환하지 않아도 어떤 오류나 경고 없이 컴파일된다.   불변 객체를 여러 타입으로 활용할 수 있게 만들어야 할 때가 있다.   제네릭은 런타임에 타입 정보가 소거되므로 하나의 객체를 어떤 타입으로든 매개변수화할 수 있다.   하지만 이렇게 하려면 요청한 타입 매개변수에 맞게 매번 그 객체의 타입을 바꿔주는 정적 팩터리를 만들어야 한다.   이 패턴은 싱글톤 팩터리라고 하며, Collections.reverseOrder 같은 함수 객체나 Collections.emptySet 같은 컬렉션용으로 사용된다.   다음은 제네릭 싱글톤 팩터리 패턴의 예제 코드이다.   private static UnaryOperator&lt;Object&gt; IDENTITY_FN = (t) -&gt; t;  @SuppressWarnings(\"unckecked\") public static &lt;T&gt; UnaryOperator&lt;Object&gt; identityFunction() {     return (UnaryOperator&lt;T&gt;) IDENTITY_FN; }   IDENTITY_FN을 UnaryOperator&lt;T&gt;로 형변환하면 비검사 형변환 경고가 발생한다.      T가 어떤 타입이든 UnaryOperator&lt;Object&gt;는 UnaryOperator&lt;T&gt;가 아니기 때문이다.     하지만 항등함수한 입력 값을 수정 없이 그대로 반환하는 특별한 함수이므로, T가 어떤 타입이든 UnaryOperator&lt;T&gt;를 사용해도 타입 안전하다.     이 사실을 알고 있기 때문에 @SuppressWarnings(\"unckecked\") 어노테이션을 추가하면 오류나 경고 없이 컴파일 된다.   자기 자신이 들어간 표현식을 사용하여 타입 매개변수의 허용 범위를 한정할 수 있다.   재귀적 타입 한정(recursive type bound)이라는 개념이다.   재귀적 타입 한정은 주로 타입의 자연적 순서를 정하는 Comparable 인터페이스와 함께 쓰인다.   public interface Comparable&lt;T&gt; {       int compareTo(T o);   }   여기서 타입 매개변수 T는 Comparable&lt;T&gt;를 구현한 타입이 비교할 수 있는 원소의 타입을 정의한다.   실제로 거의 모든 타입은 자신과 같은 타입의 원소와만 비교할 수 있다.   다음은 이 제약을 코드로 표현한 코드이다.   public static &lt;E extends Comparable&lt;E&gt;&gt; E max(Collection&lt;E&gt; c);     타입 한정인 &lt;E extends Comparable&lt;E&gt;&gt;는 “모든 타입 E는 자신과 비교할 수 있다.”라고 읽을 수 있다.   상호 비교 가능하다는 뜻이다.                  3. 한정적 와일드카드를 사용해 API 유연성을 높여라.   매개변수화 타입은 불공변(invariant)이다.    즉 서로 다른 타입 Type1과 Type2가 있을 떄 List은 List의 하위 타입도 상위 타입도 아니다.      예를들어 `List`은 `List`의 하위 타입이 아니라는 뜻이다.   `List`에는 어떤 객체든 넣을 수 있지만 `List`에는 문자열만 넣을 수 있다.    즉 `List`은 `List`가 하는 일을 제대로 수행하지 못하니 하위 타입이 될 수 없다. (리스코프 치환 원칙에 어긋난다.)   Stack의 public API를 추려보자.   public class Stack&lt;E&gt; {     public Stack();     public void push(E e);     public E pop();     public boolean isEmpty(); }   여기에 일련의 원소를 스택에 넣는 메서드를 추가해야 한다고 해보자.      와일드카드 타입을 사용하지 않는 pushAll 메서드 (결함있음)   public void pushAll(Iterable&lt;E&gt; src) {     for(E e : src)         push(e); }   이 메서드는 깨끗하게 컴파일되지만 완벽하진 않다. Iterable src의 원소 타입이 스택의 원소 타입과 일치하면 잘 작동한다.   하지만 Stack&lt;Number&gt;로 선언한 후 pushAll(intVal)을 호출하면 다음과 같은 오류 메시지가 뜬다. (intVal은 Integer타입이다.)   StackTest.java7: error: incompatible types: Iterable&lt;Integer&gt; cannot be converted to Iterable&lt;Number&gt;     numberStack.pushAll(integers);                         ^   Integer는 Number의 하위 타입이므로 잘 작동할 것 같지만 매개변수화 타입이 불공변이기 때문에 오류 메시지가 뜬다.   이런 상황은 한정적 와일드카드 타입이라는 매개변수화 타입으로 해결할 수 있다.    pushAll의 입력 매개변수 타입은 ‘E의 Iterable’이 아니라 ‘E의 하위 타입의 Iterable’이어야 하며,       와일드카드 타입 Iterable&lt;? extends E&gt;가 위와 같은 뜻이 된다.   public void pushAll(Iterable&lt;? extends E&gt; src) {       . . .   }   이번에는 popAll 메서드를 구현하면서 Stack&lt;Number&gt;의 원소를 Object용 컬렉션은로 옮긴다고 가정해보자.   public void popAll(Collection&lt;E&gt; dst) {      . . . }  Stack&lt;Number&gt; numberStack = new Stack&lt;&gt;(); Collection&lt;Object&gt; objects - ...; numberStack.popAll(objects);   위 코드를 컴파일하면 “Collection&lt;Object&gt;는 Collection&lt;Number&gt;의 하위 타입이 아니다.” 라는   pushAll을 사용했을 때와 비슷한 오류가 발생한다.   이번에는 pushAll의 입력 매개변수의 타입이 ‘E의 Collection’이 아니라 ‘E의 상위 타입의 Collection’이어야 한다.   (모든 타입은 자기 자신의 상위 타입이다.)  와일드카드 타입을 사용한 Collection&lt;? super E&gt;가 정확히 이런 의미이다.   public void popAll(Collection&lt;? super E&gt; dst) {      . . . }   이제 Stack과 클라이언트 코드 모두 말끔히 컴파일된다.   유연성을 극대화하려면 원소의 생상자나 소비자용 입력 매개변수에 와일드카드 타입을 사용하자.   한편, 입력 매개변수가 생산자와 소비자 역할을 동시에 한다면 와일드카드 타입을 써도 좋을 게 없다.     타입을 정확히 지정해야 하는 상황으로 이때는 와일드카드 타입을 쓰지 말아야 한다.       ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2020-11-20/response&generic/",
        "teaser": null
      },{
        "title": "Jenkins 배포 자동화",
        "excerpt":"어쩌다보니 배포 자동화도 하게 되었는데 ci와 마찬가지로 스크립트를 작성해서 꼼꼼하게 배포 과정을 공부해보기로 했다. 처음에는 젠킨스가 docker로 띄워진줄 모르고 ssh key를 생성하고 배포용 서버에 넣어줬는데   다음과 같은 메시지가 뜨면서 실패해서 당황했지만     Host key verification failed.Host key verification failed.   젠킨스를 docker로 띄웠을 때는 ssh key를 jenkins_home에서 생성해야 한다는 것을 알 수 있었다.       Script   아직 완성된건 아니지만 원하는 git branch 로 언제든지 배포용 서버에 배포될 수 있게 젠킨스 설정을 마쳤다.   #!/bin/bash   #원하는 브랜치에서 clone받아 배포해볼 수 있게 파라미터로 브랜치만 받는다.  git clone -b $branch --single-branch https://github.com/depromeet/8th-final-team5-backend.git  #properties를 생성하는 쉘 파일을 만들 계획인데 프로젝트 진행을 위해 일단 다음과 같이 생성했다.  cd 8th-final-team5-backend ./mvnw clean package cd ./target mkdir config cd ./config touch application.properties  #active를 prod로 설정해줘야 디폴트 파일로 실행되지 않는다.  echo \"spring.profiles.active=prod\" &gt;&gt; application.properties echo \"spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\" &gt;&gt; application.properties echo \"spring.datasource.url=jdbc:mysql://dodo.mysql.database.azure.com:3306/dodo?useUnicode=yes&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;serverTimezone=Asia/Seoul\" &gt;&gt; application.properties echo \"spring.datasource.username=\" &gt;&gt; application.properties echo \"spring.datasource.password=\" &gt;&gt; application.properties echo \"spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl\" &gt;&gt; application.properties  #배포용 서버에 있던 이전 파일들을 삭제한다.  ssh dangdang@20.196.153.12 \"rm -rf ~/dodo/*\"  #jar파일과 properties가 들어있는 config 디렉토리를 배포용 서버로 보내준다.  cd ../ scp -r -P 22 config dangdang@20.196.153.12:dodo scp -P 22 5th-final-0.0.1-SNAPSHOT.jar dangdang@20.196.153.12:dodo  #우선 java가 들어가는 프로세스를 kill하는데 이 부분도 어떻게 해결해야 할지 아직 고민중이다. ssh dangdang@20.196.153.12 \"pkill -9 java\"     #배포, log는 dodo 디렉토리의 tomcat.log에 저장된다.  ssh dangdang@20.196.153.12 \"cd dodo; nohup java -jar 5th-final-0.0.1-SNAPSHOT.jar &gt;&gt; tomcat.log &amp;\"   아직 많은 부분을 수정해야 하지만 원하는 브랜치를 젠킨스의 Build With Parameters에서 파라미터로 넘겨 빌드시키면      자동으로 배포용 서버에 jar와 config를 생성해 넘겨 배포되는 자동 배포가 완성되었다.   properties 파일을 생성하는 부분과 실행 중인 프로세스를 kill하는 부분을 조금 더 고민해보고 수정할 예정이다.   ","categories": ["Depromeet","Jenkins"],
        "tags": ["jenkins"],
        "url": "/2020-11-21/jenkins-cd/",
        "teaser": null
      },{
        "title": "AWS S3, BULK INSERT",
        "excerpt":"AWS S3 : 프로필 이미지 저장   설계   사용자가 kakao, naver로 회원가입을 하지만 따로 프로필 이미지를 지정하고 싶은 경우     이미지 파일을 받는다. 반려견은 3장의 이미지 파일을 등록할 수 있다.     3장의 이미지 파일은 우선순위가 있다는 것이 주의할 점이다.   그래서 이미지와 사용자, 반려견의 연관관계에 대해 고민이 많았는데       나중에 서비스에 sns 기능을 추가할 생각이 있기 때문에     다음 두가지 방법 중 2번째 방법으로 구현하기로 했다.         방법1 : Image 테이블에 모든 정보 넣기          방법2 : 우선순위, 카테고리 별로 테이블 따로 두기                   AWS S3      모든 종류의 데이터를 원하는 형식으로 저장 가능하다.   저장할 수 있는 데이터의 전체 볼륨과 객체 수에 제한이 없다.   key 기반의 객체 스토리지, 데이터 저장 및 검색에 사용되는 고유 키가 할당된다.         Object Storage, S3   S3의 가장 큰 특징인 내구성과 가용성을 이해하기 위해 객체 스토리지(Object Storage)가 어떤 방식으로 설계되었는지 이해해보자.     다음은 일반적인 스토리지의 예시이다.      한 사용자가 데이터를 업로드하고 또 다른 사용자가 해당 데이터를 다운로드 하려는데     시간이 지나 수명이 다했더나 물리적인 손상으로 인해 데이터가 있는 영역이 손상되었다고 가정하자.   이제 그 공간에 놓인 데이터는 내구성이 손상되었으며, 사용할 수 없게 되었으므로 가용성 또한 훼손되었다.      물리적인 저장 공간이 어떻게 설계되었느냐에 따라 손상될 확률에 차이가 있겠지만      물리 장비의 한계상 결국 언젠가 데이터의 내구성과 가용성에 문제가 생길 수 밖에 없다.   그래서 이런 물리적인 한계를 논리적인 방식으로 극복하고자 한 구성이 객체 스토리지이다.         객체 스토리지는 기본적으로 내부 복제를 전제로 한다. (내부 복제가 고유 특징이라고 할 수는 없다.)   하나의 단위 객체가 업로드되면 자동적으로 내부의 여러 위치에 복제본을 생성한다.   S3의 경우 동일 Region 내의 여러 AZ에 걸쳐 복제본을 생성한다.      내부적으로 복제가 수행되면 어느 한 객체에 손상이 발생하더라도 손상되지 않은 복제본이 있기 때문에 내구성이 상승한다.   가용성 또한 향상된다. 복제본도 원본과 동일하게 실제 다운로드 요청에 응답하는데 사용되기 때문이다.   하지만 내부 복제에는 일정한 시간이 소요되기 때문에 내부 복제가 모두 완료(Fully Propagated)되기 이전에는     각기 다른 객체의 위치에서 응답하므로 사용자별로 일관되지 않은 응답이 발생할 수 있다.      새로 쓰기(create)의 경우 일부 요청에 객체 목록이 표시되지 않음   덮어쓰기의 경우 일부 요청에 이전 버전의 객체를 응답할 수 있음   삭제의 경우 일부 요청에 삭제되기 전의 객체가 표시되거나 응답할 수 있음   위와 같은 현상은 일시적인 것이며, 일정 시간이 지난 후에는 내부 복제가 모두 완료되어 모든 사용자에게 일관된 응답을 제공하게 된다.      이것을 Eventual Consistency(최종 일관성)를 제공한다고 말하며, 이는 객체 스토리지의 특성이자 S3의 특성이 된다.   객체 스토리지 및 S3의 공통적인 특성은 다음과 같다.     객체의 생성, 삭제만 지원한다. 수정은 지원하지 않는다.   덮어쓰기가 가능하지만 내부적으로 수정처리하는 것이 아니라 동일한 경로로 재생성하는 방식이다.   객체 데이터와 관련도니 부가정보는 객체 데이터 외부에 별도로 저장하여 관리한다.     부가정보를 Metadata라고 부르며 “Key-Value” 형태로 항목을 자유롭게 추가하여 관리할 수 있다.   HTTP(S) 프로토콜을 사용하여 업로드/다운로드할 수 있다.   참고 : https://acstory.tistory.com/33             aws s3 bulk upload   그동안 AWS S3를 2번 정도 사용해봤는데 여러 이미지를 저장해야 하는 경우가 없어서     putObject() 메소드만 사용해서 하나의 MultipartFile만 저장했었다.   이번에는 반려동물의 프로필 이미지 3개를 한번에 저장해야 했기 때문에     이미지 리스트를 한번에 저장할 수 있는 기능이 있는지 찾아봤다.   TransferManager를 사용하여 List&lt;File&gt;을 한번에 넘겨주니     랜덤 문자열로 지정한 폴더와 이미지가 잘 저장된다.   참고 : https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/HLuploadFileJava.html             BULK INSERT   대용량 데이터를 로드하는 방법은 다양하다. 그 중 많이 사용하는 BULK INSERT에 대해 알아보기로 했다.   INSERT INTO T VALUES(a, b, c); INSERT INTO T VALUES(d, e, f);   위 INSERT 는 다음과 같이 바꿀 수 있다.   INSERT INTO T VALUES (a, b, c), (d, e, f);   그러나 JPA에서 @GeneratedValue(strategy = GenerationType.IDENTITY) 이렇게 Auto Increment로 설정했을 때          saveAll() 을 사용해서 List로 저장하면 bulk insert로 저장될거라고 생각했는데 데이터 개수만큼 Insert 또는 Update 쿼리가 나간다.   Hibernate에서 Auto Increment인 경우 bulk insert를 지원하지 않는다고 하는데         Entity의 Id를 알 수 없는 경우 Transactional write behind       (쓰기 지연 : 트랜잭션이 커밋되기 전까지 쿼리 저장소에 모아뒀다가 한번에 실행)과 충돌이 발생하기 때문이다.   Ex. OneToMany의 Entity를 Insert하는 경우       (1) 부모 Entity를 Insert하고 생성된 Id 리턴       (2) 자식 Entity에서 부모의 Id를 전달받아 Fk에 채워서 Insert   이 과정에서 쿼리를 모아서 실행하는게 Hibernate의 방식인데        부모 Entity를 한번에 대량 등록하면, Fk에 어떤 부모의 Id를 매핑해야 되는지 알 수 없기 때문에 bulk insert가 불가능하다.            (그래서 Hibernate가 JDBC 수준에서 batch insert를 비활성화한다.)   왜 IDENTITY 방식을 권장할까?    bulk insert를 위해 TABLE이나 SEQUENCE(mysql에는 sequence가 없음) 방식으로 바꿔야 하나 잠시 고민했는데       채번에 따른 부하가 상당해서 IDENTITY 방식보다 더 느린 결과가 나올 수 있다고 한다. (+ 성능상 이슈와 Dead Lock에 대한 이슈)             참고 : JPA GenerationType에 따른 INSERT 성능 차이   어떤 변경없이 IDENTITY 방식을 그대로 사용할거지만        왜 IDENTITY를 사용해야 하는지 알아볼 수 있는 좋은 경험이었다.   참고     https://vladmihalcea.com/why-you-should-never-use-the-table-identifier-generator-with-jpa-and-hibernate/   https://jojoldu.tistory.com/507      ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2020-11-26/review3/",
        "teaser": null
      },{
        "title": "동네 반려견 탐색 기능을 위한 주소 저장",
        "excerpt":"우리집에서 가까이 있는 반려동물을 탐색하는 기능을 구현하기 위해   kakao map api를 사용하여 주소를 저장해보기로 했다.   Kakao Map Api      developers.kakao   좌표로 주소 변환하기   내 애플리케이션 생성 후 승인키를 발급 받아 좌표로 주소를 변환하는 api에 헤더로 넘겨주면 된다.   내 애플리케이션에서 승인키 발급 뿐만 아니라 도메인과 IP 설정을 해줘야 api 사용이 가능하다.       좌표와 주소를 어떻게 저장할까   클라이언트에서 x, y 좌표를 받아 주소를 변환하는 것까지 테스트를 마치고   DB에 좌표를 저장하고 가까이 있는 반려동물을 조회해야 하는데   MySQL에 Point 타입으로 저장하고 조회할 수 있다는 사실을 알게 되었다.   다음과 같이 설정하여 공간 데이터 타입을 사용할 수 있으며     공간 데이터 타입을 활용하여 위치 데이터를 인덱싱할 수 있다.      pom.xml   &lt;dependency&gt;     &lt;groupId&gt;com.vividsolutions&lt;/groupId&gt;     &lt;artifactId&gt;jts&lt;/artifactId&gt;     &lt;version&gt;${version}&lt;/version&gt; &lt;/dependency&gt;  &lt;dependency&gt;     &lt;groupId&gt;org.hibernate&lt;/groupId&gt;     &lt;artifactId&gt;hibernate-spatial&lt;/artifactId&gt;     &lt;version&gt;${version}&lt;/version&gt; &lt;/dependency&gt;          application.yml   spring:       jpa:           database-platform: org.hibernate.spatial.dialect.mysql.MySQL56InnoDBSpatialDialect            INDEX   Point 타입은 다음과 같이 인덱스 생성이 가능하다.   CREATE SPATIAL INDEX [index_name] ON [table_name] ([index_column]);        ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2020-12-03/address/",
        "teaser": null
      },{
        "title": "Index",
        "excerpt":"예전에 교내 수업에서 프로젝트를 하면서 인덱스를 적용해보면서       어떤 경우에 인덱스를 타지 않는지 주의 사항에 대해서는 알게 되었지만       어떻게 생성해야 최적으로 생성할 수 있는지는 헷갈리기 때문에    더 알아보고 제대로 설정해보고자 Real MySQL을 읽어보기로 했다.       인덱스란?   데이터베이스 테이블의 모든 데이터를 검색해서 원하는 결과를 가져오려면 시간이 오래 걸린다.     그래서 칼럼의 값과 해당 레코드가 저장된 주소를 키와 값의(key-value) 쌍으로 인덱스를 만들어두는 것이다.    최대한 빠르게 찾아갈 수 있게 칼럼의 값을 주어진 순서로 미리 정렬해서 보관한다.   SortedList는 DBMS의 인덱스와 같은 구조이고 ArrayList는 데이터 파일과 같은 자료구조를 사용한다.   인덱스는 저장되는 컬럼의 값을 이용해 항상 정렬된 상태로 유지한다.   때문에 데이터가 저장될 때마다 항상 값이 정렬되서 저장하는 과정이 복잡하고 느리지만,   이미 정렬돼 있어서 빨리 원하는 값을 찾아올 수 있다.       B-Tree 인덱스 키 검색   B-Tree 인덱스를 이용한 검색은 100%일치 또는 값이 앞부분만 일치하는 경우에 사용할 수 있다.   부등호 비교나 값의 뒷부분이 일치하는 경우에는 B-Tree 인덱스를 이용한 검색이 불가능하다.   또한 인덱스의 키값에 변형이 가해진 후 비교되는 경우에는 절대 B-Tree의 빠른 검색 기능을 사용할 수 없다.   따라서 함수나 연산을 수행한 결과로 정렬한다거나 검색하는 작업은 B-Tree의 장점을 이용할 수 없다.   인덱스 조회 주의사항은 다음과 같다.      첫번째 인덱스 컬럼이 조회 쿼리에 없으면 인덱스를 타지 않는다.   AND 연산자는 각 조건들이 읽어와야할 ROW 수를 줄이는 역할을 하지만,    or 연산자는 비교해야할 ROW가 더 늘어나기 때문에 풀 테이블 스캔이 발생할 확률이 높다.   인덱스로 사용된 컬럼값 그대로 사용해야만 인덱스가 사용된다.     ex. where salary * 10 &gt; 150000; 는 인덱스를 못타지만, where salary &gt; 150000 / 10; 은 인덱스를 사용   null 값의 경우 is null 조건으로 인덱스 레인지 스캔 가능   인덱스 순서와 조회 순서를 지킬 필요는 없다. 조회조건에 포함되어 있는지가 중요하다.       선택도 (기수성)   모든 인덱스 키값 가운데 유니크한 값의 수를 의미한다.              전체 인덱스 기값은 100개인데 그중에서 유니크한 값의 수는 10개라면 기수성은 10이다.               중복된 값이 많아지면 기수성은 낮아지고 선택도 또한 떨어진다.                       인덱스는 선택도가 높을수록 검색 대상이 줄어들기 때문에 그만큼 빠르게 처리된다.       읽어야 하는 레코드의 건수   인덱스를 통해 테이블의 레코드를 읽는 것은 인덱스를 거치지 않고 바로 테이블의 레코드를 읽는 것보다 높은 비용이 드는 작업이다.     테이블에 레코드가 100만 건이 저장돼 있는데, 그중에서 50만 건을 읽어야 하는 쿼리가 있다고 가정하자.     이 작업은 필요 없는 50만 건을 버리는 것이 효율적일지, 인덱스를 통한 필요한 50만 건만 일어 오는 것이 효율적일지 판단해야 한다.   일반적인 DBMS의 옵티마이저에서는 인덱스를 통해, 테이블에서     직접 레코드 1건을 읽는 것보다 4~5배 정도 더 비용이 많이 드는 작업으로 예측된다.       인덱스를 통해 읽어야 할 레코드의 건수가 전체 테이블 코드의 20~25%를 넘어서면 인덱스를 이용하지 않고     직접 테이블을 모두 읽어서 필요한 레코드만 가져내는(필터링) 방식으로 처리하는 것이 효율적이다.       B-Tree 인덱스를 통한 데이터 읽기   인덱스 사용을 결정하려면 MySQL(각 스토리지 엔진)이 어떻게 인덱스를 이용해서 레코드를 읽어오는지 알아야 한다.   1) 인덱스 레인지 스캔    인덱스를 통해 레코드를 한 건만 읽는 경우와 한 건 이상을 읽는 경우 각각 다른 이름으로 구분하지만   모두 묶어서 “인덱스 레인지 스캔”이라고 표현할 수 있다.   SELECT * FROM employees WHERE first_name BETWEEN 'Ebbe' AND 'Gad'   인덱스 레인지 스캔은 검색해야 할 인덱스 범위가 결정되었을 때 사용하는 방식이다.     검색하려는 값의 수나 검색 결과와는 관계없이 레인지 스캔이라고 표현한다.     루트 노드에서부터 비교를 시작해 브랜치 노드를 거치고 최종적으로     리프 노드까지 찾아 들어가면 실제로 원하는 시작 지점을 찾을 수 있다.       시작 위치를 찾으면 그때부터 리프 노드의 레코드만 순서대로 읽으면 된다.   중요한 것은 인덱스의 리프 노드에서 검색 조건에 일치하는 건들은 데이터 파일에서 레코드를 읽어오는 과정이 필요하다는 것이다.    이때 리프 노드에 저장된 레코드 주소로 데이터 파일의 레코드를 읽어오는데 레코드 한 건 한 건 단위로 랜덤 I/O가 한 번씩 실행된다.   2) 인덱스 풀 스캔  인덱스 레인지 스캔과 마찬가지로 인덱스를 사용하지만 인덱스 레인지 스캔과 다르게 인덱스의 처음부터 끝까지 모두 읽는 방식을 인덱스 풀 스캔이라고 한다.   쿼리의 조건절에 사용된 컬럼이 인덱스의 첫 번째 컬럼이 아닌 경우 인덱스 풀 스캔 방식이 사용된다.   일반적으로 인덱스의 크기는 테이블의 크기보다 작으므로 직접 테이블을 처음부터 끝까지 읽는 것보다는 인덱스만 읽는 것이 효율적이다.    쿼리가 인덱스에 명시된 컬럼만으로 조건을 처리할 수 있는 경우 주로 이 방식이 사용된다.   먼저 인덱스 리프 노드의 제일 앞 또는 제일 뒤로 이동한 후,     인덱스의 리프 노드를 연결하는 Linked list를 따라서 처음부터 끝까지 스캔하는 방식을 인덱스 풀 스캔이라고 한다.         이 방식은 인덱스 레인지 스캔보다는 빠르지 않지만 테이블 풀 스캔보다는 효율적이다.     인덱스에 포함된 컬럼만으로 쿼리를 처리할 수 있으면 테이블의 레코드를 읽을 필요가 없기 때문에 적은 디스크 I/O로 쿼리를 처리할 수 있다.      주의   인덱스 풀 스캔 방식은 인덱스를 사용하는 것이지만 효율적인 방법은 아니며 일반적으로 인덱스를 생성하는 목적은 아니다.   3) 루스 인덱스 스캔    루스 인덱스 스캔은 말 그대로 느슨하게 혹은 듬성듬성하게 인덱스를 읽는 것을 의미한다.     루스 인덱스 스캔은 인덱스 레인지 스캔과 비슷하게 작동하지만,   중간마다 필요치 않은 인덱스 키값은 무시하고 다음으로 넘어가는 형태로 처리한다.   일반적으로 GROUP BY 또는 집합 함수 중 MAX(), MIN() 함수에 대해 최적화하는 경우 사용된다.       B-Tree 인덱스의 가용성과 효율성  쿼리의 WHERE 조건이나 GROUP BY 또는 ORDER BY 절이 어떤 경우에 인덱스를 사용할 수 있고     어떤 방식으로 사용할 수 있는지 식별할 수 있어야 한다.       그래야 쿼리의 조건을 최적화하거나 역으로 쿼리에 맞게 인덱스를 최적으로 생성할 수 있다.   1) 비교 조건의 종류와 효율성   다중 칼럼 인덱스에서 각 칼럼의 순서와 그 칼럼에 사용된 조건이 동등 비교(“=”)인지   아니면 크다(“&gt;”) 또는 작다(“&lt;”)와 같은 범위 조건인지에 따라 각 인덱스 칼럼의 활용 형태가 달라지며,    효율 또한 달라진다. 예제로 알아보자.   SELECT * FROM dept_emp  WHERE dept_no='d002' AND emp_no &gt;= 10114;   위 쿼리를 위해 dept_emp 테이블에 각각 칼럼의 순서만 다른 2가지 케이스로 인덱스를 생성했다고 가정하자.      케이스 A : dept_no + emp_no   케이스 B : emp_no + dept_no   케이스 A는 dept_no='d002' AND emp_no &gt;= 10114 인 레코드를 찾고   그 이후에는 dept_no='d002'가 아닐 때까지 인덱스를 읽기만 하면 된다.   이 경우 읽은 레코드가 모두 사용자가 원하는 결과임을 알 수 있다.   즉 5건의 레코드를 찾는 데 꼭 필요한 5번의 비교 작업만 수행한 것이므로 상당히 효율적으로 인덱스를 이용한 것이다.   하지만 케이스 B는 우선 emp_no &gt;= 10144 AND dept_no='d022'인 레코드를 찾고,   그 이후 모든 레코드에 대해 dept_no='d022'가 맞는지 비교하는 과정을 거쳐야 한다.     이처럼 인덱스를 통해 읽은 레코드가 나머지 조건에 맞는지 비교하면서 취사선택을 하는 작업을 필터링이라고도 한다.   작업 범위를 결정하는 조건은 많으면 많을수록 쿼리의 처리 성능을 높이지만 체크 조건은 많다고 해서      (최종적으로 가져오는 레코드는 작게 만들지 몰라도) 쿼리의 처리 성능을 높이지는 못한다.      오히려 쿼리 실행을 더 느리게 만들 때가 많다.   2) 인덱스의 가용성    B-Tree 인덱스의 특징은 왼쪽 값에 기준해서 오른쪽 값이 정렬돼 있다는 것이다.   여기서 왼쪽이라 함은 하나의 컬럼 내에서뿐만 아니라 다중 칼럼 인덱스의 칼럼에 대해서도 함께 적용된다.      케이스 A : INDEX (first_name)   케이스 B : INDEX (dept_no, emp_no)   SELECT * FROM employees WHERE first_name LIKE '%mer';   이 쿼리는 인덱스 레인지 스캔 방식으로 인덱스를 이용할 수는 없다.   그 이유는 first_name 칼럼에 지정된 값의 왼쪽부터 한 글자씩 비교해 가면서 일치하는 레코드를 찾아야 하는데.   조건절에 주어진 상수값에는 왼쪽 부분이 고정되지 않았기 때문이다.   다음은 케이스 B의 인덱스가 지정된 dept_emp 테이블에 대한 쿼리이다.   SELECT * FROM dept_emp WHERE emp_no &gt;= 10144;   인덱스가 (dept_no, emp_no) 칼럼 순서대로 생성돼 있다면 인덱스의 선행 칼럼인 dept_no 값 없이   emp_no 값으로만 검색하면 인덱스를 효율적으로 사용할 수 없다.   케이스 B의 인덱스는 다중 칼럼으로 인덱스가 만들어졌기 때문에 dept_no에 대해 먼저 정렬한 후,   다시 emp_no 칼럼으로 정렬돼있기 때문이다.       project   CREATE INDEX IDX_USER_PET ON User (petId);    CREATE INDEX IDX_USER_LOCATION ON User (locationId);    CREATE INDEX IDX_PROFILE_PET ON PetProfile (petId);   CREATE INDEX IDX_PROFILE_USER ON UserProfile (userId);    CREATE INDEX IDX_BREED_PET ON PetBreed (petId);   CREATE INDEX IDX_CHARACTER_PET ON PetCharacter (petId);    CREATE INDEX IDX_INTEREST_PET ON PetInterest (petId);    CREATE SPATIAL INDEX IDX_LOCATION_POINT ON Location (point);     우선 자주 조회하고 중복이 없는 key에 index를 생성했고    사용자의 주소 좌표를 저장하는 point는 가까이에 있는 사용자를 조회해야 하기 때문에     SPATIAL INDEX로 생성했다.     나중에 거리 계산 로직이 결정되면 EXPLAIN으로 key가 원하는대로 나오는지 확인이 필요하다.   ","categories": ["MySQL","Database"],
        "tags": ["mysql","database"],
        "url": "/2020-12-06/index/",
        "teaser": null
      },{
        "title": "Gradle vs. Maven",
        "excerpt":"    예전에 안드로이드 실습과 디프만 워밍업 프로젝트에서 gradle을 사용해봤는데      우선 왜 gradle이 선택되었는지 알아보자.       빌드 도구 종류: Gradle vs Maven  maven과 gradle은 빌드 관리 도구이다.    빌드 관리 도구란 빌드 자동화를 수행해 실행 가능한 프로그램으로 바꿔주는 도구이다.   즉 코드를 컴파일해서 binary code로 만들고 패키징, 테스트하여 실행 가능한   프로그램이 나오기 까지의 과정(빌드)을 자동화하는 것이다.      Performance 측면에서 gradle이 maven보다 빠른 성능을 보여준다.   https://gradle.org/maven-vs-gradle/              Maven     자바용 프로젝트 관리 도구   pom.xml 을 이용한다.   사용할 라이브러리 뿐만 아니라 해당 라이브러리가 작동하는데 필요한 다른 라이브러리들까지 네트워크를 통해 자동으로 다운로드한다.   정해진 라이프사이클에 의하여 작업을 수행하며, 프로젝트 관리 기능도 포함하고 있다.              Gradle     오픈소스 기반의 build 자동화 시스템   JVM 기반의 빌드 도구로 기존의 Ant와 Maven을 보완   설정 주입 방식 (Configuration Injection)   Groovy 문법 사용                     Gradle 사용을 고려해야할 이유  (1) 속도가 빠르다.      (2) Build라는 동적인 요소를 XML로 정의하기에는 어려운 부분이 많다.     설정 내용이 길어지고 가독성이 떨어진다.   의존 관계가 복잡한 프로젝트 설정하기에 부적절하다.   상속 구조를 이용한 멀티 모듈 구현   특정 설정을 소수의 모듈에서 공유하기 위해서는 부모 프로젝트를 생성하여 상속하게 해야한다.       (3) Gradle은 Groovy를 사용하기 때문에 동적인 빌드는 Groovy 스크립트로 플러그인을 호출하거나 직접 코드를 작성하면 된다.     설정 주입 방식을 사용해서 공통 모듈을 상속해서 사용하는 단점을 커버한다.   설정 주입 시 프로젝트의 조건을 체크할 수 있어서 프로젝트별로 주입되는 설정을 다르게 할 수 있다.       (4) 성능     Incrementality: gradle은 가능한 경우 변경된 파일만 작업해 중복을 피한다.   build cache: 동일한 입력에 대해서 gradle 빌드를 재사용한다.   gradle 데몬: 빌드 정보를 메모리에 유지하는 프로세스를 구동한다.   Performance 측면에서 gradle이 maven보다 빠른 성능을 보여준다.   https://gradle.org/maven-vs-gradle/                     참고     https://docs.gradle.org/current/userguide/java_library_plugin.html   https://tomgregory.com/how-to-use-gradle-api-vs-implementation-dependencies-with-the-java-library-plugin/   https://medium.com/mindorks/implementation-vs-api-in-gradle-3-0-494c817a6fa   https://docs.gradle.org/4.6/release-notes.html   https://blog.gradle.org/incremental-compiler-avoidance#about-annotation-processors   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-01-06/buildtool/",
        "teaser": null
      },{
        "title": "ssh config 사용해서 ssh 접속하기",
        "excerpt":"젠킨스를 도커로 띄워 사용하면서 ssh 접속을 자주 경험했었다.     이전에 젠킨스 사용하며 ssh 접속 방법 : https://hyerin6.github.io/2020-04-24/0424/   항상 원격 서버에 public key를 등록하고 (.ssh/authorized_keys)                   ssh 계정@호스트주소 명령으로 ssh 접속을 했는데                    이번에는 config 파일을 이용해 원격 접속을 더 간단하게 해보기로 했다.       config 파일을 이용한 원격 접속   (1) ~/.ssh에 config 파일을 생성한다. 접근 권한은 600으로 설정   cd ~/.ssh  touch config  chmod 600 config       (2) config 파일 내 원격 접속 정보 추가     Host : ssh 접속 시 이용할 별명   HostName : ip 혹은 host 주소   User : (원격 서버) 계정   IdentityFile : ssh 접속에 이용할 private key (id_rsa : Private Key file)   위 정보를 config 파일에 담아야 하는데 다음과 같이 작성하면 된다.    이번 프로젝트에서는 port도 지정해야해서 Port 설정도 추가했다.  Host woof   HostName [ip 혹은 host 주소]   User [계정]   IdentityFile [private key (위치)]   Port [port]   별명을 woof로 설정했기 때문에 ssh 접속할 때 다음과 같이 접속하면 된다.  ssh woof   직접 설정한 이름을 이용해서 ssh 접속을 간편하게 할 수 있다.       (3) 패스워드가 있다면 패스워드 입력 후 접속이 가능하다.                          Passphrase 는 키의 비밀번호로, 암호화되어 키 생성에 사용된다.   ","categories": ["Depromeet"],
        "tags": [],
        "url": "/2021-01-15/ssh-config/",
        "teaser": null
      },{
        "title": "Counting Sort & Radix Sort",
        "excerpt":"Counting Sort (계수 정렬)   보통 빠르다는 정렬 알고리즘으로는 대표적으로      퀵 정렬(Quick Sort), 힙 정렬(Heap Sort), 합병 정렬(Merge Sort) 등이 있다.      정렬은 보통 데이터끼리 비교하는 경우가 많아 𝚶(nlogn)보다 작아질 수 없는 것이 한계다.           정렬 방법  (1) 정렬할 배열에 들어있는 값들 각각의 수를 세기 위한 count 배열을 생성한다.    값의 종류가 많지 않다면, count 배열의 크기도 크지 않을 것이다.   (2) 정렬할 배열을 선형 탐색하며, 각 값들의 수를 센다.   (3) 각 값들의 수는 알고 있다는 것은, 정렬 결과 배열에 각 값들이 순서대로 몇 개씩 들어있어야 하는지 안다는 것이다. 정렬 결과 배열을 생성한다.   두 수를 비교하는 과정이 없기 때문에 빠른 배치가 가능하지만 count 배열이라는 새로운 배열을 선언해야 한다.          배열 안에 있는 max값의 범위에 따라 counting 배열의 길이가 달라지게 된다.         예로들어 10개의 원소를 정렬하고자 하는데, 수의 범위가 0~1억이라면 메모리가 매우 낭비가 된다.   즉 Counting Sort가 효율적인 상황에서 쓰려면 수열의 길이보다 수의 범위가 극단적으로 크면 메모리가 엄청 낭비 될 수 있다는 것이다.    상황에 맞게 정렬 알고리즘을 써야하고 Quick 정렬의 경우 시간복잡도 평균값이 𝚶(nlogn)으로 빠른편이면서 배열도 하나만 사용하기 때문에  공간복잡도는 𝚶(𝑛)으로 시간과 메모리 둘 다 효율적이라 대표적으로 많이 쓰인다.       수행시간  수행시간: O(n + m)    메모리 요구량: O(n + m)           n &gt; m          수행시간: O(n)    메모리 요구량: O(n)                 n &lt; m            수행시간: O(m)    메모리 요구량: O(m)           TreeMap  counting sort를 구현할 때, 자바의 TreeMap 클래스가 유용하다.    Map 인터페이스를 implements 했기 때문에 사용법은 다음과 같다.   - 데이터 저장: map.put(key, value) - 데이터 값 조회: map.get(key) - 데이터 제거: map.remove(key)      HashMap 클래스는 해시 테이블 자료구조로 구현되었고, put, get, remove 모두 O(1) 이다.   TreeMap 클래스는 레드 블랙 트리 자료구조로 구현되었다. put, get, remove 모두 O(log N) 이다.   레드 블랙 트리는 이진 트리이므로, TreeMap 클래스의 데이터 목록은 키(key) 값을 기준으로 정렬되어 있다.          그러기 때문에 별도에 정렬은 하지 않고 TreeMap에 값을 순차적으로 출력하면 된다.    하지만 TreeMap은 Key값이 중복이 되지 않기 때문에 값의 갯수를 value에 넣어야 한다.             Radix Sort(기수 정렬)   낮은 자리 수 부터 비교하여 정렬해 간다는 것을 기본 개념으로 하는 정렬 알고리즘이다.          자릿수가 고정되어 있으니, 안전성이 있고(이때 데이터들 간의 상대적 순서는 보존되어야 한다.)        기수 정렬은 비교 연산을 하지 않으며, 무엇보다도 전체 시간복잡도 역시 O(dn)이어서, 정수와 같은 자료의 정렬 속도가 매우 빠르다.        정렬할 데이터의 radix가 작은 경우에 활용할 수 있다.   하지만, 데이터 전체 크기에 기수 테이블의 크기만한 메모리가 더 필요하다.         기수 정렬은 정렬 방법의 특수성 때문에, 부동소수점 실수처럼 특수한 비교 연산이 필요한 데이터에는 적용할 수 없지만, 사용 가능할 때에는 매우 좋은 알고리즘이다.           용어 정리          digit   십진수의 digit는 10개이다. (0,1,2,3,4,5,6,7,8,9)   이진수의 digit는 2개이다. (0,1)    16진수의 digit는 16개이다. (0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F)                 radix      digit의 수를 radix라고 한다.  십진수의 radix는 10 이다.  이진수의 radix는 2 이다.  16진수의 radix는 16 이다.                                 (1)       (2)       (3)       (4)                       0123       1560       0004       0004       0004                 2154       2150       0222       1061       0123                 0222       1061       0123       0123       0222                 0004       0222       2150       2150       0283                 0283       0123       2154       2154       1061                 1560       0283       1560       0222       1560                 1061       2154       1061       0283       2150                 2150       0004       0283       1560       2154           (1) 일의 자리를 기준으로 정렬한다.  (2) 십의 자리를 기준으로 정렬한다.  (3) 백의 자리를 기준으로 정렬한다.  (4) 천의 자리를 기준으로 정렬한다. 이 단계에서 정렬이 완료된다.         만약 배열에 음수도 들어있다면,    모든 자릿 수를 정렬한 후에, 부호(+,-)를 고려하여 순서를 변경하는 작업을 추가하거나,   아니면 미리 양수와 음수를 분리한 후, 양수 부분과 음수 부분을 따로 radix sort해야 한다.   배열에서 양수와 음수를 분리할 때는 quick sort의 partition을 응용할 수 있다.          대부분의 데이터에서 자릿 수는 상수이다.     그런데, 각 자리의 정렬을 O(N lo gN) 시간에 한다면, radix sort의 시간도 O(N lo gN) 시간이된다.   각 자리의 정렬을 O(N) 시간에 한다면, radix sort의 시간도 O(N) 시간이 된다.    각 자리의 값의 수는 digit 수와 같다.    digit 수는 작기 때문에, digit 값을 기준으로 정렬하는 작업은 counting sort 알고리즘을 적용하면 된다.            구현               알고리즘 문제     1920 수 찾기            문제 https://www.acmicpc.net/problem/1920       코드 https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B1920.java                2750 수 정렬하기            문제 https://www.acmicpc.net/problem/2750       코드 https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B2750.java                2751 수 정렬하기 2            문제 https://www.acmicpc.net/problem/2751       코드 https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B2751.java                10989 수 정렬하기 3            문제 https://www.acmicpc.net/problem/10989       코드 https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B10989.java                      10815 숫자 카드            문제 https://www.acmicpc.net/problem/10815       코드 https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B10815.java                  2075 N번째 큰 수            문제 https://www.acmicpc.net/problem/2075       코드1 (priorityQueue 사용) https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B2075.java       코드2 (radix sort 사용) https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B2075_v2.java                     제출번호 25490906: radix sort로 구현한 결과   제출번호 25477319: priorityQueue로 구현한 결과      ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-01-20/countingSort/",
        "teaser": null
      },{
        "title": "lowerBound & upperBound",
        "excerpt":"BinarySearch  다음은 일반적으로 원하는 값(Key)을 찾을 때 사용하는 binarySearch이다.   static int binarySearch(int[] list, int key) {     int left = 0;     int right = list.length - 1;          while(left &lt;= right) {         int mid = (left + right) / 2;                  if(list[mid] == key) {             return mid;         } else if(list[mid] &lt; key) {             left = mid + 1;         } else {             right = mid - 1;         }     } \t     return -1; }   key 값을 찾으면 바로 index를 return 하고 못 찾으면 -1을 return 한다.            lowerBound, upperBound   private static int lowerBound(List&lt;Integer&gt; data, int target) {     int begin = 0;     int end = data.size();      while(begin &lt; end) {         int mid = (begin + end) / 2;          if(data.get(mid) &gt;= target) {             end = mid;         } else {             begin = mid + 1;         }     }     return end; }  private static int upperBound(List&lt;Integer&gt; data, int target) {     int begin = 0;     int end = data.size();      while(begin &lt; end) {         int mid = (begin + end) / 2;          if(data.get(mid) &lt;= target){             begin=mid+1;         } else {             end = mid;         }     }     return end; }       lowerBound  범위 [begin, end] 안의 원소들 중, 특정 key보다 크거나 같은 첫번째 원소의 인덱스를 리턴한다.        만약 그런 원소가 없다면 end 인덱스를 리턴한다.   upperBound  범위 [begin, end] 안의 원소들 중, 특정 key보다 큰 첫번째 원소의 인덱스를 리턴한다.       만약 그런 원소가 없다면 end 인덱스를 리턴한다.             관련 문제     문제 https://www.acmicpc.net/problem/10816   풀이 코드 https://github.com/hyerin6/Algorithm/blob/master/Baekjoon/src/training/B10816.java   upperbound에서 key보다 큰 인덱스값을 뽑아내는 이유는      upperBound - lowerBound를 통해서 중복값의 개수를 구하기 위해서이다.      ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-01-21/lowerBound&upperBound/",
        "teaser": null
      },{
        "title": "JUnit5 시작하기",
        "excerpt":"JUnit 테스트 코드를 작성해보자.   예전에 진행했던 SNS 프로젝트를 다시 Rest API로 구현하는 중에 JUnit5로 테스트 코드를 작성해보기로 했다. 아직 구현 기능이 많지 않고 이번 프로젝트에서 DB, 서버 배포 등을 구체적으로 결정하지 않았기 때문에 천천히 예제로 테스트 코드를 작성해보고 프로젝트에도 적용할 예정이다.           JUnit5 특징   JUnit4가 단일 jar 였던 것에 반해 JUnit5는 다음과 같은 모듈로 구성되어 있다.      JUnit Platform JVM에서 동작하는 테스트 프레임워크 테스트를 발견하고 계획을 생성하고 결과를 보고하는 TestEngine 인터페이스를 정의     JUnit Jupiter TestEngine의 실제 구현체, 테스트를 실행시키기 위해 TestEngine을 Platform에 제공     JUnit Vintage TestEngine에서 JUnit3 및 JUnit4 기반 테스트를 실행하기 위한 기능을 제공          Gradle 설정   dependencies {      . . .      testImplementation('org.springframework.boot:spring-boot-starter-test') {         exclude module: 'junit'     }     testImplementation 'org.junit.jupiter:junit-jupiter-api'     testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine' }  test {     useJUnitPlatform() }        위 JUnit5의 특징에서 알아봤듯이 junit에 3, 4 버전이 포함되어 있기 때문에   junit5만 사용할 생각이라면 위 gradle 설정처럼 junit을 제외하면 된다.   그러나 junit5는 jupiter-api, jupiter-engine을 필요로하기 때문에 위와 같은 설정을 추가해야 한다.           Spring Boot에서는 어떻게?   스프링 부트 2.0에서 일반적인 스프링과 마찬가지로 @ExtendWith 어노테이션을 사용하지만 @ContextConfiguration 대신에 @SpringBootTest을 사용한다. @SpringBootTest 어노테이션은 애플리케이션 컨텍스트를 실행해준다.   @ExtendWith(SpringExtension.class) @SpringBootTest class SimpleSpringTest {      @Autowired     public MessageComponent messageComponent;      @Test     public void test() {         assertEquals(\"Hello world!\", messageComponent.getMessage());     }  }          Spring Boot가 아니라면?   @ExtendWith(SpringExtension.class) @ContextConfiguration(classes = { MySpringApplication.class }) class SimpleSpringTest {     . . . }      @ExtendWith : spring 또는 Mokito 라이브러리를 확장해서 사용 가능   @ContextConfiguration : 이 어노테이션으로 컨텍스트 설정 가능          JUnit5와 Mockito 사용   Mockito는 개발자가 동작을 직접 제어할 수 있는 가짜(Mock) 객체를 지원하는 테스트 프레임워크다.   Spring은 여러 객체들 간의 의존성이 존재해 단위 테스트 작성이 어려워질 수 있는데   이를 해결하기 위해 가짜 객체를 주입시키는 Mockito 라이브러리를 활용할 수 있다.         1) Mock 객체 의존성 주입   Mockito에서 Mock 객체의 의존성 주입을 위해 어노테이션을 사용한다.      @Mock : Mock 객체를 만들어 반환해주는 어노테이션   @Spy : Stub하지 않은 메소드들은 원본 메소드 그대로 사용하는 어노테이션   @InjectMocks : 가짜 객체를 자동으로 주입시켜주는 어노테이션       예를들어 UserController에 대한 단위 테스트를 작성하고자 할 때, UserService를 사용하고 있다면   @Mock 어노테이션으로 가짜 UserService를 만들고,   @InjectMocks 어노테이션으로 UserController에 이를 주입시킬 수 있다.         2) Stub   의존성이 있는 객체는 가짜 객체를 주입하면 어떤 결과를 반환하라고 정해진 답변을 준비시켜야 한다.       Mockito는 다음과 같은 stub 메서드를 제공한다.      doReturn() : Mock 객체가 특정한 값을 반환해야 하는 경우   doNothing() : Mock 객체가 아무것도 반환하지 않는 경우   doThrow() : Mock 객체가 예외를 발생시키는 경우       예를들어 UserService의 findAllUser() 호출 시 빈 ArrayList를 반환해야 한다면 다음과 같이 작성하면 된다.   doReturn(new ArrayList()).when(userService).findAllUser();         3) Mockito와 JUnit의 결합   Mockito도 테스팅 프레임워크다. 그래서 JUnit과 결합하기 위해 별도의 작업이 필요하다.       기존의 JUnit4에서 Mockito를 사용하기 위해 클래스 어노테이션으로   @RunWith(MockitoJUnitRunner.class)를 불여야했다.       JUnit5부터는 @ExtendWith(MockitoExtention.class)를 사용해야 결합이 가능하다.          참고      JUnit에 대한 블로그 게시글 https://hyerin6.github.io/2020-01-13/Junit-테스트-구현/   공식 레퍼런스 https://junit.org/junit5/docs/current/user-guide/#overview   샘플 코드 https://github.com/junit-team/junit5-samples/tree/main/junit5-jupiter-starter-gradle   Mockito https://mangkyu.tistory.com/145      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-05-22/JUnit5/",
        "teaser": null
      },{
        "title": "[Effective Java] 객체 생성과 파괴",
        "excerpt":"1. 생성자 대신 정적 팩토리 메서드를 고려하라  클래스의 인스턴스를 얻는 전통적인 수단은 public 생성자이다.    클래스는 생성자와 별도로 static factory method를 제공하며 다음과 같은 장단점이 있다.   장점  1. 이름을 가질 수 있다.           2. 호출될 때마다 인스턴스를 새로 생성하지 않아도 된다.         ex.Boolean.valueOf(boolean)               불변 클래스는 미리 인스턴스를 만들거나 새로 생성한 인스턴스를 캐싱해 재활용할 수 있으므로 메모리 측면에서 유리하다.               이렇게 언제 어느 인스턴스를 살아있게 할지를 철저히 통제할 수 있다. 이를 인스턴스 통제 클래스라고 한다.            인스턴스를 통제하면 다음과 같이 만들 수 있다.     싱글톤   인스턴스화 불가   불변 값 클래스에서 동치 인스턴스가 하나뿐임을 보장 (a==b 일 때만 a.equals(b)가 성립)         3. 하위 타입 객체를 반환할 수 있다.     java 8: 인터페이스에는 public 정적 멤버만 허용   java 9: private 정적 메서드까지 허용하지만 정적 필드와 정적 멤버 클래스는 public이어야 한다.                  4. 입력 매개변수에 따라 매번 다른 클래스의 객체를 반환할 수 있다.            반환 타입의 하위 타입이기만 하면 어떤 클래스의 객체를 반환하든 상관없다.         5. 정적 팩토리 메서드를 작성하는 시점에 반환할 객체의 클래스가 존재하지 않아도 된다.               이러한 유연함은 Service Provider 프레임워크의 근간이 된다. 대표적인 예로 JDBC가 있다.     DriverManager.registerDriver() 메서드로 각 DBMS별 Driver를 설정한다. (제공자 등록 API)   DriverManager.getConnection() 메서드로 DB 커넥션 객체를 받는다. (service access API)   Connection Interface는 DBMS 별로 동작을 구현하여 사용할 수 있다. (service Interface)   위에서 설명한 3개의 핵심 컴포넌트와 더불어 종종 서비스 제공자 인터페이스라는 네 번째 컴포넌트가 쓰이기도 한다.   이는 서비스 인터페이스의 인스턴스를 생성하는 팩토리 객체를 설명해준다.    서비스 제공자 인터페이스가 없다면 각 구현체를 인스턴스로 만들 때 리플렉션을 사용해야 한다.       단점  1. 상속을 하려면 public이거나 protected 생성자가 필요하므로 정적 팩토리 메서드만 제공하면 하위 클래스를 만들 수 없다.                 컬렉션 프레임 워크의 유틸리티 구현 클래스는 private 생성자만 제공하므로 상속이 불가하다.           이러한 제약은 상속보다 컴포지션을 사용하도록 유도되어 오히려 더 장점으로 작용한다.                 2. 정적 팩토리 메서드는 프로그래머가 찾기 어렵다.               흔히 사용하는 명명 방식을 지켜보자.       정적 팩터리 메서드는 각각의 쓰임새가 있으니, 장단점을 잘 인식하고 무작정 public 생성자만 사용하는 습관을 고쳐보자.                  2. 생성자에 매개변수가 많다면 빌더를 고려하라.  매개변수 개수가 많을 때, 다음과 같은 방법들을 고려해볼 수 있다.   방법(1) 점층적 생성자 패턴  public class Exam {     private final int a;     private final int b;     private final int c;     private final int d;          public Exam(int a, int b) {         this(a, b, 0);     }          public Exam(int a, int b, int c) {         this(a, b, c, 0);     }          public Exam(int a, int b, int c, int d) {         this(a, b, c, d);     } }   위 코드와 같이 필수 매개변수만 받는 생성자, 필수 매개변수와 선택 매개변수 1개를 받는 생성자, … 형태로 선택 매개변수를 전부 다 받는 생성자까지 늘려가는 방식이다.    그러나 매개변수 개수가 많아지면 클라이언트 코드를 작성하거나 읽기 어렵다.       방법(2) 선택 매개변수가 많다면 자바빈즈 패턴 (Java Beans)  매개변수가 없는 생성자로 객체를 만들어 Setter 메서드들을 호출해 원하는 매개변수의 값을 설정하는 방식이다.   그러나 객체를 하나 만들려면 메서드 여러 개를 호출해야 하고, 객체가 완전히 생성되기 전까지는 일관성(consistency)이 무너진 상태에 놓이게 된다.    자바빈즈 패턴에서는 클래스를 불변으로 만들 수 없으며 스레드 안전성을 얻으려면 개발자가 추가 작업을 해야한다.       방법(3) 안전성과 가독성을 겸비한 빌더 패턴 (Builder Pattern)  객체를 직접 만드는 대신 필수 매개변수만으로 생성자(혹은 정적 팩토리)를 호출해 빌더 객체를 얻는다.    빌더 객체가 제공하는 일종의 Setter 메서드로 원하는 선택 매개변수들을 설정하고 매개변수가 없는 build 메서드를 호출해 필요한 객체를 얻는다.   빌더의 Setter는 자신을 반환하기 때문에 연쇄적으로 호출할 수 있다. &gt; 플루언트 API(fluent API) / 메서드 연쇄(method chaining)      빌더 패턴은 계층적으로 설계된 클래스와 함께 쓰기에 좋다. 각 계층의 클래스에 관련 빌더를 멤버로 정의한다.   public abstract class Pizza {     public enum Topping { ... }     final Set&lt;Topping&gt; toppings;          // 추상 클래스는 추상 빌더를, 구체 클래스는 구체 빌더를 갖게 한다.      abstract static class Builder&lt;T extends Builder&lt;T&gt;&gt; {         . . .         return self();     }          abstract Pizza build();          // 하위 클래스는 이 메서드를 재정의(overriding)하여        // this를 반환하도록 해야한다.      protected abstract T self();      }       빌더 패턴은 상당히 유연하다. 빌더 하나로 여러 객체를 순회하면서 만들 수 있고, 빌더에 넘기는 매새변수에 따라 다른 객체를 만들 수도 있다.      장점만 있는 것은 아니다. 객체를 만들려면 그에 앞서 빌더부터 만들어야 한다. 빌더 생성 비용이 크지는 않지만 성능에 민감한 상황에서는 문제가 될 수 있다.        생성자나 정적 팩토리가 처리해야 할 매개변수가 많다면 빌더 패턴을 선택하는 게 더 낫다.                  3. private 생성자나 열거 타입으로 싱글톤 패턴임을 보증하라.  싱글톤이란 인스턴스를 오직 하나만 생성할 수 있는 클래스이다.       예를 들어 함수와 같은 무상태 객체나 설계상 유일해야 하는 시스템 컴포넌트를 들 수 있다.   그러나 클래스를 싱글톤으로 만들면 타입을 인터페이스로 정의하지 않으면     싱글톤 인스턴스를 가짜(mock) 구현으로 대체할 수 없기 때문에 이를 사용하는 클라이언트를 테스트하기 어렵다.           싱글톤을 만드는 방식   1. 생성자 private, 유일한 인스턴스에 접근할 수 있는 수단은 public static final 멤버               2. 정적 팩토리 메서드를 public static 멤버로 제공          정적 팩토리 메서드 방식의 장점     API를 바꾸지 않고도 싱글톤이 아니게 변경할 수 있다.   정적 팩토리를 제네릭 싱글톤 팩토리로 만들 수 있다.   정적 팩토리의 메소드 참조를 supplier(공급자)로 사용할 수 있다.       위에서 설명한 두가지 방법으로 인스턴스가 전체 시스템에서 하나뿐임이 보장된다.               그러나 예외가 있는데 권한이 있는 클라이언트 리플렉션 API인 AccessibleObject.setAccessible을 사용해 private 생성자를 호출할 수 있다.                      이 공격을 방어하고 싶다면 생성자를 수정하여 객체가 두 번 생성되려 할 때 예외를 던지게 하면 된다.    3. 원소가 하나인 열거 타입을 선언           싱글톤 클래스를 직렬화하려면 단순히 Serializable을 구현한다고 선언하는 것만으로는 부족하다.               모든 인스턴스 필드를 일시적(transient)이라고 선언하고 readResolve 메서드를 제공해야 한다.   // 싱글톤임을 보장해주는 readResolve 메서드  private Object readResolve() {     // 진짜 인스턴스를 반환하고 가짜는 가비지 컬렉터에 맡긴다.      return INSTANCE; }  public enum Elvis {     INSTANCE;          public void leaveTheBuilding() { ... } }      public 필드 방식과 비슷한 위 방법은 더 간결하고 추가 노력없이 직렬화할 수 있고, 리플렉션 공격도 막아준다.       대부분 상황에서 원소가 하나뿐인 열거 타입이 싱글톤을 만드는 가장 좋은 방법이다.      단, 만들려는 싱글톤이 Enum 외의 클래스를 상속해야 한다면 이 방법은 사용할 수 없다.      열거 타입이 다른 인터페이스를 구현하도록 선언할 수는 있다.                   4. 인스턴스화를 막으려면 private 생성자를 사용하라.  정적 메서드와 정적 필드만 담은 클래스를 만들 때가 있을 것이다.           객체지향적으로 좋아 보이지는 않지만 분명 쓰임새가 있다.      유틸리티 함수를 만드는데 유용하게 쓰인다.   java.util.Collections 처럼 특정 인터페이스를 구현하는 객체를 생성해주는 정적 메서드(혹은 팩토리)를 모아놓을 수 있다.   final 클래스와 관련한 메서드들을 모아놓을 때도 사용한다.       정적 멤버만 담은 유틸리티 클래스는 인스턴스로 만들어 쓰려고 설계할 게 아니다.             그러나 생성자를 명시하지 않으면 컴파일러가 자동으로 매개변수가 없는 기본 생성자를 만들어준다.   추상 클래스는 하위 클래스를 만들어 인스턴스화하면 그만이기 때문에 인스턴스화를 막을 수 없다.              이때 인스턴스화를 막는 간단한 방법은 private 생성자를 추가하는 것이다.          이 방식은 상속을 불가능하게 하는 효과도 있다. 모든 생성자는 상위 클래스의 생성자를 호출하게 되는데          이를 private로 선언했으니 하위 클래스가 상위 클래스의 생성자에 접근할 길이 없다.                  5. 자원을 직접 명시하지 말고 의존 객체 주입을 사용하라.  맞춤법 검사기 SpellChecker은 사전(Dictionary)에 의존한다.     이렇게 자원에 의존하는 클래스의 경우 정적 유틸리티 클래스로 구현한 경우를 볼 수 있다.        정적 유틸리티를 잘못 사용한 경우  public class SpellChecker {     private static final Lexicon dictionary = ...;          private SpellChecker() {} // 객체 생성 방지          public static boolean isValid(String word) { ... }     public static List&lt;String&gt; suggestions(String type) { ... } }       싱글톤을 잘못 사용한 경우  public static SpellChecker INSTANCE = new SpellChecker(...);      위 예제들은 유연하지 않고 테스트하기도 어렵다.   사전은 언어별로 따로 있고 특수 어휘용 사전, 테스트용 사전도 필요하다.   SpellChecker가 여러 사전을 사용할 수 있도록 만들어보자.   필드에서 final 한정자를 제거하고 다른 사전으로 교체하는 메서드를 추가할 수 있지만   이 방식은 오류를 내기 쉽고 멀티 스레드 환경에서는 쓸 수 없다.   사용하는 자워에 따라 동작이 달라지는 클래스에는 정적 유틸리티 클래스나 싱글톤 방식은 적합하지 않다.       다음 조건을 만족해야 한다.     클래스가 여러 자원 인스턴스를 지원해야 한다.   클라이언트가 원하는 자원을 사용해야 한다.   위 조건을 만족하는 패턴은 인스턴스를 생성할 때 생성자에 필요한 자원을 넘겨주는 방식으로 의존 객체 주입의 한 형태이다.   private final Lexicon dictionary;  public SpellChecker(Lexicon dictionary) {     this.dictionary = Objects.requireNonNull(dictionary); }   위와 같은 의존 객체 주입은 불변을 보장하여 여러 클라이언트가 의존 객체들을 안심하고 공유할 수 있고    생성자, 정적 팩토리, 빌더 모두에 똑같이 응용할 수 있다.        의존 객체 주입이라 하는 기법은 클래스의 유연성, 재사용성, 테스트 용이성을 개선해준다.                  6. 불필요한 객체 생성을 피하라.  똑같은 기능의 객체를 매번 생성하기보다는 객체 하나를 재사용하는 편이 나을 때가 많다.                       재사용은 빠르고 세련되며 특히 불변 객체는 언제든 재사용할 수 있다.            생성자 대신 정적 팩토리 메서드를 제공하는 불변 클래스에서는      정적 팩토리 메서드를 사용해 불필요한 객체 생성을 피할 수 있다.        이는 불변 객체만이 아니라 가변 객체라 해도 사용 중에 변경되지 않을 것임을 안다면 재사용할 수 있다.          불변 인스턴스를 클래스 초기화(정적 초기화) 과정에서 직접 생성해 캐싱해두고     필요할 때 그 인스턴스를 재사용하자.       객체가 불변이라면 재사용해도 안전함이 명확하다. 그러나 훨씬 덜 명확하거나 심지어 직관에 반대되는 상황도 있다.   어댑터를 생각해보자. 어댑터는 실제 작업은 뒷단 객체에 위임하고 자신은 제 2의 인터페이스 역할을 해주는 객체이다.    어댑터는 뒷단 객체만 관리하면 되기 때문에 뒷단 객체 하나당 어댑터 하나씩만 만들어지면 충분하다.        EX1) Map 인터페이스의 KeySet 메서드            Map 객체 안의 key를 전부 담은 Set 뷰를 반환한다.      매번 같은 Set 인스턴스를 반환할까?      반환된 Set 인스턴스가 일반적으로 가변이라도 반환된 인스턴스가 기능적으로 모두 똑같다.       모두 같은 Map 인스턴스를 대변하기 때문에 KeySet이 뷰 객체를 여러 개 만들어도 상관은 없지만 그럴 필요도 없고 이득도 없다.       EX2) 오토박싱(auto boxing)       오토박싱은 프로그래머가 기본 타입과 박싱된 기본 타입을 섞어 쓸 때 자동으로 상호 변환해주는 기술이다.   구분을 흐려주지만 완전히 없애주는 것은 아니다.   private static long sum() {    Long sum = 0L;    for(long i = 0; i &lt;= Integer.MAX_VALUE; ++i) {       sum += i;    }        return sum; }   위 프로그램이 정확한 답을 내기는 한다. 하지만 제대로 구현했을 때보다 훨씬 느리다.      sum 변수를 long이 아닌 Long으로 선언해서 불필요한 Long 인스턴스가 약 231개나 만들어진 것이다.   박싱된 기본 타입보다는 기본 타입을 사용하고, 의도치 않은 오토박싱이 숨어들지 않도록 주의해야 한다.                  7. 다 쓴 객체 참조를 해제하라.   메모리 누수에 취약한 상황은 다음과 같다.   1) Stack   public Object pop() {    if(size == 0) {       throw new EmptyStackException();    }        return elements[--size]; }   스택이 커졌다가 줄어들 때 스택에서 꺼내진 객체들을 가비지 컬렉터가 회수하지 않는다.      여기서 다 쓴 참조는 elements 배열의 ‘활성 영역’ 밖의 참조들이다.   가비지 컬렉션 언어에서 메모리 누수를 찾기 까다롭다.     객체 참조 하나를 살려두면 가비지 컬렉터는 그 객체 뿐만 아니라      그 객체가 참조하는 모든 객체를 회수해가지 못한다.   해결 방법: 참조를 다 썼을 때 null 처리한다.       2) 캐시  객체 참조를 캐시에 넣고 그 객체를 다 쓴 뒤로도 한참을 놔두는 일을 자주 접할 수 있다.   해결 방법     캐시 외부에서 키를 참조하는 동안만 엔트리가 살아있는 캐시가 필요한 상황이면 WeakHashMap을 사용   백그라운드 스레드 활용   캐시에 새 엔트리를 추가할 때 부수 작업 수행 (LinkedHashMap의 removeEldestEntry)       3) 리스너(listener), 콜백(callback)  클라이언트가 콜백을 등록만하고 명확히 해지하지 않으면 콜백이 쌓인다.   해결 방법: 콜백을 약한 참조(weak reference)로 저장하면 가비지 컬렉터가 즉시 수거한다.                  8. finalizer와 cleaner 사용을 피하라.  Java는 두 가지 객체 소멸자를 제공한다.    그러나 예측할 수 없고 일반적으로 불필요하기 때문에 기본적으로 쓰지 말아야 한다.          즉시 수행된다는 보장이 없다.          즉 제때 실행되어야 하는 작업에서 사용하면 안된다.          이를 신속히 수행할지는 가비지 컬렉터 알고리즘에 달렸다.            수행 시점 뿐만 아니라 수행 여부조차 보장하지 않는다.       접근할 수 없는 일부 객체에 딸린 종료 작업을 전혀 수행하지 못한채 프로그램이 종료될 수도 있다.          따라서 프로그램 생애주기와 상관없는 상태를 영구적으로 수정하는 작업에서 finalizer와 cleaner에 의존하면 안된다.       예) 데이터베이스와 같은 공유 자원의 영구 락(lock) 해제를 맡기면 안된다.           System.gc, System.runFinalization 메서드에 현혹되면 안된다.       finalizer와 cleaner가 실행될 가능성은 높여줄 수 있으나 보장해주진 않는다.           finalizer 동작 중 발생한 예외는 무시되며, 처리할 작업이 남았더라도 그 순간 종료된다.        심각한 성능 문제와 보안 문제를 일으킬 수 있다.          finalizer 공격 원리는 생성자나 직렬화 과정에서 예외가 발생하면,       이 생성되다 만 객체에서 악의적인 하위 클래스의 finalizer가 수행될 수 있게 한다.             객체 생성을 막으려면 생성자에서 예외를 던지는 것만으로 충분하지만, finalizer가 있다면 그렇지도 않다.       final이 아닌 클래스를 finalizer 공격으로부터 방어하려면 아무 일도 하지 않는 finalizer 메서드를 만들고 final로 선언해야한다.       finalizer의 쓰임새  1) 자원의 소유자가 close 메서드를 호출하지 않는 것에 대비한 안전망 역할             2) 네이티브 피어(native peer): 자바 객체가 네이티브 메서드를 통해 기능을 위임한 네이티브 객체                 네이티브 피어는 자바 객체가 아니니 가비지 컬렉터는 그 존재를 알지 못한다.          자바 피어를 회수할 때 네이티브 객체까지 회수하지 못하므로 finalizer나 cleaner를 사용            단 성능 저하를 감당할 수 없으면 close 메서드를 사용해야 한다.       그렇다면 파일이나 스레드 등 종료해야 할 자원은 어떻게?  AutoCloseable을 구현해주고, 클라이언트에서 인스턴스를 다 쓰고 나면 close 메서드를 호출하면 된다.             9. try-finally 보다는 try-with-resource를 사용하라.  자바 라이브러리에 close 메서드를 호출해 직접 닫아줘야 하는 자원이 많다.   ex. InputStream, OutputStream, java.sql.Connection 등    자원 닫기는 클라이언트가 놓치기 쉬워서 예측할 수 없는 성능 문제로 이어질 수 있다.   이런 자원 중 안전망으로 finalizer를 활용하고는 있지만 전통적으로     자원이 제대로 닫힘을 보장하는 수단으로 try-finally가 쓰였다.           BufferedReader br = new BufferedReader(new FileReader(path));  try{   return br.readLine(); } finally {   br.close(); }   위 메서드 실행 중 기기에 물리적인 문제가 생긴다면?  1) readLine 메서드가 예외를 던진다.   2) close 메서드도 위와 같은 이유로 실패한다.   이런 상황이라면 두 번째 예외가 첫 번째 예외를 완전히 집어삼켜 버린다.    그러면 스택 추적 내역에 첫 번째 예외에 관한 정보는 남지 않게 되며,         실제 시스템에서의 디버깅을 어렵게 한다.   위 문제는 자바 7에서 등장한 try-with-resources로 해결되었다.     이 구조를 사용하려면 해당 자원이 AutoCloseable 인터페이스를 구현해야 한다.      ","categories": ["Effective Java","Java"],
        "tags": ["java"],
        "url": "/2021-05-24/chap2/",
        "teaser": null
      },{
        "title": "[Effective Java] 모든 객체의 공통 메서드",
        "excerpt":"10. equals는 일반 규약을 지켜 재정의 하라.  equals는 재정의하기 쉬워 보이지만 실수하면 결과는 끔찍하다.         문제를 회피하는 가장 쉬운 방법은 아예 재정의하지 않는 것이다.        다음 상황 중 하나에 해당한다면 재정의하지 않는 것이 최선이다.                 각 인스턴스가 본질적으로 고유하다.    ex. Thread            인스턴스의 ‘논리적 동치성’을 검사할 일이 없다.   ex. Pattern            상위 클래스에서 재정의한 equals가 하위 클래스에도 맞는 경우            클래스가 private이거나 package-private이고 equals 메서드를 호출할 일이 없는 경우           equals를 재정의해야 할 떄는 언제인가?  객체 식별성(object identity, 물리적으로 같은가)이 아니라 논리적 동치성을 확인해야 하는데,     상위 클래스의 equals가 논리적 동치성을 비교하도록 재정의되지 않았을 때다.       주로 값을 표현하는 Integer와 String이 해당된다.       equals 메서드는 동치 관계를 구현하며, 다음을 만족한다.     반사성: x.equals(x)는 true   대칭성: x.equals(y)가 true이면, y.equals(x)도 true   추이성: x.equals(y)가 true이고 y.equals(z)가 true이면, x.equals(z)도 true   일관성: x.equals(y)를 반복해서 호출하면 항상 true이거나 false를 반환   null 아님: null이 아닌 모든 참조 값 x에 대해, x.equals(null)은 false다.   위 규약을 어기면 그 객체를 사용하는 다른 객체들이 어떻게 반응할지 알 수 없다.               11. equals를 재정의하려거든 hashCode도 재정의하라.  equals를 재정의한 클래스 모두에서 hashCode도 재정의해야 한다.      그렇지 않으면 hashCode 일반 규약을 어기게 되어 해당 클래스의 인스턴스를     HashMap이나 HashSet 같은 컬렉션의 원소로 사용할 때 문제를 일으킬 것이다.             다음은 Object 명세의 규약이다.          equals 비교에 사용되는 정보가 변경되지 않았다면 애플리케이션이 실행되는 동안    그 객체의 hashCode 메서드는 몇 번을 호출해도 일관되게 항상 같은 값을 반환해야 한다.            equals(Object)가 두 객체를 같다고 판단했을 때, 두 객체의 hashCode는 똑같은 값을 반환해야 한다.            equals(Object)가 두 객체를 다르다고 판단했더라도 두 객체의 hashCode가 서로 다른 값을 반환할 필요는 없다.   단, 다른 객체에 다른 값을 반환해야 해시테이블의 성능이 좋아진다.           hashCode 재정의를 잘못했을 때 크게 문제되는 조항은 두 번째다.      즉, 논리적으로 같은 객체는 같은 해시코드를 반환해야 한다.               12. toString을 항상 재정의하라.  Object의 기본 toString은 클래스_이름@16진수로_표시한_해시코드를 반환한다.        equals와 hashCode 규약만큼 대단히 중요하진 않지만,      toString을 잘 구현한 클래스를 사용한 시스템은 디버깅하기 쉽다.            실전에서 toString은 그 객체가 가진 주요 정보 모두를 반환하는 게 좋다.   포맷을 명시하든 아니든 여러분의 의도는 명확히 밝혀야 한다.   포맷 명시 여부와 상관없이 toString이 반환한 값에 포함된 정보를 얻어올 수 있는 API를 제공하자.               13. clone 재정의는 주의해서 진행하라.  Cloneable은 복제해도 되는 클래스임을 명시하는 용도의 믹스인 인터페이스(mixin interface)이다.   아쉽게 의도한 목적을 제대로 이루지 못했다.   가장 큰 문제는 clone 메서드가 선언된 곳이 Cloneable이 아니라 Object이고,   protected에 있다는 것이다. 그래서 Cloneable을 구현하는 것만으로는 외부 객체에서   clone 메서드를 호출할 수 없다.            메서드가 하나도 없는 Cloneable 인터페이스는 무슨일을 할까?  인터페이스를 구현한다는 것은 일반적으로 해당 클래스가 그 인터페이스에서 정의한 기능을 제공한다고 선언하는 행위다.          그런데 Cloneable의 경우 상위 클래스에 정의된 (Object)protected 메서드인 clone의 동작 방식을 결정한다.        실무에서 Cloneable을 구현한 클래스는 clone 메서드를 public으로 제공하며     사용자는 복제가 제대로 이뤄지리라 기대한다.     이 기대를 만족시키려면 그 클래스와 모든 상위 클래스는 복잡하고 강제할 수 없고      허술하게 기술된 프로토콜을 지켜야만 하는데 그 결과로 깨지기 쉽고 위험하며 모순적인 매커니즘이 탄생한다.           생성자를 호출하지 않고도 객체를 생성할 수 있게 되는 것이다.        clone 메서드의 일반 규약은 허술하다.    다음 식들은 일반적으로 참이지만, 필수는 아니다.     x.clone() != x   x.clone().getClass() == x.getClass()   x.clone().equals(x)   관례상 이 메서드가 반환하는 객체는 super.clone을 호출해 얻어야 하다.   이 관예를 다른다면 다음 식도 참이다.     x.clone.getClass() == x.getClass()       가변 상태를 참조하지 않는 클래스용 clone 메서드  @Override  public PhoneNumber clone() {   try {     return (PhoneNumber) super.clone();   } catch (CloneNotSuppoertedException e) {     throw new AssertionError();   } }   위 코드는 clone 메서드를 가진 상위 클래스를 상속해 Cloneable을 구현한 코드다.     위 clone 메서드가 동작하게 하려면 PhoneNumber의 클래스 선언에 Cloneable을 구현한다고 추가하면 된다.     그러나 이 코드는 클래스가 가변 객체를 참조하는 순간 재앙으로 돌변한다.       가변 상태를 참조하는 클래스용 clone 메서드  @Override  public Stack clone() {   try {     Stack result = (Stack) super.clone();     result.elements = elements.clone();     return result;   } catch (CloneNotSupportedException e) {     throw new AssertionError();   } }   clone 메서드가 단순히 super.clone의 결과를 그대로 반환한다면 어떻게 될까?           반환된 Stack 인스턴스의 size 필드(int size)는 올바른 값을 갖겠지만,     elements 필드(Object[] elements)는 원본 Stack 인스턴스와 똑같은 배열을 참조할 것이다.       원본이나 복제본 중 하나를 수정하면 다른 하나도 수정되어 불변식을 해친다.   Stack 클래스의 생성자를 호출한다면 이러한 상황은 일어나지 않는다.    clone 메서드는 사실상 생성자와 같은 효과를 낸다.    clone은 원본 객체에 아무런 해를 끼치지 않는 동시에 복제된 객체의 불변식을 보장해야 한다.   Stack의 clone 메서드가 제대로 동작하게 하려면 스택 내부 정보를 복사해야 하는데     가장 쉬운 방법은 elements 배열의 clone을 재귀적으로 호출해주는 것이다.   한편 elements 필드가 final이었다면 위 방식은 작동하지 않는다.   이는 근본적인 문제로 직렬화와 마찬가지로 Cloneable 아키텍처는 ‘가변 객체를 참조하는 필드는 final로 선언하라’는 일반 용법과 충돌한다.      복제할 수 있는 클래스를 만들기 위해 일부 필드에서 final 한정자를 제거해야 할 수도 있다.        clone을 재귀적으로 호출하는 것만으로는 충분하지 않을 때도 있다.    해시테이블 내부는 버킷들의 배열이고, 각 버킷은 키-값 쌍을 담는 연결 리스트의 첫 번째 엔트리를 참조한다.   다음은 Stack에서처럼 단순히 버킷 배열의 clone을 재귀적으로 호출한 코드이다.       잘못된 clone 메서드 - 가변 상태를 공유한다.  @Override  public HashTable clone() {   try {     HashTable result = (HashTable) super.clone();     result.buckets = buckets.clone();     return result;   } catch (CloneNotSupportedException e) {     throw new AssertionError();   } }   복제본은 자신만의 버킷 배열을 갖지만, 이 배열은 원본과 같은 연결 리스트를 참조하여     원본과 복제본 모두 예기치 않게 동작할 가능성이 있다.      이를 해결하려면 각 버킷을 구성하는 연결 리스트를 복사해야 한다.   다음은 일반적인 해법이다.         복잡한 가변 상태를 갖는 클래스용 재귀적 clone 메서드  public class HashTable implements Cloneable {   private Entry[] buckets = ...;      private static class Entry {     final Object key;     Object value;     Entry next;          Entry(Object key, Object value, Entry next) {       this.key = key;       this.value = value;       this.next = next;     }          // 이 엔트리가 가리키는 연결 리스트를 재귀적으로 복사       Entry deepCopy() {       return new Entry(key, value, next == null ? null : next.deepCopy());     }   }      @Override   public HashTable clone() {     try {       HashTable result = (HashTable) super.clone();       result.buckets = new Entry[buckets.length];       for(int i = 0; i &lt; buckets.length; ++i) {         if(buckets[i] != null) {           result.buckets[i] = buckets.deepCopy();         }       }       return result;     } catch (CloneNotSupportedException e) {       throw new AssertionError();     }   } }   Entry의 deepCopy 메서드는 자신이 가리키는 연결 리스트 전체 복사를 위해 자신을 재귀적으로 호출한다.    이 기법은 간단하지만 연결 리스트를 복제하는 방법으로는 그다지 좋지 않다.    재귀 호출 때문에 원소 수만큼 스택 프레임을 소비하며, 리스트가 길면 스택 오버플로를 일으킬 수도 있다.    이 문제를 피하려면 deepCopy를 재귀 호출 대신 반복자를 써서 순회하는 방법을 사용해야 한다.   Entry deepCopy() {   Entry result = new Entry(key, value, next);   for (Entry p = result; p.next != null; p = p.next) {     p.next = new Entry(p.next.key, p.next.value, p.next.next);   }   return result; }       Cloneable을 이미 구현한 클래스를 확장한다면 어쩔 수 없이 clone을 잘 작동하도록 구현해야 한다.   그렇지 않은 상황에서는 복사 생성자와 복사 팩토리라는 더 나은 객체 복사 방식을 제공할 수 있다.       복사 생성자  public Yum(Yum yum) { ... };  복사 생성자란 단순히 자신과 같은 클래스의 인스턴스를 인수로 받는 생성자를 말한다.        복사 팩토리  public static Yum newInstance(Yum yum) { ... };       정리  새로운 인터페이스를 만들 때 Cloneable을 확장해서는 안 되며,     새로운 클래스도 이를 구현해서는 안 된다.       final 클래스라면 Cloneable을 구현해도 위험이 크지 않지만     성능 최적화 관점에서 검토한 후 별다른 문제가 없을 때만 드물게 허용해야 한다.     기본 원칙은 ‘복제 기능은 생성자와 팩토리를 이용하는 게 좋다.’라는 것이다.      단, 배열은 clone 메서드 방식이 가능 깔끔한, 규칙의 합당한 예외라 할 수 있다.               14. Comparable을 구현할지 고려하라.  public interface Comparable&lt;T&gt; {   int compareTo(T t); }      Comparable 인터페이스의 유일한 메서드는 compareTo이다.   compareTo는 Object의 메서드는 아니지만 두 가지 성격을 제외하면 equals와 같다.   compareTo는 단순 동치성 비교에 더해 순서까지 비교할 수 있으며, 제네릭하다.       정리  순서를 고려해야 하는 값 클래스를 작성한다면 꼭 Comparable 인터페이스를 구현하여,  그 인스턴스들을 쉽게 정렬하고 검색, 비교 기능을 제공하는 컬렉션과 어우러지도록 해야 한다.   compareTo 메서드에서 필드의 값을 비교할 때 ** 연산자는 쓰지 말아야 한다.**       그 대신 박싱된 기본 타입 클래스가 제공하는 정적 compare 메서드나     Comparator 인터페이스가 제공하는 비교자 생성 메서드를 사용하자.      ","categories": ["Effective Java","Java"],
        "tags": ["java"],
        "url": "/2021-06-01/chap3/",
        "teaser": null
      },{
        "title": "[Effective Java] 클래스와 인터페이스",
        "excerpt":"클래스와 인터페이스를 쓰기 편하고, 견고하며 유연하게 만드는 방법을 알아보자.       15. 클래스와 멤버의 접근 권한을 최소화하라.   어설프게 설계된 컴포넌트와 잘 설계된 컴포넌트의 가장 큰 차이는?          클래스 내부 데이터와 내부 구현 정보를 외부 컴포넌트로부터 얼마나 잘 숨겼느냐다.   잘 설계된 컴포넌트는 모든 내부 구현을 완벽히 숨겨 구현과 API를 깔끔히 분리한다.      이는 정보은닉, 혹은 캡슐화라고 하는 개념이기도 하다.       정보 은닉의 장점   1) 시스템 개발 속도를 높인다.       여러 컴포넌트를 병렬로 개발할 수 있기 때문이다.      2) 시스템 관리 비용을 낮춘다.       각 컴포넌트를 빠르게 파악할 수 있고 교체 부담이 감소한다.         3) 정보 은닉 자체가 성능을 높여주지는 않지만 성능 최적에 도움이 된다.          완성된 시스템을 프로파일링해 최적화할 컴포넌트를 정해        다른 컴포넌트에 영향을 주지 않고 해당 컴포넌트만 최적화할 수 있기 때문이다.             4) 소프트웨어 재사용성을 높인다.         5) 큰 시스템을 제적하는 난이도를 낮춘다.              시스템 전체가 완성되지 않아도 개별 컴포넌트의 동작을 검증할 수 있기 때문이다.       자바는 정보 은닉을 위한 다양한 장치를 제공한다.      그중 접근 제어 매커니즘은 클래스, 인터페이스, 멤버의 접근성 (접근 허용 범위)을 명시한다.       각 요소의 접근성은 그 요소가 선언된 위치, 접근 제한자(private, protected, public)로 정해진다.   접근 제한자를 제대로 활용하는 것이 정보 은닉의 핵심이다.    기본 원칙은 모든 클래스와 멤버의 접근성을 가능한 한 좁혀야 한다는 것이다.      소프트웨어가 올바른 동작을 하는 한 항상 가장 낮은 접근 수준을 부여해야 한다고 할 수 있다.        (가장 바깥) 탑레벨 클래스와 인터페이스에 부여할 수 있는 접근 수준은   package-private와 public이다.      package-private : 해당 패키지에서만 이용할 수 있다.         package-private으로 선언하면 API가 아닌 내부 구현이 되어 언제든 수정할 수 있다.    즉, 클라이언트에 아무런 피해 없이 다음 릴리스에서 수정, 교체, 제거할 수 있다.        public : API가 되므로 하위 호환을 위해 영원히 관리해줘야만 한다.       한 클래스에서만 사용하는 package-private 탑레벨 클래스나 인터페이스는    이를 사용하는 클래스 안에 private static으로 중첩시켜보자.     탑레벨로 두면 같은 패키지의 모든 클래스가 접근할 수 있지만 private static으로 중첩시키면   바깥 클래스 하나에서만 접근할 수 있다.   이보다 더 중요한 것은 public일 필요가 없는 클래스의 접근 수준을 package-private 탑레벨 클래스로 좁히는 일이다.    public 클래스는 그 패키지의 API인 반면, package-private 탑레벨 클래스는 내부 구현에 속하기 때문이다.       멤버(필드, 메서드, 중첩 클래스, 중첩 인터페이스)에 부여할 수 있는 접근 수준은 네 가지다.           private: 멤버를 선언한 탑레벨 클래스에서만 접근할 수 있다.            package-private: 멤버가 소속된 패키지 안의 모든 클래스에서 접근할 수 있다.             접근 제한자를 명시하지 않았을 때 적용되는 패키지 접근 수준이다.             (단, 인터페이스의 멤버는 기본적으로 public이 적용된다.)            protected: package-private의 접근 범위를 포함하며,         이 멤버를 선언한 클래스의 하위 클래스에서도 접근할 수 있다.            (제약이 조금 따름)            public: 모든 곳에서 접근할 수 있다.                  private와 package-private 멤버는 모두 해당 클래스의 구현에 해당하므로 보통은 공개 API에 영향을 주지 않는다.     단, Serializable을 구현한 클래스에서는 그 필드들도 외도치 않게 공개 API가 될 수도 있다.       public 클래스에서 멤버의 접근 수준을 package-private에서 protected로     바꾸는 순간 그 멤버에 접근할 수 있는 대상 범위가 넓어진다.       public클래스의 protected 멤버는 공개 API이므로 영원히 지원돼야 한다.   따라서 protected 멤버의 수는 적을수록 좋다.       멤버 접근성을 좁히지 못하게 방해하는 제약이 있다.         상위 클래스의 메서드를 재정의할 때는 그 접근 수준을 상위 클래스에서보다 좁게 설정할 수 없다는 것이다.        이 제약은 상위 클래스의 인스턴스는 하위 클래스의 인스턴스로 대체해 사용할 수 있어야 한다는 규칙     (리스코프 치환 원칙)을 지키기 위해 필요하다.            클래스가 인터페이스를 구현하는 건 이 규칙의 특별한 예로 볼 수 있고     이때 클래스는 인터페이스가 정의한 모든 메서드를 public으로 선언해야 한다.          public 클래스의 인스턴스 필드는 되도록 public이 아니어야 한다.        필드가 가변 객체를 참조하거나 final이 아닌 인스턴스 필드를 public으로 선언하면        그 필드에 담을 수 있는 값을 제한할 힘을 잃게 된다.   또한 필드가 수정될 때 (락 획득 같은) 다른 작업을 할 수 없게 되므로         public 가변 필드를 갖는 클래스는 일반적으로 스레드 안전하지 않다.   이러한 문제는 정적 필드에서도 마찬가지이나, 예외가 하나 있다.                  필요한 구성 요소는 상수로 public static final 필드로 공개해도 좋다.   길이가 0이 아닌 배열은 모두 변경 가능하니 주의하자.       따라서 클래스에서 public static final 배열 필드를 두거나        이 필드를 반환하는 접근자 메서드를 제공해서는 안 된다.            이런 필드는 클라이언트에서 내용을 수정할 수 있게 되고 다음과 같은 보안 허점이 존재한다.   public static final Thing[] VALUES = { ... };   어떤 IDE가 생성하는 접근자는 private 배열 필드의 참조를 반환하여    이 같은 문제를 똑같이 일으키니 주의해야 한다.          해결책은 두 가지다.   1) 앞 코드의 public 배열을 private으로 만들고 public 불변 리스트 추가   public static final Thing[] PRIVATE_VALUES = { ... }; public static final List&lt;Thing&gt; VALUES =      Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES));       2. 배열을 private으로 만들고 그 복사본을 반환하는 public 메서드를 추가(방어적 복사)   private static final Thing[] PRIVATE_VALUES = { ... }; public static final Thing[] values() {     return PRIVATE_VALUES.clone(); }       클라이언트가 무엇을 원하는지 판단해 둘 중 하나를 선택하면 된다.       자바 9에서는 모듈 시스템이라는 개념이 도입되면서 두 가지 암묵적 접근 수준이 추가되었다.       패키지가 클래스들의 묶음이듯, 모듈은 패키지들의 묶음이다.    모듈은 자신에 속하는 패키지 중 공개(export)할 것들을 선언한다.    protected 혹은 public 멤버라도 해당 패키지를 공개하지 않았다면 모듈 외부에서는 접근할 수 없다.    모듈 시스템을 활용하면 클래스를 외부에 공개하지 않으면서도     같은 모듈을 이루는 패키지 사이에서는 자유롭게 공유할 수 있다.       두 가지 암묵 접근 수준은 숨겨진 패키지 안에 있는   public 클래스의 public 혹은 protected 멤버와 관련이 있다.   이 암묵적 접근 수준들은 각각 public 수준과 protected 수준과 같으나            그 효과가 모듈 내부로 한정되는 변종인 것이다.       이런 상황은 흔하지 않으며 패키지들 사이에서 클래스들을 재배치하면 대부분 해결된다.   모듈의 JAR 파일을 자신의 모듈 경로가 아닌 애플리케이션의 클래스패스(classpath)에 두면              그 모듈 안의 모든 패키지는 마치 모듈이 없는 것처럼 행동한다.       즉 모듈이 공개했는지 여부와 상관없이 public 클래스가 선언한               모든 public 혹은 protected 멤버를 모듈 밖에서도 접근할 수 있게 된다.   이를 활용한 대표적인 예가 JDK이다.   자바 라이브러리에서 공개하지 않은 패키지들은 해당 모듈 밖에서는 절대로 접근할 수 없다.        모듈의 장점을 누리려면 해야 할 일이 많다.    먼저 패키지들을 모듈 단위로 묶고, 모듈 선언에 패키지들의 모든 의존성을 명시한다.    다음 소스 트리를 재배치하고, 모듈 안으로부터 일반 패키지로의 모든 접근에 특별한 조치를 취해야 한다.            16. public 클래스에서는 public 필드가 아닌 접근자 메서드를 사용하라.   class Point {     public double x;     public double y; }   이런 클래스는 데이터 필드에 직접 접근할 수 있으니 캡슐화의 이점을 제공하지 못한다.      API를 수정하지 않고는 내부 표현을 바꿀 수 없고 불변식을 보장할 수 없다.   외부에서 필드에 접근할 때 부수 작업을 수행할 수 없다.   이를 private으로 바꾸고 public 접근자를 추가한다.   private double x;  public double getX() { return x; }   패키지 바깥에서 접근할 수 있는 클래스라면 접근자를 제공함으로써        클래스 내부 표현 방식을 언제든 바꿀 수 있는 유연성을 얻을 수 있다.      public 클래스가 필드를 공개하려면 이를 사용하는 클라이언트가 생기므로    내부 표현 방식을 마음대로 바꿀 수 없게 된다.           package-private 클래스 혹은 private 중첩 클래스라면 데이터 필드를 노출한다 해도 하등의 문제가 없다.        클라이언트 코드가 이 클래스 내부 표현에 묶이긴 하나,         클라이언트도 어차피 이 클래스를 포함하는 패키지 안에서 동작하는 코드일 뿐이다.           따라서 패키지 바깥 코드는 전혀 손대지 않고도 데이터 표현 방식을 바꿀 수 있다.            public 클래스의 필드가 불변이라면 직접 노출할 때의 단점이 조금은 줄어들지만 좋은 생각은 아니다.    API를 변경하지 않고는 표현 방식을 바꿀 수 없고    필드를 읽을 때 부수 작업을 수행할 수 없다는 단점이 여전하다.        단, 불변식은 보장됨   ex. 불변 필드를 노출한 public 클래스   public final class Time {      public final int hour;          . . .      }               17. 변경 가능성을 최소화하라.   불변 클래스란 그 인스턴스의 내부 값을 수정할 수 없는 클래스다.      불변 클래스는 가변 클래스보다 설계하고 구현, 사용하기 쉬우며 오류 발생 확률도 적고 훨씬 안전하다.   자바 플랫폼 라이브러리에도 다양한 불변 클래스가 있다.      String   기본 타입의 박싱된 클래스들   BigInteger   BigDecimal       클래스를 불변으로 만들려면 다음 5가지 규칙을 따르면 된다.           객체의 상태를 변경하는 메서드를 제공하지 않는다.            클래스를 확장할 수 없도록 한다.            모든 필드를 final로 선언한다.            모든 필드를 private으로 선언한다.            자신 외에는 내부의 가변 컴포넌트에 접근할 수 없도록 한다.           불변 객체는 단순하다.   불변 객체는 생성된 시점의 상태를 파괴할 때까지 그대로 간직한다.          반면 가변 객체는 변경자 메서드의 상태 전이를 정밀하게 문서로 남겨놓지 않으면         신뢰하기 어려울 수도 있다.       불변 객체는 근본적으로 스레드 안전하여 따로 동기화할 필요가 없다.   다른 스레드에 영향을 줄 수 없으니 불변 객체는 안심하고 공유할 수 있다.       따라서 불변 클래스라면 한번 만든 인스턴스를 최대한 재활용하기 권한다.           가장 쉬운 방법은 자주 쓰이는 값들을 상수 public static final로 제공하는 것이다.   ex)   public static final Complex ZERO = new Complex(0, 0);       불변 클래스는 자주 사용되는 인스턴스를 캐싱하여 같은 인스턴스를     중복 생성하지 않게 해주는 정적 팩토리 메서드를 제공할 수 있다.        박싱된 기본 타입 클래스 전부와 BigInteger가 여기 속한다.   이런 정적 팩토리를 사용하면 여러 클라이언트가 인스턴스를 공유하여    메모리 사용량과 가비지 컬렉션 비용이 줄어든다.   새로운 클래스를 설계할 때 public 생성자 대신 정적 팩토리를 만들어두면,      클라이언트를 수정하지 않고도 필요에 따라 캐시 기능을 나중에 덧붙일 수 있다.       불변 객체는 자유롭게 공유할 수 있음은 물론, 불변 객체끼리는 내부 데이터를 공유할 수 있다.   BigInteger를 예로 들자.                      BigInteger 클래스 내부에서 값의 부호와 크기를 따로 표현하는데           부호에는 int 변수를, 크기에는 int 배열을 사용하는 것이다.           이때 배열은 비록 가변이지만 복사하지도 않고 원본 인스턴스가 가리키는 내부 배열을 그대로 가리킨다.       객체를 만들 때 다른 불변 객체들을 구성요소로 사용하면 이점이 많다.   구조가 아무리 복잡하더라도 불변식을 유지하기 훨씬 수월하기 때문이다.      좋은 예로, 불변 객체는 맵의 키와 집합(Set) 원소로 쓰기에 안성맞춤이다.      맵이나 집합은 안에 담긴 값이 바뀌면 불변식이 허물어지는데      불변 객체를 사용하면 그런 걱정은 하지 않아도 된다.       불변 객체는 그 자체로 실패 원자성을 제공한다.   상태가 절대 변하지 않으니 불일치 상태에 빠질 가능성이 없다.      실패 원자성 :   메서드에서 예외가 발생한 후에도 그 객체는 여전히 유효한 상태이어야 한다.        불변 클래스에도 단점은 있다. 값이 다른면 반드시 독립된 객체로 만들어야 한다는 것이다.   값의 가짓수가 많다면 이를 모두 만드는 데 큰 비용을 처리해야 한다.                                           ex) 백만 비트짜리 BigInteger에서 비트 하나를 바꿔야 한다.                                           BigInteger moby = ...; moby = moby.flipBit(0);           flipBit 메서드는 새로운 BigInteger 인스턴스를 생성한다.    원본과 한 비트만 다른 백만 비트짜리 인스턴스를 만들었다.   이 연산은 BigInteger의 크기에 비례해 시간과 공간을 잡아먹는다.       BigInteger처럼 임의 길이의 비트 순열을 표현하는 BitSet은 가변이고    원하는 비트 하나만 상수 시간 안에 바꿔주는 메서드를 제공한다.       BigSet moby = ...; moby.flip(0);           원하는 객체를 완성하기까지의 단계가 많고,     그 중간 단계에서 만들어진 객체들이 모두 버려진다면 성능 문제가 더 불거진다.       이 문제를 해결하는 방법은 다음 두 가지이다.       1. 다단계 연산 (multistep operation)들을 예측하여 기본 기능으로 제공       이런 다단계 연산을 기본으로 제공하면 더 이상 각 단계마다 객체를 생성하지 않아도 된다.    불변 객체는 내부적으로 아주 영리한 방식으로 구현할 수 있기 때문이다.            2. 클라이언트들이 원하는 복잡한 연산들을 정확히 예측할 수 있으면 package-private의 가변 동반 클래스 만으로 충분하다.       그렇지 않다면 이 클래스를 public으로 제공하는 것이 최선이다.                 대표적인 예로 String 클래스가 있다.                String의 가변 동반 클래스가 StringBuilder(와 StringBuffer)                                                    불변 클래스를 만드는 또 다른 설계 방법 몇 가지가 있다.   클래스가 불변임을 보장하려면 자신을 상속하지 못하게 해야 한다고 했는데    가장 쉬운 방법은 final 클래스로 선언하는 것이지만, 더 유연한 방법이 있다.   모든 생성자를 private 혹은 package-private으로 만들고 public 정적 팩토리를 제공하는 방법이다.      다음은 구체적인 예제 코드이다.   public class Complex {   private final double re;   private final double im;      private Complex(double re, double im) {     this.re = re;     this.im = im;   }      public static Complex valueOf(double re, double im) {     return new Complex(re, im);   }  }   위 방식이 최선일 때가 많다.   바깥에서 볼 수 없는 package-private 구현 클래스를 원하는 만큼 만들어 활용할 수 있으니 훨씬 유연하다.        패키지 바깥의 클라이언트 입장에서 이 불변 객체는 사실상 final이다.         정적 팩토리 방식은 다수의 구현 클래스를 활용한 유연성을 제공하고,     다음 릴리스에서 객체 캐싱 기능을 추가해 성능을 끌어올릴 수도 있다.                                           BigInteger는?                                                   BigInteger와 BigDecimal의 메서드들은 모두 재정의할 수 있게 설계되었고,    하위 호환성이 발목을 잡아 아직 문제 해결을 하지 못했다.     때문에 만약 신뢰할 수 없는 클라이언트로부터 BigInteger와 BigDecimal 인스턴스를   인수로 받는다면 주의해야 한다.    이 값들이 불변이어야 보안을 지킬 수 있다면 인수로 받은 객체가 진짜인지 확인해야 한다.    신뢰할 수 없는 하위 클래스의 인스턴스라고 확인되면, 이 인수들을 가변이라고 가정하고    방어적으로 복사해 사용해야 한다는 뜻이다.       public static BigInteger safeInstance(BigInteger val) {     return val.getClass() == BigInteger.class ?            val : new BigInteger(val.toByteArray()); }                                                          정리           어떤 메서드도 객체의 상태 중 외부에 비치는 값을 변경할 수 없다.            클래스는 꼭 필요한 경우가 아니라면 불변이어야 한다.            불변으로 만들 수 없는 클래스라도 변경할 수 있는 부분은 최소화하자.            다른 합당한 이유가 없다면 모든 필드는 private final 이어야 한다.            생성자는 불변식 설정이 모두 완료된, 초기화가 완벽히 끝난 상태의 객체를 생성해야 한다.                                       20. 추상 클래스보다는 인터페이스를 우선하라.   자바가 제공하는 다중 구현 매커니즘은 인터페이스와 추상 클래스다.         자바 8부터 인터페이스도 디폴트 메서드를 제공할 수 있게 되어 두 메커니즘 모두 인스턴스 메서드를 구현 형태로 제공할 수 있다.           둘의 가장 큰 차이는 추상 클래스가 정의한 타입을 구현하는 클래스는 반드시 추상 클래스의 하위 클래스가 되어야 한다는 점이다.        자바는 단일 상속만 지원하므로 추상 클래스 방식은 새로운 타입을 정의하는 데 커다란 제약을 갖고 있는 것이다.   반면 기존 클래스 위에 새로운 추상 클래스를 끼워넣기는 어려운 게 일반적이다.     두 클래스가 같은 추상 클래스를 확장하길 원한다면, 그 추상 클래스는 계층구조상 두 클래스의 공통 조상이어야 한다.        이 방식은 클래스 계층구조에 혼란을 일으킨다.       인터페이스는 믹스인(mixin) 정의에 안성맞춤이다.       믹스인이란 클래스가 구현할 수 있는 타입으로 믹스인을 구현한 클래스에       원래의 ‘주된 타입’ 외에도 특정 선택적 행위를 제공한다고 선언하는 효과를 준다.         예) Comparable은 자신을 구현한 클래스의 인스턴스들끼리는 순서를 정할 수 있다고 선언하는 믹스인 인터페이스이다.   추상 클래스로는 믹스인을 정의할 수 없다.    이유는 앞서와 같이, 기존 클래스에 덧씌울 수 없기 때문이다.          클래스는 두 부모를 둘 수 없고 클래스 계층구조에는 믹스인을 삽입하기에 합리적인 위치가 없기 때문이다.   mixin에 대해 더 알아보기 : https://hyerin6.github.io/2021-06-21/mixin/       인터페이스로는 계층구조가 없는 타입 프레임워크를 만들 수 있다.   public interface Singer {     AudioClip sing(Song s); }  public interface SongWriter {     Song compose(int chartPosition); }   위와 같은 가수 인터페이스와 작곡가 인터페이스가 있다.         우리 주변에 작곡도 하는 가수가 제법있는데,    타입을 인터페이스로 정의하면 가수 클래스가 Singer와 Songwriter 모두를 구현해도 문제가 없다.      Singer와 Songwriter 모두를 확장하고 새로운 메서드까지 추가한 제 3의 인터페이스를 정의할 수도 있다.   // Singer와 Songwriter 모두 구현  public class People implements Singer, SongWriter {     @Override     public void Sing(String s) {      }     @Override     public void Compose(int chartPosition) {      } }  // Singer와 Songwriter 모두 확장, 새로운 메서드까지 추가한 제 3의 인터페이스 정의  public interface SingerSongWriter extends Singer, Songwriter {         AudioClip strum();         void actSensitive(); }       위와 같은 구조를 클래스로 만들려면?   public abstract class Singer {     abstract void sing(String s); }  public abstract class SongWriter {     abstract void compose(int chartPosition); }  public abstract class SingerSongWriter {     abstract void strum();     abstract void actSensitive();     abstract void Compose(int chartPosition);     abstract void sing(String s); }   가능한 조합 전부를 각각의 클래스로 정의한 고도비만 계층구조가 만들어질 것이다.        추상 클래스로 만들었기 때문에 Singer 클래스와 SongWriter 클래스를 둘다 상속할 수 없어       다음과 같은 SingerSongWriter라는 또 다른 추상 클래스를 만들어서 클래스 계층을 표현할 수 밖에 없다.      매개변수 타입만 다른 메서드들을 수없이 많이 가진 거대한 클래스를 낳을 수 있다.   이는 조합 폭발(combinato-rial explosion)이라고 부르는 현상이다.       래퍼 클래스 관용구와 함께 사용하면 인터페이스는 기능을 향상 시키는 안전하고 강력한 수단이 된다.   타입을 추상 클래스로 정의해두면 그 타입에 기능을 추가하는 방법은 상속뿐이다.       상속해서 만든 클래스는 래퍼 클래스보다 활용도가 떨어지고 깨지기는 더 쉽다.         인터페이스 메서드 중 구현 방법이 명백한 것이 있다면, 그 구현을 디폴트 메서드로 제공할 수 있다.    그런데 디폴트 메서드에도 제약은 있다.   1) Object의 equals, hashcode 같은 메서드는 디폴트 메서드로 제공해서는 안된다. 2) public이 아닌 정적 멤버도 가질 수 없다. 3) 본인이 만들지 않은 인터페이스에는 디폴트 메서드를 추가할 수 없다.       인터페이스와 추상 골격 구현 (skeletal implementation) 클래스를 함께 제공하는 식으로    인터페이스와 추상 클래스의 장점을 가질 수 있다.    인터페이스로 타입 정의, 필요한 디폴트 메서드 구현       추상 골격 구현 클래스는 나머지 메서드까지 구현     이렇게 골격 구현을 확장하는 것만으로 이 인터페이스를 구현하는데 필요한 일이 대부분 완료된다.    이는 템플릿 메서드 패턴과 같다.   예) 컬렉션 프레임워크의 AbstractList, AbstractSet 클래스     두 추상 클래스는 각각 List, Set 인터페이스의 추상 골격 구현 클래스이다.       추상 골격 구현 클래스는 아래 게시물에서 더 알아보자.  https://hyerin6.github.io/2021-06-20/skeletal_implementation/   위 게시물에서 예제로 인터페이스의 디폴트 메소드를 사용하지 않고 추상 골격 구현 클래스를 만들어 중복을 제거했다.        그런데 Vending을 구현하는 구현 클래스가 VendingManuFacturer라는 제조사 클래스를 상속받아야해서    추상 골격 구현을 확장하지 못하는 상황일 땐 어떻게 해야할까?   public class VendingManuFacturer {     public void printManufacturerName() { . . . } }  // 상속받아야 하는 클래스를 구현체가 상속받는다. public class SnackVending extends VendingManufacturer implements Vending {     InnerAbstractVending innerAbstractVending = new InnerAbstractVending();      @Override     public void start() {         innerAbstractVending.start();     }      @Override     public void chooseProduct() {         innerAbstractVending.chooseProduct();     }      @Override     public void stop() {         innerAbstractVending.stop();     }      @Override     public void process() {         printManufacturerName();         innerAbstractVending.process();     }      private class InnerAbstractVending extends AbstractVending {         @Override         public void chooseProduct() {             System.out.println(\"choose product\");             System.out.println(\"chocolate\");             System.out.println(\"cracker\");         }     } }   인터페이스를 구현한 클래스에서 해당 골격 구현을 확장한 private 내부 클래스를 정의하고        각 메소드 호출을 내부 클래스의 인스턴스에 전달하여 골격 구현 클래스를 우회적으로 이용하는 방식을        시뮬레이트한 다중 상속(simulated multiple inheritance)이라고 한다.       단순 구현(simple implementation)   단순 구현은 골격 구현의 작은 변종이다.      단순 구현도 골격 구현과 같이 상속을 위해 인터페이스를 구현한 것이지만,      추상 클래스가 아니란 점이 다르다.    이러한 단순 구현은 그대로 써도 되고 필요에 맞게 확장해도 된다.      예) AbstractMap.SimpleEntry                     21. 인터페이스는 구현하는 쪽을 생각해 설계하라.   자바 8전에 기존 구현체를 깨뜨리지 않고는 인터페이스에 메서드를 추가할 방법이 없었다.          자바 8에서 기존 인터페이스에 메서드를 추가할 수 있도록 디폴트 메서드를 소개했지만,       위험이 완전히 사라진 것은 아니다.   디폴트 메서드를 선언하면 그 인터페이스를 구현한 후     디폴트 메서드를 재정의하지 않은 모든 클래스에서 디폴트 구현이 쓰이게 된다.      그러나 모든 기존 구현체들과 매끄럽게 연동되리라는 보장은 없다.    디폴트 메서드는 구현 클래스에 대해 아무것도 모른 채 합의 없이 삽입될 뿐이다.   자바 8에서 핵심 컬렉션 인터페이스들에 다수의 디폴트 메서드가 추가되었다.    주로 람다를 활용하기 위해서다.    하지만 생각할 수 있는 모든 상황에서 불변식을 해치지 않는 디폴트 메서드를 작성하기란 어렵다.   자바 8에서 추가된 Collection 인터페이스 추가된 removeIf 메서드   반복자를 이용해 순회하면서 각 원소를 인수로 넣어 predicate를 호출해서,     predicate가 true를 반환하면 iterator의 remove() 메서드를 호출해 원소를 제거 한다.   default boolean removeIf(Predivate&lt;? super E&gt; filter) {     Objects.requireNonNull(filter);     boolean result = false;     for ( Iterator&lt;E&gt; it = iterator(); it.hashNext(); ) {         if (filter.test(it.next())) {             it.remove();             result = true;         }     }     return result; }   이렇게 Collection에 새롭게 들어간 디폴드 메서는 과연 모든 Collection에 대해 정상작동 할까?       apache가 만든 SynchronizedCollection   이 클래스는 스레드 안정성을 위해서 동기화가 되어있는 List의 wrapper 클래스이다.          다음과 같이 코드를 보면 동기화 코드가 있는걸 확인할 수 있다.    @Override     public boolean add(final E object) {         synchronized (lock) {             return decorated().add(object);         }     }   그러나 이 클래스는 removeIf 메서드를 재정의하지 않는다.            즉 자바8과 함께 쓴다면 스레드 안전성을 갖지 못한다.      removeIf의 구현은 동기화에 대해 아무것도 모르기 때문에 락 객체를 사용할 수 없다.    SynchronizedCollection 인스턴스를 여러 스레드가 공유하는 환경에서 한 스레드가 removeIf를 호출하면    ConcurrentModificationException이 발생하거나 다른 예기치 못한 결과로 이루어 질 수 있다.    JDK에서 이런 문제를 예방하기 위해 구현 클래스에서 removeIf() 디폴트 메서드를 재정의했다.   Collections.synchronizedCollection 클래스의 removeIf()   @Override public boolean removeIf(Predicate&lt;? super E&gt; filter) {     synchronized (mutex) {         return c.removeIf(filter);     } }   하지만 JDK에 속하지 않은 제 3의 기존 컬렉션 구현체들은 이런 언어 차원의 인터페이스에 맞춰 수정될 기회가 없다.       해결 방법은?      기존 인터페이스에 디폴트 메서드로 새 메서드를 추가하는 일은 꼭 필요한 경우가 아니면 피해야 한다.         새로운 인터페이스를 만드는 경우라면 표준적인 메서드 구현을 제공하는 데 아주 유용한 수단이다.           디폴트 메서드는 인터페이스로부터 메서드를 제거하거나 기존 메서드의 시그니처를 수정하는 용도가 아님을 명심              디폴트 메서드라는 도구가 생겼어도 인터페이스 설계는 세심하게        새로운 인터페이스는 릴리스 전에 반드시 테스트를 거쳐야 한다.        인터페이스를 릴리스한 후라도 결함을 수정하는게 가능한 경우도 있겠지만, 절대 그 가능성에 기대서는 안된다.                 22. 인터페이스는 타입을 정의하는 용도로만 사용하라.      인터페이스 : 자신을 구현한 클래스의 인스턴스를 참조할 수 있는 타입 역할   인터페이스 구현 : 자신의 인스턴스로 무엇을 할 수 있는지 클라이언트에게 얘기해주는 것          예) 상수 인터페이스    메서드 없이 상수를 뜻하는 static final 필드만 갖고 있는 인터페이스    정규화된 이름을(qualified name) 쓰는 것을 피하고자 이 인터페이스를 구현한다.   상수는 내부 구현에 해당한다.       상수 인터페이스 구현       -&gt; 내부 구현을 클래스의 API로 노출하는 행위          -&gt; 클라이언트 코드가 내부 구현에 해당하는 이 상수들에 종속             23. 태그 달린 클래스보다는 클래스 계층구조를 활용하라.   두 가지 이상의 의미를 표현할 수 있으며,      그중 현재 표현하는 의미를 태그 값으로 알려주는 클래스가 있다.           예) 원과 사각형을 표현할 수 있는 클래스   class Figure {     enum Shape { RECTANGLE, CIRCLE };          // 태그 필드 - 현재 모양을 나타낸다.        final Shape shape;          // 다음 필드들은 모양이 사각형일 때만 쓰인다. (RECTANGLE)     double length;     double width;          // 다음 필드는 모양이 원일 때만 쓰인다. (CIRCLE)        double radius;          // 사각형 생성자        Figure(double length, double width) { . . . }          // 원 생성자      Figure(double radius) { . . . }          double area() {         switch(shape) {             . . .         }     }       }   태그 달린 클래스에는 단점이 한가득이다.      열거 타입 선언   태그 필드   switch   가독성   다른 의미를 위한 코드로 인한 메모리 낭비   필드를 final로 선언하려면 해당 의미에 쓰이지 않는 필드도 생성자에서 초기화해야함   또 다른 의미를 추가하면 코드 수정 (ex. switch 문을 찾아 새 의미 처리 코드 추가)   인스턴스의 타입만으로 현재 나타내는 의미를 알 수 없다.   태그 달린 클래스는 장황하고, 오류를 내기 쉽고 비효율적이다.       객체 지향 언어는 타입 하나로 다양한 의미의 객체를 표현하는 훨씬 나은 수단을 제공한다.   -&gt; 클래스 계층구조를 활용하는 서브 타이핑(subtyping) 이다.        태그 달린 클래스를 클래스 계층구조로 바꾸는 방법   (1) 가장 먼저 계층 구조의 루트(root)가 될 추상 클래스 정의      (2) 태그 값에 따라 동작이 달라지는 메서드는 추상 메서드로 선언      (3) 태그 값에 상관없는 동작이 일정한 메서드는 루트 클래스에 일반 메서드로 추가       (4) 모든 하위 클래스에서 공통으로 사용하는 데이터 필드들도 전부 루트 클래스에 올림      (5) 루트 클래스를 확장한 구체 클래스를 의미별로 하나씩 정의한다.       // Figure.java  abstract class Figure {     abstract double area(); }  // Circle.java  class Circle extends Figure {     final double radius;      Circle(double radius) { this.radius = radius; }      @Override      double area() { return Math.PI * (radius * radius); } }  // Rectangle.java class Rectangle extends Figure {     final double length;     final double width;      Rectangle(double length, double width) {         this.length = length;         this.width  = width;     }          @Override      double area() { return length * width; } }  // Square.java class Square extends Rectangle {     Square(double side) {         super(side, side);     } }      루트 클래스 : Figure   태그 값에 따라 동작이 달라지는 구현체 : Square, Rectangle       (1) 루트 클래스를 건드리지 않고 다른 개발자들이 독립적으로 계층구조 사용, 확장 가능   (2) 타입이 의미별로 존재      변수 의미를 명시하거나 제한 가능   특정 의미만 매개변수로 받기 가능   (3) 타입 사이의 자연스러운 계층 관계를 반영할 수 있어      유연성과 컴파일타임 타입 검사 능력이 높아짐                24. 멤버 클래스는 되도록 static으로 만들자.   중첩 클래스는 자신을 감싼 바깥 클래스에서만 쓰여야 하며,    그 외에 쓰임새가 있다면 톱레벨 클래스로 만들어야 한다.      정적 멤버 클래스   (비정적) 멤버 클래스   익명 클래스   지역 클래스       1. 정적 멤버 클래스   정적 멤버 클래스는 바깥 클래스의 private 멤버에도 접근할 수 있다는 점만 제외하면 일반 클래스와 똑같다.         private으로 선언하면 바깥 클래스에서만 접근할 수 있다.       2. 비정적 멤버 클래스   정적 멤버 클래스와 비정적 멤버 클래스의 구문상 차이는 static이 있고 없고 차이다. 의미상 차이는 꽤 크다.                   정적 멤버 클래스 vs 비정적 멤버 클래스   (1) 객체 생성      정적 내부 클래스의 경우 다음과 같이 객체 생성이 가능하다.   class A {     static class B { ... } }  void foo() {     A.B b = new B(); }   static 예약어가 있음으로 인해 독립적으로 생성할 수 있다.           비정적 내부 클래스인 경우 다음과 같이 생성해야 한다.   class A {     class B { ... } }  void foo() {     // ex1     A a = new A();     A.B b = a.new B();          // ex2     A.B b = new A().new B(); }   반드시 A 객체를 생성한 뒤 A 객체를 이용해서 생성해야 한다.     즉 비정적 내부 클래스는 바깥 클래스에 대한 참조가 필요하다는 것이다.       (2) 메모리 누수 가능성   비정적 내부 클래스의 경우 바깥 클래스에 대한 참조를 가지고 있기 때문에 메모리 누수가 발생할 여지가 있다.     바깥 클래스는 더 이상 사용되지 않지만 내부 클래스의 참조로 인해 GC가 수거하지 못해        바깥 클래스의 메모리 해제를 하지 못하는 경우가 발생할 수 있다.   정적 내부 클래스의 경우 바깥 클래스에 대한 참조 값을 가지고 있지 않기 때문에 메모리 누수가 발생하지 않는다.       (3) 사용 시기   메모리 누수가 발생할 수 있는 문제점이 있기 때문에       내부 클래스가 독립적으로 사용된다면 정적 클래스로 선언하여 사용하는 것이 좋다.             비정적 멤버 클래스      비정적 클래스를 어댑터 패턴을 이용하여 바깥 클래스를 다른 클래스로 제공할 때 사용하면 좋다.      예) HashSet의 keySet() : Map의 key에 해당하는 값들을 Set으로 반환       어댑터 패턴을 이용해서 Map을 Set으로 제공한다.          정적 멤버 클래스         바깥 클래스가 표현하는 객체의 한 부분(구성 요소)을 나타낼 때 쓴다.      예) Map 구현체의 키-값 쌍을 표현하는 엔트리 객체        엔트리 선언 시 static을 빠뜨려도 맵은 동작하겠지만      모든 엔트리가 바깥 Map으로 참조를 갖게 되어 공간과 시간이 낭비된다.       (4) 멤버 클래스가 public이나 protected 멤버라면?   공개된 클래스의 public이나 protected 멤버라면 정적이냐 아니냐는 두 배로 중요해진다.     멤버 클래스 역시 공개 API가 되기 때문에 향후 릴리스에서 static을 붙이면 하위 호환성이 떨어진다.       비정적 멤버 클래스 정리      비정적 멤버 클래스의 인스턴스는 바깥 클래스의 인스턴스와 암묵적으로 연결         비정적 멤버 클래스의 인스턴스 메서드에서 정규화된 this를 사용              (클래스명.this 형태로 바깥 클래스의 이름을 명시하는 용법)                     바깥 인스턴스의 메서드를 호출하거나 바깥 인스턴스의 참조를 가져올 수 있다.                             비정적 멤버 클래스의 인스턴스와 바깥 인스턴스 사이의 관계는         멤버 클래스가 인스턴스화될 때 확립되며, 더 이상 변경할 수 없다.       3. 익명 클래스 (Anonymous Inner Class)           이름이 없다.            바깥 클래스의 멤버도 아니다.            멤버와 달리 쓰리는 시점에 동시에 인스턴스가 만들어진다.            오직 비정적인 문맥에서 사용될 때만 바깥 클래스의 인스턴스를 참조할 수 있다.            정적 문맥에서라도 상수 변수 이외의 정적 멤버는 가질 수 있다.       즉, 상수 표현을 위해 초기화된 final 기본 타입과 문자열 필드만 가질 수 있음        익명 클래스는 응용하는 데 제약이 많은 편이다.           선언한 지점에서만 인스턴스를 만들 수 있다.            instanceof 검사나 클래스의 이름이 필요하 작업은 수행 불가            여러 인터페이스를 구현할 수 없다.            인터페이스를 구현하는 동시에 다른 클래스를 상속할 수 없다.            익명 클래스를 사용하는 클라이언트는 그 익명 클래스가 상위 타입에서 상속한 멤버 외에는 호출할 수 없다.       // 인터페이스 사용 public interface Monster{     String getName(); }   public static void main(String args[]){     Monster monster = new Monster(){         String name;         public String getName(){             return name;         }     };     System.out.println(monster.getName()); }   // 클래스 상속 사용  public class Pet{     String name = \"부모 클래스\";     public String getName(){             return name;     } }  public static void main(String[] args){     Pet pet = new Pet(){             String name = \"익명 내부 클래스\";             @Override             public String getName(){                 return name;             }     };     System.out.println(pet.getName()); // 결과 : 익명 내부 클래스 }   Pet 익명 클래스는 Pet 클래스는 아니다.                      생성된 인스턴스의 클래스 이름 확인 instance.getClass().getName                  Pet + $ + n(생성된 몇번 째) 이런식의 클래스 이름이 나온다.               인터페이스로 선언된 익명 클래스는 현재 main에 속해있는 클래스 이름을 반환한다.             즉 자바에서는 이 서로 두개의 클래스를 같은 클래스로 보고 있지 않다는 것이다.       사용 시기           자바가 람다를 지원하기 전에 즉석에서 작은 함수 객체나 처리 객체를 만드는 데   익명 클래스를 주로 사용했다.            정적 팩토리 메서드를 구현할 때 사용한다.           지역 클래스   네 가지 중첩 클래스 중 가장 드물게 사용된다.   지역 클래스는 지역 변수처럼 메소드 내부에 정의되는 클래스를 말한다.      지역 클래스 지역 변수를 선언할 수 있는 곳이면 실질적으로 어디서든 선언할 수 있고,      유효 범위도 지역 변수와 같다.       멤버 클래스처럼 이름이 있고 반복해서 사용할 수 있다.         익명 클래스처럼 비정적 문맥에서 사용될 때만 바깥 인스턴스를 참조할 수 있으며   정적 멤버는 가질 수 없다.       핵심 정리      메서드 밖에서도 사용해야 하거나 메서드 안에 정의하기엔 너무 길다면 멤버 클래스로 만든다.               멤버 클래스의 인스턴스 각각이 바깥 인스턴스를 참조한다면 비정적으로,          그렇지 않으면 정적으로 만든다.            중첩 클래스가 한 메서드 안에서만 쓰인다면 그 인스턴스를 생성하는 시점이 단 한 곳이고           해당 타입으로 쓰기에 적합한 클래스나 인터페이스가 이미 있다면 익명 클래스로 만든다.          그렇지 않으면 지역 클래스로 만든다.             25. 톱레벨 클래스는 한 파일에 하나만 담으라.   소스 파일 하나에 톱레벨 클래스를 여러 개 선언하더라도 자바 컴파일러가 불평하지는 않지만        아무런 이득 없이 위험을 감수해야 하는 행위다.   한 클래스를 여러 가지로 정의할 수 있지만 어느 소스 파일을 먼저 컴파일하냐에 따라 달라진다.     예) 집기(Utensil)와 디저트(Dessert) 클래스를 담은 Utensil.java      Main.java   public class Main {     public static void main(String[] args) {         System.out.println(Utensil.Name + Dessert.Name);            } }      Utensil.java  ``` class Utensil {    static final String NAME = “pan”; }   class Dessert {      static final String NAME = “cake”; }   * Dessert.java      class Utensil {      static final String NAME = “pot”; }   class Dessert {      static final String NAME = “pie”; } ```       이때 우연히 똑같은 두 클래스를 담은 Dessert.java 파일을 만들었다고 해보자.      javac Main.java Dessert.java 명령으로 컴파일한다면?       컴파일 오류가 나고 클래스 중복 정의했다고 알려줄 것이다.          javac Main.java나 javac Main.java Utensil.java 명령으로 컴파일하면?    pancake를 출력한다.         javac Main.java Dessert.java 명령으로 컴파일하면?   potpie를 출력한다.       컴파일러에 어느 소스 파일을 먼저 건네느냐에 따라 동작이 달라지므로 반드시 바로 잡아야 하는 문제다.          해결책은 톱레벨 클래스들을 서로 소스 파일로 분리하면 그만이다.    다른 클래스에 딸린 부차적인 클래스라면 정적 멤버 클래스를 사용하는 방법을 고민해볼 수 있다.   정적 멤버 클래스로 만들면 읽기 좋고, private으로 선언하면 접근 범위도 최소로 관리할 수 있다.      ","categories": ["Effective Java","Java"],
        "tags": ["java"],
        "url": "/2021-06-04/chap4/",
        "teaser": null
      },{
        "title": "Sign up, Sign in 구현",
        "excerpt":"issue #54   User Entity   서비스에서 필요한 uid, name, profile image만 갖고 있다.           sns로 로그인하기 때문에 uid를 저장       사용자를 식별할 수 있는 uid가 있지만 pk는 MySQL의 auto increment로 설정            기본 생성자의 접근 제어자 : protected, Builder 사용            Setter나 필드를 수정할 수 있는 메서드는 없다.           UserRepository      CRUD 처리를 위한 공통 인터페이스   oprional 사용       Sign up   kakao에서 제공하는 API를 활용하여 사용자 인증과 정보를 받는다.      kakao에서 제공하는 절차             litebook에서 진행되는 상세 절차                    Q&amp;A   Q. User Entity 기본 생성자 접근자를 protected로 변경한 이유는?   A. new User()을 막을 수 있어 객체의 일관성을 유지할 수 있다.                 private이 아닌 protected로 설정하는 이유는 JPA에서 기본 생성자가 필요한데                protected로 제어하는 것까지 허용되기 때문이다.       Q. JPA 기본 생성자가 필요한 이유는?   A. 지연 로딩을 사용하는 경우      임시로 hibernate가 생성한 proxy 객체를 사용하게 되는데        이러한 proxy 객체는 해당 class를 상속하기 때문에 public 혹은 protected 기본 생성자가 필요하게 된다.       Q. Builder 패턴을 사용한 이유는?   A. 불필요한 Setter 생성을 방지하고 불변 객체로 만들기 위함이다.               @Builder 어노테이션을 사용하여 빌더 패턴을 적용하였고              @Builder 어노테이션을 선언하면 전체 인자를 갖는 생성자를 자동으로 만들기 때문에               @AllArgsConstructor(access=AccessLevel.PRIVATE) 접근자를 private로 만들어              외부에서 접근할 수 없도록 만들었다.       Q. 왜 Optional을 사용했는가?   A. 우선 Optional 이란 존재할 수도 있지만 안 할 수도 있는 객체           (null이 될 수도 있는 객체)를 감싸고 있는 일종의 래퍼 클래스다.      null 관련 문제 1) 런타임에서 NullPointerException 예외를 발생시킬 수 있다. 2) NPE 방어를 위해서 들어간 null 체크 로직 때문에 코드 가독성과 유지보수성이 떨어진다.    Optional로 객체를 감싸서 사용하게 되면서 NPE를 유발할 수 있는 null을 직접 다루지 않아도 된다.              실제 프로젝트에서 작성한 코드는 다음과 같다.   userRepository.findByUid(uid).orElseThrow(() -&gt; new NotFoundException(...));       Q. ResponseEntityConstants는 왜 만들었는가?   A. api 응답에 필요한 Response 클래스를 별도로 만들어 재사용성을 높였다.       Q. Service 레이어에 인터페이스를 사용한 이유는?   A. 1) SocialAuthService 인터페이스         로그인으로 회원가입, 로그인을 진행하는데                지금 구현한 kakao 로그인을 제외하고 naver, google, facebook 등                확장성을 고려해 인터페이스를 사용했다.   또한 제네릭으로 파라미터 타입을 제한하여              회원가입, 로그인 로직에 필요한 추가 필드나 로직이 있는 경우           누구도 수정이 편리하도록 구현했다.   2) LoginService 인터페이스            현재 구현한 로그인 방식은 세션 로그인 방식이다.                 KakaoAuthService.java의 signIn() 메서드의 코드에서                   kakao api를 활용하여 사용자 인증 과정과 세션 로그인이 필요하다.   그런데 위에서 설명한 회원가입, 로그인 방식이 확장되면    세션 로그인 코드는 계속 중복되서 나타날 것이고    만약 세션 로그인이 아닌 jwt나 spring security 등으로 변경되는 경우     많은 코드를 변경해야 한다.   LoginService 인터페이스를 구현해서   반복되는 코드를 줄이고 확장을 대비할 수 있다.   ","categories": ["Spring","JPA"],
        "tags": ["spring","jpa"],
        "url": "/2021-06-17/issue54/",
        "teaser": null
      },{
        "title": "[Effective Java] 추상 골격 구현 클래스",
        "excerpt":"추상 골격 구현 클래스란?  인터페이스의 장점과 추상 클래스의 장점을 결합   자판기를 개발할 것이다.         음료 자판기, 커피 자판기, 라면 자판기 등등 여러 타입이 있다.       Interface   자판기 인터페이스  public interface Vending {     void start();     void chooseProduct();     void stop();     void process(); }       캔디 구현체  public class CandyVending implements Vending {      @Override     public void start() {         System.out.println(\"Start Vending machine\");     }          @Override     public void chooseProduct() {         System.out.println(\"Produce diiferent candies\");         System.out.println(\"Choose a type of candy\");         System.out.println(\"pay for candy\");         System.out.println(\"collect candy\");     }          @Override     public void stop() {         System.out.println(\"Stop Vending machine\");     }          @Override     public void process() {         start();         chooseProduct();         stop();     }      }       음료수 자판기  public class DrinkVending implements Vending {      @Override     public void start() {         System.out.println(\"Start Vending machine\");     }          @Override     public void chooseProduct() {         System.out.println(\"Produce diiferent soft drinks\");         System.out.println(\"Choose a type of soft drinks\");         System.out.println(\"pay for drinks\");         System.out.println(\"collect drinks\");     }          @Override     public void stop() {         System.out.println(\"stop Vending machine\");     }          @Override     public void process() {         start();         chooseProduct();         stop();     }      }       main  public class VendingManager {     public static void main(String[] args) {         Ivending candy = new CandyVending();         Ivending drink = new DrinkVending();         candy.process();         drink.process();     } }       start(), stop(), process()가 중복된다.           그렇다고 유틸리티클래스에 코드를 넣으면 SRP                            (단일 책임 원칙, 객체는 하나의 책임(역할)만을 가져야 한다.)가 깨지게 된다.                  이처럼 인터페이스는 중복 코드를 만들게 될 수 있다.       Abstract  그렇다면 추상 클래스는?  public abstract class AbstractVending {     public void start() {         System.out.println(\"Start Vending machine\");     }          public abstract void chooseProduct();          public void stop() {         System.out.println(\"Stop Vending machine\");     }          public void process() {         start();         chooseProduct();         stop();     } }  public class CandyVending extends AbstractVending {     @Override     public void chooseProduct() {         System.out.println(\"Produce diiferent candies\");         System.out.println(\"Choose a type of candy\");         System.out.println(\"pay for candy\");         System.out.println(\"collect candy\");     } }  public class DrinkVending extends AbstractVending {     @Override     public void chooseProduct() {         System.out.println(\"Produce diiferent soft drinks\");         System.out.println(\"Choose a type of soft drinks\");         System.out.println(\"pay for drinks\");         System.out.println(\"collect drinks\");     } }  public class VendingManager {     public static void main(String[] args) {         AbstractVending candy =  new CandyVending();         AbstractVending drink =  new DrinkVending();         candy.process();         System.out.println(\"*********************\");         drink.process();     } }   중복은 제거했지만 구현 클래스들은 다른 상속을 포기해야 한다.       Abstract Interface Skeletal Implementation      인터페이스를 만든다.   인터페이스를 구현하는 추상 메서드를 만들어서 공통 메서드를 구현한다.   구현 클래스에 추상 클래스를 상속한 private 이너클래스 (Delegator 패턴)를 만든다.  그리고 그 클래스를 변수로 가지고 포워딩한다.       인터페이스  public interface Vending {     void start();     void chooseProduct();     void stop();     void process(); }       인터페이스를 구현한 추상 클래스  public abstract class AbstractVending implements Vending {      // 중복되는 메서드는 구현      public void start() {         System.out.println(\"Start Vending machine\");     }          // 구현체마다 다른 기능은 추상 메서드로 정의      public abstract void chooseProduct();          public void stop() {         System.out.println(\"Stop Vending machine\");     }          public void process() {         start();         chooseProduct();         stop();     }      }       구현 클래스에 추상 클래스를 상속한 private inner class 구현 &amp; inner class 객체를 변수로 가지고 포워딩   public class CandyVending implements Vending {        // 구현마다 다른 기능은 구현체 클래스에 private inner class에 추상 클래스를 상속받아 재정의      private class AbstractVendingDelegator extends AbstractVending {          @Override          public void chooseProduct() {             System.out.println(\"Produce diiferent candies\");             System.out.println(\"Choose a type of candy\");             System.out.println(\"pay for candy\");             System.out.println(\"collect candy\");          }     }      // inner class의 객체를 변수로 포워딩      AbstractVendingDelegator delegator = new AbstractVendingDelegator();          @Override     public void start() {         delegator.start(); // 각 메서드 호출을 내부 클래스의 인스턴스 메서드 호출     }          @Override     public void chooseProduct() {         delegator.chooseProduct();     }          @Override     public void stop() {         delegator.stop();     }          @Override     public void process() {         delegator.process();     } }   인터페이스로 인한 중복을 추상클래스로 지우고 Delegator 패턴으로 추상 클래스 상속에 대한 단점을 지울수 있다.       ","categories": ["Effective Java","Java"],
        "tags": ["java"],
        "url": "/2021-06-20/skeletal_implementation/",
        "teaser": null
      },{
        "title": "[Effective Java] Mixin",
        "excerpt":"Mixin   이펙티브의 클래스와 인터페이스 부분을 읽다가 mixin이란 개념이 나왔는데   믹스인이란 클래스가 구현할 수 있는 타입으로 믹스인을 구현한 클래스에          원래의 '주된 타입' 외에도 특정 선택적 행위를 제공한다고 선언하는 효과를 준다.            예) Comparable은 자신을 구현한 클래스의 인스턴스들끼리는 순서를 정할 수 있다고 선언하는 믹스인 인터페이스이다.        이처럼 대상 타입의 주된 기능에 선택적 기능을 '혼합(mixed-in)'한다고 해서 믹스인이라고 부릅니다.    위 설명만으로 부족해 mixin에 대해 찾아봤는데    스택 오버플로에 나와 같은 고민으로 글을 작성한 사람도 있었다.  https://stackoverflow.com/questions/17987704/an-example-of-a-mixin-in-java       Using mixins in Java  클래스에 기능을 덧붙여야 할 때가 있는데 대부분 Mixin보다는 Delegator로 구현한다.      이번에는 일급 컬렉션(first class collections)을 사용하여 Java에서 Mixin을 구현하는 방법을 알아보자.      일급 컬렉션에 대해  https://woowacourse.github.io/javable/post/2020-05-08-First-Class-Collection/  https://jojoldu.tistory.com/412        exam1. 구독자 목록을 포함한 Magazine.java, Newspaper.java   일반적으로 다음과 같이 모델링한다.   // Magazine.java class Magazine {     private List&lt;Subcriber&gt; subscribers;          public void addSub(Subscriber subscriber) {         subscribers.add(subscriber);     }          public List&lt;Subcriber&gt; primeSubscribers() {         . . .     } }  // Newspaper.java    class Newspaper {     private DateTime date;      private List&lt;Subcriber&gt; subscribers;           public void addSub(Subscriber subscriber) {         subscribers.add(subscriber);     }          public List&lt;Subcriber&gt; primeSubscribers() {         . . .     } }   구독자 목록 관련된 작업이 두 클래스에서 모두 중복된다.        구독자 목록인 List&lt;Subcriber&gt; subscribers을       필드로 갖고 있는 다른 클래스를 만들면 이를 해결할 수 있다.   class Subcribers {     private List&lt;Subcriber&gt; subscribers;  }       List와 Subscribers을 별도의 클래스로 분리   custom arrayList에서 동작하게 하려면 List를 재정의해야 한다.   interface ListMixin&lt;T&gt; extends List&lt;T&gt; {     List&lt;T&gt; getRecords();          default int size() {         return getRecords().size();     }          . . .      }       Subscribers에서 ListMixin 인터페이스를 구현하고      getRecords() 메서드를 재정의하여 구독자 목록을 반환함으로써       이 클래스를 List처럼 사용할 수 있다.      구독자 리스트에 관련된 작업이 전부 이 클래스에 들어간다.   class Subcribers implements ListMixin&lt;Subcriber&gt; {     private List&lt;Subcriber&gt; subcribers = new ArrayList&lt;&gt;();          @Override      public List&lt;Subcriber&gt; getRecords() {         return subcribers;     }          public void addSub(Subscriber subscriber) {         subscribers.add(subscriber);     }          . . .      }       이제 Magazine.java, Newspaper.java에서     구독자 명단을 반환하는 로직을 다루지 않아도 된다.   class Magazine {      private Subcribers Subcribers;          . . .      }       exam2. mixin exam code  interface TimeStamped { \tlong getStamp(); }   class TimeStampedImp implements TimeStamped { \tprivate final long timeStamp;  \tpublic TimeStampedImp() { \t\ttimeStamp = new Date().getTime(); \t}  \tpublic long getStamp() { \t\treturn timeStamp; \t} }   interface SerialNumbered { \tlong getSerialNumber(); }   class SerialNumberedImp implements SerialNumbered { \tprivate static long counter = 1; \tprivate final long serialNumber = counter++;  \tpublic long getSerialNumber() { \t\treturn serialNumber; \t} }   class Basic { \tprivate String value;  \tpublic void set(String val) { \t\tvalue = val; \t}  \tpublic String get() { \t\treturn value; \t} }   class Mixin extends Basic implements TimeStamped, SerialNumbered { \tprivate TimeStamped timeStamp = new TimeStampedImp(); \tprivate SerialNumbered serialNumber = new SerialNumberedImp();  \tpublic long getStamp() { \t\treturn timeStamp.getStamp(); \t}  \tpublic long getSerialNumber() { \t\treturn serialNumber.getSerialNumber(); \t} }   public class Mixins { \tpublic static void main(String[] args) { \t\tMixin mixin1 = new Mixin(); \t\tMixin mixin2 = new Mixin();  \t\tmixin1.set(\"test string 1\"); \t\tmixin2.set(\"test string 2\");  \t\tSystem.out.println(mixin1.get() + \" \" + mixin1.getStamp() + \" \" + mixin1.getSerialNumber()); \t\tSystem.out.println(mixin2.get() + \" \" + mixin2.getStamp() + \" \" + mixin2.getSerialNumber()); \t} }             ","categories": ["Effective Java","Java"],
        "tags": ["java"],
        "url": "/2021-06-21/mixin/",
        "teaser": null
      },{
        "title": "[Effective Java] 제네릭",
        "excerpt":"제네릭을 지원하기 전에는 컬렉션에서 객체를 꺼낼 때마다 형변환을 해야 했다.           제네릭을 사용하면 컬렉션이 담을 수 있는 타입을 컴파일러에게 알려준다.          컴파일러는 알아서 형변환 코드를 추가할 수 있고 엉뚱한 타입의 객체를 넣으려는 시도를            컴파일 과정에서 판단하여 더 안전하고 명확한 프로그램을 만들어준다.       26. 로 타입은 사용하지 말라.  클래스와 인터페이스 선언에 타입 매개변수가 쓰이면 이를 제네릭 클래스 혹은 제네릭 인터페이스라 한다.       ex) List 인터페이스는 원소의 타입을 나타내는 타입 매개변수 E를 받는다.   제네릭 클래스 + 제네릭 인터페이스 = 제네릭 타입    각각의 제네릭 타입은 일련의 매개변수화 타입을 정의한다.     ex) List은 원소의 타입이 String인 리스트를 뜻하는 매개변수화 타입이다.       Raw Type 이란?   Raw Type은 타입 파라미터가 없는 제네릭 타입을 의미한다.     다음 예제 코드에서 t가 로 타입 변수이다.    애초에 제네릭으로 정의되지 않은 클래스나 인터페이스에는 로 타입이 없다.   public class Trouble&lt;T&gt; {     public List&lt;String&gt; getStrs() { return Arrays.asList(\"str\"); } }  public static void main(String[] args) {     Trouble t = new Trouble();          for(String str : t.getStrs()) { // 컴파일 에러 발생          System.out.println(str);     } }        Raw Type을 사용하면 왜 컴파일 에러가 발생할까?   Raw Type의 슈퍼 클래스는 Raw Type이다.  상속 받지 않은 로 타입의 생성자, 인스턴스 메서드, 필드는 로 타입이다.  로 타입은 파라미터 T만 지우는게 아니라 슈퍼 클래스의 타입 파라미터,  해당 클래스에 정의된 모든 타입 파라미터를 지워버린다.      예제에서 t.getStrs()의 반환 타입이 List&lt;String&gt;이 아닌 로 타입 List가 된 것이다.   private final Collection stamps = ...; stamps.add(new Coin()); // stamp만 저장하기로 했는데 실수로 coin을 저장함   for(Iterator i = stamps.iterator(); i.hasNext();); {     Stamp stamp = (Stamp) i.next(); // ClassCastException을 던진다.     stamp.cancel(); }   오류는 가능한 발생 즉시, 이상적으로는 컴파일 할 때 발견하는 것이 좋다.        위 코드는 런타임에 오류를 알아챌 수 있는데 이렇게 되면                     런타임에 문제를 겪는 코드와 원인을 제공하는 코드가 동떨어져 있을 가능성이 커진다.       제네릭을 활용하면 Stamp 인스턴스만 취급한다는 정보가 타입 선언 자체에 녹아든다.  private final Collection&lt;Stamp&gt; stamps = ...;    이렇게 선언하면 stamps에는 Stamp 인스턴스만 넣어야 함을 컴파일러가 인지하게 된다.    아무런 경고 없이 컴파일 된다면 의도대로 동작할 것임을 보장한다.     컴파일러는 컬렉션에서 원소를 꺼내는 모든 곳에 보이지 않는 형변환을 추가하여 절대 실패하지 않음을 보장한다.       로 타입을 쓰면 제네릭이 안겨주는 안전성과 표현력을 모두 잃게 된다.     그렇다면 쓰면 안되는 로 타입을 왜 만들어놓은 걸까?      그 이유는 호환성 때문이다.   제네릭은 자바 5부터 사용할 수 있다.     기존 코드를 모두 수용하면서 제네릭을 사용하는 새로운 코드와 맞물려 돌아가게 해야 하기 때문이다.       List&lt;Object&gt;처럼 임의 객체를 허용하는 매개변수화 타입은 괜찮다.   로 타입인 List와 매개변수화 타입인 List&lt;Object&gt;의 차이는 무엇일까?   List는 제네릭 타입에서 완전히 발을 뺀 것이고,      List&lt;Object&gt;는 모든 타입을 허용한다는 의미를 컴파일러에 명확히 전달한 것이다.   매개변수로 List를 받는 메서드에는 List&lt;String&gt;을 넘길 수 있지만   List&lt;Object&gt;를 받는 메서드에는 넘길 수 없다.    이는 제네릭의 하위 타입 규칙 때문이다.   List&lt;String&gt; 은 List의 하위 타입이지만, List&lt;Object&gt;의 하위 타입은 아니다.     List&lt;Object&gt; 같은 매개변수화 타입을 사용할 때와 달리     List같은 로 타입을 사용하면 타입 안정성을 잃게 된다.         public static void main(String[] args) {     List&lt;String&gt; strings = new ArrayList&lt;&gt;();     unsafeAdd(strings, Integer.valueOf(42));      String s = strings.get(0); // 컴파일러가 자동으로 형변환 코드를 넣어준다.  }  private static void unsafeAdd(List list, Object o) {     list.add(o); }   위 코드는 컴파일은 되지만 로 타입인 List를 사용하여 다음과 같은 경고가 발생한다.   warning: [unchecked] unchecked call to add(E) as a member of the raw type List     list.add(0);             ^   strings.get(0)의 결과를 형변환하려 할 때 ClassCastException을 던진다.    Integer를 String으로 변환하려 시도한 것이다.    이 형변환은 컴파일러가 자동으로 만들어준 것이라 보통은 실패하지 않는다.     하지만 이 경우 컴파일러의 경고를 무시했기 때문에 나타난 결과다.   로 타입인 List를 매개변수화 타입인 List&lt;Object&gt;로 바꾼 다음 다시 컴파일해보면,     다음 오류 메세지지가 출력되며 컴파일조차 되지 않는다.   // 변경 코드  unsafeAdd(List&lt;Object&gt; list, Object o) { . . . }  // error error: incompatible types: List&lt;String&gt; cannot be  converted to List&lt;Object&gt;     unsafeAdd(strings, Integer.valueOf(42));        ^   로 타입을 사용하여 잘못된 타입을 사용했을 경우, 해당 에러를 런타임 시에 알게 되지만         매개변수화 타입을 정의한 제네릭을 사용했을 경우, 해당 오류를 컴파일 즉시 잡아낼 수 있다는 점에서          제네릭은 안전성을 제공한다.       제네릭 타입을 쓰고 싶지만 실제 타입 매개변수가 무엇인지 신경 쓰고 싶지 않다면          와일드카드(물음표, ?)를 사용하자.   비한정적 와일드카드 타입인 Set&lt;?&gt;와 로 타입인 Set은 무슨 차이일까?          특징을 간단히 말하면 와일드카드 타입은 안전하고, 로 타입은 안전하지 않다.   로 타입 컬렉션에는 아무 원소나 넣을 수 있으니 타입 불변식을 훼손하기 쉽다.       반면, Collection&lt;?&gt;에는 (null 외에) 어떤 원소도 넣을 수 없다.              27. 비검사 경고를 제거하라.  제네릭을 사용하기 시작하면 수많은 컴파일러 경고를 보게 될 것이다.   예) Set&lt;Lark&gt; exaltation = new HashSet();   위 코드는 unchecked conversion 경고를 출력한다.     컴파일러가 알려준 타입 매개변수를 명시하면 경고가 사라지는데    자바 7부터 지원하는 다이아몬드 연산자(&lt;&gt;)로 해결할 수 있다.   new HashSet&lt;&gt;();   위 예제는 해결하기 쉬운 경고다.    해결하기 어렵더라도 할 수 있는 한 모든 비검사 경고를 제거하면    그 코드는 타입 안전성이 보장된다.       만약 경고를 제거할 수 없지만 타입 안전하다고 확신할 수 있다면      최대한 좁은 범위에 @SuppressWarnings 어노테이션을 적용하자.     경고를 숨기기로 한 근거가 있어야 한다.             ","categories": ["Effective Java","Java"],
        "tags": ["java"],
        "url": "/2021-07-06/chap5/",
        "teaser": null
      },{
        "title": "Baekjoon 기초 수학 알고리즘 풀이",
        "excerpt":"    10430     문제   https://www.acmicpc.net/problem/10430   (A+B)%C는 ((A%C) + (B%C))%C 와 같을까? (A×B)%C는 ((A%C) × (B%C))%C 와 같을까?          풀이   주어진 식대로 System.out.println() 해주면 된다.             4375     문제   https://www.acmicpc.net/problem/4375   1로만 이루어진 n의 배수를 찾아, 그 중 가장 작은 수의 자리수를 출력하라.          풀이   input = n   num = num * 10 + 1; // 1, 11, 111, ... 1로만 이뤄진 수를 구한다.  num = num % n; // n의 배수인지 확인하기 위해 나머지를 구한다.                  1037     문제   https://www.acmicpc.net/problem/1037   양수 A가 N의 진짜 약수가 되려면, N이 A의 배수이고, A가 1과 N이 아니어야 한다.  어떤 수 N의 진짜 약수가 모두 주어질 때, N을 구하는 프로그램을 작성하시오.          풀이   약수가 전부 주어지기 때문에 가장 작은 수 * 가장 큰 수 가 N이 된다.             17427     문제   https://www.acmicpc.net/problem/17427   두 자연수 A와 B가 있을 때, A = BC를 만족하는 자연수 C를 A의 약수라고 한다.  예를 들어, 2의 약수는 1, 2가 있고, 24의 약수는 1, 2, 3, 4, 6, 8, 12, 24가 있다.  자연수 A의 약수의 합은 A의 모든 약수를 더한 값이고, f(A)로 표현한다.  x보다 작거나 같은 모든 자연수 y의 f(y)값을 더한 값은 g(x)로 표현한다. 자연수 N이 주어졌을 때, g(N)을 구해보자.          풀이   n 이하인 수들 중에서 i를 약수로 갖는 수  =&gt; n 이하의 i의 배수  =&gt; 개수를 구하려면 n/i 이다.   answer += i * (n / i)   입력이 최대 1,000,000 이므로 long 타입으로 선언해야 한다.            17425     문제   https://www.acmicpc.net/problem/17425   문제는 위 17427번과 같지만 입력 방법이 다르다.          풀이   해당 자연수의 약수의 합을 저장하는 코드: N logN      이전 약수의 합을 저장하는 코드(dp): N     테스트 케이스 만큼 실행되는 코드: T   총 시간 복잡도는 N logN + T 이므로 위 계획으로 문제를 풀 시간은 충분하다.      그러나 테스트 케이스마다 약수의 합을 구하는 코드를 실행하면 시간 초과가 뜬다.    미리 문제를 해결해놓고 테스트 케이스에 따라 답을 꺼내와야 한다.                      2609     문제   https://www.acmicpc.net/problem/2609          풀이   최소 공배수는 N * M /최대 공약수 로 구할 수 있다.               1978     문제   https://www.acmicpc.net/problem/1978   주어진 수 N개 중에서 소수가 몇 개인지 찾아서 출력하는 프로그램을 작성하시오.          풀이   에라토스테네스의 체를 이용하여 소수를 찾는다.      2의 배수 제거, 3의 배수 제거, … 를 반복하는 개념이다.   boolean[] prime = new boolean[n + 1]; Arrays.fill(prime, true);  // 0 과 1 은 소수가 아니므로 false prime[0] = false; prime[1] = false;  for (int i = 2; i * i &lt;= n; ++i) {     if (prime[i]) {         // 이미 2의 배수가 걸러졌기 때문에 i 의 제곱수부터 시작해도 된다.         for (int j = i * i; j &lt;= n; j += i) {              prime[j] = false;         }     } }               1929     문제   https://www.acmicpc.net/problem/1929   M이상 N이하의 소수를 모두 출력하는 프로그램을 작성하시오.          풀이   에라토스테네스의 체를 이용하여 소수를 찾는다.    코드는 위와 동일하다.               6588     문제   https://www.acmicpc.net/problem/6588   4보다 큰 모든 짝수는 두 홀수 소수의 합으로 나타낼 수 있다.   예를 들어 8은 3 + 5로 나타낼 수 있고, 3과 5는 모두 홀수인 소수이다.            풀이   이것도 에라토스테네스의 체를 이용하여 소수를 찾은 후 시작한다.   while (true) {     int num = Integer.parseInt(br.readLine());     boolean ok = false;     if (num == 0) {         break;     }     for (int i = 2; i &lt;= num / 2; i++) {         if (prime[i] &amp;&amp; prime[num - i]) {             sb.append(num + \" = \" + i + \" + \" + (num - i) + \"\\n\");             ok = true;             break;         }     }     if (!ok) {         sb.append(\"Goldbach's conjecture is wrong.\\n\");     } }      ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-07-11/codeplus-%EA%B8%B0%EC%B4%88-%EC%88%98%ED%95%99/",
        "teaser": null
      },{
        "title": "자바의 완전 기본 문법부터 정리",
        "excerpt":"    컴파일 &amp; 실행  자바의 경우 다음과 같은 과정으로 진행된다.   코드 작성 &gt; 컴파일 &gt; 실행    코드를 작성하고 콘솔에서 컴파일 및 실행을 하면 된다.   컴파일은 javac 명령어를 사용하고 실행은 java 명령을 사용한다.          개발자가 작성한 코드를 컴퓨터가 이해할 수 있도록 엮어주는 작업이 컴파일이다.             .java 확장자의 소스를 컴파일하면 .class 확장자를 가진 파일이 생성되어 디스크에 저장된다.    .class 파일은 바이너리 파일로 되어있고, 컴파일하는 프로그램을 컴파일러라고 부르며,   자바에서는 java.exe 프로그램이 그 역할을 수행한다. (Mac이나 Linux에서는 javac)    컴파일시 코드에 규칙을 지키지 않았다면, 오류를 내면서 컴파일이 되지 않는다.   컴파일을 마친 클래스 파일은 JVM에서 읽어서 운영체제에서 실행된다.                  JIT 컴파일러  Just In Time의 약자   프로그램 실행을 보다 빠르게 하기 위한 기술이고 명칭은 컴파일러지만 실행시에 적용된다.   JIT 컴파일러는 프로그램의 성능에 영향을 주는 지점에 대해서 지속적으로 분석한다.      분석된 지점은 부하를 최소화하고 높은 성능을 내기 위한 최적화의 대상이 된다.   JIT 컴파일러를 사용한다는 것은?                    언제나 자바 메서드가 호출되면 바이트코드를 컴파일하고 실행 가능한 네이티브 코드로 변환한다는 의미다.         매번 JIT 컴파일하면 성능 저하가 심하므로 최적화 단계를 거치게 된다.   javac 컴파일러는 소스코드를 바이트코드로 변환 (.class)     자바 프로그램을 실행할 때 JVM은 항상 바이트코드로 시작,   동적으로 기계에 의존적인 코드로 변환한다.   JIT은 애플리케이션에서 각각의 메서드를 컴파일할 만큼 시간적 여유가 없어서   모든 코드는 초기에 인터프리터에 의해서 시작되고 해당 코드가 충분히 많이 사용될 경우에 컴파일할 대상이 된다.   - 인터프리터     Java 인터프리터는 javac 명령으로 자바 프로그램을 자바 바이트코드로 컴파일하고,    Java 인터프리터가 한 줄씩 해석하여 기계어로 변역한다.     - 컴파일  고급언어로 작성된 프로그램을 목적 프로그램(컴퓨터가 읽을 수 있는) 번역 후    링킹(Linking) 작업을 통해 실행 프로그램을 생성한다.     - 링킹(Linking) 컴파일이 끝나면 나눠져 있는 Object 파일들이나 다른 파일(라이브러리)를 엮어주는 작업이다.                   HotSpot  JVM에서 이 작업은 각 메서드에 있는 카운터를 통제되며, 메서드에 두 개의 카운터가 존재한다.      수행 카운터 (invocation counter)     메서드를 시작할 때마다 증가한다.       백에지 카운터 (backedge counter)          높은 바이트코드 인덱스에서 낮은 인덱스로 컨트롤 흐름이 변경될 때마다 증가하며     메서드에 루프가 존재하는지 확인할 때 사용된다.   backedge counter는 invovation counter 보다 컴파일 우선순위가 더 높다.      이 카운터들이 인터프리터에 의해 증가될 때마다 한계치에 도달했는지 확인하고 도달한 경우 인터프리터는 컴파일을 요청한다.             OSR  HotSpot VM은 OSR(On Stack Replacement)라는 특별한 컴파일도 수행한다.   OSR은 인터프리터에서 수행한 코드 중 오랫동안 루프가 지속되는 경우   중간에 컴파일해야 남은 반복을 빠르게 수행할 수 있기 때문에 사용된다.   최적화되지 않은 코드가 수행되고 있는 것을 발견하면 인터프리터에 두지 않고 컴파일된 코드로 변경한다.             참조 자료형  생성자는 몇 개까지 만들 수 있을까?   자바는 여러 생성자를 가질 수 있다. 100개가 되도 상관 없다.   이러한 이유는 다음 예를 통해 알아보자.   자바 패턴 중에서 DTO 라는 것이 있다. (Data Transfer Object)   어떤 속성을 갖는 클래스를 만들고 그 속성들을 쉽게 전달하기 위해 DTO라는 것을 만든다.   비슷한 클래스로 VO라는 것도 있다.   VO는 Value Object의 약자로 DTO와 형태는 동일하지만, VO는 데이터를 담아두기 위한 목적이고   DTO는 데이터를 다른 서버로 전달하기 위한 것이 목적이다.             접근 제어자      public   누구나 접근 가능       protected     같은 패키지 내에 있거나 상속받은 경우에만 접근 가능       package-private   같은 패키지 내에 있을 때만 접근 가능       private   해당 클래스 내에서만 접근 가능             상속   public class Child extends Parent      extends는 “확장하다.”는 뜻이다.     extends Parent는 “Parent 클래스를 확장” 한다는 말이다.   이렇게 확장하면 부모 클래스에서 선언되어 있는 public 및 protected로 선언되어 있는      모든 변수와 메서드를 내가 갖고 있는 것처럼 사용할 수 있다.        즉, 다른 패키지에 선언된 부모 클래스의 접근 제어자가 없거나    private로 선언된 것들은 자식 클래스에서 사용할 수 없다.         Child child = new Child(); child.printName();   위 코드에서 Parent 클래스의 메서드를 호출하지도 않았는데, 확장한 클래스인 Child의 생성자를 호출하니 자동으로 부모 클래스의 기본 생성자가 호출된다.   기본 생성자란 매개변수가 아무것도 없는 생성자를 의미한다.          부모 클래스에서는 기본 생성자를 만들어 놓는 것 이외에는 상속을 위해 해야하는 작업은 없다.   자식 클래스의 생성자가 호출되면 자동으로 부모 클래스의 매개변수 없는 생성자가 실행된다.   자식 클래스에서는 부모 클래스에 있는 public, protected로 선언된   모든 인스턴스 및 클래스 변수와 메서드를 사용할 수 있다.             상속과 생성자  만약 부모 클래스에 기본 생성자가 없다면 어떻게 될까?   // public Patrent() {  // System.out.println(\"Parent constructor\");  // }   기본 생성자를 주석 처리 했다.   다시 실행해보면, Parent constructor 메시지가 출력되지 않고 정상적으로 처리된다.    문제가 없다고 생각할 수도 있지만 부모 클래스에 매개변수를 받는 메서드가 있을 경우에는 문제가 생긴다.   매개변수가 있는 생성자를 만들었을 경우, 기본 생성자는 자동으로 만들어지지 않는다.   해결 방법은 두 가지다.             (1) 부모 클래스에 “매개변수가 없는” 기본 생성자를 만든다.   (2) 자식 클래스에서 부모 클래스의 생성자를 명시적으로 지정하는 super()을 사용한다.   명시적으로 지정하지 않아도 컴파일시 자동으로 super()가 추가된다.             메서드 Overriding  상속 광계를 보다 유연하게 활용하기 위한 메서드 Overriding에 대해 알아보자.    자식 클래스에서 부모 클래스에 있는 메서드와 동일하게 선언하는 것을 “메서드 Overriding”이라고 한다 .      접근 제어자   리턴 타입   메서드 이름   매개변수 타입 및 개수   위 목록 모두 동일해야만 메서드 Overriding 이라고 부른다.   Overriding된 메서드의 접근 제어자는 부모 클래스에 있는 메서드와 달라도 되지만,   접근 권한이 확장되는 경우에만 허용된다.   접근 권한이 축소될 경우 컴파일 에러가 발생한다.             Overloading  Overloading(오버로딩)과 헷갈릴 수 있다.      Overloading(오버로딩): 확장   Overriding(오버라이딩): 덮어씀   오버로딩은 같은 이름의 메서드 여러 개를 가지면서 매개변수의 유형과 개수가 다르도록 하는 기술이다.             형변환   Parent obj = new Child(); // OK! Child obj2 = new Parent(); // Fail!    왜 첫번째 코드는 되는데 두번째 코드는 안될까?    Child 클래스에서 Parent 클래스에 있는 메서드와 변수 사용이 가능하다.     반대로 Parent 클래스에서는 Child 클래스에 있는 모든 메서드와 변수들을 사용할 수 없다.     정확하게는 Parent 클래스에서 Child 클래스의 모든 메서드, 변수를 사용할 수도 있고 그렇지 않을 수도 있다.   만약 Child 클래스에 추가된 메서드나 변수가 없으면 가능할 수도 있다.    하지만 자바 컴파일러에서는 자식 객체를 생성할 때 부모 생성자를 사용하면 안된다고 못을 박는다.      명시적으로 형변환(casting)을 한다고 알려줘야만 한다.   Child child = (Child) new Parent();     위 코드는 Parent cannot be cast to Child Exception이 발생한다.       Parent p = new Parent(); Child c = new Child(); Parent p2 = c; Child c2 = p;   분명 마지막 라인에서 컴파일 에러가 발생할 것이다.        “incompatible types”라는 에러가 뜨며 컴파일 되지 않는다.       그 이유는 parent 객체는 Child 클래스에 선언되어 있는 메서드나 변수를 완전히 사용할 수 없기 때문이다.       컴파일 오류만을 피하려면 다음과 같이 형변환을 해야만 한다.   Child c2 = (Child)p;   “너 이제 Child 클래스인 것처럼 행동해!” 라고 명시적으로 선언해주는 것이다.   컴파일은 정상적으로 수행되지만, 예외가 발생한다.    p가 실제로 Parent 클래스의 객체이므로 컴파일 오류는 넘겼지만   실행시에는 “얘는 원래 Parent 클래스의 객체라서 못쓰겠는데요..” 라는 예외가 발생한 것이다.       Child c = new Child(); Parent p2 = c; Child c2 = (Child) p2;   위 코드는 아무런 문제 없이 실행될 것이다.    왜 아무 문제 없이 실행될까?   Parent p2 = child;   p2는 child를 대입한 것이다. 그리고 child는 Child 클래스의 객체다.    p2로 겉모습은 Parent 클래스의 객체인 것처럼 보이지만,   실제로는 Child 클래스의 객체이기 때문에 p2를 Child 클래스로 형변환해도 전혀 문제 없다.       Parent[] parentArray = new Parent[3]; parentArray[0] = new Child(); parentArray[1] = new Parent(); parentArray[2] = new Child();   위 코드에서 문제는 없다.  그런데 타입이 Parent인지 Child인지 어떻게 구분할 수 있을까?   이럴때는 instanceof 예약어를 사용하면 된다.             Polymorphism  Polymorphism은 다형성이다.         형태가 다양하다. &gt; 어떤 형태가 다양하다는 걸까?   예) Parent, Child, ChildOther 클래스가 있다.          Child와 ChildOther은 Parent 클래스를 상속받았다.   Parent parent1 = new Parent(); Parent parent2 = new Child(); Parent parent3 = new ChildOther();  parent1.printName(); parent2.printName(); parent3.printName();   전부 Parent 타입으로 선언하고 각 객체의 printName() 메서드를 호출했다.      위 코드의 결과는 상이하다.   이유는 선언시에는 모두 Parent 타입으로 선언했지만,     실제로 호출된 메서드는 생성자를 사용한 클래스에 있는 것이 호출된다.   “형변환을 하더라도 실제 호출되는 것은 원래 객체에 있는 메서드가 호출된다.”    라는 것이 바로 다형성이고 Polymorphism이다.             자식 클래스에서 할 수 있는 일들   생성자 관련          자식 클래스의 생성자가 호출되면 자동으로 부모 클래스의 매개변수가 없는 기본 생성자가 호출된다.            명시적으로 super()라고 지정할 수도 있다.           변수 관련          부모 클래스에 private로 선언된 변수를 제외한 모든 변수가 자신의 클래스에 선언된 것처럼 사용할 수 있다.            부모 클래스에 선언된 변수와 동일한 이름을 가지는 변수를 선언할 수도 있다.   (그러나 이렇게 덮어쓰는 것은 권장하지 않는다.)            부모 클래스에 선언되어 있지 않는 이름의 변수를 선언할 수 있다.           메서드 관련          변수처럼 부모 클래스에 선언된 메서드들이 자신의 클래스에 선언된 것처럼 사용할 수 있다.            부모 클래스에 선언된 메서드와 동일한 시그니처를 사용함으로써 메서드를 Overriding할 수 있다.            부모 클래스에 선언되어 있지 않은 이름의 새로운 메서드를 선언할 수 있다.               인터페이스와 추상클래스, enum   interface, abstract  자바에서 .class 파일을 만들 수 있는 것에는 클래스에만 있는 것이 아니다.      interface와 abstract 클래스도 있다.       final  상속과 관련해서 알아야 하는 또 하나의 예약어는 final이다.   final은 클래스, 메서드, 변수에 선언할 수 있다.       final 클래스  public final class FinalClass { ... }   클래스가 final로 선언되어 있으면 상속을 해줄 수 없다.       더 이상 확장해서는 안 되는 클래스, 누군가 이 클래스를 상속받아서 내용을 변경해서는 안 되는 클래스를 선언할 때는 final로 선언하면 된다.       final 메서드  public abstract class FinalMethodClass {     public final void printLog(String data) {         System.out.println(\"Data = \" + data);     } }   메서드를 final로 선언하면 더 이상 Overriding할 수 없다.    FinalMethodClass를 상속해도 printLog() 메서드는 override할 수 없다.       final 변수  변수에서 final을 쓰는 것은 좀 다르다.    변수에 final을 사용하면 그 변수는 “더 이상 바꿀 수 없다.”라는 말이다.     그래서 인스턴스 변수나 static으로 선언된 클래스 변수는 선언과 함께 값을 지정해야만 한다.   final int instanceVariable;   위 코드는 컴파일 에러가 발생한다.      final로 선언했기 때문에 변수 생성과 동시에 초기화를 해야만 컴파일시 에러가 발생하지 않는다.     생성자나 메서드에서 초기화하면 되지 않나? 라고 생각할 수도 있겠지만,      그러면 중복되어 변수 값이 선언될 수도 있기 때문에 final의 기본 의도를 벗어난다.       그렇다면 매개변수나 지역변수는 어떨까?   public void method(final int parameter) {     final int localVariable; }   매개변수나 지역변수를 final로 선언하는 경우에는 반드시 선언할 때 초기화할 필요는 없다.    매개변수는 이미 초기화되어 넘어왔고,   지역변수는 메서드를 선언하는 중괄호 내에서만 참조되므로 다른 곳에서 변경할 일이 없다.   그러나 매개변수, 지역변수 초기화 후 다른 값을 할당하려고 하면 컴파일 에러가 발생한다.             참조 자료형 변수   public class FinalReferenceType {     final MemberDTO dto = new MemberDTO(); }  public static void main(Stirng args[]) {     FinalReferenceType referenceType = new FinalReferenceType();     referenceType.checkDTO(); }  public void checkDTO() {     System.out.println(dto);     dto = new MemberDTO(); }   객체를 final로 선언했을 때는 어떻게 처리될까?       dto가 final이기 때문에 값을 할당할 수 없다는 메시지와 함께 에러가 발생한다.      참조 자료형도 두 번 이상 값을 할당하거나 새로 생성자를 사용하여 초기화할 수 없다.   checkDTO() 메서드를 수정해보자.   public void checkDTO() {     System.out.println(dto);     dto.name = \"Hyerin\";     System.out.println(dto); }   메서드를 이렇게 변경한 후 컴파일해 보면 전혀 문제가 없다.   name 값이 “Hyerin”으로 잘 할당되어 있다.   dto 객체, 즉 MemberDTO 클래스의 객체는 FinalReferenceType에서 두 번 이상 생성하 수 없다.               하지만 그 객체의 안에 있는 객체들은 final로 선언된 것이 아니기 때문에 그러한 제약이 없다.             enum  enum 클래스라는 상수의 집합도 있다.    final로 String과 같은 문자열이나 숫자들을 나타내는 기본 자료형의 값을 고정할 수 있다.   이를 “상수(constant)”라고 한다.   어떤 클래스가 상수만으로 만들어져 있을 경우에는 class 선언 부분에 enum이라고 선언하면   이 객체는 상수의 집합이다. 를 명시적으로 나타낸다.   // 선언  public enum OverTimeValues {     THREE_HOUR,     FIVE_HOUR; }  // 사용  OverTimeValues.THREE_HOUR   enum 타입은 enum클래스이름.상수이름을 지정함으로써 클래스의 객체 생성이 완료된다고 생각하면 된다.       enum 클래스는 생성자를 만들 수 있지만 생성자를 통해 객체를 생성할 수는 없다.   public enum OverTimeValues {     THREE_HOUR(18000);          private final int amout;          OverTimeValues(int amout) {         this.amount = amount;     } }   enum 클래스의 생성자는 아무것도 명시하지 않는 package-private과 private만 접근 제어자로 사용할 수 있다.     public이나 protected를 생성자로 사용해서는 안된다.   각 상수를 enum 클래스 내에서 선언할 때에만 이 생성자를 사용할 수 있다.   그렇다면 enum 클래스는 생성자가 없는데 어떻게 이상없이 작동했을까?   enum 클래스도 일반 클래스와 마찬가지로 컴파일할 때 생성자를 자동으로 만들어 준다.             enum 클래스의 부모  enum 클래스의 부모는 무조건 java.lang.Enum 이어야 한다.    자바에서 다중 상속은 허용되지 않지만 일반 클래스들은 상속에 상속을 거쳐서 여러 부모를 가질 수 있다.   하지만 enum 클래스는 무조건 java.lang.Enum 이라는 클래스의 상속을 받는다.   extends java.lang.Enum 이라는 문장을 사용하지는 않지만        컴파일러가 알아서 이 문장을 추가해서 컴파일한다.          그렇기 때문에 enum에 extends하면 안 된다.   Enum 클래스의 생성자는 다음과 같다.   protected Enum(String name, int ordinal)     컴파일러에서 자동으로 호출되도록 해놓은 생성자다.    개발자가 이 생성자를 호출할 수 없다.      name은 enum 상수의 이름이고, ordinal은 enum의 순서이다.    Enum 클래스의 부모 클래스는 Object 클래스이기 때문에 Object 클래스의 메서드들은 모두 사용할 수 있다.    그러나 개발자들이 Object 클래스의 4개 메서드를 오버라이딩하지 못하도록 막아놓았다.             예외      checked exception   error   runtime exception &amp; unchecked exception       Error  에러는 자바 프로그램 밖에서 발생한 예외를 말한다.   Error는 프로세스에 영향을 주고, Exception은 스레드에만 영향을 준다.       런타임 예외  런타임 예외는 예외가 발생할 것을 미리 감지하지 못했을 때 발생한다.   컴파일할 때 예외가 발생하지 않는다. 하지만 실행시에는 발생할 가능성이 있다.   컴파일시 체크하지 않기 때문에 unchecked exception 이라고도 부른다.      Exception을 바로 확장한 클래스들이 Checked 예외이며,   RuntimeException 밑에 확장되어 있는 클래스들이 런타임 예외들이다.              Throwable: java.lang.Throwable  Exception과 Error의 공통 부모 클래스는 당연히 Object 클래스다.           공통 부모 클래스가 하나 더 있는데 java.lang 패키지에 선언된 Throwable 클래스다.   상속 관계가 이렇게 되어 있는 이유는 Exception이나 Error의 성경은 다르지만      모두 동일한 이름의 메서드를 사용하여 처리할 수 있도록 하기 위함이다.       Throwable 생성자     Thowable()   Thowable(String message)   Throwable(String message, Throwable cause)   Throwable(Throwable cause)      message: 예외 메시지  cause: 별도의 예외 원인        Throwable 오버라이딩 메서드  Throwable 클래스에 선언되어 있고 Exception 클래스에서 오버라이딩한 메서드는 10개가 넘는다.    많이 사용되는 메서드를 살펴보자.           getMessage()     예외 메시지를 String 형태로 제공받는다.    메시지를 활용하여 별도의 예외 메시지를 사용자에게 보여주려고 할 때 좋다.                toString() 예외 메시지를 String 형태로 제공받는다.    getMessage() 보다 약간 더 자세하게, 예외 클래스 이름도 같이 제공한다.                printStackTrace()        가장 첫 줄에는 예외 메시지를 출력하고 두 번째 줄부터는        예외가 발생하게 된 메서드들의 호출관계(스택 트레이스)를 출력해준다.           public void throwable() {     int[] intArray = new int[5];          try {         intArray = null;         System.out.println(intArray[5]);     } catch(Throwable t) {         // *      } }   위 * 위치에 위에서 알아본 메서드를 사용해보자.           System.out.println(t.getMessage()); // 출력 : null           System.out.println(t.toString()); // 출력 : java.lang.NullPointerException          System.out.println(t.printStackTrace());     /* 출력 : java.lang.NullPointerException          at c.exception.ThrowableSample.throwable(...)   at c.exception.ThrowableSample.main(...) */             예외를 만들어보자.  Throwable을 직접 상속 받는 클래스는 Exception과 Error가 있다고 했다.        Exception을 처리하는 예외 클래스는 개발자가 임의로 추가해서 만들 수 있다.        Throwable이나 그 자식 클래스의 상속을 받아야 한다.   public class MyException extends Exception {     public MyException() {         super();     }          public MyException(String message) {         super(messaage);     } }   이렇게 만든 예외 클래스는 어떻게 사용할까?   try {     if(number &gt; 12) {         throw new MyException(\"Number is over than 12\");     } catch(MyException e) {         e.printStackTrace();     } }   MyException이 예외 클래스가 되려면 Throwable 클래스의 자식 클래스가 되어야 한다고 했다.    만약 MyException을 선언할 때 관련된 클래스를 확장하지 않았을 때는  이 부분에서 제대로 컴파일이 되지 않는다.                  자바 예외 처리 전략  예외를 처리할 때 표준을 정해두고 진행해야 한다.   (1) 예외가 항상 발생하지 않고, 실행시에 발생할 확률이 매우 높은 경우 런타임 예외로 만드는 것이 나을 수도 있다.  즉, extends RuntimeException 으로 선언하는 것이다.   이렇게 되면, 해당 예외를 던지는 메서드를 사용하더라도 try-catch로 묶지 않아도 컴파일시에 예외가 발생하지 않는다.     그러나 이 경우에는 예외가 발생할 경우 해당 클래스를 호출하는 다른 클래스에서 예외를 처리하도록 구조적인 안전장치가 되어 있어야만 한다.    try-catch로 묶지 않은 메서드를 호출하는 메서드에서 예외를 처리하는 try-catch가 되어 있는 것을 의미한다.   public void methodCaller() {     try {         methodCalled();     } catch(Exception e) {      // 예외처리      } }   public void methodCallee() {     // RuntimeException 예외 발생 가능성이 있는 부분  }   이와 같이 unchecked exception인 RuntimeException이 발생하는 메서드가 있다면    그 메서드를 호출하는 메서드는 try-catch로 묶어주지 않더라도 컴파일할 때 문제가 발생하지는 않는다.       (2) 임의의 예외 클래스를 만들 때에는 반드시 try-catch로 묶어줄 필요가 있을 경우에만 Exception 클래스로 확장한다.  일반적으로 실행시 예외를 처리할 수 있는 경우에는 RuntimeException 클래스를 확장하는 것을 권장한다.       (3) catch문 내에서 아무런 작업 없이 공백으로 놔두면 예외 분석이 어려워지므로 꼭 로그 처리와 같은 예외 처리를 해줘야만 한다.                예외 관련 Q&amp;A          예외를 처리하기 위한 세 가지 블록은?      try/catch/finally                    (1)번 답 중 “예외가 발생하든 안하든 반드시 실행해야 하는 부분”은 어떤 블록인가요?        finally                (1)번 답 중에서 “여기서 예외가 발생할 것이니 조심하세요.”라고 선언하는 블록은 어떤 블록인가요?   try           예외의 종류 세 가지는 각각 무엇인가요?            Error       RuntimeException(unchecked exception)       Checked Exception                     프로세스에 치명적인 영향을 주는 문제가 발생한 것을 무엇이라고 하나요?        Error                try나 catch 블록 내에서 예외를 발생시키는 키워드는 무엇인가요?   throw new Exception                메서드 선언 시 어떤 예외를 던질 수도 있다고 선언할 때 사용하는 키워드?    throws Exception              직접 예외를 만들 때 어떤 클래스의 상속을 받아서 만들어야 하나요?   Throwable이나 Throwable의 자식 클래스              String  public final class String extends Object     public final 로 선언되었다.      public : 누구나 사용할 수 있다.    final : 이 클래스를 확장할 수 없다.        implements Serializable, Comparable&lt;String&gt;, CharSequence           Serializable 인터페이스      구현해야 하는 메서드가 하나도 없는 인터페이스다.     구현한다고 선언만 하면 해당 객체를 파일로 저장하거나 다른 서버에 전송 가능한 상태가 된다.                  Comparable 인터페이스     이 인터페이스는 compareTo()라는 메서드만 선언되어 있다.     이 메서드는 매개변수로 넘어가는 객체와 현재 객체가 같은지를 비교하는데 사용한다.                  CharSequence 인터페이스    이 인터페이스는 해당 클래스가 문자열을 다루기 위한 클래스라는 것을 명시적으로 나타내는 데 사용된다.                  Null 체크  어떤 참조 자료형도 널이 될 수 있다.   객체가 널이라는 것은?     객체가 아무런 초기화가 되어 있지 않음   클래스에 선언되어 있는 어떤 메서드도 사용할 수 없음              비교 equals vs. compareTo  메서드 이름은 다르지만 매개변수로 넘어온 값과 String 객체가 같은지 비교하기 위한 메서드다.    단지 IgnoreCase가 붙은 메서드들은 대소문자 구분을 할지 안할지 여부만 다르다.              immutable String  JDK5 이상은 String 더하기 연산을 할 경우, 컴파일할 때 자동으로 해당 연산을 StringBuilder로 변환해 준다.      따라서 일일이 더하는 작업을 변환해 줄 필요는 없으나 for 루프와 같은 반복 연산을 할 때에는 자동으로 변환해주지 않는다.              CharSequence  String, StringBuilder, StringBuffer 클래스의 공통점은   CharSequence 인터페이스를 구현했다는 점이다.   세 가지 중 하나의 클래스를 사용하여 매개변수로 받는 작업을 할 때    String이나 StringBuilder 타입으로 받는 것보다 CharSequence 타입으로 받는 것이 좋다.              클래스 안의 클래스  자바에서 클래스 안에 클래스가 들어갈 수 있다.   이러한 클래스를 Nested 클래스라고 부른다.   Nested 클래스는 선언한 방법에 따라 static nested class와 inner class로 구분된다.      차이는 static으로 선언되었는지 여부다.   inner class는 또 두가지로 나뉘는데 로컬(지역) 내부 클래스, 익명 내부 클래스라고 부른다.               왜 Nested 클래스를 만드는 걸까?          한 곳에서만 사용되는 클래스를 논리적으로 묶어서 처리할 필요가 있을 때 &gt; Static Nested 사용 이유       캡슐화가 필요할 때 &gt; inner class 사용 이유            A 클래스에 private 변수가 있다. 이 변수에 접근하고 싶은 B라는 클래스를 선언하고   B 클래스를 외부에 노출시키고 싶지 않을 경우  즉 내부 구현을 감추고 싶을 때를 의미한다.            소스의 가독성과 유지보수성을 높이고 싶을 때             static nested  내부 클래스는 감싸고 있는 외부 클래스의 어떤 변수도 접근할 수 있다.     private로 선언된 변수까지도 접근 가능하다.    하지만 static nested 클래스를 그렇게 사용하는 것은 불가능하다.   이름에서 알 수 있듯이 static 하기 때문이다.   public class OuterOfStatic {    // (1)     static class StaticNested{  // (2)         private int value = 0;         // getter, setter     } }   이 클래스를 컴파일해 보자.    내부에 있는 Nested 클래스는 별도로 컴파일할 필요가 없다. 자동으로 컴파일된다.       그러면 이 static nested 클래스의 객체는 어떻게 생성할까?   OuterOfStatic.StaticNested staticNested = new OuterOfStatic.StaticNested();   감싸고 있는 클래스 이름 뒤에 .(점)을 찍고 쓰면 된다.    객체 사용 방법은 일반 클래스와 동일하다.       그렇다면 왜 static nested 클래스를 만들까?  클래스를 묶기 위해서다.   School 클래스: 학교 관리 클래스   University 클래스: 대학교 관리 클래스    Student 클래스: School 학생이지 University 학생인지 불분명하다.       이렇게 겉으로 보기에 유사하지만 내부적으로 구현이 달라야 할 때 static nested 클래스를 사용한다.        static nested 클래스로 만드면 School에서 만든 경우, University 클래스에서는 사용할 수 없다.              내부 클래스  public class OuterOfInner {     class Inner {         private int value = 0;         // getter, setter     } }   static 선언이 없다.   그러므로 이 Inner 클래스의 객체를 생성하는 방법도 다르다.   OuterOfInner outer = new OuterOfInner(); OuterOfInner.Inner inner = outer.newInner();   Inner 클래스의 객체를 생성하기 전에는 먼저 Inner 클래스를 감싸고 있는 Outer 클래스의 객체를 만들어야만 한다.    outer 객체를 통해서 Inner 클래스의 객체를 만들어 낼 수 있다.       이와 같이 복잡한 Inner 클래스 객체를 왜 사용하는걸까?  앞에서 이러한 내부 클래스를 만드는 이유를 캡슐화 때문이라고 했다.    하나의 클래스에서 어떤 공통적인 작업을 수행하는 클래스가 필요한데 다른 클래스에서는 전혀 필요가 없을 때   이러한 내부 클래스를 만들어 사용한다.             익명 클래스  내부 클래스를 만드는 것보다도 더 간단한 방법은 익명 클래스를 만드는 것이다.   말 그대로 이름이 없는 클래스다.   public class Machine {     Remocon tv = new Remocon() {         @Override         public void on() { . . . }     }; }  Machine machine = new Machine(); machine.tv.on();   클래스 이름도 없고 객체 이름도 없기 때문에 다른 클래스나 메서드에서 참조할 수 없다.      그래서 객체를 해당 클래스 내에서 재사용하려면, 객체 생성 후 사용하면 된다.      (그러나 재사용할 일이 없을 때 사용하도록 하자.)       왜 익명 클래스라는 것을 제공하는 것일까?  클래스를 만들고 그 클래스를 호출하면 그 정보는 메모리에 올라간다.    즉 클래스를 많이 만들면 만들수록 메모리를 많이 필요해지고 애플리케이션을 시작할 때 더 많은 시간이 소요된다.    따라서 이렇게 간단한 방법으로 객체를 생성할 수 있도록 해놓았다.             내부 클래스 특징  Nested 클래스를 사용하려면 알고 있어야 하는 사항은 참조 가능한 변수들이다.      static nested 클래스에서 외부 클래스의 static 변수만 참조할 수 있다.     만약 참조하는 코드가 있다면 컴파일시에 에러가 발생하므로 어떻게라도 사용할 수 없다.       내부 클래스와 익명 클래스는 외부 클래스의 어떤 변수라도 참조할 수 있다.       그렇다면 반대로 외부 클래스에서 static nested 클래스의 인스턴스 변수나       내부 클래스의 인스턴스 변수로서의 접근하는 것은 가능할까?         반대로의 참조도 가능하다. private라고 해도 접근할 수 있다.              어노테이션이란?  어노테이션은 클래스나 메서드 등의 선언시에 @를 사용하는 것을 의미한다.      컴파일 정보를 알려주거나   컴파일할 때와 설치(deployment)시 작업을 지정하거나   실행할 때 별도의 처리가 필요할 때       자바에서 사용하기 위해서 정해져 있는 어노테이션은 3개           @Override             해당 메서드가 부모 클래스에 있는 메서드를 오버라이드 했다는 것을 명시적으로 선언                @Deprecated       미리 만들어져 있는 클래스나 메서드가 더 이상 사용되지 않는 경우    그런 것을 deprecated라고 하는데 컴파일러에게 “사용하지 않으니 누가 쓴다면 경고해달라.”라고 알려주는 것이다.               @SupressWarnings          컴파일에서 경고를 알리는 경우가 있다.    일부러 이렇게 코딩했으니 경고해줄 필요가 없다고 알려주는 것이다.           메타 어노테이션이라는 것은 개발자가 어노테이션을 선언할 때 사용한다.     @Target   @Retention   @Documented   @Inherited       어노테이션 선언 방법  추가로 알아야 하는 어노테이션은 @interface 이다.   @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface UserAnnotation {     public int numer();     public String text() default \"This is first annotation\"; }       상속을 지원하지 않는다.  자바의 상속은 많은 이점을 제공한다.                  enum 클래스와 마찬가지로 미리 만들어 놓은 어노테이션을 확장하는 것이 불가능하다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2021-07-17/%EC%9E%90%EB%B0%94%EC%9D%98%EC%8B%A0(1)/",
        "teaser": null
      },{
        "title": "자바를 제대로 사용할 수 있는 방법",
        "excerpt":"    자바의 역사와 JVM          JDK (Java Development Kit)      JDK 자바 개발 도구, JVM용 소프트웨어 개발 도구                             Java SE (Java Standard Edition)            자바의 표준안이다.   자바라는 언어가 어떠한 문법적인 구성을 가졌는지와 같은 것들을 정의                   JRE (Java Runtime Environment)    JRE는 실행만을 위한 환경이다. (JVM용 OS)          JRE만 설치하면, 컴파일하는 프로그램이 제외된 상태로 설치된다.                    JVM (Java Virtual Machine)          자바 프로그램이 수행되는 프로세스를 의미한다.       java 명령어로 애플리케이션이 수행되면 이 JVM 위에서 애플리케이션이 동작한다.                   JIT 컴파일러는 도대체 뭘까?  동적 변환(dynamic translation)이라고 보면 된다.    명칭은 컴파일러지만 실행시에 적용되는 기술이다.          인터프리트 방식: 프로그램을 실행할 때마다 컴퓨터가 알아들을 수 있는 언어로 변환하는 작업 수행   정적 컴파일 방식: 실행하기 전에 변환 작업을 딱 한 번만 수행한다.       JIT은 위 두 가지 방식을 혼합한 것이라고 보면 된다.    변환 작업은 인터프리터에 의해서 지속적으로 수행되지만, 필요한 코드의 정보는 캐시에 담아두었다가 재사용한다.        분명히 javac 명령어로 컴파일 했는데 그럼 정적 컴파일 방식 아닌가?   javac 명령어로 컴파일 하는 단계에서 만들어진 .class 파일은 바이트 코드일 뿐이다.     이렇게 한 번 컴파일한 코드는 어느 OS에서나 사용할 수 있다.    즉 class 파일은 컴퓨터가 알아들을 수 있도록 기계 코드로 다시 변환 작업이 필요하다는 것이다.    이 변환 작업을 JIT 컴파일러에서 한다고 보면 된다.              HotSpot은 뭘까?  Sun에서 개발한 JVM 이름이다.   HotSpot 종류          HotSpot 클라이언트 컴파일러     애플리케이션 시작 빠르게, 적은 메모리를 점유하기 위함            HotSpot 서버 컴파일러     애플리케이션 수행 속도에 초점을 맞춤                    실수를 방지할 수 있도록 도와주는 제네릭  자바는 여러 타입이 존재하기 때문에 형변환을 하면서 많은 예외가 발생할 수 있다.           DTO 클래스   public class CastingDTO implements Serializable {     private Object object;          // Setter, Getter }          CastingDTO 사용   CastingDTO dto1 = new CastingDTO(); dto1.setObject(new String());  CastingDTO dto2 = new CastingDTO(); dto2.setObject(new StringBuilder());  CastingDTO dto3 = new CastingDTO(); dto3.setObject(new StringBuffer());   위 코드는 컴파일과 문제 없이 실행된다.    그런데 저장되어 있는 값을 꺼낼 때 문제가 발생한다.   getObject() 메서드 리턴 타입이 Object이기 때문이다.        다음과 같은 형변환이 필요하다.  String temp = (String)dto1.getObject();       그런데 인스턴스 변수 타입이 StringBuilder인지 StringBuffer인지 혼동될 경우 어떻게 될까?   instanceof 예약어를 사용하여 타입을 점검하면 된다.  if(temp instanceof StringBuilder)   이러한 단점을 보완하기 위해서 Java 5 부터 새롭게 추가된 제네릭(Generic)이라는 것이 있다.             제네릭은 뭘까?  제네릭은 타입 형변환에서 발생할 수 있는 문제점을 사전에 없애기 위해서 만들어졌다.    컴파일할 때 점검한다는 의미다.           Generic DTO 클래스   public class CastingGenericDTO&lt;T&gt; implements Serializable {     private T object;          // Setter, Getter }          Generic 클래스 사용   CastingGenericDTO&lt;String&gt; dto = new CastingGenericDTO&lt;&gt;();   객체를 선언할 때 꺽쇠 안에 각 타입을 명시해 줘서 귀찮을 것 같지만    getObject() 메서드를 사용하여 객체를 가져올 때는 간단해진다.   String temp = dto.getObject();   형변환할 필요가 없어졌다.       만약 잘못된 타입으로 치환하면 컴파일 자체가 안 된다.      따라서 실행 시에 형변환으로 인해 예외가 발생하는 일은 없다.               제네릭을 사용하는 이유  (1) 컴파일할 때 타입을 체크해서 에러를 사전에 잡을 수 있다.   (2) 컴파일러가 타입 캐스팅을 해주기 때문에 개발자가 편리하다.   (3) 타입만 다르고 코드의 내용이 대부분 일치할 때 코드의 재사용성이 좋아진다.               Java 8     Lambda(람다) 표현식   Functional(함수형) 인터페이스   Stream   Optional   인터페이스의 기본 메서드   날짜 관련 클래스 추가   병렬 배열 정렬   StringJoiner 추가             Java8: Optional  optional이라는 단어는 “선택적인”이라는 의미다.                 Optional은 Functional 언어인 Haskell과 Scala에서 제공하는 기능을 따 온 것이다.                 객체를 편리하게 처리하기 위해서 만든 클래스라고 보면 된다.   Optional 클래스는 java.util 패키지에 속해 있다.   public final class Optional&lt;T&gt; extends Object   Optional 클래스는 깡통이라고 생각하면 된다.    이 깡통에 물건을 넣을 수도 있고, 아무 물건이 없을 수도 있다.    그래서 기본적인 깡통으로 만들기 위해서 Optional 클래스는 new Optional()과 같이 객체를 생성하지 않는다.           Optional 객체 생성  API 문서를 잘 살펴보면 Optional 클래스를 리턴하는        empty(), of(), ofNullable() 메서드들이 존재한다.              (1) Optional.empty()     null이 아닌 객체를 담고 있는 Optional 객체를 생성한다.    이 비어있는 객체는 Optional 내부적으로 미리 생성해놓은 싱글톤 인스턴스입니다.          (2) Optional.of(value)     null이 아닌 객체를 담고 있는 Optional 객체를 생성한다.       null이 넘어올 경우 NullPointerException을 던지기 때문에 주의해서 사용해야 한다.        (3) Optional.ofNullable(value)      null인지 아닌지 확신할 수 없는 객체를 담고 있는 Optional 객체를 생성한다.       null이 넘어올 경우 NPE를 던지지 않고 Optional.empty()와 동일하게     비어있는 Optional 객체를 얻어옵니다.             객체 꺼내기  Optional이 담고 있는 객체를 꺼내로기 위해서 다양한 인스턴스 메서드를 제공한다.       (1) get()   비어있는 Optional 객체에 대해서 NoSuchElementException을 던진다.       (2) orElse(T other)   비어있는 Optional 객체에 대해서 넘어온 인자를 반환한다.       (3) orElseGet(Supplier&lt;? extends T&gt; other)    비어있는 Optional 객체에 대해서 넘어온 함수형 인자를 통해 생성된 객체를 반환한다.     orElse(T other)의 게으른 버전이다.      비어있는 경우에만 함수가 호출되기 때문에   orElse(T other) 대비 성능상 이점을 기대할 수 있다.         (4) orElseThrow(Supplier&lt;? extends T&gt; exceptionSupplier)    비어있는 Optional 객체에 대해서 넘어온 함수형 인자를 통해 생성된 예외를 던집니다.           Java8: Default method  Java8부터는 default 메서드가 추가되었다.   public interface DefaultStaticInterface {     default String getEmail() {         return name + \"@gmail.com\";     }  }   위 코드는 Java8에서 컴파일이 잘 된다.    DefaultStaticInterface를 구현하고 getName() 메서드를 재정의하면?    이 경우도 괜찮다.   그렇다면 default 메서드를 왜 만들었을까?      “하위 호환성” 때문이다.   예를들어, 오픈소스를 만들었다고 가정하자.      많은 사람들이 사용하고 있는데 인터페이스에 새로운 메서드를 만들어야 하는 상황이 발생했다.      자칫 잘못하면 오류가 발생하고 수정해야 하는 일이 발생할 수도 있다.      이럴 때 사용하는 것이 default 메서드다.           Java8: 병렬 배열 정렬 (Parallel array sorting)  배열을 정렬하는 가장 간편한 방법은 java.util 패키지의 Arrays 클래스를 사용하는 것이다.    이 Arrays 클래스에는 다음과 같은 static 메서드들이 존재한다.      binarySearch()   copyof()   equals()   fill()   hashCode()   sort()   toString()       Java8 에서는 paralleleSort()라는 정렬 메섬드가 제공되며    Java7 에서 소개된 Fork-Join 프레임워크가 내부적으로 사용된다.   사용법은 다음과 같다.   int[] intValues = new int[10]; Arrays.parallelSort(intValues);   sort()의 경우 단일 스레드로 수행되며,       parallelSort()는 필요에 따라 여러개의 스레드로 나뉘어 작업이 수행된다.   parallelSort()가 CPU를 더 많이 사용하게 되겠지만 처리 속도는 더 빠르다.            Java8: StringJoiner  StringJoiner은 java.util에 포함되어 있으며   순차적으로 나열되는 문자열을 처리할 떄 사용한다.   String[] stringsArray = new String[]{\"A\", \"B\", \"C\"};   위 배열을 (A, B, C) 이렇게 변환하고 싶으면 어떻게 해야 할까?   콤마(,) 처리를 위해 if문을 넣거나 substring을 사용해야 하는데   이러한 단점을 보완하기 위해 StringJoiner가 만들어졌다.         StringJoiner joiner = new StringJoiner(\",\");  for(Stirng s : stringArray) {     joiner.add(s);    }  System.out.println(joiner);                 Java8: Lambda 표현식  익명 클래스를 사용하면 가독성도 떨어지고 불편한데    이러한 단점을 보완하기 위해 람다 표현식이 만들어졌다.   대신 이 표현식은 인터페이스에 메서드가 하나인 것들만 적용 가능하다.   그래서 익명 클래스 &lt;-&gt; 람다 표현식 전환이 가능하다.                 Java8: Stream  자바의 스트림은 “연속된 정보”를 처리하는 데 사용한다.        자바에 연속된 정보로 배열, 컬렉션이 있다.     배열에는 스트림을 사용할 수 없지만 List로 변환하는 방법은 다양하다.      Integer[] values = {1, 3, 5};  // (1) List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(Arrays.asList(values));  // (2) List&lt;Integer&gt; list = Arrays.stream(values).collect(Collectors.toList());       스트림 구조  list.stram().filter(x -&gt; x &gt; 10).count()      stream() : 스트림 생성   filter() : 중개 연산   count() : 종단 연산      메서드 참조  forEach()를 사용해 목록을 출력해보자.   forEach(System.out::println)   :: 이 더블 콜론은 정확하게 Method Reference 라고 부른다.   즉 메서드 참조를 의미한다.               static 메서드 참조     ContainingClass::staticMethodName                    특정 객체의 인스턴스 메서드 참조    containingObject::instanceMethodName                 특정 유형의 임의의 객체에 대한 인스턴스 메서드 참조   ContainingType::methodName                생성자 참조 ClassName::new           stream map()  map()은 스트림 값을 변환한다.   list.stream.map(x -&gt; x*3).forEach(System.out::println)   이렇게 map()을 사용하면 스트림에서 처리하는 값들을 중간에 변경할 수 있다.      ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2021-07-17/%EC%9E%90%EB%B0%94%EC%9D%98%EC%8B%A0(2)/",
        "teaser": null
      },{
        "title": "OAuth 2.0 란?",
        "excerpt":"    OAuth 2.0  OAuth 2.0은 자신이 소유한 리소스에 소프트웨어 애플리케이션이 접근할 수 있도록 허용해줌으로써 접근 권한을 위임해주는 프로토콜이다.         토큰을 이용해 애플리케이션이 해당 리소스에 접근할 수 있습니다.                  리소스 소유자   일반적으로 리소스 소유자는 서비스 사용자, 웹 브라우저를 이용한다고 가정                 보호된 리소스 리소스 소유자가 접근하는 구성 요소이다.      대부분 웹 API의 형태를 띤다. API를 통해 읽고 쓰는 작업                클라이언트   리소스 소유자 대신 보호된 리소스에 접근하는 소프트웨어 요소                          인가 그랜트 절차  이전에도 OAuth 2.0 인가 그랜트 절차에 대해 학습한 적이 있는데   페이코 개발자 센터 이미지를 참고하여 다시 기억해보자.     참고: https://developers.payco.com/guide/development/start               과거의 자격 증명 공유 (와 자격 증명 탈취)  기업 환경에서 많이 사용되는 한 가지 방법은 사용자의 자격 증명을 복사해 연결하고자 하는 다른 서비스에 전달하는 것이다.   이 경우 클라이언트가 마치 사용자인 것처럼 사용자가 입력한 id/password를 보호된 리소스에 전달한다.   위 방법이 가능하기 위해서는 클라이언트 애플리케이션과 보호된 리소스에 대한     사용자의 자격 증명이 동일해야 하며 다음과 같은 문제점이 생긴다.      자격 증명 탈취에 대한 보안성이 제한         ex) 하나의 기업이 동일한 정책과 네트워크 통제 안에서 클라이언트와 인가 서버, 보호된 리소스를 운영하면      사용자는 그 기업의 여러 서비스에 대해 동일한 자격 증명을 이용할 수 있다.        사용자의 비밀번호가 클라이언트 애플리케이션에 노출         보호된 리소스 입장에서 자신에게 접근하는 것이 실제 리소스 소유자인지 클라이언트인지 구분할 수 없다.              OAuth 2.0 장단점  장점          사용자의 권한 위임 결정은 캡처하고 네트워크상에 표현하는 데 매우 뛰어나다.            보안 결정 절차에 여러 당사자가 참여할 수 있으며, 특히 런타임 시 사용자가 보안 결정을 한다.            유사한 프로토콜에 비해 훨씬 간단하고 안전하다.            클라이언트 개발자가 이전의 보안 프로토콜처럼 더 이상 시그니처 정규화나 복잡한 보안 정책 문서를 분석하지 않아도 된다.            OAuth 토큰을 제대로 사용하면 보다 향상된 보안성을 제공한다.            만약 어떤 클라이언트가 침해된다면, 피해는 해당 클라이언트의 사용자로 국한된다.    클라이언트가 침해되더라도 리소스 소유자의 자격 증명 데이터는 유출되지 않는다.            독립적인 개발자가 수천 개의 클라이언트를 안전하게 관리하는 것보다 하나의 인가 서버를 안전하게 관리하는 편이 훨씬 쉽다.            OAuth 2.0의 확장성과 모듈화 &gt; 다양한 환경에서도 적용해 사용할 수 있다.             단점          유연성으로 OAuth 구현체 간의 기본적인 호환성에 문제가 발생할 수 있다.            OAuth의 스펙에는 많은 부분을 선택 사항으로 기술하고 있기 때문에   두 시스템 간에 OAuth를 구현하고자 하는 개발자들을 혼란스럽게 만들 수 있다.            선택 사항 중 일부를 잘못 이해하거나 적절히 수행하지 않으면 안전하지 않은 OAuth 구현이 될 수 있다.                OAuth 2.0이 아닌 것  OAuth가 널리 쓰임에도 실제로 보면 OAuth가 아닌 것이 많다.     프로토콜을 이해함에 있어서 차이점이 무엇인지 이해하는 것도 중요하다.               OAuth는 HTTP 프로토콜과 독집적으로 정의되지 않는다.    OAuth 2.0 토큰은 메시지 시그니처를 제공하지 않기 때문에 HTTPS를 이용해야 한다.            OAuth는 인증 프로토콜이 아니다.    OAuth 트랜잭션 자체만으로 사용자가 누구인지 알 수 없다.   또한, OAuth는 여러 곳에서 인증을 사용한다.   그렇다고 해서 내제된 인증 자체만으로 OAuth가 인증 프로토콜이 되지는 않는다.            사용자 간의 권한 위임 메커니즘은 정의하지 않는다.   리소스 소유자가 다른 사람을 인가할 수 있게 하려면 OAuth만으로는 힘들다.            OAuth는 인가 절차 메커니즘을 정의하지 않는다.    권한 위임이 이뤄졌다는 사실을 전달하는 방법을 제공하지만, 권한 인가 자체의 내용을 정의하는 것은 아니다.            OAuth는 토큰의 포맷을 정의하지 않는다.    OAuth 프로토콜은 토큰의 내용이 클라이언트 애플리케이션에게 완전히 불투명하다고 명확히 기술하고 있다.            OAuth 2.0은 1.0과 달리 암호화 방법을 정의하지 않는다.            OAuth 2.0은 단일 프로토콜이 아니다.     OAuth 스펙은 사용 방법이 각기 다른 여러 가지 정의와 흐름으로 나뉜다.           참고 33p - 56p            클라이언트에 대한 CSRF 공격  인가 코드 그랜트 타입과 암시적 그랜트 타입에서 상태(state) 파라미터 사용을 권장하고 있다.    클라이언트가 요청과 콜백 사이의 상태를 유지하기 위해 사용하는 구조가 정해지지 않은 값으로서   인가 서버는 유저에이전트를 클라이언트로 다시 리다이렉트 시킬 때 이 값을 전달한다.   CSRF(Cross-Site Request Forgery) 공격을 방지하기 위해 이 값을 사용해야 한다.   CSRF란 악의적인 애플리케이션이 현재 사용자가 인증된 웹 사이트로     사용자의 웹 브라우저가 요청을 보내게 함으로써 원하지 않는 작업이 이뤄지도록 만드는 것이다.       웹 브라우저가 요청을 만들고(쿠키를 이용해) 그로 인해 특정 작업이 수행된다는 것이다.   CSRF 공격을 막기 위한 가장 일반적이고 효과적인 방법은 각각의 HTTP 요청에 예측할 수 없는 값을 추가하는 것이다.    이는 OAuth 스펙에서도 설명하는 방법이다.       참고 195p            OAuth 토큰이 무엇인가?  클라이언트는 인가 서버로부터 토큰을 발급받아 보호된 리소스에 전달한다.    인가 서버는 토큰을 생성해 클라이언트에게 발급하고,   토큰을 리소스 소유자의 권한 위임과 클라이언트의 권한과 연결시켜 관리한다.  보호된 리소스는 클라이언트로부터 전달받은 토큰이 클라이언트가 요청한 작업을 수행할 수 있는 권한이 있는지 확인한다. 토큰은 권한 위임 행위 결과를 나타낸다.   이렇게 중요한데 OAuth에서 토큰에 대한 언급이 전혀 없다.   왜 구체적으로 정의하지 않을까?    토큰을 구체적으로 정의하지 않는 이유는 OAuth 특성이나 위험 환경 그리고 요구 사항이 각기 다른 다양한 곳에서 적용해 사용할 수 있기 때문이다.   토큰의 유효 기간이 만료되거나 폐기될 수 있고, 무기한으로 지정해 사용하거나 다양한 조랍으로 사용할 수 있다.   또한 시스템의 특정 사용자나 모든 사용자를 나타내거나 아무런 사용자도 나타내지 않을 수 있다.       참고 278p            구조화된 토큰: JSON Web Token  공유해 사용하는 데이터베이스에서 토큰을 찾는 것 대신 토큰 안에 필요한 정보를 담아 만들면 어떨까?      그렇게 하면 인가 서버는 어떤 네트워크 API 호출 없이 도큰 자체 만으로 보호된 리소스와 간접적으로 통신할 수 있게 된다.   인가 서버가 JWT를 지원하도록 수정한다고 가정해보자.      토큰의 구조가 이전과 달라졌는데도 클라이언트 코드는 수정할 필요가 없다.     이는 클라이언트에게 있어서 토큰의 구조는 명확하지 않다는 OAuth 2.0의 중요한 스펙 덕분이라고 할 수 있다.           참고 279p            OAuth 2.0이 인증 프로토콜이 아닌 이유  먼저, 인증이란 무엇인가?    인증은 현재 사용자가 누구인지 그리고 현재 사용자가 애플리케이션을 사용하고 있는지 여부를 애플리케이션에게 알려주는 것이다.   일반적으로 자격 증명(id/password 같은)을 애플리케이션에 제공함으로써   사용자가 현재 주장하는 자신임을 알리는 보안 아키텍처의 일부분이라고 할 수 있다.   하지만 OAuth 2.0은 자체적으로 사용자에게 어떤 것도 알려주지 않을 뿐만 아니라   사용자가 자신의 존재를 어떻게 증명했는지 또는 존재했는지에 대해서도 알려주지 않는다.   토큰을 요청하고 획득, 그 토큰을 이용해 API에 접근하지만   누가 해당 클라이언트를 인가했는지 또는 인가되는 과정에 사용자가 있었는지는 전혀 알지 못한다.   클라이언트에게 권한을 인가하기 위한 강력한 패러다임이지만     사용자가 현재 있고, 누군지를 알아내는 인증과는 상반된다고 할 수 있다.         참고 354p            인증(Authentication) vs. 인가(Authorization)  둘은 표면적으로는 유사하지만 기본적인 성격은 분명히 다르다.           인증(Authentication)     클라이언트가 자신이 주장하는 사용자와 같은 사용자인지를 확인하는 과정    ex) 방문자가 자신이 회사 건물에 들어 갈 수있는지 확인 받는 과정이다.            인가(Authorization)        권한부여, 클라이언트가 하고자 하는 작업이 해당 클라이언트에게 허가된 작업인지를 확인  ex) 방문자가 회사 건물에 방문했을 때, 허가된 공간에만 접근 가능하다.           인증을 거친 후 인증된 사용자에 대한 특정한 권한을 부여 한다.            이 게시글은 OAuth2 In Action 를 참고하여 작성되었습니다.😇      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-07-23/OAuth2/",
        "teaser": null
      },{
        "title": "모놀리틱 서비스 vs. 마이크로 서비스",
        "excerpt":"           모놀리틱 아키텍처 (Monolithic Architecture)  모놀리틱 아키텍처는 비즈니스 로직, DB, UI 등을 하나의 패키지에 담아 빌드하고 배포하는 아키텍처다.   빠르고 쉽게 서비스를 구성할 수 있어 적은 비용으로 서비스 출시가 가능하다는 장점이 있다.        모놀리틱 아키텍처의 한계  코드가 많아지고 복잡해짐에 따라 모놀리틱의 아키텍처의 한계점이 드러난다.      부분장애가 전체 서비스의 장애로 확대될 수 있다.   소스 코드의 수정이 어렵다.     여러 컴포넌트가 하나의 서비스에 강하게 결합되어 있기 때문에 서비스 수정에 대한 영향도 파악이 어렵다.   한 프레임워크와 언어에 종속적이다.   부분적인 Scale-out이 어렵다.   과하게 사용되지 않는 다른 모든 서비스가 Scale-out되어야 하기때문에 Scale-out이 어렵다.       새로운 아키텍처의 필요성     코드 주소의 독립성   기능별 분산된 구조   기능별 최적화도니 기술 적용 가능           마이크로 서비스 아키텍처 (Microservices Architecture)  마이크로 서비스 아키텍처는 하나의 큰 애플리케이션을   여러 개의 작은 애플리케이션으로 쪼개어 변경과 조합이 가능하도록 만든 아키텍처다.   애플리케이션을 핵심기능 별로 세분화하고 각 기능을 서비스라고 부르며,   독립적으로 구축하고 배포할 수 있다.   서비스는 각 별도의 프로세스에서 실행되며, HTTP 자원 API 같은 가벼운 매커니즘으로 통신한다.   💡   독립적인 배포, 다른 프로그래밍 언어나 다른 DB 사용 가능       MSA는 언제 적용할까?  MSA는 어느정도 트래픽이 나오고 큰 규모의 서비스에 사용해야 한다.   어느 정도 규모가 있어야 유지보수 비용이 줄어들기 때문에 모든 프로젝트에 MSA가 적합하다고 할 수 없다.       장점     부하가 집중되는 특정 서비스를 자원을 할당해 스케일 아웃할 수 있어 효율적인 자원 사용이 가능하다.   서비스의 변경이 다른 서비스에 영향을 미칠 가능성이 적다.   서비스 단위로 독립적인 배포가 가능하다.   시스템의 아키텍처가 개발 조직과 나아가 회사 조직 문화에 큰 영향을 미치는데,            특정 서비스의 개선과 수정 작업이 다른 서비스의 이해 당사자들과 독립적으로 진행될 수 있다.       의사결정이 빠르고, 독립적인 테스트의 구축이 용이해 품질이 증가한다.               단점     서비스 간의 통신에 대한 처리가 추가적으로 필요하다.   공유 자원 접근이 어렵다.   배포와 실행이 복잡하다.       MSA의 원칙          서비스 하나에 책임도 하나     하나의 단위 요소가 여러 개의 책임을 가지면 결국 다른 요소들과 높은 결합도를 형성하게 됩니다.   이러한 단일 책임 원칙이 서비스 차원에도 적용해야 한다는 것입니다.               마이크로서비스는 자율적      마이크로서비스는 자기 완비적으로 독립적으로 배포할 수 있으며,     자율적인 서비스로서 비즈니스의 범위와 실행에 대해 전적인 책임을 져야합니다.     마이크로서비스는 라이브러리 의존성을 포함한 모든 의존 관계와     웹서버나 컨테이너 또는 물리적인 차원을 추상화하는 가상머신을 모두 함께 갖고 있어야합니다.     대표적인 예로 Spring Boot의 flatJar 방식, 내장형 서버가 있습니다.                  MSA에 필요한 기술     REST 각 서비스들은 대체로 REST API와 같이 가벼운 프로토콜을 이용하여 통신한다.            API Gateway  각 서비스들이 서로를 직접 호출하는 것이 아니라, API Gateway를 거쳐 통신하도록 한다.     API Gateway는 부하를 분산시키는 로드 밸런싱, 캐싱, API 미터링, 모니터링 등 다양한 기능을 수행한다.        VM/Docker(K8s)    각 서비스들은 편리한 배포 및 확장을 위하여 가상 머신이나 Docker 컨테이너 상에서 동작한다.       위 기술은 다른 포스트에서 자세하게 알아보자.             참고     쿠팡 테크 블로그   nginx microservices   guruble 블로그   이동욱님 개발 블로그: soa/모놀리틱/msa 아키텍처      ","categories": ["Architecture"],
        "tags": ["architecture"],
        "url": "/2021-07-23/msa/",
        "teaser": null
      },{
        "title": "HTTP API vs. RESTful API",
        "excerpt":"   API, REST, REST API, RESTful API, HTTP, URL, URI, URN…        개발하면서 많은 키워드들을 보게 되는데 정확히 어떤 의미인지 정리해보자.        API  예)  나 - 리모컨 - 에어컨 손님 - 점원 - 요리사    여기서 API는 리모컨과 점원이라고 할 수 있다.       API는 응용 프로그램(애플리케이션)에서 운영체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 있게 만든 인터페이스를 의미한다.    즉 API는 애플리케이션과 운영체제, 애플리케이션과 프로그래밍 언어가 제공하는 기능 사이의 상호작용을 도와준다.           REST (Representational State Transfer)  REST는 자원을 이름으로 구분, 해당 자원의 상태를 주고 받는 것을 의미한다.      http uri를 통해 자원을 명시한다.   http method를 통해 해당 자원에 대한 CURD 연상을 적용하는 것을 의미한다.       REST 구성 요소     자원(resource): HTTP URI   자원에 대한 행위: HTTP Method   자원에 대한 행위의 내용: HTTP Message Pay Load       REST 특징     server-client 구조   stateless (무상태)   cacheable (캐시 처리 기능)   Layered system (계층화)   uniform interface (인터페이스 일관성)              REST API  REST의 원리를 따르는 API를 의미한다.   리소스에 대한 행위를 http method로 정의하는 방식이다.            http://hyerin.com/run 명사 사용, 마지막에 슬래시(/) ❌   http://hyerin.com/test-blog 언더바(_) ❌, 하이픈(-) 🆗   http://hyerin.com/photo.png ➡️ /photo 파일 확장자는 URI에 포함되지 않는다.   http://hyerin.com/post/1 행위를 포함하지 않는다.            RESTful API  REST API 설계 가이드를 따라 API를 만드는 것이다.    RESTful API 자체만으로 API의 목적이 무엇인지 쉽게 알 수 있다.          HTTP  하이퍼텍스트(html) 문서를 교환하기 위해 만들어진 프로토콜이다.    윕상에서 네트워크로 서버끼리 통신할 때 어떠한 형식으로 서로 통신하자고 규정해 놓은 통신구조라고 보면 된다.       비연결성 (Connectionless)  비연결성은 클라이언트와 서버가 한 번 연결을 맺은 후,   클라이언트 요청에 대해 서버가 응답을 마치면 연결을 끊어버리는 성징을 말한다.   http 프로토콜은 왜 한 번 맺은 연결을 끊을까?  http는 인터넷 상에서 불특정 다수의 통신 환경을 기반으로 설계되었다.    만약 서버에서 다수의 클라이언트와 연결을 계속 유지해야 한다면 많은 리소스가 발생한다.       장점) 연결을 유지하기 위한 리소스를 줄이면 더 많은 연결을 할 수 있으므로 비연결적인 특징을 갖고 있다.   단점) 그러나 서버는 클라이언트를 기억하고 있지 않으므로 동일한 클라이언트의 모든 요청에 대해   매번 새로운 연결을 연결/해제 해야 하므로 오버헤드가 발생한다.      keepAlive  오버헤드에 대한 해결책으로 http의 keepAlive 속성을 사용할 수 있다.    keepAlive는 지정된 시간동안 서버와 클라이언트 사이에서 패킷 교환이 없을 경우,    상대방에게 안부를 묻기 위해 패킷을 주기적으로 보내는데 패킷에 반응이 없으면 접속을 끊는다.      그러나 keepAlive 속성이 완벽한 해결책은 아니다.   keepAlive 상태로 유지하기 위해 메모리를 많이 사용하게 되므로 주의해야 한다.                   무상태 (Stateless)  Connectionless로 인해 서버는 클라이언트를 식별할 수 없다. 이를 Stateless라고 한다.   클라이언트의 상태를 모른다는 것은 요청이 오면 그에 따른 응답을 할 뿐   각각의 요청과 응답은 독립적이며, 어떤 상태를 저장하지 않는다는 의미다.       쇼핑몰에서 옷을 구매하기 위해 로그인 했다.      로그아웃하기 전까지 '로그인'이라는 상태가 계속 유지되는 것처럼 보이지만      로그인 상태는 유지되지 않는다.          그렇다면 매번 로그인을 다시 해야하나?     상태를 기억하는 방법은 다양하다.      Cookie, Session, Token: https://hyerin6.github.io/2021-07-23/session-token/   OAuth 2.0: https://hyerin6.github.io/2021-07-23/OAuth2/            응답 상태 코드     100 ~ 메시지 정보   200 ~ 요청 성공   300 ~ 리다이렉션   400 ~ 클라이언트 에러   500 ~ 서버 에러   참고: https://brunch.co.kr/@leedongins/65            HTTP Method  클라이언트가 서버에 요청할 때 어떤 목적을 갖는 행위힌지 HTTP Method에 명시한다.                GET  GET 메서드는 특정 리소스의 표시를 요청한다.   GET을 사용하는 요청은 오직 데이터를 받기만 한다.            HEAD  HEAD 메서드는 GET 메서드의 요청과 동일한 응답을 요구하지만, 응답 본문을 포함하지 않는다.            POST  POST 메서드는 특정 리소스에 엔티티를 제출할 때 쓰인다.    이는 종종 서버의 상태의 변화나 부작용을 일으킨다.            PUT  PUT 메서드는 목적 리소스 모든 현재 표시를 요청 payload로 바꾼다.            DELETE  DELETE 메서드는 특정 리소스를 삭제한다.            CONNECT  CONNECT 메서드는 목적 리소스로 식별되는 서버로의 터널을 맺는다.            OPTIONS  OPTIONS 메서드는 목적 리소스의 통신을 설정하는 데 쓰인다.            TRACE (en-US)  TRACE 메서드는 목적 리소스의 경로를 따라 메시지 loop-back 테스트를 한다.            PATCH  PATCH 메서드는 리소스의 부분만을 수정하는 데 쓰인다.                URI, URL, URN          URI  서버 리소스 이름은 통합 자원 식별자(uniform resource identifier) 혹은 URI라고 불린다.   URI는 인터넷의 우편물 주소 같은 것으로, 정보 리소스를 고유하게 식별하고 위치를 지정할 수 있다.   그리고 이 URI에는 두 가지 형태가 있는데 이것이, URL, URN이라는 것이다.          URL  통합 자원 지시자(uniform resource locator, URL)는 URI의 가장 흔한 형태이다.   URL은 특정 서버의 한 리소스에 대한 구체적인 위치를 서술한다.   URL은 리소스가 정확히 어디에 있고 어떻게 접근할 수 있는지 분명히 알려준다.          URN  URI의 두 번째 형태는 유니폼 리소스 이름(uniform resource name, URN) 이다.    URN은 콘텐츠를 이루는 한 리소스에 대해, 그 리소스의 위치에 영향 받지 않는 유일무이한 이름 역할을 한다.    이 위치 독립적인 URN은 리소스를 여기저기로 옮기더라도 문제없이 동작한다.    리소스가 그 이름을 변하지 않게 유지하는 한, 여러 종류의 네트워크 접속 프로토콜로 접근해도 문제없다.    예를 들어, 다음의 URN은 인터넷 표준 문서 ‘RFC 2141’가 어디에 있거나 상관없이 그것을 지칭하기 위해 사용할 수 있다.   단순하게 말하자면, URI는 규약이고, URL은 규약에 대한 형태라고 생각하면 된다.            참고     https://stackoverflow.com/questions/176264/what-is-the-difference-between-a-uri-a-url-and-a-urn       ","categories": ["Web"],
        "tags": ["web"],
        "url": "/2021-07-23/restfulapi/",
        "teaser": null
      },{
        "title": "Token 인증 방식이 생긴 이유",
        "excerpt":"Session 인증 방식은 공부해보기 전에도 많이 들었고 많이 사용하기 때문에 익숙하다.       그런데 왜 Token 방식이 생겼을까? 어떤 차이가 있는지 알아보기로 했다.   session, cookie, token을 학습하며 자주 마주치는  CORS, XSS, CSRF도 간단하게 알아보자.       Stateless한 HTTP  HTTP는 stateless한 특성을 가지고 있어 각 통신의 상태는 저장되지 않는다.     즉 매번 새 페이지를 요청할 때마다 로그인을 해야 한다는 것인데, 이렇게 되면 사용자는 매우 불편해진다.   이 문제를 해결하기 위한 대표적인 도구가 바로 세션(Session)과 토큰(Token)이다.  세션과 토큰 모두 존재 목적은 거의 같지만 차이점은 많다.             세션 기반 인증 (Session, Cookie)               토큰 기반 인증         CORS(Cross-Origin Resource Sharing)  CORS는 보안 기능이다.      CORS가 도메인 website.com에서 사용 가능한 서버에서 구성되면,    리소스는 AJAX를 통해 동일한 도메인에서 제공되는 주소에서 시작되어야 한다.   domain-b.com에서 CORS를 활성화하고 domain-b.com의 GET 요청만 허용하도록 구성한 경우,     domain-a.com에 호스팅된 https://domain-b.com/images/test.png 이미지를 이용하려고 할 때     대부분의 방문자에게 해당 이미지가 로드되지 않는다.   브라우저는 origin URL을 담고 있는 origin이라는 요청헤더를 더해준다.     서버는 이때 반드시 Access-Control-Allow-Origin이라는 응답헤더로 답해줘야한다.       해당 응답헤더의 값은 반드시 origin 요청헤더의 값과 같거나 *(모든 URL이 괜찮다는 것을 의미함)이어야한다.               XSS(Cross Site Scripting)  xss는 주입식 공격이다.   공격자가 악의적인 스크립트를 신뢰할 수 있는 웹사이트에 삽입하는 방법의 공격이다.               CSRF(Cross Site Request Forgery)  CSRF는 악의적인 웹사이트, 전자 메일, 블로그, 인스턴트 메시지 또는 프로그램으로 인해    사용자의 웹 브라우저가 사용자가 인증 된 다른 신뢰할 수 있는 사이트에서 원치 않는 작업을 수행 할 때 발생하는 공격 유형이다.   이 취약점은 브라우저가 세션 쿠키, IP주소 또는 각 요청과 유사한 인증 리소스를 자동으로 보내는 경우에 발생 할 수 있다.       ","categories": ["Web"],
        "tags": ["web"],
        "url": "/2021-07-23/session-token/",
        "teaser": null
      },{
        "title": "Web Server vs. Web Application Server",
        "excerpt":"    Static Pages      1️⃣   GET /path/index.html        2️⃣   READ(DB에서 읽기) /path/index.html       3️⃣   {file contents}    4️⃣   STATUS(응답) {file contents}               web server는 파일 경로 이름을 받아 경로와 일치하는 file contents를 반환한다.            항상 동일한 페이지를 반환한다.            image, html, css, javascript                        Dynamic Pages      1️⃣   GET /src/servlet?uid=Alice STATUS Response Alice      2️⃣   GET /src/servlet?uid=Bob STATUS Response Bob               인자의 내용에 맞게 동적인 contetns를 반환한다.            웹 서버에 의해서 실행되는 프로그램을 통해서 만들어진 결과물     Servlet: WAS 위에서 돌아가는 Java Program            개발자는 Servlet에 get()을 구현한다.              Web Server와 WAS 차이          Web Server     소프트웨어와 하드웨어로 구분된다.   HTTP 프로토콜을 기반으로 하여 클라이언트의 요청을 서비스 하는 기능을 담당한다.    요청에 따라 두 가지 기능 중 적절하게 선택하여 수행            정적인 컨텐츠 제공, WAS를 거치지 않고 바로 자원을 제공       동적인 컨텐츠 제공, 클라이언트의 요청을 WAS에 보내고 WAS에서 처리한 결과를 클라이언트에게 전달           예) Apache Server, Nginx       WAS(Web Application Server)     DB 조회나 다양한 로직 처리를 요구하는 동적인 컨텐츠를 제공하기 위해 만들어진 Application Server   HTTP를 통해 컴퓨터나 장치에 애플리케이션을 수행해주는 미들워에(소프트웨어 엔진)이다.   웹 컨테이너 혹은 서블릿 컨테이너 라고도 부른다.   컨테이너란 JSP, Servlet을 실행시킬 수 있는 소프트웨어를 말한다.   WAS는 JSP, Servlet 구동 환경을 제공한다.  WAS = Web Server + Web Container   프로그램 실행 환경, DB 접속 기능 제공, 트랜잭션 관리 기능, 비즈니스 로직 수행   예) Tomcat, Jeus            Web Server와 WAS를 구분하는 이유           Web Server를 통해 정적인 파일들을 Application Server까지 가지 않고 앞단에서 빠르게 보내줄 수 있다.  Web Server에서는 정적 컨텐츠만 처리하도록 기능을 분배하여 서버의 부담을 줄일 수 있다.               Web Server만을 이용한다면 사용자가 원하는 요청에 대한 결과값을 모두 미리 만들어 놓고 서비스를 해야 한다.  하지만 이렇게 수행하기에는 자원이 절대적으로 부족하다.  따라서 WAS를 통해 요청에 맞는 데이터를 DB에서 가져와서 비즈니스 로직에 맞게   그때 그때 결과를 만들어서 제공함으로써 자원을 효율적으로 사용할 수 있다.               WAS만 사용하지 않는 이유는?  자원 이용의 효율성 및 장애 극복, 배포 및 유지보수의 편의성을 위해 Web Server와 WAS를 분리한다.  Web Server를 WAS 앞에 두고 필요한 WAS들을 Web Server에 플러그인 형태로 설정하면 더욱 효율적인 분산 처리가 가능하다.  자세한 이점은 다음과 같다.         기능을 분리하여 서버 부하 방지     WAS는 DB 조회나 다양한 로직을 처리하느라 바쁘기 때문에     단순한 정적 컨텐츠는 WS에서 빠르게 클라이언트에게 제공하는 것이 좋다.   WAS는 기본적으로 동적인 컨텐츠를 제공하기 위해 존재하는 서버다.   정적 컨텐츠 요청까지 WAS가 처리한다면 정적 데이터 처리로 인해 부하가 커지고,     동적 컨텐츠 처리가 지연됨에 따라 수행 속도가 느려진다.       물리적으로 분리하여 보안 강화  SSL에 대한 암복호화 처리에 WS를 사용       여러 대의 WAS를 연결 가능     Load Balancing을 위해서 WS 사용   fail over (장애 극복), fail back 처리에 유리   대용량 웹 애플리케이션의 경우(여러 서버 사용) WS와 WAS를 분리하여    무중단 운영을 위한 장애 극복에 쉽게 대응할 수 있다.   예) 앞 단의 WS에서 오류가 발생한 WAS를 이용하지 못하도록 한 후     WAS를 재시작함으로써 사용자는 오류를 느끼지 못하고 이용할 수 있다.       여러 웹 애플리케이션 서비스     하나의 서버에 PHP Application과 Java Application 함께 사용 가능   접근 허용 IP 관리   2대 이상의 서버에서의 세션 관리도 WS에서 처리하면 효율적이다.            참고     https://gmlwjd9405.github.io/2018/10/27/webserver-vs-was.html   https://gmlwjd9405.github.io/2018/10/29/web-application-structure.html   https://gmlwjd9405.github.io/2018/10/28/servlet.html  ","categories": ["Web"],
        "tags": ["web"],
        "url": "/2021-07-23/ws-was/",
        "teaser": null
      },{
        "title": "Session은 어떻게 작동할까?",
        "excerpt":"    질문     유튜버 개발바닥의 기술면접 대표 질문 3가지: https://youtu.be/3ArYMq5AomI            요즘 개발서적 외에 유튜브로도 가끔 개발 관련 영상을 보는데    위 영상의 질문이 좋아 정리해야겠다는 생각이 들었다.   HttpSession.getAttribute(\"user\");  사용자 A가 접속해도 \"user\"를 key로 가져오고  사용자 B가 접속해도 \"user\"를 key로 가져온다.    같은 key를 쓰는데 어떻게 A와 B를 구분해서 값을 가져올까?           답변  session은 각 클라이언트마다 하나씩 생성되어 제공합니다.    그래서 HttpSession.getAttribute(\"user\")는 서로 다른 값을 리턴합니다.              그럼 왜 session은 각 클라이언트마다 하나씩 생성될까?      HTTP 특성: https://hyerin6.github.io/2021-07-23/restfulapi/   Session 특성: https://hyerin6.github.io/2020-02-06/session/   Cookie 특성: https://hyerin6.github.io/2020-02-06/cookie/       HTTP 특성    (1) Stateless(무상태) 프로토콜이다.       (2) 클라이언트와 서버가 요청과 응답을 주고 받으면 연결이 끊어진다.   (3) 클라이언트가 다시 요청하면 서버는 이전 요청을 기억하지 못한다.  (4) 클라이언트와 서버는 서로 상태를 유지하지 않는다.       Session 특성    (1) 클라이언트가 처음 서버에 연결을 하면 어떤 하나의 SessionID가 생성된다.   (2) SessionID는 고유한 ID이다.   (3) 이 ID를 통해 서버는 클라이언트를 구분하고 요청에 대한 응답을 한다.     즉 식별할 수 있는 고유한 값이 없다면 서버는 요청에 대한 응답을 내릴 수가 없을 것이다.      때문에 세션에서는 식별이 가능한 고유 값을 생성하고 서버는 그 값으로 사용자를 구분합니다.      ","categories": ["Web"],
        "tags": ["web"],
        "url": "/2021-07-26/session-how-do-they-work/",
        "teaser": null
      },{
        "title": "Git-flow 란?",
        "excerpt":"           많은 사람들이 프로젝트에서 git flow를 사용했다고 소개한다.      정확히 어떤 것인지 알고 사용해보자.             Git-flow 란?  Git으로 개발할 때 사용되는 방법론으로 완벽하게 따라할 필요는 없고     각자 개발 환경에 따라 변형해서 사용하면 된다.   5가지의 브랜치를 사용한다.     master : 기준이 되는 브랜치로 제품을 배포   develop : 개발 브랜치로 개발자들이 이 브랜치를 기준으로 각자 작업한 기능들을 합칩니다. (Merge)   feature : 단위 기능을 개발하는 브랜치 (develop으로 merge)   release : 배포를 위해 master 브랜치로 보내기 전에 먼저 QA(품질검사)   hotfix : master 브랜치로 배포 후 버그가 생겼을 때 수정                 IntelliJ 에서 Git-flow   1. git-flow 설치   brew로 git flow avh를 설치했다.  brew install git-flow-avh       처음에 brew install git-flow로 git-flow를 설치하니 버전이 0.4.1이라 안된다는 메시지가 떴다.     찾아보니 git-flow-avh를 설치하라는 가이드가 나오는데 설치하고보니 다음과 같은 차이가 있었다.           git flow     hotfix를 dev와 master에 각각 merge를 한다.     (즉, 가지가 hotfix하나에서 dev와 master branch로 두갈래 나뉘어진다.)                  git flow avh    hotfix가 dev branch로 merge되고, hotfix가 merge된 dev branch를 master branch에 머지한다.      즉, hotfix &gt; dev &gt; master 순이다.           2. git flow init 에러 해결   현재 git flow avh를 설치하니 git flow 버전은 1.12.3 이다.       git flow init 시에 에러가 발생했는데, ~/.gitflow_export 에 FLAGS_GET_OPT_CMD 환경 변수가 있는 것이 원인이었다.       삭제 후에 정상적으로 작동한다.      issue: https://github.com/fork-dev/Tracker/issues/418   Post installation setup: https://github.com/petervanderdoes/gitflow-avh/wiki/Installing-on-Mac-OS-X#post-installation-setup              3. IntelliJ 플러그인 사용하기   git-flow-integration 플러그인을 사용하자.    플러그인 설치 후, 오른쪽 하단에 Gitflow가 생긴다.       Init Repo 클릭 후, 설정하면 된다.      기본 옵션은 Git Flow 규칙을 따르기 때문에 기본 규칙을 따른다면 OK를 클릭하면 된다.             develop을 확인할 수 있다.          앞에서 봤던 feature, release 등을 확인할 수 있다.       ","categories": ["Git"],
        "tags": ["git"],
        "url": "/2021-07-30/gitflow/",
        "teaser": null
      },{
        "title": "DbSchema 사용하기",
        "excerpt":"Dbschema는 Java 기반의 ERD 설계툴이다.      설계한 ERD를 HTML5로 생성하는 기능이 있으므로     프로그램이 없는 곳에서도 브라우저만 있으면 ERD를 리뷰할 수 있다.   https://dbschema.com/       MySQL Workbench나 DataGrip을 사용해봤기 때문에 사용법이 어렵지는 않았다.   다음과 같이 ERD를 그리면 프로젝트 진행 중 관리하기 쉽게 DDL을 출력할 수 있고   html로 파일 생성, 공유가 가능하다.           아직 완벽하게 마무리한 테이블 설계는 아니지만, Dbschema를 사용하여 설계해봤고   추후 기능을 확실하게 정하면 수정할 예정이다.  🏃🏻‍♀️   ","categories": ["MySQL","Database"],
        "tags": ["mysql","database"],
        "url": "/2021-07-31/dbschema/",
        "teaser": null
      },{
        "title": "Gradle 사용",
        "excerpt":"    gradle 사용법  Spring 프로젝트를 만들고보니 build.gradle 파일에 다음과 같은 간단한 코드가 들어있었다.   plugins { \tid 'org.springframework.boot' version '2.4.2-SNAPSHOT' \tid 'io.spring.dependency-management' version '1.0.10.RELEASE' \tid 'java' }  group = 'com.test' version = '0.0.1-SNAPSHOT' sourceCompatibility = '1.8'  repositories { \tmavenCentral() \tmaven { url 'https://repo.spring.io/milestone' } \tmaven { url 'https://repo.spring.io/snapshot' } }  dependencies { \timplementation 'org.springframework.boot:spring-boot-starter-web' \ttestImplementation 'org.springframework.boot:spring-boot-starter-test' }  test { \tuseJUnitPlatform() }   프로젝트에 필요한 설정을 해보자.                   플러그인 의존성 관리를 위한 설정   buildscript { \text { \t\tspringBootVersion = '2.4.2-SNAPSHOT' \t} \trepositories { \t\tmavenCentral() \t\tjcenter() \t} \tdependencies { \t\tclasspath(\"org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}\") \t} }   ext 라는 키워드는 build.gradle에서 사용하는 전역변수를 설정하겠다는 의미로         springBootVersion 전역변수를 생성하고 그 값을 ‘2.4.2-SNAPSHOT’로 설정한 것이다.                                           즉 spring-boot-gradle-plugin라는 스프링 부트 그레들 플러그인의 2.4.2-SNAPSHOT를 의존성으로 받겠다는 의미이다.             플러그인 의존성들을 적용할 것인지 결정   plugins { \tid 'org.springframework.boot' \tid 'io.spring.dependency-management' \tid 'java' }   io.spring.dependency-management 플러그인은 스프링 부트의 의존성들을 관리해 주는 플러그인이라 꼭 추가해야 한다.              각종 의존성(라이브러리)들을 어떤 원격 저장소에서 받을지   repositories {     mavenCentral()     jcenter() }   기본적으로 mavenCentral을 많이 사용하지만, 최근에는 라이브러리 업로드 난이도 때문에 jcenter도 많이 사용한다.   jcenter에 라이브러리를 업로드하면 mavenCentral에도 업로드될 수 있도록 자동화를 할 수 있습니다.              프로젝트 개발에 필요한 의존성들을 선언   dependencies {     implementation 'org.springframework.boot:spring-boot-starter-web'     testImplementation 'org.springframework.boot:spring-boot-starter-test' }   특정 버전을 명시하면 안됩니다. 버전을 명시하지 않아야만 맨 위에 작성한     ‘org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}’의 버전을 따라가게 된다.   이렇게 관리할 경우 각 라이브러리들의 버전 관리가 한 곳에 집중되고, 버전 충돌 문제도 해결되어 편하게 개발을 진행할 수 있다.   implementation을 사용한 이유는 공식 문서와 구글링을 참고했고, 간단하게 요약해보면 다음과 같은 이유이다.                implementation을 사용한 이유   (1) 의존성 옵션  gradle 프로젝트는 여러 모듈을 포함할 수 있고 하나의 모듈은 다른 모듈을 의존할 수 있다.       모듈이 커지면 빌드 시간이 오래 걸리고 여러 모듈이 많이 얽혀 있을수록 빌드 시간이 오래 걸린다.   Gradle 3.0 부터 의존 라이브러리 수정 시 재빌드가 필요한 라이브러리를 선택적으로 할 수 있도록          compile 대신 api 와 implementation 으로 나눠 필요없는 경우 재빌드 하지 않도록 한다.       (2) api와 implementation 차이          api : 의존 라이브러리 수정 시 본 모듈을 의존하고 있는 모듈들 또한 재빌드         A(api) &lt;- B &lt;- C 의 경우 C에서 A를 접근할 수 있음             A 수정 시 B와 C 모두 재빌드                  implementation: 의존 라이브러리 수정 시 본 모듈까지만 재빌드        A(implementation) &lt;- B &lt;- C 의 경우 C에서 A를 접근할 수 없음       A 수정 시 B까지 재빌드          implementation은 dependency 가 compile classpath 에 들어가지 않아서 transitive dependency 를 실수로 depend 하지 않는다.          더 빠른 compile 이 가능하고, dependency change 가 발생했을 때 recompile 을 적게 한다. 쉬운 배포가 가능하다.       (3) 의존성 옵션들          implementation      의존 라이브러리 수정시 본 모듈까지만 재빌드        본 모듈을 의존하는 모듈은 해당 라이브러리의 api 를 사용할 수 없음                 api  의존 라이브러리 수정시 본 모듈을 의존하는 모듈들도 재빌드    본 모듈을 의존하는 모듈들도 해당 라이브러리의 api 를 사용할 수 있음                compileOnly    compile 시에만 빌드하고 빌드 결과물에는 포함하지 않음      runtime 시 필요없는 라이브러리인 경우 (runtime 환경에 이미 라이브러리가 제공되고 있는가 하는 등의 경우)     참고: https://blog.gradle.org/introducing-compile-only-dependencies                 runtimeOnly    runtime 시에만 필요한 라이브러리인 경우                 annotationProcessor   annotation processor 명시 (gradle 4.6)           ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-07-31/gradle/",
        "teaser": null
      },{
        "title": "QueryDSL 사용",
        "excerpt":"    QueryDsl 이란?  EntityManager.find() 메소드를 사용하면 식별자로 엔티티 하나를 조회할 수 있다.     이렇게 조회한 엔티티에 객체 그래프 탐색을 사용하면 연관된 엔티티들을 찾을 수 있다.     둘은 가장 단순한 검색 방법이다.      식별자로 조회 EntityManager.find()   객체 그래프 탐색 ex) a.getB().getC()       현실적으로는 위 기능만으로 개발하기 어렵기 때문에 SQL로 필요한 내용을 최대한 걸러서 조회해야 하는데       ORM을 사용하면 데이터베이스 테이블이 아닌 엔티티 객체를 대상으로 개발하므로      검색도 테이블이 아닌 엔티티 객체를 대상으로 하는 방법이 필요하다.     JPQL이 이런 문제를 해결하기 위해 만들어졌는데 다음과 같은 특징이 있다.      테이블이 아닌 객체를 대상으로 검색하는 객체지향 쿼리다.   SQL을 추상화해서 특정 데이터베이스 SQL에 의존하지 않는다.       SQL이 데이터베이스 테이블을 대상으로 하는 데이터 중심의 쿼리라면 JPQL은 엔티티 객체를 대상으로 하는 객체지향 쿼리다.          JPQL을 사용하면 JPA는 이 JPQL을 분석한 다음 적절한 SQL을 만들어 데이터베이스를 조회한다.           그리고 조회한 결과로 엔티티 객체를 생성해서 반환한다.       JPA가 공식 지원하는 기능은 다음과 같다.      JPQL   Criteria 쿼리: JPQL을 편하게 작성하도록 도와주는 API, 빌더 클래스 모음   네이티브 SQL: JPA에서 JPQL 대신 직접 SQL을 사용할 수 있다.   QueryDSL: Criteria 쿼리처럼 JPQL을 편하게 작성하도록 도와주는 빌더 클래스 모음, 비표준 오픈소스 프레임워크다.   JDBC 직접 사용, MyBatis 같은 SQL 매퍼 프레임워크 사용: 필요하면 JDBC를 직접 사용할 수 있다.       QueryDSL은 JPQL의 빌더(Criteria) 클래스이다.               코드 기반이며 단순하고 사용하기 쉽다는 장점이 있다.   public void queryDSL() {              EntityManager em = emf.createEntityManager();                    JPAQuery query = new JPAQuery(em);     QMember qMember = new QMember(\"m\"); // JPQL 병칭 = m              List&lt;Member&gt; members =          query.from(qMember)             .where(qMember.name.eq(\"회원\"))             .orderBy(qMember.name.desc())             .list(qMember); }             QueryDSL을 사용하려면 우선 com.mysema.query.jpa.impl.JPAQuery 객체를 생성해야 한다.           이때 엔티티 매니저를 생성자에 넘겨준다.              그리고 사용할 쿼리 타입(Q)을 생성하는데 생성자에는 별칭을 주면 된다.             이 별칭은 JPQL에서 별칭으로 사용한다.              QueryDsl 사용하기  Spring Boot 2.3부터 Gradle 6.3 이상을 요구한다.          예전에 작성한 코드를 가지고 Spring Boot와 Gradle을 버전업했다.                           인텔리제이에서 Querydsl을 이용해서 생성하는 Q클래스를 불러올 수 없다는 경고가 노출된다.       gradle은 프로젝트의 의존성을 관리하고 작성된 코드를 배포 가능한 형태로 가공하는 개발도구다.       그리고 그 버전이 매우 빠른 속도로 업데이트 된다. 기능의 변동도 많다.        때문에 기존에 작성한 스크립트가 쓸모가 없어지거나 동작하지 않는 등의 상황이 발생한다.       gradle 플러그인(https://plugins.gradle.org/)을 사용하다보면 그런 상황을 많이 마주하게 된다.   그 중에 JPA 엔티티 클래스(javax.persistence.Entity 선언클래스)를 가공하여      Query와 유사한 작성법으로 사용할 수 있는 Q클래스를 생성하는 Queyrdsl JPA 플러그인이 대표적인 경우다.     https://github.com/querydsl/querydsl   http://www.querydsl.com/static/querydsl/latest/reference/html/ch02.html#jpa_integration       Querydsl JPA는 프로젝트 내에서 @Entity 어노테이션을 선언한 클래스를 탐색하고      JPAAnnotationProcessor를 이용하여 Q클래스를 생성한다.     생성된 Q클래스는 자바 언어가 가지는 정적코드의 장점을 활용하여 안전한 쿼리문을 작성할 수 있다.   Annotation processor가 등장하기 이전 그레이들 버전(4.6 이전)에서는     JPAAnnotationProcessor의 작동을 정의하는 스크립트를 정의하는 것이 쉽지 않았다.       gradle에서 qureydsl를 사용하는 방법은 두가지다.     플러그인 com.ewerk.gradle.plugins.querydsl을 사용   annotationProcessor 사용             플러그인 com.ewerk.gradle.plugins.querydsl 사용   apply plugin: \"com.ewerk.gradle.plugins.querydsl\"  def queryDslDir = \"src/main/generated\" querydsl {     library = \"com.querydsl:querydsl-apt:4.2.2\" // 사용할 AnnotationProcesoor 정의     jpa = true     querydslSourcesDir = queryDslDir } sourceSets {     main {         java {             srcDir queryDslDir         }     } }  compileQuerydsl {     options.annotationProcessorPath = configurations.querydsl }  configurations {      // 아래를 지정하지 않으면, compile로 걸린 JPA 의존성에 접근하지 못한다.     querydsl.extendsFrom compileClasspath }   이 gradle 플러그인은 2018.7 에 출시된 1.0.10 를 마지막으로 더이상 업데이트가 없다.    gradle 4.6 에서 Annotation Processor 가 소개되고,   이를 반영한 gradle 5.X 가 출시됐을 때는 정상적으로 작동하지 않았다.   그래서 위 스크립트 부분 중 다음 부분이 추가되었다.   compileQuerydsl {     options.annotationProcessorPath = configurations.querydsl }       querydsl-apt 에 있는 AnnotationProcessor 의 경로를 설정해준다.   그리고 gradle 6.x 에서는 다음 코드를 추가해주면 정상작동한다고 한다.   configurations {      // 아래를 지정하지 않으면, compile로 걸린 JPA 의존성에 접근하지 못한다.     querydsl.extendsFrom compileClasspath }   최신버전에서 정상 동작시키려고 뭔가 하나씩 설정을 추가하는 상황이 발생한다.      또한 gradle 플러그인은 IntelliJ IDEA 연동에 문제 일으키기 때문에    Annotation Processor을 권장한다.            Cannot find symbol 오류  QueryDSL과 Hibernate/Eclipse Metamodel Generator를 함께 사용할 때     아직 생성되지 않은 메타 모델 클래스를 사용하는 코드들 때문에 cannot find symbol 에러가 발생할 수 있는데,     이는 이 둘을 서로 따로 생성했을 때 발생하는 현상이다.   Lombok을 함께 사용할 경우 각 AP가 실행된 뒤에 다시 lombok AP가 돌면서 발생하는 것으로 알고 있는데      이 둘을 함께 지정해서 APT를 수행해야 에러가 나지 않는다.             Annotation Processor 설정 사용  gradle 4.6(https://docs.gradle.org/4.6/release-notes.html)에서 소개된       Annotation processor는 어노테이션이 선언된 클래스처리를 별도의 프로세서에서 처리하여 성능향상을 꽤했다.   def querydslVersion = '4.3.1'  dependencies {     implementation 'org.springframework.boot:spring-boot-starter-web'     implementation 'org.springframework.boot:spring-boot-starter-data-jdbc'     implementation 'org.springframework.boot:spring-boot-starter-data-jpa'      // Querydsl     implementation group: 'com.querydsl', name: 'querydsl-jpa', version: querydslVersion     implementation group: 'com.querydsl', name: 'querydsl-apt', version: querydslVersion     implementation group: 'com.querydsl', name: 'querydsl-core', version: querydslVersion      annotationProcessor group: 'com.querydsl', name: 'querydsl-apt', version: querydslVersion     annotationProcessor group: 'com.querydsl', name: 'querydsl-apt', version: querydslVersion, classifier: 'jpa'     annotationProcessor(\"jakarta.persistence:jakarta.persistence-api\")     annotationProcessor(\"jakarta.annotation:jakarta.annotation-api\")      runtimeOnly 'com.h2database:h2'     compileOnly 'org.projectlombok:lombok'     annotationProcessor 'org.projectlombok:lombok'     testImplementation('org.springframework.boot:spring-boot-starter-test') {         exclude group: 'org.junit.vintage', module: 'junit-vintage-engine'     }     testImplementation 'org.junit.jupiter:junit-jupiter:5.6.0'     testImplementation 'org.assertj:assertj-core:3.15.0' }  def generated='src/main/generated' sourceSets {     main.java.srcDirs += [ generated ] }  tasks.withType(JavaCompile) {     options.annotationProcessorGeneratedSourcesDirectory = file(generated) }  clean.doLast {     file(generated).deleteDir() }              참고     https://stackoverflow.com/questions/62521275/problem-with-generating-querydsl-classes-with-gradle   https://jojoldu.tistory.com/372   http://honeymon.io/tech/2020/07/09/gradle-annotation-processor-with-querydsl.html   https://kangwoojin.github.io/programing/query-dsl-setting-3/   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-02/querydsl/",
        "teaser": null
      },{
        "title": "프로젝트에서 Enum 사용 (Enum Converter)",
        "excerpt":"    지금까지 프로젝트에서 Enum을 사용할 때, 남성/여성을 표현하기 위해 사용해본 적이 있다.   JPA 프로젝트에서 enum을 사용하는 방법은 다음과 같다.       @Enumerated  @Enumerated 은 두가지 저장 방법을 제공한다.           EnumType.ORDINAL: ENUM이 정의된 순서의 인덱스로 DB에 값을 저장         Enum에 정의된 순서를 기반으로 인덱스가 만들어지고, DB에 저장되는 방식인데      값이 추가될 때 순서가 바뀌면서 데이터를 잘못 가져오는 문제가 발생할 수 있다.                          EnumType.STRING: ENUM의 이름 자체를 DB에 값으로 저장.      Name 값을 그대로 DB에 저장하는 방식인데, Name 값을 변경해야 하는 상황이라면 바뀐 데이터를 처리하는 일이 생기고        DB에 데이터를 낭비하면서 넣게 된다.                   @Converter  DB에 값을 효율적이게 저장할 수 있는 방법이 바로 @Converter 이다.      @Convertor    아래와 같은 구조로 사용된다.      영속성 컨텍스트 &gt; Convetor &gt; DB         영속성 컨텍스트에 데이터가 들어가고, 실제 디비로 들어가거나 나오기 직전에     Convetor 로직이 있다면 돌고 난 후에 DB로 접근하게 되어있다.        프로젝트에 적용한 부분은 다음과 같다.  좋아요(Like) 기능을 게시글(Post)과 댓글에(Comment) 적용하기 위해     Type enum을 만들고 @Enumerated 사용의 문제점을 해결하기 위해    AttributeConverter를 구현했다.          Like   @Entity public class Like { \t@Id \t@GeneratedValue(strategy = GenerationType.IDENTITY) \tprivate Long id;  \t@Convert(converter = LikeTypeConverter.class) \tprivate Type type;  \t@ManyToOne \t@JoinColumn(name = \"user_id\") \tprivate User user;  \tprivate Long parentId;  \t. . .  }          Type   public enum Type { \tPOST(1), COMMENT(2);  \tpublic int type;  \tType(int type) { \t\tthis.type = type; \t}  \tpublic int toDbValue() { \t\treturn type; \t}  \tpublic static Type from(Integer dbData) { \t\treturn Stream.of(Type.values()) \t\t\t.filter(x -&gt; x.type == dbData) \t\t\t.findFirst() \t\t\t.orElseThrow(IllegalArgumentException::new); \t}  }          LikeTypeConverter   @Converter public class LikeTypeConverter implements AttributeConverter&lt;Type, Integer&gt; {      // DB에 어떤 값이 저장되는지  \t@Override \tpublic Integer convertToDatabaseColumn(Type attribute) { \t\treturn attribute.toDbValue(); \t} \t     // DB에서 Entity로 값을 넣을 때 어떤 값을 리턴하는지  \t@Override \tpublic Type convertToEntityAttribute(Integer dbData) { \t\treturn Type.from(dbData); \t} }       참고     https://techblog.woowahan.com/2600/   https://tech.yangs.kr/16   https://hungrydiver.co.kr/bbs/detail/develop?id=43   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-06/enum-converter/",
        "teaser": null
      },{
        "title": "파일 리스트와 데이터 요청을 하나의 객체로 바인딩",
        "excerpt":"    우선 @RequestParam, @RequestBody, @ModelAttribute의 차이를 정확히 알아야 한다.       @RequestParam  @RequestParam은 1개의 HTTP 요청 파라미터를 받기 위해서 사용한다.    @RequestParam은 필수 여부가 true 이기 때문에 기본적으로 반드시 해당 파라미터가 전송되어야 한다.   해당 파라미터가 전송되지 않으면 400 error가 발생한다.    반드시 필요한 변수가 아니라면 옵션을 통해 설정해야 한다.         @RequestBody  클라이언트가 전송하는 Json(application/json) 형태의 HTTP Body 내용을 Java Object로 변환시켜주는 역할이다. 그래서 Body가 존재하지 않는 Get 메서드에서 @RequestBody를 사용하려고 하면 에러가 발생하게 된다.    @RequestBody로 받는 데이터는 Spring에서 관리하는 MessageConverter 중 하나인   MappingJackson2HttpMessageConverter를 통해 Java 객체로 변환한다.         @ModelAttribute  클라이언트가 전송하는 multipart/form-data 형태의 HTTP Body 내용과 HTTP 파라미터들을   Setter을 통해 1 대 1로 객체에 바인딩하기 위해 사용된다.       JSON이나 XML과 같은 형태의 데이터를 변환시키는 @RequestBody와 달리          @ModelAttribute는 multipart/form-data 형태의 HTTP Body와 HTTP 파라미터들을 매핑시킨다는 차이가 있다.            Create Post  SNS 개발을 위해 content(String)와 image(MultipartFile)를 List 형태로 받아야 하는 상황이다.         이미지는 AWS S3에 저장하며, 파일 이름과 URL을 DB에 저장한다.       방법 1: 사진을 Base64로 인코딩하여 JSON으로 전달   // DTO public class CreatePostRequest { \tprivate String content; \tprivate List&lt;String&gt; images; }  // Controller @PostMapping(\"/posts\") public ResponseEntity&lt;Void&gt; create(@ModelAttribute CreatePostRequest request) {     ... }           Base64로 이미지를 변환하는 경우 최대 33% 까지 파일의 크기가 증대된다.     따라서 네트워크 대역 낭비가 심하다.            Spring에서 특정 크기 이상의 데이터가 Body에 담기는 경우 요청을 해석하지 못하는 상황이 발생한다.                방법 2: 각각의 데이터를 별도로 form으로 전달   // Controller  @PostMapping(\"/posts\") public ResponseEntity&lt;Void&gt; create(@RequestParam String content,                                     @RequestParam List&lt;MultipartFile&gt; images) {     ... }           객체를 form을 이용해 데이터를 전달받고 데이터들을 객체로 매핑하기 위해    Spring type convertion을 이용해야 한다.            List를 받는 경우 데이터의 논리적인 연관을 파악하기 어렵다.                  방법 3: form 데이터를 하나의 객체로 전달   // DTO  public class CreatePostRequest { \tprivate String content; \tprivate List&lt;MultipartFile&gt; images; }  // Controller  @PostMapping(\"/posts\") public ResponseEntity&lt;Void&gt; create(@ModelAttribute CreatePostRequest request) {     ... }   @ModelAttribute를 사용하여 form data를 객체로 바로 매핑하는 방법이다.       데이터 간의 논리적인 연관관계를 표현할 수 있고,     Base64와 같이 인코딩 하지 않기 때문에 파일 사이즈가 증대되는 현상도 발생하지 않는다.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-09/post-crud/",
        "teaser": null
      },{
        "title": "createdAt 어떻게 저장할까?",
        "excerpt":"    아래 코드는 sns 프로젝트의 게시글 엔티티 클래스이다.     많은 어노테이션이 붙어있는데 이번에는 엔티티 생성, 수정 시간을 기록하는    필드에 대해 알아보자.        @Setter @Getter @Builder @NoArgsConstructor(access = AccessLevel.PROTECTED) @AllArgsConstructor(access = AccessLevel.PRIVATE) @EntityListeners(AuditingEntityListener.class) @Entity public class Post { \t@Id \t@GeneratedValue(strategy = GenerationType.IDENTITY) \tprivate long id;  \tprivate String content;  \t@ManyToOne \t@JoinColumn(name = \"user_id\") \tprivate User user;  \t@CreatedDate \t@Column(updatable = false, nullable = false) \tprivate LocalDateTime createdAt;  \t@LastModifiedDate \tprivate LocalDateTime updatedAt; }       @CreatedDate &amp; @LastModifiedDate   @CreatedDate는 엔티티 생성 시 특정 필드를 자동으로 데이터베이스에 매핑해주기 위해 사용한다.       그런데 아무런 설정 없이 @CreatedDate 어노테이션만 붙이면 다음과 같은 에러가 발생하거나 NULL이 저장된다.   not-null property references a null or transient value createddate       다음과 같은 설정이 필요하다.      SpringApplication에 @EnableJpaAuditing 붙이기   콜백 요청을 원하는 엔티티에 @EntityListeners(AuditingEntityListener.class) 붙이기   왜 이런 설정이 필요한지 더 알아보자.       @EntityListeners  엔티티를 DB에 적용하기 이전에 콜백을 요청할 수 있는 어노테이션             AuditingEntityListener          Auditing이란 감시하다라는 뜻이다.                   엔티티를 영속성 컨텍스트에 저장하거나 수정한 후 update하는 경우       자동으로 auditor, time을 매핑하여 DB에 넣도록 도와준다.                   스프링 부트의 엔트리 포인트인 실행 클래스에 @EnableJpaAuditing을 적용하여 JPA Auditing을 활성화 해야한다.             위 설정들을 마치면 엔티티에 따로 createdAt과 updatedAt을 set 하지 않아도 자동으로 DB에 저장된다.       @CreationTimestamp  앞서 알아본 @CreatedDate는 Spring Data에서 제공하는 어노테이션이고    @CreationTimestamp는 하이버네이트에서 제공하는 어노테이션이다.   설정 없이 사용할 수 있지만 하이버네이트에 종속되어 버리니      @CreatedDate를 사용하기로 했다.       참고     https://docs.spring.io/spring-data/jpa/docs/1.7.0.DATAJPA-580-SNAPSHOT/reference/html/auditing.html   https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#auditing.annotations   https://docs.jboss.org/hibernate/orm/current/userguide/html_single/Hibernate_User_Guide.html#mapping-generated-CreationTimestamp   https://bgpark.tistory.com/133   https://docs.jboss.org/hibernate/orm/5.2/userguide/html_single/Hibernate_User_Guide.html#events-jpa-callbacks      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-14/createdAt/",
        "teaser": null
      },{
        "title": "스프링 예외 발생 위치와 처리 방법",
        "excerpt":"스프링 처리 과정      스프링의 처리 과정을 보면 예외가 발생하는 부분은 크게 두 가지로 나눌 수 있다.      DispatcherServlet 내에서 발생하는 예외 (Controller, Service, Repository 등)   DispatcherServlet 전의 서블릿(Filter)에서 발생하는 예외         DispatcherServlet 내에서 발생한 예외   DispatcherServlet 내에서 발생하는 예외는 HandlerExceptionResolver를 사용한 예외 전략으로 내부에서 자체적으로 해결할 수 있다.   HandlerExceptionResolver 사용은 다음 링크 참고   https://jaehun2841.github.io/2018/08/30/2018-08-25-spring-mvc-handle-exception/#handlerexceptionresolver%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%B2%98%EB%A6%AC         DispatchherServlet 전에 발생한 예외   DispatcherServlet 전의 서블릿(Filter)에서 발생하는 예외는 HandlerExceptionResolver의 처리를 받을 수 없다.   Filter에서 예외가 발생하면 Web Application 레벨에서 처리를 해줘야 한다.       해결 방법은 다음과 같다.      web.xml 에서 error-page 등록, 사용자에게 에러 응답   Filter 내부 예외 처리를 위한 Filter 생성, try-catch문을 사용하여 예외 처리   Filter 내부 try-catch문에서 발생한 예외를  HandlerExceptionResolver를 빈으로 주입받아 @ExceptionHandler에서 처리       HandlerExceptionResolver의 예외 처리 방법           Controller Level: @ExceptionHandler            Global Level: @ControllerAdvice            Method Level: try/catch             (1) Controller Level: @ExceptionHandler   스프링에서 Controller에서 발생하는 예외를 공통적으로 처리할 수 있는 기능을 제공한다.   @ExceptionHandler애노테이션을 통해 Controller의 메서드에서 throw된 Exception에 대한 공통적인 처리를 할 수 있다.   TestController내에서 발생하는 TestException에 대해서 예외가 발생하면 controllerExceptionHandler메서드에서 모두 처리해준다.     Controller 메서드 내의 하위 서비스 (Service, Repository등등)에서 예외가 발생하더라도,   중간에 처리하지 않는 이상 Controller단까지 예외가 던져지게 되고 @ExceptionHandler가 예외를 처리하게 된다.   Checked Exception, Runtime Exception 상관 없이 Controller까지 예외를 throw하면 처리가 가능하다.   @RestController public class TestController {      // 예외 핸들러     @ExceptionHandler(value = TestException.class)     public String controllerExceptionHandler(Exception e) {         log.error(e.getMessage());         return \"/error/404\";     }      @GetMapping(\"hello1\")     public String hello1() {         throw new TestException(\"hello1 에러 \"); // 예외 발생     }      @GetMapping(\"hello2\")     public String hello2() {         throw new TestException(\"hello2 에러 \"); // 예외 발생     } }         (2) Global Level: @ControllerAdvice   하나의 Controller가 아닌 여러 Controller에서 발생하는 예외를 처리하려면 @ControllerAdvice를 사용해야 한다.   @ControllerAdvice는 모든 Controller에서 발생하는 예외를 처리할 수 있게 해주는 애노테이션이다.   DispatcherServlet에서 발생하는 예외를 전역적으로 처리해준다.   DispatcherServlet에서 발생하는 예외만 처리할 수 있고 Filter에서 발생하는 예외는 따로 처리를 하지 않으면 처리가 불가능하다.   Q. Controller의 @ExceptionHandler와 ControllerAdvice의 @ExceptionHandler중 높은 우선순위는?   A. Controller의 @ExceptionHandler가 먼저다.         (3) Method Level: try/catch   생략  ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-16/spring-exception/",
        "teaser": null
      },{
        "title": "Spring Security란?",
        "excerpt":"    Spring Security  Spring 기반의 애플리케이션의 보안을(인증과 권한, 인가 등) 담당하는 스프링 하위 프레임워크다.   SpringSecurity는 인증과 권한에 대한 부분을 Filter 흐름에 따라 처리하고 있다.   Filter는 DispatcherServlet으로 가기 전에 적용되므로 가장 먼저 URL 요청을 받지만,   Interceptor는 Dispatcher와 Controller 사이에 위치한다는 점에서 적용 시기의 차이가 있다.          SpringContextHolder   SpringContextHolder는 보안 주체의 세부 정보를 포함하여 응용프로그램의 현재 보안 컨텍스트에 대한 세부 정보가 저장된다.       SecurityContext   Authentication을 보관하는 역할이며, SecurityContext를 통해 Authentication 객체를 꺼내올 수 있다.       Authentication   Authentication은 현재 접근하는 주체의 정보와 권한을 담은 인터페이스다.   Authentication 객체는 SecurityContext에 저장되며,   SecurityContextHolder를 통해 SecurityContext에 접근하고   SpringContext를 통해 Authentication에 접근할 수 있다.   public interface Authentication extends Principal, Serializable { \t// 현재 사용자의 권한 목록을 가져옴  \tCollection&lt;? extends GrantedAuthority&gt; getAuthorities(); \t \t// credenrials(ex.password)을 가져옴  \tObject getCredentials(); \t \tObject getDetails(); \t \t// Principal 객체를 가져옴  \tObject getPrincipal(); \t \t// 인증 여부를 가져옴  \tboolean isAuthenticated(); \t \t// 인증 여부를 설정함  \tvoid setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException; }       UsernamePasswordAuthenticationToken   UsernamePasswordAuthenticationToken은 인증 전 객체를 생성하고 인증 완료된 객체를 생성하는 생성자를 갖고 있다.       AuthenticationProvider   AuthenticationProvider에서는 실제 인증에 대한 부분을 처리하는데   인증 전의 Authentication 객체를 받아서 인증이 완료된 객체를 반환하는 역할을 한다.   AuthenticationProvider 인터페이스를 구현해서 Custom한 AuthenticationProvider을 작성해서 AuthenticationManager에 등록한다.   public interface AuthenticationProvider { \t// 인증 전 Authentication 객체를 받아서 인증된 Authentication 객체를 반환  \tAuthentication authenticate(Authentication var1) throw AuthenticationException; \t \tboolean supports(Class&lt;?&gt; var1); }       AuthenticationManager   인증에 대한 부분은 SpringSecurity의 AuthenticationManager을 통해서 처리하는데   실제로는 AuthenticationManager에 등록된 AuthenticationProvider에 의해 처리된다.   인증에 성공하면 인증 성공 객체를 생성하여 SecurityContext에 저장한다.   인증 상태를 유지하기 위해 세션에 보관하며, 인증이 실패한 경우 AuthenticationException을 발생시킨다.     AuthenticationManager를 implements한 ProviderManager는 실제 인증 과정에 대한 로직을 가지고 있는   AuthenticationProvider를 List로 가지고 있으며, ProviderManager는 for문을 통해 모든 provider를 조회하면서 authenticate 처리를 한다.      ProviderManager에 개발자가 직접 구현한 CustomAuthenticationProvider를 등록하는 방법은   WebSecurityConfigureAdapter를 상속해 만든 SecurityConfig에서 할 수 있다.   WebSecurityConfigureAdapter의 상위 클래스에서는 AuthenticationManager를 가지고 있기 때문에   직접만든 CustomAuthenticationProvider를 등록할 수 있다.       UserDetails   인증에 성공하여 생성된 UserDetails 객체는 Authentication 객체를 구현한 UsernamePasswordAuthenticationToken을 생성하기 위해 사용된다.       UserDetailsService   UserDetailsService 인터페이스는 UserDetails 객체를 반환하는 단 하나의 메소드를 가지고 있는데   일반적으로 이를 구현한 클래스의 내부에 UserRepository를 주입받아 DB에서 User 정보를 가져온다.   public interface UserDetailsService { \tUserDetails loadUserByUsername(String var1) throws UsernameNotFoundException; }         참고     https://mangkyu.tistory.com/76   https://jeong-pro.tistory.com/205   https://coding-start.tistory.com/153      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-22/springsecurity(1)/",
        "teaser": null
      },{
        "title": "Spring Security 로그인 절차",
        "excerpt":"    로그인은 어떻게 진행될까?                  사용자가 로그인을 요청한다.            AuthenticationFilter (사용할 구현체 : UsernamePasswordAuthenticationFilter)가 HttpServletRequest에서 사용자가 보낸 아이디와 패스워드를 인터셉트한다. Front 단에서 유효성 검사를 할 수 있지만 서버에서도 가능하다. HttpServletRequest에서 꺼내온 사용자 아이디와 패스워드를 진짜 인증을 담당할 AuthenticationManager 인터페이스 (구현체: ProviderManager)에게 인증용 객체(UsernamePasswordAuthenticationToken)로 만들어줘서 위임한다.            AuthenticationFilter에게 인증용 객체(UsernamePasswordAuthenticationToken)을 전달받는다.            실제 인증을 할 AuthenticationProvider에게 Authentication 객체 (UsernamePasswordAuthenticationToken)을 다시 전달한다.            DB에서 사용자 인증 정보를 가져올 UserDetailsService 객체에게 사용자 아이디를 넘겨주고 DB에서 인증에 사용할 정보 (id/password, 권한 등)을 UserDetails 객체로 전달받는다.            AuthenticationProvider는 UserDetails 객체를 전달받은 이후 실제 사용자의 입력 정보와 UserDetails 객체를 가지고 인증을 시도한다.       7~10. 인증이 완료되면 사용자 정보를 가진 Authentication 객체를 SecurityContextHolder에 담은 이후 AuthenticationSuccessHandler를 실행한다. 실패 시 AuthenticationFilureHandler를 실행한다.              로그인   AuthenticationFilter, DelegatingFilterProxy   우선 클라이언트(브라우저)로 부터 요청(Request)이 오면, 그 요청은 ApplicationFilter 객체들로 먼저 가게 된다.   DispatcherServlet에 도달하기 전이다.      ApplicationFilter들을 거치다가 DelegatingFilterRegistrationBean 이라는 필터를 만나게 된다.   이 필터는 DelegatingFIlterProxy라는 클래스로 만들어진 스프링 빈을 등록시켜주는 역할을 한다.         Filter   스프링 부트에서는 @EnableAutoConfiguration 어노테이션을 이용해서   SecurityFilterAutoConfiguration 클래스를 로드하고 디폴트로 이름이 SpringSecurityFilterChain 빈을 등록해준다.   이때 스프링 시큐리티가 만든 DelegatingFilterProxy 클래스인 SpringSecurityFilterChain 이라는 이름의 스프링 빈을 등록하고   이후에는 이 DelegatingFilterProxy(SpringSecurityFilterChain)가 필터로 동작하게 된다.      DelegatingFilterProxy가 처리를 위임하는 필터 클래스는 FilterChainProxy다.     이 클래스 내부에 체인으로 등록된 필터를 순서대로 수행하는 것이다.     DelegatingFIlterProxy ▶️ FIlterChainProxy ▶️ List 구조        SpringSecurityFilterChain은 스프링에서 보안과 관련된 여러 필터 리스트를 갖고 있는 객체로 필터 리스트를 순회하면서 필터링한다.   필터 리스트는 AuthenticationFilter들이고, 스프링 시큐리티가 자동으로 생성한다.   SpringSecurityFilterChain이라는 필터가 갖고 있는 필터 중 하나로 UsernamePasswordAuthenticationFilter라는 필터가 있다.   이 필터는 ID/Password를 이용한 인증을 담당하는 필터다.         OAuth 2.0   그렇다면 OAuth 2.0을 이용한 인증을 하려면 어떻게 동작할까?   UsernamePasswordAuthenticationFilter는 OAuth 2.0 인증을 할 수 없으니 인증되지 않은 채로 다음 필터로 넘어간다.   그 후 OAuth2ClientAuthenticationProcessingFilter라는 필터에서 OAuth 2.0을 이용한 인증이 진행된다.   이 필터로 OAuth를 쓴다고 설정하면 스프링 시큐리티가 설정해준다.      여러 필터를 거치며 인증이 완료되면 해당 요청(Request)은 인증된 요청이 되는 것이다.   요청에 대한 인증은 UsernamePasswordAuthenticationFilter가 담당한다.   public Authentication attempAuthentication(HttpServletRequest request, HttpServletResponse response) { \t \t... \t \tUsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); \tthis.setDetails(request, authRequest); \treturn this.getAuthenticationManager().authenticate(authRequest); }   attempAuthentication(request, response) 메소드를 보면 요청으로부터   username, password를 얻어오고   그 값으로 UsernamePasswordAuthenticationToken(Authentication)을 생성한다.   그 다음 참조하고 있던 AuthenticationManager(구현체: ProviderManager)에게 인증을 진행하도록 위임한다.     여기서 UsernamePasswordAuthenticationToken은 Authentication 인터페이스의 구현체다.   Authentication의 구현체만 AuthenticationManager 인증 과정을 수행할 수 있다.     그렇다면 개발자가 스프링 시큐리티를 이용해 인증 절차를 만들려면?   AuthenticationProvider 인터페이스를 구현해서 ProviderManager가   그 클래스의 객체에게 인증을 위임하도록 하면 개발자가 원하는 인증 처리를 할 수 있게 된다.         참고     https://mangkyu.tistory.com/76   https://jeong-pro.tistory.com/205   https://coding-start.tistory.com/153      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-22/springsecurity(2)/",
        "teaser": null
      },{
        "title": "Spring Security + OAuth2.0 + Kakao",
        "excerpt":"    Spring Security에 대한 포스팅은 다음 링크를 참고           Spring Security란?: https://hyerin6.github.io/2021-08-22/springsecurity(1)/            Spring Security 로그인 절차: https://hyerin6.github.io/2021-08-22/springsecurity(2)/           OAuth2.0 로그인을 사용한다면 UsernamePasswordAuthenticationFilter 대신 OAuth2LoginAuthenticationFilter가 호출된다.   두 필터의 상위 클래스는 AbstractAuthenticationProcessingFilter이고, 스프링 시큐리티가 상위 클래스를 호출하면 로그인 방식에 따라 구현체인 UsernamePasswordAuthenticationFilter와 OAuth2LoginAuthenticationFilter가 동작한다.           Spring Security Configuration           @EnableWebSecurity는 스프링 시큐리티 설정들을 활성화 시켜준다.       oauth2Client()로 OAuth2 클라이언트 구성 요소를 지정할 수 있다.            authorizedClientService(authorizedClientService())                http.oauth2Login()으로 OAuth2 로그인 관련 처리를 설정할 수 있다.            userService()는 OAuth2 인증 과정에서 Authentication을 생성에 필요한       OAuth2User를 반환하는 클래스를 지정한다.            customUserType(KakaoOAuth2User.class, SOCIAL_TYPE)       OAuth2User 타입을 지정한다.            successHandler()는 인증을 성공적으로 마친 경우 처리할 클래스를 지정한다.       failureHandler()는 인증을 실패한 경우 처리할 클래스를 지정한다.           OAuth2 인증 과정           사용자가 소셜 로그인 성공            AbstractAuthenticationProcessingFilter에서 OAuth2 로그인 과정을 호출            Resource Server에서 넘겨주는 정보대로       OAuth2LoginAuthentiationFilter의 attemptAuthentication()에서 인증 과정을 수행            attemptAuthentication() 처리 과정에서 OAuth2AuthenticationToken을 생성하기 위해       OAuth2LoginAuthenticationProvider의 authenticate() 호출            authenticate() 처리 과정에서 OAuth2User를 생성하기 위해       OAuth2UserService의 loadUser() 호출            loadUser() 처리 과정에서 OAuth2User를 반환            (6)번까지 끝내면 AbstractAuthenticationProcessingFilter에서 SuccessHandler의 onAuthenticationSuccess()을 호출한다.       기본적으로 리다이렉션하는 역할인데 커스텀해서 지정할 수 있다.            (6)번까지의 과정이 정상적으로 끝나지 않았다면 AbstractAuthenticationProcessingFilter에서 FailureHandler의 onAuthenticationFailure()을 호출한다.           여기까지 올바른 요청일 경우의 처리 과정이고 이외의 경우는 다음과 같다.      인증되지 않은 사용자가 인증이 필요한 URL에 접근하려 한다면 authenticationEntityPoint에서 예외 처리   인증된 사용자가 권한이 부족한 URL에 접근하려 한다면 accessDeniedHandler에서 예외 처리           인증 코드 요청   Spring Security와 OAuth2를 사용해서 자신이 등록한 kakao api의 인증 코드 api를 호출하려면 해당 역할을 하는 endpoint를 알아야 한다.   여기서 endpointsms Filter이고 해당 역할을 하는 Filter는 OAuth2AuthorizationRequestRedirectFilter이다.   이 필터에서 this.authorizationRequestResolver가 registrationID인 kakao 값으로 설정 정보를  조회한다.   인증 코드를 얻기 위해 호출할 API 주를 만들고 해당 주소로 리다이렉션한다.       Spring Security OAuth2 설정을 끝내고 브라우저 주소창에   http://localhost::8080/oauth2/authorization/kakao을 입력하면 카카오톡 로그인 페이지가 뜬다.   사용자가 로그인에 성공하면 카카오에 등록한 Callback URL인 redirect_uri가 호출된다.           Access Token 요청   code를 요청할 때 redirect_uri을 보내는데 redirect_uri를 어떻게 처리해서 access token을 얻어올 수 있을까?   직접 Controller에서 token을 얻는 API를 만드는 예제를 본 적이 있는데  프레임워크를 사용하고 있기 때문에 나는 프레임워크를 이용할 것이다.       Access token을 획득하는 역할의 Filter는 OAuth2LoginAuthenticationFilter이다.   OAuth2LoginAuthenticationToken 클래스 변수에 access token과 함께 kakao user 정보도 가지고 있다.           로그인 상태 처리   Spring Security는 기본적으로 세션 기반으로 동작한다.   그러나 stateless로 만들고 싶은 경우 OAuth2 인증 처리 후 실행되는 successHandler를 커스텀하면 된다.   이 방법은 현재 프로젝트에서 kakao라는 provider에 의존하는 문제가 있다.   이 의존 문제는 OAuth2UserService의 loadUser() 메소드에서 Map&lt;String, Object&gt; 타입으로   OAuth2 회원 정보 조회 API의 Response를 파싱하는 코드를 소셜에 맞게 변경해야 한다는 것이다.       이 문제는 CustomUserTypesOAuth2UserService를 사용하여 해결할 수 있다.   Custom User Type을 Map에 담아 파라미터로 넘겨서 사용하고 Map의 Key는 Client의 Registration ID로 설정하는 것이다.   설정은 다음과 같이 하면 된다.   @Override     protected void configure(HttpSecurity http) throws Exception {         http.authorizeRequests()             .anyRequest().authenticated()             .and()             .oauth2Client()             .authorizedClientService(authorizedClientService())             .and()             .oauth2Login()             .userInfoEndpoint()             .customUserType(KakaoOAuth2User.class, SOCIAL_TYPE)             .userService(oAuth2UserService())             .and()             .successHandler(authenticationSuccessHandler());     } }           저장된 인증 정보 사용   Spring Security는 인증을 하면 인증 정보를 SecurityContextHolder 클래스를 통해 메모리에 저장한다.   세션 키로 메모리에 저장된 인증 정보를 꺼내서 무언가 처리하고 싶다면 다음과 같이 사용하면 된다.               controller에서 매개변수로 받는 방법 @AuthenticationPrincipal OAuth2User oauth2User            코드에서 얻는 방법 Authentication auth = SecurityContextHolder.getContext().getAuthentication();           위 방법으로 JWT를 사용하지 않고 구현하려면 구현해야 하는 클래스도 많고 설정해야 하는 부분도 많으며, 문제점도 있다. 그래서 JWT를 함께 사용하는 예제가 많은데 그 이유에 대해서는 다음 게시글에서 확인할 수 있다.   https://hyerin6.github.io/2021-08-24/springsecurity(4)/   ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-24/springsecurity(3)/",
        "teaser": null
      },{
        "title": "Spring Security OAuth2.0에서 JWT를 사용하는 이유",
        "excerpt":"    Spring Security에 대한 포스팅은 다음 링크를 참고           Spring Security란?: https://hyerin6.github.io/2021-08-22/springsecurity(1)/            Spring Security 로그인 절차: https://hyerin6.github.io/2021-08-22/springsecurity(2)/            Spring Security OAuth2 (+ Kakao Login): https://hyerin6.github.io/2021-08-24/springsecurity(3)/             구현          Spring Security를 학습해보면서 Spring Security와 OAuth2.0을 사용하여 위와 같이 Kakao Login 기능을 구현해봤다.   Spring Security 세션에 별다른 설정 없이 진행한다면 사용자 정보를 출력해보는 것까지는 문제없이 구현할 수 있었다.   하지만 그 다음 인증 과정에서 문제가 많았다.       이렇게 직접 구현해보기 전에 RefreshToken을 DB에 저장해두고 AccessToken이 만료되면 RefreshToken으로 AccessToken을 재발급 받는   로그인 / 로그인 유지 과정을 Spring Security 프레임워크로 구현하려고 했으나 다음과 같은 문제점들이 생겼다.       ID/Password가 아닌 OAuth2로 로그인하는 과정은   AbstractAuthenticationProcessingFilter에서 OAuth2 로그인 과정을 호출한다.   상황에 맞게 AuthenticationProcessingFilter가 작동하는데 OAuth2 로그인으로 설정했기 때문에   OAuth2LoginAuthenticationFilter의 attemptAuthentication()에서 다음과 같은 인증 과정을 수행한다.       (1) DefaultOAuth2UserService (구현: kakaoOAuth2UserService) loadUser()에서 request로 받은 값들을 OAuth2User로 반환한다.  (2) OAuth2AuthorizedClientService (구현: KakaoOAuth2AuthorizedClientService) 위 loadUser()에서는 AccessToken과 User 정보만 받을 수 있고 RefreshToken은 OAuth2AuthorizedClientService 클래스에서 받을 수 있다.  (3) AuthenticationSuccessHandler (구현: KakaoAuthenticationSuccessHandler) 로그인 성공 후 처리를 진행한다.       문제점(1)  AccessToken은 ResourceServer를 구현해 Introspection으로 토큰에 대한 인증 과정을 수행해야 한다.   참고: https://www.oauth.com/oauth2-servers/token-introspection-endpoint/          access_token은 Bearer 토큰 형식으로 단순히 암호화된 문자열이다.   Bearer 토큰으로 리소스 서버에 리소스를 요청하면 해당 토큰이 유효한지, 토큰 인증한 회원이 누구인지 인증서버에 추가 확인하는 과정이 필요하다.   이러한 토큰을 opaque token 이라고 한다.       access_token 인증 과정의 번거로움을 보완하기 위해 JWT 토큰 사용을 고려해볼 수 있다.   JWT는 JSON String이 암호화된 문자열로 토큰 자체에 특정한 정보를 세팅할 수 있다는 것이 특징이다.   회원의 id나 인증에 필요한 정보를 포함시킬 수 있기 때문에 Bearer 토큰처럼 회원 확인을 위해   인증 서버를 한번 더 거칠 필요가 없다.   JWT를 사용하면 다음과 같은 인증 과정을 갖는다.          문제점(2)  Spring Security 프레임워크를 사용해서 브라우저를 통해 발급받은 Kakao AccessToken을 브라우저를 통해서가 아닌   RestAPI로(ex.postman을 사용해서 헤더에 access token을 담아 요청하는 경우) 사용하는 경우 인증이 안된다.       문제점(3)  Spring Security에서 RefreshToken을 저장하는 방법은 inMemory, JDBC 두 가지이다.   JDBC에 저장하는 토큰 관리 방법은 다음과 같은 테이블을 만들고 Spring Security에서 정의한대로 구현해야 한다.       create table IF NOT EXISTS oauth_client_details (   client_id VARCHAR(256) PRIMARY KEY,   resource_ids VARCHAR(256),   client_secret VARCHAR(256),   scope VARCHAR(256),   authorized_grant_types VARCHAR(256),   web_server_redirect_uri VARCHAR(256),   authorities VARCHAR(256),   access_token_validity INTEGER,   refresh_token_validity INTEGER,   additional_information VARCHAR(4096),   autoapprove VARCHAR(256) );       처음 계획한대로 Spring Security를 사용해서 RefreshToken을 DB에 저장하고   로그인이 필요한 API마다 AuthorizationServer(Kakao)에 토큰의 유효성을 검사하는 방식까지   구현하려고 했으나 너무 많은 클래스를 구현해야 하고 Spring Security가 어떻게 동작하는지 알아보기 위해   시작한 구현이기 때문에 이정도에서 만족하고 OAuth2와 JWT를 사용한 로그인 방식으로 변경했다.       이번주부터는 Spring Security를 사용하지 않고 JWT를 사용한 Kakao 로그인을 구현할 예정이다.         참고          https://daddyprogrammer.org/post/1287/spring-oauth2-authorizationserver-database/            https://daddyprogrammer.org/post/1754/spring-boot-oauth2-resourceserver/            https://www.oauth.com/oauth2-servers/token-introspection-endpoint/           ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-08-26/springsecurity(4)/",
        "teaser": null
      },{
        "title": "로그인한 User 정보는 어디에서 가져올까?",
        "excerpt":"    spring security를 사용하지 않고 Kakao API와 JWT를 이용해 직접 회원가입, 로그인을 구현했다.   유저 정보가 필요한 API들이 많은데 로그인에 성공한 유저의 정보는 어떻게 가져와야할까?         로그인한 정보 가져오는 방법   1. 로그인에 성공할 때마다 DB에서 조회하기   JwtInterceptor 에서 헤더의 Jwt AccessToken을 파싱해서 userId 값을 가져올 수 있다.   userId 값으로 DB에서 유저 정보를 가져올 수 있는데 그렇다면 Interceptor에서  어디에 저장하면   Controller나 Service 레이어에서 유저 정보를 사용할 수 있을까?   ThreadLocal 변수를 선언하면 멀티 스레드 환경에서 각 스레드마다 독립적인 변수를 가지고,   get(), set() 메소드를 통해 값에 대해 접근할 수 있다.   즉, Java의 ThreadLocal을 사용하면 Interceptor에서 유저 정보를 저장하고 원하는 곳에서 꺼내 사용할 수 있다.          ThreadLocal 변수 선언   public class UserContext { \t \tpublic static final ThreadLocal&lt;User&gt; CONTEXT = new ThreadLocal&lt;&gt;();  \tpublic static User getContext() { \t\treturn UserContext.USER_CONTEXT.get(); \t} \t }          ThradLocal 값 저장   // JwtInterceptor에서 조회 및 저장  User user = userService.getUser(userId); UserContext.CONTEXT.set(user);          ThreadLocal 변수 사용   User user = UserContext.getContext();         그러나 위 코드에 아쉬운 점이 있다.           User의 userId 값만 필요한 API가 있기 때문에 JwtInterceptor (사용자자의 요청마다) 에서       매번 DB에서 User 엔티티를 조회하는 것은 불필요하다.            User 정보가 필요한 곳에서 User user = UserContext.getContext(); 코드가 반복된다.           위 두 문제를 해결하기 위해 다음과 같은 방법을 적용해봤다.           2. 커스텀 어노테이션 만들기   우선 어노테이션을 만든다.   @Target(ElementType.PARAMETER) @Retention(RetentionPolicy.RUNTIME) public @interface Authenticationprincipal { }        어노테이션을 통해 사용자 정보를 받기 위해   다음 HandlerMethodArgumentResolver 인터페이스를 구현해야 한다.          supportsParameter 메서드를 거쳐 resolverArgument 메서드에서 헤더값을 꺼내와 다음과 같이 유저 정보를 리턴할 수 있다.   이번 프로젝트에서 구현한 코드는 다음과 같다.       @RequiredArgsConstructor @Component public class AuthenticationArgumentResolver implements HandlerMethodArgumentResolver {  \tprivate final JwtService jwtService;  \t@Override \tpublic boolean supportsParameter(MethodParameter parameter) { \t\treturn parameter.getParameterAnnotation(Authenticationprincipal.class) != null; \t}  \t@Override \tpublic Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, \t\tNativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception { \t\tString accessToken = HeaderUtil.getAccessToken(webRequest); \t\treturn jwtService.decode(accessToken); \t}  }           Spring Security에서는 User 정보를 어떻게 가져올까?   Spring Security 사용 시, 로그인한 유저 정보를 가져오는 방법은 다음과 같다.   // 방법 1 Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); User user = (User)authentication.getPrincipal();  // 방법 2 @GetMapping(\"/\") public String home(@AuthenticationPrincipal User user) { ... }      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-09-12/login-success/",
        "teaser": null
      },{
        "title": "자바 직렬화란?",
        "excerpt":"    프로젝트를 하던 중 직렬화가 필요한 순간이 많았는데 직렬화가 무엇인지,   왜 필요한지 어떤 주의사항들이 있는지 알아보고자 직접 예제를 통해 학습하고   이펙티브 자바 직렬화 부분을 참고했다.       자바 직렬화란?   자바 직렬화란 자바 시스템 내부에서 사용되는 객체 또는 데이터를 외부의 자바 시스템에서도 사용할 수 있도록   바이트 형태로 (byte) 데이터를 반환하는 기술과 바이트로 변환된 데이터를 다시 객체로 변환(역직렬화)하는 기술이다.   직렬화된 객체는 다른 VM에 전송하거나 디스크에 저장한 후 나중에 역직렬화할 수 있다.       직렬화 / 역직렬화 하는 법   자바 기본(primitive) 타입과 java.io.Serializable 인터페이스를 상속받은 객체는 직렬화 할 수 있는 기본 조건을 가진다.   역직렬화는 다음과 같은 조건을 만족해야 한다.      직렬화 대상이 된 객체의 클래스가 클래스 패스에 존재해야 하며 import 되어 있어야 한다.   자바 직렬화 대상 객체는 동일한 serialVersionUID 를 가지고 있어야 한다.          serialVersionUID 가 자동 생성되긴 하지만 클래스의 구조 정보를 이용하여 생성되기 때문에     클래스의 구조가 달라지면 역직렬화 과정에서 예상하지 못한 InvalidClassException을 유발할 수 있음을 주의해야 한다.          serialVersionUID가 없으면?   Q. User를 직렬화 한 데이터를 저장해두고, User에 새로운 필드를 추가하고 기존에 저장해둔 데이터를 역직렬화하면 잘 될까?   name, age 필드만 있던 User 객체를 직렬화하고 email 필드를 추가한 후 역직렬화를 해봤다.   serialVersionUID를 명시한 경우와 그렇지 않은 경우 어떤 차이가 있을까?          serialVersionUID를 명시한 경우      email 필드를 추가하고 역직렬화를 했지만 User 객체의 역직렬화는 잘 진행되어   email 필드는 null로 출력되었다.          serialVersionUID를 명시하지 않은 경우      InvalidClassException가 발생하면서 역직렬화가 진행되지 않았다.               테스트 코드: https://github.com/hyerin6/TIL/tree/main/Mentoring/SerializationQuiz            직렬화 주의사항: https://hyerin6.github.io/2021-09-13/serialize(2)/           ","categories": [],
        "tags": [],
        "url": "/2021-09-13/serialize(1)/",
        "teaser": null
      },{
        "title": "[Effective Java] 직렬화가 품고 있는 위험",
        "excerpt":"    직렬화 관련 게시글     직렬화란? : https://hyerin6.github.io/2021-09-13/serialize(1)/         85. 자바 직렬화의 대안   직렬화의 근본적인 문제는 공격 범위가 넓고 지속적으로 더 넓어져 방어하기 어렵다는 점이다.   ObjectInputStream의 readObject 메서드를 호출하면서 객체 그래프가 역직렬화되기 때문이다.   readObject 메서드는 클래스패스 안의 거의 모든 타입의 객체를 만들어낼 수 있는 생성자다.   바이트 스트림을 역직렬화하는 과정에서 이 메서드는 그 타입들 안의 모든 코드를 수행할 수 있다.   즉 그 타입들의 코드 전체가 공격 범위에 들어간다는 뜻이다.   역직렬화 과정에서 호출되어 잠재적으로 위험한 동작을 수행하는 메서드들이 있고 (이를 가젯이라고 부른다.)   가젯을 함께 사용하여 가젯 체인을 구성해 공격할 수도 있다.   또한 역직렬화에 시간이 오래 걸리는 짧은 스트림을 역직렬화하는 것만으로도 서비스 거부 공격에 쉽게 노출될 수 있다.   이런 스트림을 역직렬화 폭탄이라고 한다.               HashSet과 문자열로 만든 역직렬화 폭탄 예시       static byte[] bomb() { \tSet&lt;Object&gt; root = new HashSet&lt;&gt;(); \tSet&lt;Object&gt; s1 = root; \tSet&lt;Object&gt; s2 = new HashSet(); \tfor(int i = 0; i &lt; 100; ++i) { \t\tSet&lt;Object&gt; t1 = new HashSet&lt;&gt;(); \t\tSet&lt;Object&gt; t2 = new HashSet&lt;&gt;(); \t\tt1.add(\"foo\"); // t1과 t2를 다르게  \t\ts1.add(t1); s2.add(t2); \t\ts2.add(t1); s2.add(t2); \t\ts1 = t1; \t\ts2 = t2; \t} \treturn serialize(root); }                   이 객체 그래프는 201개의 HashSet 인스턴스로 구성되며, 각각 3개 이하의 객체 참조를 갖는다.   스트림의 전체 크기는 5744바이트지만 역직렬화는 끝나지 않을 것이다.       문제는 HashSet 인스턴스를 역직렬화하려면 그 원소들의 해시코드를 계산해야 하는 것이다.   반복문에 의해 이 구조의 깊이는 100단계까지 만들어지고 이 HashSet을 역직렬화하려면   hashCode 메서드를 2^100번 넘게 호출해야 한다.   역직렬화가 끝나지 않는 것도 문제고 잘못되었다는 신호조차 주지 않는 것도 문제다.   이 코드는 몇 개의 객체만 생성해도 스택 깊이 제한에 걸린다.           86. Serializable을 구현할지 신중히 결정하자   직렬화할 수 있게 하려면 implements Serializable만 덧붙이면 된다.   Serializable을 구현하면 릴리스한 뒤에는 수정하기 어렵다.   클래스가 Serializable을 구현하면 직렬화된 바이트 스트림 인코딩(직렬화 형태)도 하나의 공개 API가 된다.   기본 직렬화 상태에서는 클래스의 private와 package-private 인스턴스 필드들마저   API로 공개되는 것이다. (캡슐화가 깨진다.)           문제1: SerialVersionUID   직렬화가 클래스 개선을 방해하는 예는 대표적으로 스트림 고유 식별자, 즉 직렬 버전 UID를 들 수 있다.   모든 직렬화된 클래스는 고유 식별 번호를 부여받는다.   이 번호를 명시하지 않으면 시스템이 런타임에 암호 해시 함수를 적용해 자동으로 클래스 안에 생성해 넣는다.   이 값을 생성하는 데는 클래스 이름, 구현 인터페이스, 컴파일러가 자동으로 넣은 클래스 멤버들이 고려된다.   그래서 나중에 이들 중 하나라도 수정한다면 직렬 버전 UID 값도 변한다.   즉 자동 생성되는 값에 의존하면 쉽게 호환성이 깨져버려 런타임에 InvalidClassException이 발생할 것이다.           문제2: 역직렬화는 숨은 생성자다.   두 번째 문제는 버그와 보안 구멍이 생길 위험이 높아진다는 점이다.   객체는 생성자를 사용해 만드는 게 기본인데 직렬화는 우회하는 객체 생성 기법인 것이다.   역직렬화는 일반 생성자의 문제가 그대로 적용되는 숨은 생성자다.   기본 역직렬화를 사용하면 불변식 깨짐과 허가되지 않은 접근에 쉽게 노출된다는 뜻이다.           문제3: 신버전 릴리스할 때 테스트 추가   세 번째 문제는 해당 클래스의 신버전을 릴리스할 때 테스트할 것이 늘어난다는 점이다.   직렬화 가능 클래스가 수정되면 신버전 인스턴스를 직렬화한 후 구버전으로 역직렬화할 수 있는지   그 반대도 가능한지 검사해야 한다.           주의1: 상속용으로 설계된 클래스는 대부분 Serializable을 구현하면 안 되며, 인터페이스도 대부분 Serializable을 확장해서는 안 된다.   이 규칙을 따르지 않으면, 그런 클래스를 확장하거나 그런 인터페이스를 구현하는 이에게 부담을 주게 된다.   예) 상속용으로 설계된 클래스 중 Serializable을 구현한 예로 Throwable과 Component가 있다.           주의2: 인스턴스 필드 값 중 불변식을 보장해야 할 게 있다면 반드시 하위 클래스에서 finaliza 메서드를 재정의하지 못하게 해야 한다.   finalize 메서드를 자신이 재정의하면서 final로 선언하면 된다.   이렇게 하지 않으면 finalizer 공격을 당할 수 있다.           주의3: 인스턴스 필드 중 기본값(정수 0, boolean false, 객체 null)으로 초기화되면 위배되는 불변식이 있다면 readObjectNoData 메서드 추가   기존의 직렬화 가능 클래스에 직렬화 가능 상위 클래스를 추가하는 드문 경우를 위한 메서드다.           주의4: 내부 클래스는 직렬화를 구현하지 말아야 한다.   내부 클래스에는 바깥 인스턴스의 참조와 유효 범위 안의 지역변수 값들을 저장하기 위해 컴파일러가 생성한 필드들이 자동으로 추가된다.   내부 클래스에 대한 기본 직렬화 형태는 분명하지가 않다.   단, 정적 멤버 클래스는 Serializable을 구현해도 된다.       ","categories": ["Effective Java","Java"],
        "tags": ["java"],
        "url": "/2021-09-13/serialize(2)/",
        "teaser": null
      },{
        "title": "No Offset Paging 구현",
        "excerpt":"    offset 기반의 페이징   페이지 번호와 페이지 사이즈 기반으로 구현한 기존의 페이징 방식은   다음과 같이 페이지 번호가 하단에 출력된다.             offset : 페이지 번호   limit : 페이지 사이즈           No Offset (Cursor based Pagination) 기반의 페이징   SNS 에서는 이 방식 보다는 다음과 같이 무한 스크롤을 가능하게 하는 No Offset 방식이 더 어울리며   No Offset 방식은 페이지 번호를 지정하는 방식보다 더 빠르다.          위 이미지를 보면 페이지 번호를 클릭해서 페이지가 넘어가는 게 아니라   스크롤이 페이지 끝에 닿았을 때 새로운 페이지가 로딩되는 것을 확인할 수 있다.           Q. 페이지 번호가 없는 방식을 No Offset이라 하는데 왜 더 빠를까?   A. 최신 컨텐츠가 우선으로 조회되어야 하는데 페이지 번호를 지정하는 쿼리는   앞에서 읽었던 행을 다시 읽어야 하기 때문에 뒤로 갈수록 느려진다.   No Offset 방식은 조회 시작 부분을 인덱스로 빠르게 찾아 매번 첫 페이지만 읽는다.           구현 코드      PostService   @Transactional(readOnly = true) public List&lt;Post&gt; getPosts(Long userId, Long lastPostId, Pageable pageable) { \tif (lastPostId &gt; 0) { \t\treturn postRepository.findByUserIdAndIdLessThan(userId, lastPostId, pageable); \t}  \treturn postRepository.findByUserId(userId, pageable); }       처음 조회하는 경우 lastPostId가 없기 때문에   findByUserId() 메서드를 통해 최신 게시글을 조회한다.   이후 호출되는 API 부터는 lastPostId 를 기준으로 조회한다.          PostRepository   @Repository public interface PostRepository extends JpaRepository&lt;Post, Long&gt; {  \tList&lt;Post&gt; findByUserId(Long userId, Pageable Pageable);  \tList&lt;Post&gt; findByUserIdAndIdLessThan(@Param(\"userId\") Long userId, @Param(\"id\") Long lastPostId, Pageable Pageable);  \t@Query(value = \"SELECT p\" \t\t+ \" FROM Post p\" \t\t+ \" JOIN Follow f ON p.user.id = f.follower.id\" \t\t+ \" WHERE p.user.id = :userId\" \t\t+ \" AND  f.follower.id = :userId\") \tList&lt;Post&gt; findByJoinFollow(@Param(\"userId\") Long userId, Pageable pageable);  \t@Query(value = \"SELECT p\" \t\t+ \" FROM Post p\" \t\t+ \" JOIN Follow f ON p.user.id = f.follower.id\" \t\t+ \" WHERE p.user.id = :userId\" \t\t+ \" AND  f.follower.id = :userId\" \t\t+ \" AND p.id &lt; :lastPostId\") \tList&lt;Post&gt; findByJoinFollowAndLastIdLessThan(@Param(\"userId\") Long userId, @Param(\"lastPostId\") Long lastPostId, Pageable pageable); }       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-09-14/timeline/",
        "teaser": null
      },{
        "title": "ElasticSearch 란?",
        "excerpt":"    ElasticSearch 란?   ElasticSearch는 Apache Lucene (루씬) 기반의 Java 오픈소스 분산 검색 엔진이다.   ElasticSearch를 통해 루씬 라이브러리를 단독으로 사용할 수 있게 되었고,   많은 양의 데이터를 거의 실시간으로 저장, 검색, 분석할 수 있다.   ElasticSearch는 검색을 위해 단독으로 사용되기도 하며, ELK 스택으로도 사용한다.       ELK 스택이란?             Logstash   다양한 소스(DB, csv 파일 등)의 로그 또는 트랜잭션 데이터를   수집, 집계, 파싱하여 ElasticSearch로 전달          ElasticSearch   logstash로부터 받은 데이터를 검색 및 집계하여 필요한 정보 획득          Kibana   ElasticSearch의 빠른 검색을 통해 데이터를 시각화 및 모니터링         ElasticSearch 특징   (1) 오픈소스   ES는 오픈소스로 배포된 프로젝트이다.       (2) 분산 시스템, 확장성   루씬을 사용한 검색엔진은 ES 뿐만이 아니다.   Solr도 루씬 기반의 오픈소스 검색엔진이다.   그러나 Solr는 처음부터 분산 시스템을 염두해두고 개발했기 때문에   주키퍼(Zookeeper) 같은 별도의 코디네이터가 필요하다.       ES는 네트워크 상에 있는 노드들과 바인딩돼 클러스터를 구성할 수 있다.   샤드를 기반으로 색인 데이터를 관리하고 운영 중에도 노드가 추가되면 샤드를 새로운 노드로 적절히 재분배하여 유지하기 때문에 쉽게 스케일 아웃이 (확장) 가능하다.       (3) 고가용성   샤드는 기본적으로 하나 이상의 복제본을 중복되지 않는 서로 다른 노드에 배치한다.   따라서 시스템 운영 중 특정 노드가 다운되더라도 데이터 유실 없이 동일한 결과를 얻을 수 있기 때문에 높은 가용성을 제공한다.       (4) 실시간 검색   ES는 실시간 검색 시스템이다.   클러스터가 실행되는 동안 계속해서 데이터가 입력된다. (검색 엔진에서 index, 색인이라고 부른다.)   그와 동시에 실시간에 가까운 속도로 색인된 데이터의 검색과 분석이 가능하다.       (5) 전문(full-text) 검색 엔진   루씬은 기본적으로 inverted file index 라는 구조로 데이터를 저장한다.   이는 루씬을 기반으로 만들어진 ES도 동일하다.   이런 특성을 전문 검색이라고 한다.       (6) JSON 문서 기반   ES는 문서 기반으로 정보를 저장하기 때문에 직관적이다.   쿼리문과 쿼리에 대한 결과 모두 JSON이기 때문에 사용자 입장에서는 직관적이라는 장점이 있다.       (7) RESTful  API   ES는 Rest API를 기본으로 지원하며   모든 데이터의 조회, 삭제, 입력, 수정을 HTTP 프로토콜 메소드를 통해 처리한다.         ElasticSearch와 관계형 DB 비교             Elasticsearch 7.0부터 Type이 완전히 사라졌으며,     현재 Index가 RDBMS의 Table과 Database 역할을 한다고 생각하면 된다.          ElasticSearch 아키텍처          (1) 클러스터   클러스터란 ES에서 가장 큰 시스템 단위를 의미하며,   최소 하나 이상의 노드로 이루어진 노드들의 집합이다.   서로 다른 클러스터는 데이터의 접근, 교환이 불가능한 독립적인 시스템으로 유지되며   여러 대의 서버가 하나의 클러스터를 구성할 수 있고   한 서버에 여러 개의 클러스터가 존재할 수도 있다.       (2) 노드   ES를 구성하는 하나의 단위 프로세스를 의미한다.   그 역할에 따라 Master-eligible, Data, Ingest, Tribe 노드로 구분할 수 있다.       (3) 인덱스, 샤드, 복제 (index, shard, replica)   ES에서 index는 RDBMS에서 database와 대응하는 개념이다.   shard와 replica는 ES에만 존재하는 개념이 아니라 분산 데이터베이스 시스템에도 존재하는 개념이다.       샤딩(sharding)은 데이터를 분산해서 저장하는 방법을 의미한다.   즉 ES에서 스케일 아웃을 위해 index를 여러 shard로 쪼갠 것이다.   기본적으로 1개가 존재하며 검색 성능 향상을 위해 클러스터의 샤드 개수를 조정하는 튜닝을 하기도 한다.       replica는 또 다른 형태의 shard라고 볼 수 있다.   노드를 손실했을 경우 데이터의 신뢰성을 위해 샤드들을 복제하는 것이다.           ElasticSearch는 왜 빠를까?   역색인(inverted index) 덕분이다.   인덱스는 책 앞에 삽입되는 목차,   역색인은 책 뒤에 삽입되는 키워드로 찾아볼 수 있도록 구성한 부분이라고 생각하면 된다.   ES는 텍스트를 파싱해서 검색어 사전을 만들고 inverted index 방식으로 텍스트를 저장한다.   텍스트를 파싱하고 단어, 대소문자, 유사어 체크 등의 작업을 통해 저장하기 때문에   RDBMS보다 전문 검색에 빠른 성능을 보인다.         참고          https://www.elastic.co/kr/what-is/elasticsearch            https://hsunnystory.tistory.com/175            https://www.elastic.co/guide/kr/elasticsearch/reference/current/gs-basic-concepts.html            https://victorydntmd.tistory.com/308            https://twofootdog.tistory.com/53            https://www.slideshare.net/kjmorc/ss-80803233          ","categories": ["Elasticsearch"],
        "tags": ["elasticsearch"],
        "url": "/2021-09-17/es/",
        "teaser": null
      },{
        "title": "JPA JOIN 어떻게 할까?",
        "excerpt":"    타임라인 구현   SNS 타임라인은 내가 구독하고 있는 사용자들의 최신 게시글 목록을 의미한다.   이전에 타임라인 페이징을 어떻게 구현할지 아래의 게시글에서 이야기 했었는데,   https://hyerin6.github.io/2021-09-14/timeline/   이번엔 JPA JOIN을 어떻게 작성했는지 자세히 알아보자.       엔티티는 다음과 같다.       User   @Entity public class User implements Serializable {  \tprivate static final long serialVersionUID = 1L;  \t@Id \t@GeneratedValue(strategy = GenerationType.IDENTITY) \tprivate long id;  \tprivate String userId;  \tprivate String name;  \tprivate String email;  \tprivate String profile;  \t@CreatedDate \t@Column(updatable = false, nullable = false) \tprivate LocalDateTime createdAt;  \t@LastModifiedDate \tprivate LocalDateTime updatedAt; }       Follow   @Entity public class Follow {  \t@Id \t@ManyToOne(fetch = FetchType.LAZY) \t@JoinColumn(name = \"follower_id\") \tprivate User follower;  \t@Id \t@ManyToOne(fetch = FetchType.LAZY) \t@JoinColumn(name = \"following_id\") \tprivate User following;  \t@CreatedDate \t@Column(updatable = false, nullable = false) \tprivate LocalDateTime createdAt;  \t@LastModifiedDate \tprivate LocalDateTime updatedAt;  \t@Data \t@NoArgsConstructor \t@AllArgsConstructor \tpublic static class PK implements Serializable {  \t\tprivate static final long serialVersionUID = 1L;  \t\t@JoinColumn(name = \"follower_id\") \t\tprivate User follower;  \t\t@JoinColumn(name = \"following_id\") \t\tprivate User following; \t}  }       Post   @Entity public class Post { \t@Id \t@GeneratedValue(strategy = GenerationType.IDENTITY) \tprivate long id;  \tprivate String content;  \t@ManyToOne(fetch = FetchType.LAZY) \t@JoinColumn(name = \"user_id\") \tprivate User user;  \t@CreatedDate \t@Column(updatable = false, nullable = false) \tprivate LocalDateTime createdAt;  \t@LastModifiedDate \tprivate LocalDateTime updatedAt;  \tpublic void modifyContent(String content) { \t\tthis.content = content; \t} }       JPA 연관관계를 사용하면 불필요한 조회가 발생하고   N+1 문제가 발생할 수 있기 때문에 @OneToMany는 사용하지 않았다.       왜 N+1 문제가 발생하는지, JPA 연관관계를 사용하면 어떤 단점들이 있는지 먼저 알아보자.         구현 방법1: JPA 연관관계 사용하는 경우   만약 JPA 연관관계로 조회하고자 User를 다음과 같이 구현했다고 가정해보자.   @OneToMany(mappedBy = \"user\") private List&lt;Post&gt; posts = new ArrayList&lt;&gt;();  @OneToMany(mappedBy = \"follower\") private List&lt;Follow&gt; followers = new ArrayList&lt;&gt;();  @OneToMany(mappedBy = \"following\") private List&lt;Follow&gt; followings = new ArrayList&lt;&gt;();       위와 같이 구현했다면 User 엔티티 객체만으로 Follow와 Post를 가져올 수 있다. 그러나 내부적으로는 다음과 같은 쿼리가 날아가는 것이다.   -- 팔로우 하는 모든 대상 구하기 SELECT * FROM follow WHERE follow.follower_user_id = ?  -- 첫 번째 팔로우 유저의 정보, 게시글 가져오기 SELECT * FROM user WHERE user.id = ? SELECT * FROM post WHERE post.user_id = ?  -- 두 번째 팔로우 유저의 정보, 게시글 가져오기 SELECT * FROM user WHERE user.id = ? SELECT * FROM post WHERE post.user_id = ?  -- N 번째 팔로우 유저의 정보, 게시글 가져오기  SELECT * FROM user WHERE user.id = ? SELECT * FROM post WHERE post.user_id = ?       내가 팔로우하고 있는 사용자의 정보와 게시글을 조회하기 때문에   구독하는 유저 * 2 만큼 쿼리가 날아간다.         N+1 문제 발생   쿼리 1번으로 N건을 가져왔는데,   관련 컬럼(Follow, Post)을 얻기 위해 쿼리를 N번 추가 수행하는 N+1 문제가 발생했다.         N+1 문제는 왜 발생하는걸까?   jpaRepository에 정의한 인터페이스 메서드를 실행하면   JPA는 메서드 이름을 분석해서 JPQL을 생성하여 실행하게 된다.   JPQL은 SQL을 추상화한 객체지향 쿼리 언어로서 특정 SQL에 종속되지 않고   엔티티 객체와 필드 이름을 가지고 쿼리를 한다.       그렇기 때문에 JPQL은 findAll()이란 메소드를 수행하면   해당 엔티티를 조회하는 select * from User 쿼리만 실행하게 되는것이다.   JPQL 입장에서는 연관관계 데이터를 무시하고 해당 엔티티 기준으로 쿼리를 조회한다.   때문에 연관된 엔티티 데이터가 필요한 경우, FetchType으로 지정한 시점에 조회를 별도로 호출하게 된다.         N+1 문제 해결 방법   N+1 문제를 해결할 수 있는 방법은 3가지가 있다.   특징과 문제점에 대해 알아보자.      Fetch join   @EntityGraph   BatchSize       해결방법1: Fetch join   Fetch join은 JPQL로 작성해야 한다.   타임라인 구현은 다음과 같은 방식이다.   @Query(value = \"SELECT p\" +         \" FROM Post p\" +         \" JOIN FETCH p.user u\" +         \" JOIN FETCH u.followers f\" +         \" WHERE f.follower.id = :userId AND p.id &lt; :lastPostId\") List&lt;Post&gt; findByFetchJoin(@Param(\"memberId\") Long memberId, @Param(\"lastPostId\") Long lastPostId, Pageable pageable);          Fetch join은 원하는 조건의 데이터를 한 번에 가져오기 때문에 내가 원하지 않는 추가 쿼리는 발생하지 않는다.          INNER JOIN으로 호출되는 것이 특징이다.               Fetch join은 연관된 테이블끼리만 사용할 수 있기 때문에 JPA 연관관계를 사용해야 하고 Follow와 Post 테이블은 연관관계가 없어 User 까지 같이 조인해야 합니다.                    설정해놓은 FetchType을 사용할 수 없다. Fetch Join을 사용하게 되면 데이터 호출 시점에 모든 연관 관계의 데이터를 가져오기 때문에 FetchType을 Lazy로 해놓는것이 무의미하다.                    Fetch Join 과 Pageable 함께 사용하면 LIMIT 쿼리가 제대로 적용되지 않는다. 하나의 쿼리로 조회하는 것이기 때문에 페이징 단위로 데이터를 가져오지 않는다.                    DB 에서 Fetch Join 한 결과물을 모두 가져온 후 애플리케이션 메모리에서 직접 골라내기 때문에 데이터 수가 많다면 OutOfMemory 에러가 발생할 가능성이 높다.             해결방법2: EntityGraph   @EntityGraph의 attributePaths에 쿼리 수행시 바로 가져올 필드명을 지정하면   Lazy가 아닌 Eager 조회로 가져온다.   EntityGraph 상에 있는 Entity들의 연관관계 속에서 필요한 엔티티와 컬렉션을 함께 조회하려고 할때 사용한다.   @EntityGraph(attributePaths = \"post\")          Fetch join과 동일하게 JPQL을 사용하여 query 문을 작성하고 필요한 연관관계를 EntityGraph에 설정하면 된다.          Fetch join과 다른 점은 OUTER JOIN으로 실행된다.           해결방법3: FetchMode.SUBSELECT   이 방법은 쿼리 한번으로 해결하는 것은 아니고 두번의 쿼리로 해결하는 방법이다.   연관관계의 데이터를 조회할 때 서브 쿼리로 함께 조회하는 방법이다.   @Fetch(FetchMode.SUBSELECT) @OneToMany(mappedBy = \"following\", fetch = FetchType.EAGER) private List&lt;Follow&gt; followings = new ArrayList&lt;&gt;();          즉시로딩으로 설정하면 조회시점에, 지연로딩으로 설정하면 지연로딩된 엔티티를 사용하는 시점에 위의 쿼리가 실행된다.          모두 지연로딩으로 설정하고 성능 최적화가 필요한 곳에는 JPQL 페치 조인을 사용하는 것이 추천되는 전략이다.           해결방법4: BatchSize   하이버네이트가 제공하는 org.hibernate.annotations.BatchSize 어노테이션을 이용하면   연관된 엔티티를 조회할 때 지정된 size 만큼 SQL의 IN절을 사용해서 조회한다.       @BatchSize(size=5) @OneToMany(mappedBy = \"following\", fetch = FetchType.EAGER) private List&lt;Follow&gt; followings = new ArrayList&lt;&gt;();       즉시로딩이므로 User를 조회하는 시점에 Follow를 같이 조회한다.   @BatchSize가 있으므로 Follow의 row 갯수만큼 추가 SQL을 날리지 않고,   조회한 User 의 id들을 모아서 SQL IN 절을 날린다.       성능적으로 많이 개선되었고 Pageable도 함께 사용할 수 있는 방법이다.   그런데 만약 followings 의 사이즈가 엄청나게 많다면?   성능적인 문제를 해결하기 위해 IN 쿼리를 나눠 호출해야 하는 문제가 발생한다.       N+1 문제와 해결 방법은 JPA 연관관계를 사용해서 발생한 문제들이다.   JPA 연관관계로만 해결하려고 하지 말고 JPQL로 Join, Limit 조건을 직접 작성해보자.          구현 방법2: JPQL JOIN 쿼리 직접 작성하기   \t@Query(value = \"SELECT p\" \t\t+ \" FROM Post p\" \t\t+ \" JOIN Follow f ON p.user.id = f.following.id\" \t\t+ \" WHERE f.follower.id = :userId\") \tList&lt;Post&gt; findByJoinFollow(@Param(\"userId\") Long userId, Pageable pageable);  \t@Query(value = \"SELECT p\" \t\t+ \" FROM Post p\" \t\t+ \" JOIN Follow f ON p.user.id = f.following.id\" \t\t+ \" WHERE f.follower.id = :userId\" \t\t+ \" AND p.id &lt; :lastPostId\") \tList&lt;Post&gt; findByJoinFollowAndLastIdLessThan(@Param(\"userId\") Long userId,  \t@Param(\"lastPostId\") Long lastPostId, Pageable pageable);       실제 쿼리는 다음과 같다.       select         post0_.\"id\" as id1_4_,         post0_.\"content\" as content2_4_,         post0_.\"created_at\" as created_3_4_,         post0_.\"updated_at\" as updated_4_4_,         post0_.\"user_id\" as user_id5_4_      from         \"post\" post0_      inner join         \"follow\" follow1_              on (                 post0_.\"user_id\"=follow1_.\"following_id\"             )      where         follow1_.\"follower_id\"=?      order by         post0_.\"id\" desc limit ?           참고      https://incheol-jung.gitbook.io/docs/q-and-a/spring/n+1   https://jojoldu.tistory.com/165   https://tech.wheejuni.com/2018/06/16/jpa-cartesian/      ","categories": ["Spring","JPA"],
        "tags": ["spring","jpa"],
        "url": "/2021-09-17/jpa-join/",
        "teaser": null
      },{
        "title": "JUnit5 테스트 코드 작성해보자 (+BDD)",
        "excerpt":"    JUnit 관련 포스팅 참고      JUnit Test란?   JUnit5 시작하기          테스트 코드를 작성하려다 BDDMockito 라이브러리에 대해 알게 되었고   라이브러리를 활용하여 테스트를 작성하는 법을 알아봤다.     먼저 개발하면서 자주 듣는 TDD와 BDD가 뭔지 알아보자.         TDD 란?   TDD (Test Driven Development) 는 테스트가 개발을 주도한다는 의미이다.   테스트를 먼저 만들고 통과하는 기능을 개발한다.         BDD 란?   BDD (Behavior Driven Development) 는 Danial Terhorst-North와 Charis Matts가 착안한   BDD Introducing - Dan north &amp; associates 방법론으로 BDD의 모든 근간은 TDD에서 착안되었기 때문에   TDD가 추구하는 가치와 크게 다르지 않다.       Danial Terhorst-North는 TDD를 작성하다가 코드 분석과 복잡성으로 인해   누군가 나에게 “이 코드는 ~하게 짜여진 코드야” 라고 말해줬으면 좋겠다고 생각했다고 한다.       그래서 행동 중심 개발, 행동에 기반하여 TDD를 수행하기로 생각한 것이다.   간단하게 말하면 BDD는 애플리케이션이 어떻게 행동해야 하는지에 대한 공통된 이해를 구성하는 방법이다.       TDD, BDD 많은 내용이 있지만 테스트 작성을 위해 BDDMockito 라이브러리 사용법이 대해 자세히 알아보자.         BDD 행동   (1) Narrative (논리적인 일련의 사건)   (2) Given/When/Then       모든 테스트 문장은 Narrative 하게 되어야 한다.   즉 코드보다 인간의 언어와 유사하게 구성되어야 한다.       모든 테스트 문장은 Given/When/Then 으로 나눠서 작성할 수 있어야 한다.          Given            테스트를 위해 주어진 상태       테스트 대상에게 주어진 조건       테스트가 동작하기 위해 주어진 환경                  When            테스트 대상에게 가해진 어떠한 상태       테스트 대상에게 주어진 어떤 조건       테스트 대상의 상태를 변경시키기 위한 환경                  Then            앞선 과정의 결과               어떤 상태에서 출발 (given)하여 어떤 상태의 변화를 가했을 때 (when)   기대하는 어떤 상태가 되어야 한다.         BDDMockito를 이용한 BDD   주석을 이용하여 Given/When/Then 구조를 나눈 테스트 코드를 많이 봤는데   BDDMockito를 사용하는 방법도 있다.       BDDMockito란 Mockito 라이브러리 내에 존재하는 BDDMockito 클래스를 말하며   BDD 지향적인 개발을 mockito에서 API 형태로 제공한다.           Mockito vs. BDDMockito   순수 Mockito에서 BDD의 Given/When/Then을 위해서   다음과 같이 When() 메서드와 thenReturn()을 이용하고 verify() 구문을 이용해 검증한다.       LinkedList mockedList = mock(LinkedList.class);  // stubbing when(mockedList.get(0)).thenReturn(\"first\"); when(mockedList.get(1)).thenThrow(new RuntimeException());  System.out.println(mockedList.get(0)); // first System.out.println(mockedList.get(1)); // Runtime exception 발생 System.out.println(mockedList.get(10)); // null  verify(mockedList).get(0);       위와 같이 특정 상황에 대한(when) 가짜로 결과를 만들어 주는 것을 Stubbing(스터빙)이라 한다.   가짜로 수행할 객체를 넣어주는 것이다.       일련의 BDD의 Stubbing 과정인데 뭔가 맞지 않는 부분이 있다.      when()   thenReturn()   verify()       위 코드에 존재하는 3가지 행동 과정인데 개념적으로 Given에 해당하는 Mockito의 when(mockedList.get(0))의 이름이 when이라 헷갈린다.           BDDMockito의 given() 메서드   위와 같이 헷갈리는 문제를 given()으로   더 정확한 의미를 전달하는 것으로 해결할 수 있다.   given(someClass.method(any())).willReturn()       given() 메서드   given()은 BDD의 given을 내포하고 있다.   given()의 파라미터를 이용해서 어떤 상황에,   즉 어떤 메서드가 실행되었을 때의 테스트를 위한 상황 설정이 가능하다.       위의 Stubbing 문장에서 3가지 의미를 담고 있다.      someClass.method() : Mocking 할 메서드   any() : 메소드 파라미터   willReturn() : 메소드 반환 값           Mocking 할 메소드   Mocking 할 메소드라는 말이 무슨 뜻일까?   UserService를 테스트한다고 가정해보자.       Unit Test에서 가장 중요한 것은 테스트 하려는 대상의 고립이다.   테스트 대상을 고립한다는 것은 테스트 대상에 연관된 다른 객체들은 관여하지 않도록   개발자가 가짜 객체를 넣어줘야 한다는 소리와 비슷하다.       테스트 대상을 고립하기 위해서 Mockito의 mock()을 이용했고,   테스트 대상이 특정 결과를 수행하기 위해 연관된 객체의 연상을 주입해주면 된다.       ex) UserService에는 현재 isExistByEmail 이라는 메서드가 존재한다.   해당 메서드 내부에 UserRepository 인스턴스가 existsByEmail 연산을 수행하고 있으므로   개발자는 UserRepository의 existsByEmail을 가짜로 주입해주면 된다.          해당 메서드의 파라미터   해당 메서드는 예제에서 existsByEmail 메서드를 의미한다.   String으로 email을 받는 메서드다.       다음과 같은 선택지가 존재한다.      모든 값을 받았을 때의 행동 정의 : any()   특정 값을 받았을 때의 행동 정의 : eq()         해당 메서드 수행했을 때 반환하는 값   행동을 반환할 때, 크게 3가지 방법이 존재한다.      willReturn() : 반환 값을 명시          willThrow() : 예외를 던진다.          will() + invocation will()은 willReturn()과는 조금 다르다. willReturn은 고정된 값을 반환하는데, will에서는 invocation을 통해서 새로운 객체를 반환하거나 아예 새로운 행동을 반환할 수 있다.         참고          https://dannorth.net/introducing-bdd/            https://wonit.tistory.com/493            https://mingule.tistory.com/43            https://yorr.tistory.com/26            https://dannorth.net/introducing-bdd/          ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-09-20/junit5-bdd/",
        "teaser": null
      },{
        "title": "로깅 기능 개발하고 슬랙으로 알림 받기",
        "excerpt":"    LoggingFilter로 로그 남기기   Elasticsearch에 대해 알아보면서 ELK 스택도 함께 알게 되었고   ELK(ElasticSearch Logstash Kibana) 스택으로 로깅을 구현해보기로 했다.   Elasticsearch란?       구현 방법과 함께 어떤 모습으로 로그가 쌓이는지 확인해보고   Slack에 ERROR 로그 알람을 보내는 것까지 구현해보자.          1. Logback.xml   Spring에서 기본적으로 제공하는 로그가 있지만 Logstash에 로그를 쌓아   엘라스틱서치로 보내고 싶기 때문에 resource 에 다음 파일을 추가했다.   logback.xml 파일을 따로 생성해 설정해주지 않으면   스프링이 설정해둔 로그가 찍힌다.             2. Gradle   implementation 'net.logstash.logback:logstash-logback-encoder:6.6'   logstash 사용을 위해 위 의존성을 추가한다.          3. LoggingFilter.java   @Component public class LoggingFilter extends OncePerRequestFilter {  \t@Override \tprotected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, \t\tFilterChain filterChain) throws IOException { \t\tContentCachingRequestWrapper requestWrapper = new ContentCachingRequestWrapper(request); \t\tContentCachingResponseWrapper responseWrapper = new ContentCachingResponseWrapper(response);  \t\ttry { \t\t\tfilterChain.doFilter(requestWrapper, responseWrapper); \t\t} catch (Exception e) { \t\t\tlogger.error(e); \t\t} finally { \t\t\tLoggingRequest loggingRequest = getLoggingRequest(requestWrapper); \t\t\tString log = JsonUtils.toJson(loggingRequest); \t\t\tlogger.info(log); \t\t}  \t\tresponseWrapper.copyBodyToResponse(); \t}  \tprivate LoggingRequest getLoggingRequest(ContentCachingRequestWrapper request) { \t\tString requestURI = request.getRequestURI(); \t\tString method = request.getMethod(); \t\treturn new LoggingRequest(requestURI, method); \t}  }       OncePerRequestFilter는 모든 서블릿에 일관된 요청을 처리하기 위해 만들어진 필터이다.   이 추상 클래스를 구현한 필터는 사용자의 한번에 요청 당 딱 한번만 실행되는 필터를 만들 수 있다.   필터에 대한 자세한 이야기는 다른 포스팅에서 해보자.   필터에서 logger 로그를 남기면 kibana에서 로그를 확인할 수 있다.         4. docker-compose   https://github.com/deviantony/docker-elk   위 repository를 clone 받아서 설정을 마치고 docker-compose up 명령으로 elk를 띄운다.       설정해야 하는 부분      유료 기능인 X-Pack이 포함되어 있기 때문에 주석처리하거나 없애야 한다.   logstash &gt; pipeline &gt; logstash.conf   input { \ttcp { \t\tport =&gt; 5000 \t\tcodec =&gt; json_lines \t} }  filter { \tjson { \t\tsource =&gt; \"message\" \t\tremove_field =&gt; [\"message\"] \t} }  output { \telasticsearch { \t\thosts =&gt; \"elasticsearch:9200\" \t} }       기본 포트      5044: Logstash 비트 입력   5000: Logstash TCP 입력   9600: Logstash 모니터링 API   9200: 엘라스틱서치 HTTP   9300: Elasticsearch TCP 전송   5601: 키바나         Error 로그 Slack으로 알림 받기   ELK 스택으로 로깅을 구현했다.   슬랙으로 알림을 받는건 더 쉽게 구현할 수 있다.          1. Logback.xml   &lt;appender name=\"SLACK\" class=\"com.github.maricn.logback.SlackAppender\"&gt;     &lt;webhookUri&gt;${webhook-uri}&lt;/webhookUri&gt;     &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt;         &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %msg %n&lt;/pattern&gt;     &lt;/layout&gt;     &lt;colorCoding&gt;true&lt;/colorCoding&gt; &lt;/appender&gt;  &lt;appender name=\"ASYNC_SLACK\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt;     &lt;appender-ref ref=\"SLACK\"/&gt;     &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;         &lt;level&gt;WARN&lt;/level&gt;     &lt;/filter&gt; &lt;/appender&gt;  &lt;logger name=\"com.example.loggingslack\" level=\"ALL\"&gt;     &lt;appender-ref ref=\"ASYNC_SLACK\"/&gt; &lt;/logger&gt;       위에서 먼저 설정한 logstash 설정과 함께 Logback.xml에 작성해주면 된다.          ASYNC_SLACK 현재 추천하는 방식으로 appender를 비동기 방식으로 사용하는걸 권장하고 있다.          &lt;filter&gt; 레벨을 설정하는 부분이다.          &lt;webhookUri&gt; SLACK webhookUri를 넣는 부분이다. application.yml에서 값을 가져오고 있다.         2. Incoming Webhooks   슬랙 채널에서 Incoming Webhooks을 추가하여 원하는 형태로 설정하고   webhookUri를 복사해서 Logback.xml 에 넣어준다.            3. Gradle   salck 알람을 위해 다음 의존성을 추가해준다.   implementation \"com.github.maricn:logback-slack-appender:1.4.0\"         위 모든 설정이 끝나면 ERROR 로그가 찍힐 때마다   다음과 같이 내가 설정한 슬랙 채널에 알람이 온다.          지금 전송된 알람은 테스트한 것이기 때문에 “ERROR” 라는 메시지만 전송되었지만   에러가 발생한 원인과 원하는 메시지가 전송되도록 설정해놓으면 된다.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-09-22/log-slack/",
        "teaser": null
      },{
        "title": "내가 정의해보는 스프링",
        "excerpt":"    1. 스프링 프레임워크란?          스프링 프레임워크를 정의하기 쉽지 않다.       중요하게 생각하는 것이 다양하기 때문이다.      IoC/DI, AOP, PSA를 제공해주는 프레임워크   IoC Container를 기반으로 객체지향 설계를 도와주는 프레임워크   빈의 생명주기와 주입 등을 제공해주는 프레임워크   POJO를 도와주는 툴         2. 스프링 프레임워크 정의   스프링의 핵심 개발자들이 함께 쓴 Professional Spring Framework에서   스프링은 엔터프라이즈 서비스 기능을 POJO에 제공하는 것 이라고 정의했고   가장 잘 알려진 정의는 자바 엔터프라이즈 개발을 편하게 해주는 오픈소스 경량급 애플리케이션 프레임워크이다.         2-1) 애플리케이션 프레임워크   일반적으로 라이브러리나 프레임워크는 특정 업무 분야나 한 가지 기술에 특화된 목표를 가지고 만들어진다.   예) 관계형 DB와 자바 객체를 매칭해주는 ORM 기술을 제공하는 JPA   그래서 프레임워크는 애플리케이션의 특정 계층에서 주로 동작하는 한 가지 기술 분야에 집중된다.       그러나 스프링은 애플리케이션 프레임워크라는 특징을 가지고 있다.   애플리케이션 프레임워크는 특정 계층이나 기술, 업무 분야에 국한되지 않고   애플리케이션 전 영역을 포괄하는 범용적인 프레임워크를 의미한다.   애플리케이션 프레임워크는 애플리케이션 개발의 전 과정을 빠르고 편리하며 효율적으로 진행하는데 일차적인 목표를 둔 프레임워크다.       여러 계층의 다양한 기술을 한 곳에 모아뒀다고 해서 애플리케이션 프레임워크라고 할 수 없다.   애플리케이션의 전 영역을 관통하는 일관된 프로그래밍 모델과 핵심 기술을 바탕으로   각 분야의 특정에 맞는 필요를 채워주고 있기 때문에 애플리케이션을 빠르고 효과적으로 개발할 수 있는 것이다.       MVC 프레임워크, JDBC/ORM 지원 프레임워크, IoC/DI 프레임워크, AOP 툴이라고 보는 이유는 스프링이 제공하는 핵심 기술에만 주목했기 때문이다.   스프링의 일차적인 존재 목적은 핵심 기술에 담긴 프로그래밍 모델을 일관되게 적용해서   애플리케이션 전 계층과 전 영역에 전략과 기능을 제공해줌으로써   애플리케이션을 편리하게 개발하게 해주는 애플리케이션 프레임워크로 사용되는 것이다.         2-2) 경량급 (lightweight)   스프링 자체가 가볍다거나 작은 규모의 코드로 이뤄졌다는 뜻은 아니다.   스프링은 여러 모듈로 세분화되고 수십만 라인의 코드를 가진 복잡하고 큰 규모의 프레임워크다.   경량급이라는 표현은 불필요하게 무겁지 않다는 의미다.   스프링 이전의 EJB 같은 과도한 엔지니어링이 적용된 기술과 대비시켜 설명하기 위한 표현이다.       EJB가 동작하려면 고가의 느리고 무거운 자바 서버(was)가 필요했다.   설정 파일 구조, 패키징이 난해하고 서버 배치도 불편하다는 부담이 있다.       그에 비해 스프링은 가장 단순한 서버 환경인 톰캣이나 제티에서도 완벽하게 동작한다.   단순한 개발툴과 기본적인 개발 환경으로도 엔터프라이즈 개발에서 필요로 하는 주요한 기능을 갖춘 애플리케이션을 개발하기에 충분하다.         2-3) 자바 엔터프라이즈 개발을 편하게   스프링은 근본적인 부분에서 엔터프라이즈 개발의 복잡함을 제거해내고 진정으로 개발을 편하게 해주는 해결책을 제시한다.   스프링이라는 프레임워크가 제공하는 기술이 아니라 개발자가 작성하는 애플리케이션 로직에 더 많은 관심과 시간을 쏟게 해준다.         3. 스프링의 목적   경량급 프레임워크를 이용해서 엔터프라이즈 애플리케이션 개발을 편하게 하는 것이 스프링의 정의였다.   그렇다면 스프링을 사용해서 엔터프라이즈 개발을 편하게 하려는 이유는 뭘까?   ❗️️ 엔터프라이즈 개발이 편하기 않기 때문이다.          엔터프라이즈 시스템이란? 서버에서 동작하며 기업과 조직의 업무를 처리해주는 시스템          3-1) 엔터프라이즈 개발의 복잡함   이유1: 기술적인 제약과 요구사항이 늘어났기 때문이다.   엔터프라이즈 시스템은 많은 사용자의 요청을 동시에 처리해야 하기 때문에   서버의 자원을 효율적으로 공유하고 분배해서 사용할 수 있어야 한다.   중요한 기업의 핵심 정보를 처리하거나 금융, 국방 등의 시스템을 다루기도 하기 때문에   보안성과 안정성, 확장성 면에서도 뛰어나야 한다.       타 시스템과의 연계 / 클라이언트와의 접속을 위한 리모팅 기술,   트랜잭션을 하나로 묶어서 사용하는 분산 트랜잭션의 지원도 필요하다.         이유2: 엔터프라이즈 애플리케이션이 구현해야 할 핵심기능인 비즈니스 로직의 복잡함이 증가하기 때문이다.   점차 대부분의 업무를 컴퓨터 없이 처리하기 힘들 정도로 엔터프라이즈 시스템에 대한 업무 의존도가 높어졌다.   다양하고 복잡한 업무 처리 기능을 엔터프라이즈 시스템이 구현해야 한다는 뜻이다.         이유3: 복잡함을 증가시키는 원인   비즈니스 로직과 엔터프라이즈 기술이라는 두 가지 복잡함이 얽혀있기 때문이다.         3-2) 복잡함 해결 ?   엔터프라이즈 개발에 나타나는 복잡함의 원인은 제거 대상이 아니다.   대신 복잡함을 효과적으로 상대할 수 있는 전략과 기법이 필요하다.       문제는 비즈니스 로직의 복잡함을 효과적으로 다루기 위한 방법과 기술적인 복잡함을 처리하는데 적용되는 방법이 다르다.         해결책1: 실패한 EJB   EJB의 기본 전략도 이 두 가지 종류의 복잡함을 분리하는 것이다.   애플리케이션 로직을 담은 핵심 코드에서 일부 기술적인 코드가 제거된 건 사실이지만   오히려 EJB라는 환경과 스펙에 종속되는 코드로 만들어져야 하는 더 큰 부담을 안게 되었다.      EJB라는 틀 안에서 자바 코드를 만들게 강제한다.   특정 클래스를 상속하게 함으로써 더 이상 상속 구조를 적용하지 못하게 만들어 다형성 적용을 근본적으로 제한한다.         해결책2: 비침투적인 방식을 통한 효과적인 해결책 Spring   EJB 처럼 어떤 기술을 적용했을 때 기술과 관련된 코드나 규약이 코드에 등작하는 경우 침투적인 기술이라고 한다.   스프링을 이용하면 기술적인 복잡함과 비즈니스 로직을 다루는 코드를 깔끔하게 분리할 수 있다.   중요한 것은 그 과정에서 스프링 스스로가 애플리케이션 코드에 불필요하게 나타나지 않게 하는 것이다.         3-3) 복잡함을 상대하는 스프링의 전략   스프링의 기본적인 전략은 비즈니스 로직을 담은 애플리케이션 코드와 엔터프라이즈 기술을 처리하는 코드를 분리시키는 것이다.         기술적 복잡함을 상대하는 전략   기술적인 복잡함을 분리해서 생각하면 효과적인 전략을 발견할 수 있다.       문제1: 기술에 대한 접근 방식이 일관성이 없고, 특정 환경에 종속적이다.   일관성 없는 기술과 서버 환경에 대한 스프링의 공략 방법은 바로 서비스 추상화이다.   앞서 얘기했던 트랜잭션 추상화나 OXM 추상화, 데이터 액세스 기술에 독립적으로 적용 가능한 트랜잭션 동기화 기법 등이 대표적인 예이다.       기술적인 복잡함은 일단 추상화를 통해 로우 레벨의 기술 구현 부분과 기술을 사용하는 인터페이스를 분리하고,   환경과 세부 기술에 독립적인 접근 인터페이스를 제공하는 것이 가장 좋은 해결책이다.          예) JavaMail 자바 메일은 테스트 작성이 어려운데 표준 기술이다. 이 경우 서비스 추상화를 적용할 필요가 있다.        서비스 추상화를 통해 테스트 편의성을 증대시키고 기술에 대한 세부 설정과 환경으로부터 독립적인 코드를 만들 수 있다.         문제2: 기술적인 처리를 담당하는 코드가 성격이 다른 코드에 섞여서 등장한다.   비즈니스 로직 전후로 경계가 설정되어야 하는 트랜잭션, 보안 적용, 로깅 기능 등이 대표적인 예이다.       책임에 따라 계층을 분리하고 그 사이에 서로의 기술과 특성에 의존적인 인터페이스나 예외처리 등을 최대한 제거한다고 할지라도 근본적인 엔터프라이즈 서비스를 적용하는 한 이런 문제를 쉽게 해결할 수 없다.   ▶️ 이런 복잡함을 해결하기 위한 스프링의 접근 방법은 AOP다.   AOP는 기술을 다루는 코드로 인한 복잡함을 기술 그 자체 이상으로 불필요하게 증대되지 않도록 도와주는 가장 강력한 수단이다.          비즈니스와 애플리케이션 로직의 복잡함을 상대하는 전략          비즈니스 로직의 복잡함을 상대하는 전략은 자바라는 객체지향 기술 그 자체이다.   스프링은 객체지향 언어의 장점을 제대로 살리지 못하게 방해했던 요소를 제거하도록 도와주는 것이다.          핵심 도구: 객체지향과 DI   기술과 비즈니스 로직의 복잡함을 해결하는 데 스프링이 공통적으로 사용하는 도구는 객체지향이다.   자바 엔터프라이즈 기술의 가장 큰 장점은 객체지향 설계를 가능하게 해주는 자바 언어이다.        EJB는 자바의 개게지향 장점을 취하지 못하게 한다.        스프링의 목적은 결국 “기본으로 돌아가자” 이다.   자바의 기본인 객체지향에 충실한 설계가 가능하도록 단순한 오브젝트로 개발할 수 있고,   객체지향의 설계 기법을 잘 적용할 수 있는 구조를 만들기 위해 DI 같은 유용한 기술을 편하게 적용하도록 도와주는 것이 스프링의 기본 전략이다.   서비스 추상화, 템플릿/콜백, AOP와 같은 스프링의 기술은 DI 없이는 존재할 수 없다.         4. POJO 프로그래밍   조금 더 기술적으로 스프링이 지향하는 목적이 무엇인지 알아보자.       &lt;Professional Spring Framework&gt;에서 스프링의 정수는 엔터프라이즈 서비스 기능을 POJO에 제공하는 것이라고 나와있다.   엔터프라이즈 서비스 기능을 POJO에 제공한다는 말은   엔터프라이즈 서비스 기술과 POJO라는 애플리케이션 로직을 담은 코드를 분리했다는 뜻이다.   분리됐지만 반드시 필요한 엔터프라이즈 서비스 기술을 POJO 방식으로 개발된 애플리케이션 핵심 로직을 담은 코드에 제공한다는 것이 스프링의 가장 강력한 특징과 목표다.          4-1) 스프링의 핵심: POJO   DI의 기본 아이디어는 유연하게 확장 가능한 오브젝트를 만들어두고 그 관계는 외부에서 다이나믹하게 설정해준다는 것이다.   이런 DI의 개념을 애플리케이션 전반에 걸쳐 적용하는 것이 스프링의 프로그래밍 모델이다.       스프링의 주요 기술인 IoC/DI, AOP, PSA는 애플리케이션을 POJO로 개발할 수 있게 해주는 기능 기술이라고 불린다.         POJO란?   POJO는 plain old java object의 약자이다.         POJO의 조건   그냥 평범한 자바 오브젝트라고 할 수 있지만 좀 더 명확하게 정의하면   다음 세 가지 조건을 충족해야 한다.       (1) 특정 규약에 종속되지 않는다.   POJO는 자바 언어와 꼭 필요한 API외에 종속되지 않아야 한다.   따라서 EJB2와 같이 특정 규약을 따라 비즈니스 컴포넌트를 만들어야 하는 경우는 POJO가 아니다.   자바는 단일 상속 제한 때문에 특정 클래스를 상속해서 만들어야 하는 규약이 있는 경우 객체지향적인 설계 기법을 적용하기 어려워지고 규약이 적용된 환경에 종속적이 되면 다른 환경으로 이전이 힘들다는 문제가 발생한다.          (2) 특정 환경에 종속되지 않는다.   특정 환경에 종속되어야 하는 오브젝트도 POJO라고 할 수 없다.   특히 비즈니스 로직을 담고 있는 POJO 클래스는 웹이라는 환경정보나 웹 기술을 담고 있는 클래스나 인터페이스를 사용해서는 안된다.   나중에 웹 컨트롤러와 연결돼서 사용될 것이 뻔하더라도 직접적으로 웹이라는 환경으로 제한해버리는 오브젝트나 API에 의존해서는 안된다.   이렇게되면 웹 외의 클라이언트가 사용하지 못하게 된다. 또한 웹 서버에 올리지 않고 독립적인 테스트도 힘들어진다.          비즈니스 로직을 담은 코드에 HttpServletRequest나 HttpSession, 캐시와 관련된 API가 등장하거나 웹 프레임워크의 클래스를 직접 이용하는 부분이 있다면 그것은 진정한 POJO라고 볼 수 없다.        요즘은 소스코드에 직접 메타 정보를 추가해주는 어노테이션을 많이 사용한다.   그렇다면 어노테이션을 사용하는 경우 POJO라고 할 수 있을까?   어노테이션이 단지 코드로 표현하기 적절치 않은 부가적인 정보를 담고 있고,   그래서 환경에 종속되지 않는다면 여전히 POJO라고 할 수 있다.   하지만 특정 기술과 환경에 종속적인 정보를 담고 있다면 POJO로서의 가치를 잃어버린다고 할 수 있다.       그렇다면 특정 기술 규약과 환경에 종속되지 않으면 모두 POJO라고 할 수 있을까?   자바 클래스를 써서 개발했다고 POJO 방식으로 개발했다고 할 수는 없다.   POJO는 객체지향적인 자바 언어의 기분에 충실하게 만들어져야 하기 때문이다.       POJO는 객체지향적인 원리에 충실하면서 환경과 기술에 종속되지 않고 필요에 따라 재활용될 수 있는 방식으로 설계된 오브젝트를 말한다.   그런 POJO에 애플리케이션의 핵심 로직과 기능을 담아 설계하고 개발하는 방법을 POJO 프로그래밍이라 할 수 있다.          POJO의 장점   POJO가 될 수 있는 조건이 바로 장점이 된다.       특정한 기술과 환경에 종속되지 않는 오브젝트는 그만큼 깔끔한 코드가 될 수 있다.   유연한 방식으로 원하는 레벨의 코드를 빠르고 명확하게 테스트할 수 있다.       객체지향적인 설계를 자유롭게 적용할 수 있다는 것도 큰 장점이다.   우리가 알고있는 자바와 객체지향 프로그래밍, 모델링과 설계, 디자인 패턴 등은 POJO가 아니고는 적용하기 힘들다.          POJO 프레임워크   스프링은 POJO를 이용한 엔터프라이즈 애플리케이션 개발을 목적으로 하는 프레임워크라고 했다.   POJO 프로그래밍이 가능하도록 기술적인 기반을 제공하는 프레임워크를 POJO 프레임워크라고 한다.   스프링 프레임워크와 하이버네이트를 대표적인 POJO 프레임워크로 꼽을 수 있다.       스프링을 이용하면 POJO 프로그램의 장점을 그대로 살려서 엔터프라이즈 애플리케이션의 핵심 로직을 객체지향적인 POJO를 기반으로 깔끔하게 구현하고, 동시에 엔터프라이즈 환경의 각종 서비스와 기술적인 필요를 POJO 방식으로 만들어진 코드에 적용할 수 있다.          참고      https://12bme.tistory.com/157?category=682904#   https://jongmin92.github.io/2018/02/11/Spring/spring-ioc-di/   https://tech.wheejuni.com/2018/05/02/spring-aop-how/      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-09-24/spring/",
        "teaser": null
      },{
        "title": "엘라스틱서치로 검색기능 개발하기",
        "excerpt":"       ElasticSearch란? : https://hyerin6.github.io/2021-09-17/es/   ELK : https://hyerin6.github.io/2021-09-22/log-slack/   엘라스틱서치 검색기능 구현 방법 : https://github.com/hyerin6/TIL/blob/main/Mentoring/2021-09-23.md       High Level Rest Client 란?   ElasticSearch를 사용하는 자바 애플리케이션을 만들기 위한 client api이다.       (1) 의존성   implementation 'org.springframework.boot:spring-boot-starter-data-elasticsearch'   Spring Data Elasticsearch를 사용하여 Spring 애플리케이션에서 Elasticsearch 인덱싱, 검색 및 쿼리를 사용할 수 있다.   또한, Spring Data Elasticsearch 에서 제공 하는 ElasticsearchRepository 인터페이스를 확장하는 저장소 인터페이스를 정의하면 해당 문서 클래스에 대한 CRUD 작업이 기본적으로 사용 가능하다.         (2) 환경 설정      ElasticSearchConfig   @EnableElasticsearchRepositories(\"...\") @Configuration public class ElasticSearchConfig {  \t@Value(\"${...}\") \tString elasticHost;  \t@Bean \tpublic RestHighLevelClient restHighLevelClient() { \t\treturn new RestHighLevelClient(RestClient.builder(HttpHost.create(elasticHost))); \t}  }          application.yml   spring:   elasticsearch:     rest:       uris: http://localhost:9200       ElasticSearch는 여러 노드를 등록할 수 있으며 HttpHost를 추가해주면 된다.   HttpHost의 파라미터로는 hostname, port 그리고 http 또는 https 사용의 스키마가 들어간다.         (3) 인덱스 생성      PostIndex   @ToString @Builder @NoArgsConstructor(access = AccessLevel.PROTECTED) @AllArgsConstructor @Document(indexName = \"post\") public class PostIndex {  \t@Id \tprivate String id;  \t@Field(type = FieldType.Text) \tprivate String content;  \t@Field(type = FieldType.Date) \tprivate ZonedDateTime createdAt;  \t@Field(type = FieldType.Date) \tprivate ZonedDateTime updatedAt;  }      @Document 어노테이션으로 인덱스 이름을 지정한다.   각 필드는 @Field 어노테이션으로 설정한다.   createdAt, updatedAt을 ZonedDateTime으로 선언한 것을 기억하자.          PostIndexRepository   @Repository public interface PostIndexRepository extends ElasticsearchRepository&lt;PostIndex, Long&gt; { \tList&lt;PostIndex&gt; findByContent(String content); }   ElasticsearchRepository를 상속받았다.   JpaRepository와 사용이 유사하다.          PostService   @Slf4j @RequiredArgsConstructor @Service public class PostService {  \tprivate final PostRepository postRepository; \tprivate final ImageService imageService; \tprivate final PostIndexRepository postIndexRepository;  \t@Transactional \tpublic void create(User user, CreatePostRequest request) { \t\tPost post = Post.builder() \t\t\t.user(user) \t\t\t.content(request.getContent()) \t\t\t.build();  \t\tPost savedPost = postRepository.save(post);  \t\t// imageService.create(post, request.getImages());  \t\tPostIndex postIndex = PostIndex.builder() \t\t\t.id(String.valueOf(savedPost.getId())) \t\t\t.content(request.getContent()) \t\t\t.createdAt(savedPost.getCreatedAt().atZone(ZoneId.of(\"Asia/Seoul\"))) \t\t\t.updatedAt(savedPost.getUpdatedAt().atZone(ZoneId.of(\"Asia/Seoul\"))) \t\t\t.build();  \t\tpostIndexRepository.save(postIndex); \t}   \t. . .   }   검색을 하기 위해 Post 객체를 저장할 때   PostIndex도 함께 저장해줘야 한다.   DB에 데이터를 저장하듯 IndexRepository를 이용하여 저장하면 엘라스틱서치에 데이터가 저장된다.          검색 테스트 코드   @Test void getAllIndex() { \tList&lt;MultipartFile&gt; images = new ArrayList&lt;&gt;();  \tList&lt;CreatePostRequest&gt; requests = List.of( \t\tnew CreatePostRequest(\"우주의 이야기\", images), \t\tnew CreatePostRequest(\"우유의 이야기\", images), \t\tnew CreatePostRequest(\"우기의 사랑\", images), \t\tnew CreatePostRequest(\"우리 은행\", images), \t\tnew CreatePostRequest(\"우리\", images), \t\tnew CreatePostRequest(\"우리나라\", images), \t\tnew CreatePostRequest(\"우주\", images), \t\tnew CreatePostRequest(\"우주의 나라\", images) \t);  \tfor (CreatePostRequest p : requests) { \t\tpostService.create(null, p); \t}  \tList&lt;PostIndex&gt; index = postService.getAllIndex(\"우주의\");  \tfor (PostIndex i : index) { \t\tSystem.out.println(i.toString()); \t} }         결과      노란색 부분을 보면 @Document 어노테이션으로 설정한 Indexname으로 post가 생성되어 저장된 것을 확인할 수 있다.         ElasticSearch   엘라스틱 서치에 대해 처음 학습하면서 역색인 방식으로 텍스트를 저장하기 때문에   엘라스틱 서치의 검색이 빠르다는 것으로 게시글을 마쳤는데   엘라스틱 서치에 대해 조금 더 알아보자.       (1) Elasticsearch vs. Relational DB      Elasticsearch는 키워드가 어떤 Document에 있다고 저장하는 방식이다.   해쉬 테이블과 같이 big-o 표기법에 따르면 검색 시 O(1)의 효과를 낸다.   Relational DB는 텍스트 검색 시 문서 개수만큼 연산이 수행되기 때문에 O(N)이다.       Elasticsearch에 다음과 같이 저장된다.            (2) Mapping   매핑은 스키마라고 보면 된다.   엘라스틱 서치 매핑을 하지 않으면 모두 문자열로 저장되기 때문에 데이터를 시각화할 때 불편한 상황이 발생할 수 있다.   때문에 실무에서 매핑없이 데이터를 넣는 것은 위험하다.       Spring Data Elasticsearch를 사용했기 때문에 인덱스 매니저의 Mapping에 들어가보면   다음과 같이 각 필드가 잘 매핑되어 있는 것을 확인할 수 있다.            참고   Minsuk Heo 허민석의 유튜브 강의   https://youtube.com/playlist?list=PLVNY1HnUlO24LCsgOxR_eK2Yi4sOgH9Pg       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-09-27/search/",
        "teaser": null
      },{
        "title": "Spring Transaction으로 알아보는 AOP",
        "excerpt":"    이전 게시글      Spring 정의: https://hyerin6.github.io/2021-09-24/spring/   Spring Transaction으로 알아보는 AOP: https://hyerin6.github.io/2021-10-06/aop/   Ioc/DI: https://hyerin6.github.io/2020-01-31/spring-DI-IoC/   AOP: https://hyerin6.github.io/2020-02-14/spring-AOP/         Transactional 과 AOP   Spring의 @Transactional은 어떻게 동작할까?   @Transactional 어노테이션은 AOP를 사용하여 구현되는데   트랜잭션의 begin과 commit을 메인 로직 앞 뒤로 수행해주는 기능을 담당한다.   @Transactional은 메서드가 실행되기 전 begin 메소드를 호출하고,   메소드가 종료된 후 commit을 호출한다.       Spring AOP는 Proxy 패턴으로 구현되는데 Spring에서 사용하는 두 가지 프록시 구현체가 있다.      JDK Proxy (Dynamic Proxy)   CGLib          JDK Proxy는 AOP를 적용하여 구현된 클래스의 인터페이스를 프록시 객체로 구현해서 코드를 끼워넣는 방식이다.   CGLib Proxy는 Class에 대한 Proxy생성을 지원한다. (상속을 이용)   따라서 final이나 private Method에 대한 AOP 불가능하다. (상속 된 Proxy 객체 생성 시, Override가 불가하기 때문이다.)       스프링에 대해 공부하면서 클래스를 상속하는 것에 대해서 단점을 많이 알게 되었기 때문에   “CGLib는 필요 없는게 아닐까?” 라는 생각이 드는데   그렇지 않다. 단점이 있어도 상황에 따라 최선의 선택이 될 수도 있다.         JDK Proxy   SpringBoot는 기본적으로 프록시 객체를 생성할 때 CGLib를 사용하고 있다.   그 이유는 JDK Proxy가 프록시를 생성할 때 내부적으로 Reflection을 사용하고 있기 때문이다.   리플렉션 자체가 비용이 비싼 API 이기도 하고 가급적 사용하지 않는 것을 추천하기 때문이다.   또한 JDK Proxy는 AOP 적용을 위해 반드시 인터페이스를 구현해야 한다는 단점도 있다.       Dynamic Proxy는 InvocationHandler라는 인터페이스를 구현한다. (JDK Proxy의 경우 자바에서 기본적으로 제공하고 있는 기능이다.)   InvocationHandler의 invoke 메소드를 오버라이딩하여 proxy 위임 기능을 수행하는데   이때 메소드에 대한 명세와 파라미터를 가져오는 과정에서 리플렉션을 사용한다.         CGLib   CGLib는 외부 3rd party library이며 JDK Proxy와는 달리 리플렉션을 사용하지 않고 바이트코드 조작을 통해 프록시 객체를 생성한다.   인터페이스를 구현하지 않고 해당 구현체를 상속받는 것으로 문제를 해결했기 때문에 성능상 이점도 있다.       CGLib는 Enhance 라는 클래스를 바탕으로 proxy를 생성한다.   Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(PostServiceImpl.class); // 프록시할 클래스 지정 enhancer.setCallback(NoOp.INSTANCE);  Object obj = enhancer.create(); // 프록시 생성  PostServiceImpl postService = (PostServiceImpl)obj; postService.writePost(postDTO); // 프록시를 통한 간접 접근        기본적으로 프록시 객체들은 직접 원본 객체를 호출하기 보다는 별도의 작업을 수행하는데   CGLib의 경우 callback을 사용한다.   CGLib에서 가장 많이 사용하는 콜백은 net.sf.cglib.proxy.MethodInterceptor이다.   프록시와 원본 객체 사잉에 인터셉터를 둬서 메소드 호출을 조작하는 것을 도와줄 수 있는 것이다.   PostServiceProxy → PostServiceInterceptor → PostServiceImpl         참고      https://jaehun2841.github.io/2018/07/21/2018-07-21-spring-aop3/#spring-bean%EC%97%90-%EB%8C%80%ED%95%9C-proxy%EB%8A%94   https://javacan.tistory.com/entry/114      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-10-06/aop/",
        "teaser": null
      },{
        "title": "Spring IoC/DI 란?",
        "excerpt":"    이전 게시글에서 스프링을 정의해 봤다.   https://hyerin6.github.io/2021-09-24/spring/       IoC/DI, AOP, PSA, POJO 등 다양하고 익숙한 단어들이 많이 나왔는데   사실 Spring 공부를 시작하고 토비의 스프링을 읽으면서 다음 게시글에서 정리해 본 적이 있다.      Ioc/DI: https://hyerin6.github.io/2020-01-31/spring-DI-IoC/   AOP: https://hyerin6.github.io/2020-02-14/spring-AOP/   그러나 단어 의미나 구현 방법 위주로 정리했기 때문에   처음부터 다시 꼼꼼하게 알아보기로 했다.       IoC란?   애플리케이션 코드를 작성할 때, 특정 기능이 필요하면 라이브러리를 사용한다.   이때 프로그램의 흐름을 제어하는 주체가 애플리케이션 코드이다.   하지만 프레임워크 기반의 개발에서는 프레임워크 자신이 흐름을 제어하는 주체가 되어   필요할 때마다 애플리케이션 코드를 호출하여 사용한다.       프레임워크에서 이 젱권을 가지는 것이 바로 컨테이너이다.   객체의 생성부터 생명주기 관리까지의 모든 것을 컨테이너가 맡아서 하게 된다.   이를 일반적인 제어권의 흐름이 바뀌었다고 해서 IoC (Inversion of Control, 제어의 역전) 라고 한다.         IoC 사용 목적   (1) 클래스 호출 방식   클래스 내에 선언과 구현이 같이 있기 때문에 다양한 형태로 변화가 불가능하다.                (2) 인터페이스 호출 방식   클래스와 인터페이스를 상속받아 구현하는 클래스로 분리한다.   구현 클래스 교체가 용이하여 다양한 변화가 가능하다.   그러나 구현 클래스 교체 시 호출 클래스의 코드에서 수정이 필요하다.   → 부분적으로 종속적이다.                (3) 팩토리 호출 방식   팩토리 방식은 팩토리가 구현 클래스를 생성하기 때문에 호출 클래스는 팩토리를 호출하는 코드로 충분하다.   구현 클래스 변경 시 팩토리만 수정하면 되기 때문에 호출 클래스에는 영향을 미치지 않는다.   그러나 호출 클래스에서 팩토리를 호출하는 코드가 들어가야 하는 것 또한 팩토리에 의존함을 의미한다.                (4) IoC   팩토리 패턴의 장점을 더해 어떠한 것에도 의존하지 않는 형태가 되었다.   실행 시점에 클래스간 관계가 형성된다.   즉 의존성이 삽입된다는 의미로 IoC를 DI라는 표현으로도 사용한다.              위 그림에서 화살표 방향이 바뀐 것에 주목해보자.   클래스가 팩토리를 호출하던 팩토리 패턴의 구조에서 클래스에 의존성 삽입하는 구조로 바뀌었다.         스프링을 사용하지 않으면?      오브젝트의 생명주기 문제   부품화 문제   기술 은닉과 부적절한 기술 은닉 문제       위 문제를 해결하지 못하면 웹 애프리케이션은 리소스를 잘 이용하지 못하고,   테스트, 확장, 변경이 어려워질 것이다.   Spring은 이러한 문제를 해결하기 위해 만들어진 컨테이너라고 볼 수도 있다.      오브젝트의 생명주기 문제 → DI 컨테이너로 해결   부품화 문제 → DI 컨테이너로 해결   기술 은닉과 부적절한 기술 은닉 문제 → AOP로 해결         DI  IoC는 DI(Dependency Injection)라고도 부른다.   DI는 오브젝트를 생성하고 오브젝트끼리의 관계를 생성해 소프트웨어의 부품화 및 설계를 가능하게 한다.   DI를 이용하면 인터페이스 기반의 컴포넌트를 쉽게 구현할 수 있다.       DI는 의존 관계의 주입이라는 뜻이다.   오브젝트 사이의 의존관계를 만드는 것이다.   클래스에서 new 연산자가 사라짐으로써 개발자가 팩토리 메서드 같은 디자인 패턴을 구현하지 않아도 DI 컨테이너가 건내주는 인스턴스를 인터페이스로 받아 인터페이스 기반의 컴포넌트화를 구현할 수 있게 되었다.         참고     https://isstory83.tistory.com/91      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-10-06/ioc-di/",
        "teaser": null
      },{
        "title": "엘라스틱서치 부분 검색 기능 개발",
        "excerpt":"    텍스트 분석   “엘라스틱서치는 루씬을 기반으로 구축된 텍스트 기반 검색엔진이다.”   일반적으로 특정 단어가 포함된 문서를 찾으려면 검색어로 찾을 단어를 입력하면 될 것이라 생각하겠지만   엘라스틱 서치의 기본 분석기는 내가 생각한대로 동작하지 않았다.   별도의 설정 없이 “엘라스틱서치”나 “텍스트”라고 입력해도 위 문장이 검색되지 않는다는 것이다.       엘라스틱서치는 문서를 색인하기 전에 해당 문서의 필드 타입이 무엇인지 확인하고   텍스트 타입이면 분석기 이용해 분석한다.   텍스트가 분석되면 텀(term)으로 나눠서 형태소 형태로 분석된다.   해당 형태소는 특정 원칙에 의해 필터링되어 단어가 삭제되거나   추가, 수정되고 최종적으로 역색인된다.         1) 역색인 구조   역색인 구조는 다음과 같이 요약할 수 있다.      모든 문서가 가지는 단어의 고유 단어 목록   해당 단어가 어떤 문서에 속해 있는지에 대한 정보   전체 문서에 각 단어가 몇 개 들어있는지에 대한 정보   하나의 문서에 단어가 몇 번씩 출현했는지에 대한 빈도       색인 파일들에 들어간 토큰만 변경되어 저장되고 실제 문서의 내용은 변함없이 저장된다.   색인할 때 특정한 규칙과 흐름에 의해 텍스트를 변경하는 과정을 분석(Analyze)이라고 하고 해당 처리는 분석기(Analyzer)라는 모듈을 조합해서 이루어진다.         2) 분석기 구조   분석기는 기본적으로 다음과 같은 프로세스로 동작한다.      문장을 특정한 규칙에 의해 수정한다.   수정한 문자를 개별 토큰으로 분리한다.   개별 토큰을 특정한 규칙에 의해 변경한다.          CHARACTER FILTER   문장을 분석하기 전에 입력 텍스트에 대해 특정한 단어를 변경하거나 HTML과 같은 태그를 제거하는 역할을 하는 필터   해당 내용은 텍스트를 개별 토큰화하기 전의 전처리 과정이며,   ReplaceAll() 함수처럼 패턴으로 텍스트를 변경하거나 사용자가 정의한 필터를 적용할 수 있습니다.          TOKENIZER FILTER   TOKENIZER FILTER는 분석기를 구성할 때 하나만 사용할 수 있으며 텍스트를 어떻게 나눌 것인지를 정의한다.   한글을 분해할 때는 한글 형태소 분석기의 TOKENIZER를 사용하고,   영문을 분석할 때는 영문 형태소 분석기의 TOKENIZER를 사용하는 등 상황에 맞게 적절한 TOKENIZER를 사용하면 된다.          TOKEN FILTER   토큰화된 단어를 하나씩 필터링해서 사용자가 원하는 토큰으로 변환한다.   Token Filter는 여러 단계가 순차적으로 이뤄지며 순서를 어떻게 지정하느냐에 따라 검색의 질이 달라질 수 있습니다.       전체적인 프로세스는 다음과 같다.   Character Filter → Tokenizer Filter → Token Filter → Index                                             ↕️                                           사전            부분 검색 기능을 위한 설정   1) PostIndex   @Getter @Setting(settingPath = \"/tokenizer/setting.json\") @ToString @Builder @NoArgsConstructor(access = AccessLevel.PROTECTED) @AllArgsConstructor @Document(indexName = \"post\") public class PostIndex {  \t@Id \tprivate String id;  \t@Field(type = FieldType.Text, analyzer = \"word_analyzer\") \tprivate String content;  \t@Field(type = FieldType.Date) \tprivate ZonedDateTime createdAt;  \t@Field(type = FieldType.Date) \tprivate ZonedDateTime updatedAt;  }   @Setting(settingPath = \"/tokenizer/setting.json\") 이 부분은 프로젝트 resource/** 경로의 파일을 찾는다.         2) /resources/tokenizer/setting.json   {   \"index\": {     \"max_ngram_diff\": \"10\",     \"analysis\": {       \"analyzer\": {         \"word_analyzer\": {           \"tokenizer\": \"text_tokenizer\",           \"filter\": [             \"lowercase\"           ]         }       },       \"tokenizer\": {         \"text_tokenizer\": {           \"type\": \"ngram\",           \"min_gram\": 1,           \"max_gram\": 10,           \"token_chars\": [             \"letter\",             \"digit\"           ]         }       }     }   } }   해당 파일에 사용할 분석기, 필터 등을 설정하면 인덱스 생성시에 적용된다.      letter tokenizer: 글자가 아닌 문자를 만날 때마다 텍스트를 용어로 나눈다.   token_chars: 토큰에 포함되어야 할 문자 종류. Elasticsearch는 지정된 종류에 속하지 않은 문자를 분할한다. 기본값은 []        ngram: 지정된 문자 목록 중 하나를 만날 때마다 텍스트를 먼저 단어로 분리              예) cat → cat, ca, at, c, a, t           filter lowercase: 소문자로 변환         3) PostIndexRepository   @Repository public interface PostIndexRepository extends ElasticsearchRepository&lt;PostIndex, Long&gt; {  \tList&lt;PostIndex&gt; findByContent(String content);  \t@Query(\"{\\\"match\\\": {\\\"content\\\": \\\"?0\\\"}}\") \tList&lt;PostIndex&gt; searchByContent(String content, Pageable pageable);  }   위와 같이 jpql도 사용이 가능하다.         참고      Elastic 가이드 북: https://esbook.kimjmin.net/06-text-analysis      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-10-08/es-search/",
        "teaser": null
      },{
        "title": "SSH 명칭 & 접속 과정",
        "excerpt":"    프로젝트를 하면서 SSH 접속에 관련된 내용은 다음 포스팅에서 얘기한 적이 있다.      ssh config 사용해서 ssh 접속하기   젠킨스 서버에서 프로젝트를 배포하고 싶은 서버로 ssh 명령어로 배포   사용법은 이미 알고있으니 기본 용어와 접속 과정을 자세히 알아보자.          SSH란?   SSH는 Secure Shell의 줄임말로, 원격 호스트에 접속하기 위해 사용되는 보안 프로토콜이다.   기존 원격 접속 텔넷은 암호화를 제공하지 않기 때문에 보안상 취약하다는 단점이 있다.         SSH 작동 원리   용어 정리      평문: 암호화 되지 않은 글   암호문: 암호화 되어 읽을 수 없는 글   암호화: 암호키를 사용하여 평문을 암호문으로 바꾸는 것   복호화: 암호키를 사용하여 암호문을 평문으로 바꾸는 것   대칭키: 암호화에 사용하는 키와 복호화에 사용하는 키가 같은 것   비대칭키: 암호화에 사용하는 키와 복호화에 사용하는 키가 다른 것       1) 비대칭키 방식   가장 먼저 사용자와 서버가 서로의 정체를 증명해야 한다.   이 서버 인증 시점에 사용되는 것이 비대칭키 방식이다.       다음과 같은 과정으로 인증이 진행된다.            2) 사용자 인증   사용자 인증은 서버 인증과 원리는 같지만, 서버와 클라이언트의 역할만 바뀌게 된다.                3) 대칭키 방식 (데이터 암호화)   정보를 주고 받는 과정에서 정보가 새어나가지 않기 위해 정보를 암호화해서 주고받는데   이 과정이 대칭키 방식이다.   비대칭키 방식과 달리 한 개의 키만을 사용하고, 이를 대칭 키(세션 키)라고 한다.         참고   https://library.gabia.com/contents/infrahosting/9002/  ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-10-14/ssh/",
        "teaser": null
      },{
        "title": "무중단 배포 환경 이해",
        "excerpt":"    무중단 배포란?   무중단 배포란 배포를 중단 없이 진행한다는 의미다.      배포란 개발환경에서 개발된 코드를 패키징하여     서버에서 새로운 버전의 애플리케이션을 실행하도록 하는 것을 의미한다.               이전 버전 애플리케이션을 종료시키고 새로운 버전 애플리케이션을 실행하고 새로운 버전 애플리케이션이 요청을 받을 준비가 될 때까지 서비스가 중단된다.   서비스가 중단되는 시간을 다운타임이라고 한다.       Q. 새로운 버전의 애플리케이션을 배포하기 전에 예전 버전의 애플리케이션을 중단시키는 이유는?   A. 같은 포트를 사용하기 때문이다.   하나의 서버에서 하나의 포트를 동시에 서로 다른 애플리케이션이 사용하는 것은 불가능하다.       Q. 그렇다면 서버를 두 개로 늘리면 어떻게 될까?   A. 서버가 두 개가 되면 사용자는 두 서버 모두의 IP 혹은 도메인 주소를 알아야 한다.   그리고 두 서버중 어떤 서버가 배포되고 있는지 알 방법이 없다.       그렇다면 결론은 애플리케이션 서버와 사용자 사이에 중계 해줄 서버가 필요하다.         리버스 프록시          위 그림에서 애플리케이션 서버와 사용자 사이에서 요청을 중계해주는 서버를   리버스 프록시(reverse proxy) 라고 한다.       클라이언트는 애플리케이션 서버를 모르기 때문에   리버스 프록시로 서버를 분산하면서 트래픽도 분산할 수 있게 되었다.   이렇게 트래픽을 분산하여 각 서버가 받는 부하를 분산하는 것을 로드밸런싱(Load balancing) 이라고 한다.      로드밸런싱에 대해서는 다음 게시글에서 자세히 알아보고     우선 여러가지 배포 방식에 대해 알아보자.          배포 방식   1) 롤링 (Rolling)   일반적인 배포 방식이다.   이전 버전에서 새로운 버전으로 트래픽을 점진적으로 전환하는 배포 방식으로   관리가 편하지만 배포 중 한쪽 인스턴스의 수가 감소되므로 서버 처리 용량을 미리 고려해야 한다.         2) 블루 그린 (Blue Green)   이전 버전을 블루, 새로운 버전을 그린이라고 한다.   새로운 버전을 배포하고 한번에 전환하여 모든 연결을 새로운 버전으로 바라보게 하는 전략이다.   동시에 나란히 구성하여 배포 시점에 트래픽이 일제히 전환된다.   빠른 롤백이 가능하고 운영환경에 영향을 주지 않고   실제 서비스 환경으로 테스트가 가능하다.   단 시스템 자원이 두배로 필요하기 때문에 비용이 많이 발생한다.         3) 카나리 (Canary)   지정한 서버 또는 특정 유저에게만 배포했다가 정상적이면 전체를 배포한다.   서버의 트래픽 일부를 새로운 버전으로 분산하여 오류 여부를 확인할 수 있다.   이런 전략은 A/B 테스트가 가능하며, 성능 모니터링에 유용하다.   트래픽을 분산시킬 때는 라우팅을 랜덤 하게 할 수 있고   사용자로 분류할 수도 있다.         트래픽이 많아지면?   트래픽이 많아지면 위에서 본 로드밸런싱만으로 충분하지 않다.   결국 서버 자원을 사용해서 동작하는 애플리케이션이기 때문에 다음과 같은 방법도 고려해봐야 한다.           Nginx(로드밸런싱)이 실행되는 서버 Scale-up            네트워크 장치로 로드 밸런싱 - 하드웨어            DNS 리다이렉션 - 로드밸런싱을 여러개 두는 방식           위 방법 외에도 여러 방법이 있겠지만   중요한 것은 어떤 부분이 병목인지 확인하는 것이다.         참고      포워드 프록시(forward proxy) 리버스 프록시(reverse proxy) 의 차이   L4/L7 스위치의 대안, 오픈 소스 로드 밸런서 HAProxy   배포 전략   L4 load balancer vs L7 load balancer      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-10-17/deploy/",
        "teaser": null
      },{
        "title": "Nginx 로드 밸런싱 구성",
        "excerpt":"    이전 게시글에서 무중단 배포 환경에 대해 알아보면서   로드 밸런싱에 대해 알게 되었다.   애플리케이션 서버와 사용자 사이에 중계 해줄 리버스 프록시 서버가 필요했고   자연스럽게 트래픽을 분산하여 각 서버가 받는 부하를 분산하는 로드밸런싱도 구성할 수 있게 되었다.   무중단 배포 환경 이해 포스팅 보러가기         로드 밸런싱이란?   로드밸런서는 서버에 가해지는 부하(로드)를 분산(밸런싱)해주는 장치 또는 기술이다.       Q. 로드 밸런서가 왜 필요할까?   클라이언트가 한 두명이면 서버가 여유롭게 응답할 수 있지만   수천만명이라면 하나의 서버는 지쳐서 동작을 멈추게 된다.       이러한 문제를 해결하기 위한 방법은 2가지 이다.   장단점이 있기 때문에 각각의 서비스에 특징과 사용량을 생각해 최적의 방법을 적용하면 된다.      scale-up : 현재 사용하고 있는 서버 자체의 성능을 증가시켜 처리 능력을 향상시키는 것으로 cpu, 메모리 업그레이드 등으로 서버의성능을 높이는 방식   scale-out : 기존 서버와 비슷한 사양의 사양의 여러 대의 서버를 두는 방법       scale-out의 방식으로 서버를 증설하기로 결정했다면   여러 대의 서버로 트래픽을 균등하게 분산해주는 로드밸런싱이 필요하다.         로드 밸런싱 기법   다음과 같은 다양한 로드 밸런싱 기법이 있다.       • 라운드로빈 방식(Round Robin Method) 서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식이다. 클라이언트의 요청을 순서대로 분배하기 때문에 여러 대의 서버가 동일한 스펙을 갖고 있고, 서버와의 연결(세션)이 오래 지속되지 않는 경우에 활용하기 적합하다.       • 가중 라운드로빈 방식(Weighted Round Robin Method) 각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분한다. 주로 서버의 트래픽 처리 능력이 상이한 경우 사용되는 부하 분산 방식이다. 예를 들어 A라는 서버가 5라는 가중치를 갖고 B라는 서버가 2라는 가중치를 갖는다면, 로드밸런서는 라운드로빈 방식으로 A 서버에 5개 B 서버에 2개의 요청을 전달한다.       • IP 해시 방식(IP Hash Method) 클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식이다. 사용자의 IP를 해싱해(Hashing, 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑하는 것, 또는 그러한 함수) 로드를 분배하기 때문에 사용자가 항상 동일한 서버로 연결되는 것을 보장한다.       • 최소 연결 방식(Least Connection Method) 요청이 들어온 시점에 가장 적은 연결상태를 보이는 서버에 우선적으로 트래픽을 배분한다. 자주 세션이 길어지거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합한 방식이다.       • 최소 리스폰타임(Least Response Time Method) 서버의 현재 연결 상태와 응답시간(Response Time, 서버에 요청을 보내고 최초 응답을 받을 때까지 소요되는 시간)을 모두 고려하여 트래픽을 배분한다. 가장 적은 연결 상태와 가장 짧은 응답시간을 보이는 서버에 우선적으로 로드를 배분하는 방식이다.         Nginx란?   Nginx는 웹 서버, 리버스 프록시, 캐싱, 로드 밸런싱, 미디어 스트리밍 등을 위한 오픈소스 소프트웨어이다.   위에서 계속 언급한 리버스 프록시 서버에 해당한다.   요청을 전달하고 실제 요청에 대한 처리는 뒷단의 웹 애플리케이션 서버들이 처리한다.       어떻게 운영되는지 알아보기 위해 간단한 예제로 Nginx를 사용해보자.         Nginx 무중단 배포   Nginx와 스프링 부트 3개의 서버로 무중단 배포를 완성해보자.                 Nginx는 80번 포트, 443 포트 할당   스프링 부트 1, 2, 3은 8080 포트 할당   Jenkins는 8080 포트 할당         1) 젠킨스 설정   우선 원하는 서버를 생성하고 Jenkins의 공개키(.ssh/id_rsa.pub)를   스프링 부트 서버 1, 2, 3의 authorized_keys(.ssh/authorized_keys)에 붙여넣는다.   authorized_keys의 권한을 chmod 600 ~/.ssh/authorized_keys 변경한다.          GCP를 사용하면 메타 데이터 메뉴에서 SSH 키를 쉽게 등록할 수 있다.          위 설정이 끝나고 젠킨스 관리 &gt; 시스템 설정 &gt; Publish over SSH 항목에서   Test Configuration을 해보면 SUCCESS가 출력될 것이다.                  Name: 각 인스턴스 구분이 가능하게 지정 (Job에서 표시될 이름)   Hostname: 내부 IP   Username: ssh 접근 계정 이름, 중복되어도 상관 없음 원하느대로 지정   Remote Directory: Jenkins 시스템 설정에서 SSH 설정시 지정한 홈 디렉토리 뒤에 추가로 입력하는 디렉토리 경로         git에서 프로젝트를 받아오는 jenkins 설정은 아래 게시글에서 확인할 수 있다.   https://hyerin6.github.io/2020-10-21/jenkins-ci/       컨트롤러만 있는 스프링 부트 프로젝트이기 때문에   배포 스크립트는 다음과 같이 간단하게 작성했다.                   2) Nginx 설치   Docker 컨테이너를 실행시킬 준비   sudo yum install docker sudo systemctl start docker sudo chmod 666 /var/run/docker.sock       Nginx 설치   sudo yum install nginx sudo systemctl start nginx       로드밸런싱 설정   sudo vi /etc/nginx/nginx.conf   위 경로의 파일로 들어가 다음과 같은 내용을 추가해야 한다.   upstream cpu-bound-app {   server {instance_1번의_ip}:8080 weight=100 max_fails=3 fail_timeout=3s;   server {instance_2번의_ip}:8080 weight=100 max_fails=3 fail_timeout=3s;   server {instance_3번의_ip}:8080 weight=100 max_fails=3 fail_timeout=3s; }  location / {   proxy_pass http://cpu-bound-app;   proxy_http_version 1.1;   proxy_set_header Upgrade $http_upgrade;   proxy_set_header Connection 'upgrade';   proxy_set_header Host $host;   proxy_cache_bypass $http_upgrade; }      proxy_pass : 요청이 오면 http://cpu-bound-app로 전달   proxy_set_header XXX : 실제 요청 데이터를 header의 각 항목에 할당            ex) proxy_set_header X-Real-IP $remote_addr: Request Header의 X-Real-IP에 요청자의 IP를 저장               설정 파일 적용   sudo systemctl reload nginx       여기까지 설정하면 nginx는 에러 로그를 남긴다.   이유는 SELinux (Security Enhanced Linux)가 함께 작동하는데,   이 SELinux가 HTTP 프록시를 차단하고 있는 것이 문제이다.       Nginx 에러 로그 확인   sudo tail -f /var/log/nginx/error.log       HTTP 프록시를 차단 해결   HTTP 프록시를 허용해주는 커맨드를 실행하면 위 에러를 해결할 수 있다.   sudo setsebool -P httpd_can_network_connect on       여기서 -P는 persist의 의미로, 재부팅 후에도 환경설정이 그대로 적용된다는 말이다.   이렇게 함으로써 정상적으로 도메인 접속 후 포트포워딩이 문제 없이 이루어 지는 것을 확인할 수 있었다.         Nginx 흐름      서버를 늘리지 않고 단일 서버로 두고 nginx로 요청을 받았을 뿐인데   postman으로 확인해보니 빨라진 응답 결과를 확인할 수 있었다.       Nginx는 Event-Driven 구조로 동작하기 때문에 한 개 또는 고정된 프로세스만 생성하여 사용하고,   비동기 방식으로 요청들을 동시에 처리되는 것처럼 처리할 수 있다.   Nginx는 새로운 요청이 들어오더라도 새로운 프로세스와 스레드를 생성하지 않기 때문에   프로세스와 스레드 생성 비용이 존재하지 않고, 적은 자원으로도 효율적인 운용이 가능하다.   그래서 단일 서버에서도 동시에 많은 연결을 처리할 수 있었다.         참고      https://m.post.naver.com/viewer/postView.nhn?volumeNo=27046347&amp;memberNo=2521903   https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/   https://jojoldu.tistory.com/267      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-10-18/loadbalancing/",
        "teaser": null
      },{
        "title": "Docker를 사용한 이유",
        "excerpt":"    진행하던 프로젝트를 배포하고 성능 테스트를 하기 전에   자주 사용하던 Docker와 가상화의 개념에 대해 학습해 보기로 했다.         VM(가상머신)이란?   가상머신은 물리적 하드웨어 시스템에 구축되어 자체 CPU, 메모리, 네트워크 인터페이스 및 스토리지를 갖추고 가상 컴퓨터 시스템으로 작동하는 가상 환경이다.         Docker? VM?  도커(Docker)는 컨테이너형 가상화 기술을 구현하기 위한 상주 애플리케이션과 이 애플리케이션을 조작하기 위한 명령행 도구로 구성되는 프로덕트다.   즉 컨테이너와 VM을 비교한다고 보면 된다.       공통점은 기본 하드웨어에서 격리된 환경 내에 애플리케이션을 배치한다는 것이다.   차이점은 격리된 환경을 얼마나 격리 시키는지의 차이이다.                 Guest OS: VM에 설치된 OS   Hypervisor: Guest OS와 Host OS를 분리   Host operating System: 실물 컴퓨터에 설치된 OS       VM은 컴퓨터의 리소스를 분할하여 사용하기 때문에 속도가 느리고 주변 장치와의 완벽한 호환이 어렵다.   이러한 VM의 단점을 보완하기 위해 프로세스를 격리하는 방식이 고안되었다.   이 방식이 바로 컨테이너이다.       1) Docker 컨테이너  도커 컨테이너에서 돌아가는 애플리케이션은 컨테이너가 제공하는 격리 기능 내부에 샌드 박스가 있지만   여전히 같은 호스트의 다른 컨테이너와 동일한 커널을 공유한다. (하나의 OS에 이미지를 다운 받아 사용하기 때문이다.)   즉 컨테이너는 커널은 공유하고 나머지 CPU, 메모리, 하드디스크는 컨테이너 안에 다 격리되어 있다.   결과적으로 컨테이너 내부에서 실행되는 프로세스는 호스트 시스템에서 볼 수 있다.         2) 가상 머신  가상 머신과 함께 VM 내부에서 실행되는 모든 것은 호스트 운영체제 또는 하이퍼바이저와 독립되어 있다.   프로세스 시작 → 호스트 시스템은 그것을 하드웨어 지원의 일부를 VM에 할당   특정 VM만을 위한 커널을 부팅하고 운영체제 프로세스 세트를 시작한다.         다른 가상화 기술과 함께 Docker를 사용한 이유를 더 자세히 알아보자.         가상화 기술의 종류   1) 호스트 가상화   PC 혹은 Server에 OS(윈도우, 리눅스 등)를 설치하고 그 위에 가상머신을 설치하여   그 Host OS 위에서 가상 머신 모니터가 가상환경을 구성, 관리하는 방식이다.   가상 머신 모니터는 각 가상 환경마다 VM을 생성하고 VM마다 Guest OS를 설치한다.   VM에 특정 하나의 애플리케이션을 사용하기 위해 가볍지 않은 Linux OS를 설치하게 되는 경우가 발생할 수도 있다.   ex) Windows 환경에서 Linux의 가상머신에 Mysql 데이터 베이스를 설치하는 경우       VM의 개수가 많아지면 점점 Guest OS 의 무게를 무시하지 못한다.   Host OS의 무게라도 줄이기 위해 등장한 것이 아래의 하이퍼바이저 가상화이다.         2) 하이퍼바이저 가상화   하이퍼바이저 가상화는 하드웨어 위에 가상화 전문 소프트웨어인 ‘하이퍼바이저’를 설치하고 하드웨어와 가상환경을 제어한다.   Host OS 없이 하드웨어를 직접 제어하기 때문에 효율적으로 리소스를 사용할 수 있다.   하이퍼바이저에 의해 구동되는 VM은 각 VM마다 독립된 가상 하드웨어 자원을 할당받는다.   논리적으로 분리 되어 있어서 한 VM에 오류가 발생해도 다른 VM으로 퍼지지 않는다는 장점이 있다.   하지만 VM별로 OS가 동작하기 때문에 VM동작에 사용되는 오버헤드는 아직 존재한다.         3) 컨테이너 가상화   컨테이너 가상화 기술은 Host OS 상에서 논리적인 구역을 나누어 특정 어플리케이션의 동작을 위한 라이브러리와   애플리케이션 (OS나 참조되는 App)을 컨테이너에 넣고, 개별 서버처럼 사용하는 것이 컨테이너 가상화이다.   VM 별로 OS가 없고 VM을 구동시키기 위한 OS부팅도 없기 때문에 다른 가상화 기술에 비해 가볍고 빠른게 컨테이너 가상화 기술의 특징이다.         컨테이너들을 어떻게 격리시킬 수 있는가?   1) LXC 덕분이다.   LXC는 리눅스 커널 컨테이너 기능을 위한 사용자영역 인터페이스이다.   강력한 API와 간단한 도구들을 통해 리눅스 사용자가 쉽게 시스템 또는 어플리케이션 컨테이너들을 생성/관리할 수 있게 해준다.      도커에서 어떻게 리눅스 기능을?     Docker란 Go언어로 작성된 리눅스 컨테이너 기반으로하는 오픈소스 가상화 플랫폼이다.          2) 네임스페이스   하나의 시스템에서 프로세스를 격리시킬 수 있는 가상화 기술   (별개의 독립된 공간을 사용하는 것처럼 격리된 환경을 제공하는 경량 프로세스 가상화 기술)         3) Chroots   chroot는 프로세스의 루트 디렉토리를 변경하는 것으로, 이를 통해 프로세스가 액세스 할 수있는 디렉토리를 제한하거나 시스템 라이브러리와 관련 라이브러리를 로드 할 수있다.   chroot에서 제어 할 수있는 파일이나 디렉토리에 대한 액세스만으로, 네트워크 및 프로세스 등을 컨트롤 할 수는 없다.         4) CGroups   CPU, 메모리, Network, HD I/O 등 프로세스 그룹의 시스템 리소스 사용량을 관리   어떤 애플리케이션 사용량이 너무 많다면 그 어플리케이션 같은 것을 C Group에 집어 넣어서 CPU와 메모리 사용 제한 가능   (필요한 만큼만 할당해줌)         그럼 Kubernetes는?  많은 기업에서 쿠버네티스를 잘 아는 개발자를 원하는걸 볼 수 있는데   Docker랑 뭐가 다르고 왜 그런걸까?       Docker에서 컨테이너를 사용하면 Machine의 자원을 효율적으로 사용할 수 있는데   만약 컨테이너가 기하급수적으로 증가한다면?   컨테이너를 관리하고 운영하는데 상당히 어려워져서 운영상의 효율성이 저하된다.   이러한 배경으로 나타난게 쿠버네티스이다.       도커는 기술적인 개념, 도구이고 쿠버네티스는 도커를 관리하는 툴이라고 생각하면 된다.   이미지를 컨테이너에 띄우고 실행하는 기술이 도커이고   이런 도커를 기반으로 컨테이너를 관리하는 서비스가 쿠버네티스인 것이다.   도커는 한 개의 컨테이너를 관리하는 데 최적이고   쿠버네티스는 여러 개의 컨테이너를 서비스 단위로 관리하는 데 최적화되어있다.       위와 같은 이유로 나는 많은 컨테이너를 관리할 정도의 프로젝트는 아니기 때문에   쿠버네티스를 사용하지 않았다.         참고     http://wiki.sys4u.co.kr/display/SOWIKI/1.+Virtualization+Technology      ","categories": ["Docker"],
        "tags": ["docker"],
        "url": "/2021-10-19/vm/",
        "teaser": null
      },{
        "title": "Jenkins CI/CD",
        "excerpt":"    지금 진행중인 SNS 프로젝트 에 Cacahe를 적용하기 전에   캐시 적용 전, 후 부하 테스트 결과의 차이를 확인하기 위해서   배포를 위해 Jenkins로 CI/CD 부터 자동화 시켜보자.       Jenkins 관련 포스팅      Docker로 Jenkins 사용하기   Jenkins 배포 자동화 스크립트   Jenkins 테스트 자동화 스크립트   자동 배포 마무리         CI/CD란?   RedHat 에서 정의한 CI/CD의 개념은 애플리케이션 개발 단계를 자동화하여 애플리케이션을 보다 짧은 주기로 고객에게 제공하는 방법이다.   이렇게만 들으면 왜 CI/CD 자동화를 구축해야 하는지 와닿지 않는다.   애플리케이션의 규모가 크다고 가정하자.   그럼 단순히 개발하고 테스트, 빌드, 배포를 하는데만 시간이 꽤 걸릴 것이다.   또한 한 사람이 관리하는 게 아니라 몇십명으로 구성된 팀이 관리할 것이기 때문에   이 애플리케이션의 수정본을 하나로 합치는 것부터 배포까지 시간이 오래 걸려 긴 배포 주기를 갖게 될 것이다.   시간이 오래 걸리면 사용자의 피드백을 빠르게 반영할 수 없고 배포 과정 속에서 문제가 발생할 가능성도 높다.       이런 문제점을 개선하기 위해 CI/CD를 적용해야 한다.   애플리케이션 코드 병합부터 테스트, 배포까지 라이프사이클 전체에 걸쳐   자동화시켜 더 짧은 주기로 고객들에게 애플리케이션을 제공할 수 있어야 한다.       따라서 CI/CD는 지속적인 통합(Continuous Integration),   지속적인 서비스 제공(Continuous Delivery), 지속적인 배포(Continuous Deployment)로 구성되어 있다.       지속적인 통합   지속적인 통합, CI(Continuous Integration)란 자동화된 빌드 및 테스트가 수행된 후,   개발자가 코드 변경 사항을 중앙 리포지토리에 정기적으로 병합하는 DevOps 소프트웨어 개발 방식이다.   버전 관리를 통한 코드 병합, 빌드, 테스트, 오류 보고를 자동화하여 반복적인 작업을 줄이고,   발생한 문제에 대해 빠르게 처리가 가능하여 더 좋은 품질의 소프트웨어를 개발할 수 있다.       지속적인 서비스 제공   지속적인 서비스 제공, CD(Continuous Delivery)는 반복적인 작업을 자동화한 CI 과정을 거친 소스코드를 레포지토리에 자동으로 반영하는 단계를 의미한다.   바로 프로덕션 단계로 배포하는 지속적인 배포 단계로 확장이 가능하지만, 따로 테스트 환경에 배포하여 추가적인 여러 사용자 차원에서 테스트를 검증할 수 있다.       지속적인 배포   지속적인 배포, CD(Continuous Deployment)는 CI/CD의 마지막 단계로 모든 테스트를 거친 코드를 레포지토리에 자동으로 반영하는 지속적인 서비스 제공 단계의 확장된 형태이다.   애플리케이션을 프로덕션 단계로 자동으로 배포하는 작업을 자동화하여, 개발자가 변경 사항을 적용한 후 짧은 시간 이내에 사용자는 새로운 버전의 애플리케이션을 사용할 수 있다.         CI/CD 프로세스 속에서의 애플리케이션 배포 과정         개발자는 소스 코드를 수정하고, 코드 컨벤션을 준수했는지, 코드가 잘 작동하는지 Pull Request를 보내 자동으로 확인합니다.   변경된 소스 코드에 대해 코드 리뷰를 진행한다.   코드 리뷰가 끝나면 PR Merge 작업이 수행된다.   배포 가능한 소스 코드를 주기적으로 빌드하여 테스트 버전을 생성한 후, 여러 테스트를 진행한다.   테스트 과정에서 발생한 오류를 수정하여 스토어에 배포한다.       위와 같은 작업을 자동화하여 배포 주기 단축 및 불편함을 최소화하는 것이 CI/CD 구축 목적이다.         Jenkins 설치 &amp; 기본 설정  Jenkins는 CI/CD 자동화를 제공하는 툴이다.   다양한 플로그인과 문서를 지원하기 때문에 나도 프로젝트에서 항상 사용해왔다.       설치 방법이 어려운건 아닌데 최신 버전이 아니면 플러그인이 정상적으로 설치되지 않는다.   클라우드에서 제공하는 Jenkins 서버는 최신 버전이 설치되지 않는 경우가 많으니   직접 설치하는게 좋을 것 같다.       $ sudo yum install wget $ sudo yum install maven $ sudo yum install git  $ sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo $ sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key $ sudo yum install jenkins $ sudo systemctl start jenkins $ sudo systemctl status jenkins       위와 같은 명령어로 Jenkins를 설치하고 시작할 수 있다.   이 외에 주의할 점은 java, gradle 버전 체크이다.   당연히 동일해야 하므로 확인해보는 것이 좋다.                 PR 이벤트 발생 후 머지해도 되는지 자동으로 체크  PR을 올렸는데 merge해도 될지 자동으로 테스트 후,   결과를 Git에 출력해주는 CI를 구축했다.   만약 빌드에 실패하면 merge할 수 없다고 알려주고   Details 클릭 시 스크립트를 보여주기 때문에 빠르게 오류를 찾고   PR 이벤트에 관련된 작업을 쉽게 자동화할 수 있다.       다음과 같이 PR이 발생하면 젠킨스 작업이 진행된다.          젠킨스 작업이 완료되면 PR 페이지에서 결과를 확인할 수 있다.            원하는 branch 배포하기  학습을 목적으로 진행하는 프로젝트이기 때문에 master 브랜치에 push 될 때   무조건 배포되게 설정하지 않고 Git에서 내가 원하는 브랜치를 배포하기 위해서   Build With Parameters에 String 매개변수를 지정해놨다.   브랜치를 입력하고 빌드 하기를 누르면 해당 브랜치를 clone 하고 운영 서버에 배포된다.              Jenkins에서 빌드하고 jar와 config를 운영 서버에 전송하는데   예전 프로젝트에서 배포 과정을 이해하기 위해 scp, ssh 명령어로 직접 전송하고 배포했는데   Jenkins의 Publish Over SSH 플러그인을 사용하면 쉽게 파일들을 전송할 수 있다.   한가지 주의할 점은 절대경로가 아닌 상대경로로 지정해야 정상적으로 작동한다는 것이다.   운영 서버와 ssh 접속 설정은 젠킨스 시스템 설정 &gt; Publish over SSH 에서 가능하다.   port, password, remote directory 까지 쉽게 설정할 수 있다.                 Name: SSH Server 이름을 선택하면 된다.   Verbose output in console을 체크하면 빌드할 때 상세 내역이 표시 된다.   Source files : 전송할 파일을 지정한다. 전체 파일 이동을 하려면 **/* 과 같이 입력   Remove prefix : Source files에서 지정한 경로의 하위 폴더를 지우는 기능 이다.                    위의 예시같이 입력한다면 폴더를 제외하고 jar 파일만 전송하게 될 것이다.   Remote directory : SSH Server로 지정한 서버의 원격지 폴더이다.   Exec command : 파일 전송이 모두 끝난 이후에, SSH Server로 지정한 서버에서 실행될 스크립트를 지정할 수 있는 기능         끝!            모든 설정이 끝나면 위와 같이 테스트, 배포를 편하게 진행할 수 있다.         참고     https://www.redhat.com/ko/topics/devops/what-is-ci-cd   https://engineering.linecorp.com/ko/blog/build-a-continuous-cicd-environment-based-on-data/      ","categories": ["Jenkins"],
        "tags": ["jenkins"],
        "url": "/2021-10-20/jenkins/",
        "teaser": null
      },{
        "title": "Spring boot Thymeleaf",
        "excerpt":"    테스트를 하기 전 편리함을 위해 배포, 테스트 자동화를 구축했다.   https://hyerin6.github.io/2021-10-20/jenkins/       이번 프로젝트는 백엔드에 집중하기 위해 프론트를 따로 개발하지 않았지만   테스트를 위해 사용자 회원가입, token, 유저 정보를 확인해야 했기 때문에   간단하게 index.html, login.html, user.html 파일을 생성했다.       스프링 부트가 자동 설정을 지원하는 템플릿 엔진 Thymeleaf로 구현했다.   예전에 자세히 알아보지 않고 JSP를 많이 사용했었는데   스프링 부트가 JSP를 권장하지 않는 이유와 Thymeleaf에 대해 알아보자.         템플릿 엔진이란?  템플릿 엔진은 동적 컨텐츠를 생성하는 방법이다.   템플릿 양식과 특정 데이터 모델에 따른 입력 자료를 결합하여 결과 문서를 출력하는 소프트웨어를 말하며,   view(html)와 data logic(DB connection)을 분리해주는 기능을 한다.          서버 사이드 템플릿 엔진 : 서버에서 가져온 데이터를 미리 정의된 템플릿에 넣어 html을 그린 뒤 클라이언트에게 전달해준다.    HTML 코드에서 고정적으로 사용되는 부분은 템플릿으로 만들어두고, 동적으로 생성되는 부분만 템플릿에 소스코드를 끼워넣는 방식으로 동작한다.      클라이언트 사이드 템플릿 엔진 : HTML 형태로 코드를 작성하며, 동적으로 DOM을 그리게 해주는 역할을 한다. 데이터를 받아서 DOM 객체에 동적으로 그려주는 프로세스를 담당한다.       스프링 부트가 자동 설정을 지원하는 템플릿 엔진     FreeMarker   Groovy   Thymeleaf   Mustache         JSP 자동 설정을 지원하지 않는 이유  Spring boot는 JSP를 권장하지 않는다.   JSP를 사용하면 WAR 패키징을 해야한다.   WAR 패키징으로도 임베디드 톰캣으로 실행할 수 있고 배포할 수 있으나   Undertow라는 최근에 만들어진 서블릿 엔진이 JSP를 지원하지 않는 등 제약사항이 있다.   또한 JSP에 대한 의존성을 넣으면 의존성 문제가 생기는 경우도 있다.         jar vs war  jar, war 모두 java의 jar 툴을 이용해 생성된 파일이며 애플리케이션을 쉽게 배포하고 동작시킬 수 있도록 관련 파일을 패키징해준다.       JAR (Java Archive)     .jar 자바 프로젝트를 압축한 파일   자바 리소스, 속성파일, 라이브러리 등이 포함되어 있다.   원하는 구조로 구성이 가능하고 JDK에 포함된 JRE만 가지고도 실행 가능하다.       WAR(Web Application Archive)     .war servlet/jsp 컨테이너에 배치할 수 있는 웹 애플리케이션 압축 파일   웹 관련 자원만 포함한다. (JSP, Servlet, JAR, Class, HTML 등)   JAR과 달리 WEB-INF 및 META-INF 디렉토리로 사전 정의된 구조를 사용하며 실행하기 위해서 Tomcat과 같은 웹 서버 또는 웹 컨테이너(was)가 필요하다.   WAR도 java의 jar 옵션 (java -jar)을 이용해 생성하는 JAR 파일의 일종이다.         Thymeleaf  Thymeleaf는 비교적 최근에 만들어진 템플릿 엔진이며 서버사이드 자바 템플릿 엔진의 한 종류이다.   JSP와 Thymeleaf의 가장 큰 차이점은 JSP와 달리 Servlet Code로 변환되지 않다는 점이다.   따라서 비즈니스 로직과 분리되어 오로지 View에 집중할 수 있다.       의존성 추가   implementation 'org.springframework.boot:spring-boot-starter-thymeleaf'       html 파일 생성 위치   src &gt; main &gt; resource &gt; templates 에 생성하면 된다.   &lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt;   위 코드처럼 th 네임스페이스를 추가하면 된다.       테스트  .andDo(print()) 를 통해 렌더링 된 결과까지 확인할 수 있다.   이것은 Thymeleaf를 사용했기 때문이다.   JSP를 사용하면 본문을 확인(렌더링된 결과)하는 것이 매우 힘들다.   서블릿 엔진 자체가 JSP 템플릿을 완성시키기 때문에 응답으로 내보낼 최종적인 View를 확인하기 위해서는 서블릿 엔진 개입이 필수적이다.   반면 Thymeleaf는 서블릿 컨테이너의 개입 없이 독자적으로 최종적인 View를 완성한다.   테스트에서 사용한 mockMVC는 가짜 서블릿 컨테이너이며 실제 서블릿 컨테이너가 할 수 있는 일을 다 할 수 없다.         JAR 배포      위 사진을 보면 운영 서버에 배포된 후 Thymeleaf로 구현한 view가 잘 뜨는 것을 확인할 수 있다.   png 파일인 카카오 로그인 버튼도 잘 출력된다.      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-11-02/Thymeleaf/",
        "teaser": null
      },{
        "title": "그리디 알고리즘",
        "excerpt":"    당장 좋은 것만 선택   그리디 알고리즘은 단순하지만 강력한 문제 해결 방법이다.   현재 상황에서 지금 당장 좋은 것만 고르는 방법을 의미한다.   현재의 선택이 나중에 미칠 영향에 대해서는 고려하지 않는다.       특정한 문제를 만났을 때 단순히 현재 상황에서 가장 좋아 보이는 것만을 선택해도 문제를 풀 수 있는지를 파악할 수 있어야 한다.   그리디 알고리즘은 기준에 따라 좋은 것을 선택하는 알고리즘이므로 문제에서   ‘가장 큰 순서대로’, ‘가장 작은 순서대로’와 같은 기준을 알게 모르게 제시해준다.   대체로 이 기준은 정렬 알고리즘을 사용했을 때 만족시킬 수 있으므로 그디리 알고리즘 문제는 정렬 알고리즘과 자주 짝을 이뤄 출제된다.         대표 문제: 거스름돈  카운터에 거스름돈으로 사용할 500원, 100원, 50원, 10원짜리 동전이 무한히 존재한다.  손님에게 거슬러 줘야 할 돈이 N원일 때 거슬러줘야 할 동전의 최소 개수를 구하라.  단, 거슬러 줘야 할 돈 N은 항상 10의 배수이다.        이 문제는 대표적인 그리디 문제다.   가장 큰 화폐단위 부터 돈을 거슬러주면 된다.         그리디 알고리즘의 정당성  대부분의 문제는 그리디 알고리즘을 이용했을 때 ‘최적의 해’를 찾을 수 없을 가능성이 높다.   하지만 위 거스름돈 문제는 탐욕적으로 접근했을 때 매우 효과적이다.   그 이유는 가지고 있는 동전 중에서 큰 단위가 항상 작은 단위의 배수이므로 작은 단위의 동전들을 종합해 다른 해가 나올 수 없기 때문이다.       대부분의 그리디 알고리즘 문제에서 이처럼 문제 풀이를 위한 최소한의 아이디어를 떠올리고 이것이 정당한지 검토할 수 있어야 답을 도출할 수 있다.   바로 문제 유형을 파악하기 어렵다면 다음과 같은 순서로 생각해보자.   1. 그리디 알고리즘을 먼저 의심하고, 문제를 해결할 수 있는 탐욕적인 해결법이 존재하는지 고민해본다.   2. 오랜 시간 고민해도 그리디로 해결할 수 없다면, 다이나믹 프로그래밍이나 그래프 알고리즘으로 해결할 수 있는지 고민해본다.          문제     숫자 카드 게임   1이 될 때까지   큰 수의 법칙   체육복   조이스틱   큰 수 만들기   구명보트   섬 연결하기   단속 카메라   등수 매기기   수리공 항승      ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-11-02/greedy/",
        "teaser": null
      },{
        "title": "Dijkstra & Bellman-Ford",
        "excerpt":"    가장 빠른 길 찾기  최단 경로 알고리즘은 가장 짧은 경로를 찾는 알고리즘이다.   예를 들어, ‘한 지점에서 다른 특정 지점까지의 최단 경로를 구해야 하는 경우’,   ‘모든 지점에서 다른 모든 지점까지의 최단 경로를 모두 구해야 하는 경우’ 등 다양하다.   최단 경로 알고리즘은 다음과 같이 나눌 수 있다.      다익스트라 최단 경로 알고리즘   프로이드 워셜   벨만 포드 알고리즘   그리디 알고리즘과 다이나믹 프로그래밍 알고리즘이 최단 경로 알고리즘에 그대로 적용된다는 특징이 있다.         1) 다익스트라 최단 경로 알고리즘  다익스트라 최단 경로 알고리즘은 그래프에서 여러 개의 노드가 있을 때   특정한 노드에서 출발하여 다른 노드로 가는 각각의 최단 경로를 구해주는 알고리즘이다.   다익스트라 최단 경로 알고리즘은 ‘음의 간선’이 없을 때 정상적으로 동작한다.       매번 ‘가장 비용이 적은 노드’를 선택해서 임의의 과정을 반복하기 때문에 기본적으로 그리디 알고리즘을 분류된다.   1. 출발 노드를 설정한다.  2. 최단 거리 테이블을 초기화한다.  3. 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드를 선택한다.  4. 해당 노드를 거쳐 다른 노드로 가는 비용을 계산하여 최단 거리 테이블을 갱신한다.  5. 위 과정에서 3, 4번을 반복한다.    다익스트라 알고리즘은 최단 경로를 구하는 과정에서 ‘각 노드에 대한 현재까지의 최단 거리’ 정보를 항상 1차원 리스트에 저장하며  리스트를 계속 갱신한다는 특징이 있다.   이러한 1차원 리스트를 최단 거리 테이블이라 한다.       다익스트라 알고리즘을 구현하는 방법은 2가지이다.   방법1) 구현하기 쉽지만 느리게 동작하는 코드  방법2) 구현하기에 조금 더 까다롭지만 빠르게 동작하는 코드         다익스트라 예제         1번 노드에서 다른 노드로 가는 비용을 계산하자.                  1       2       3       4       5       6                       0       2       5       1       ∞       ∞           이후 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드를 선택해야 한다.       1번 에서 최단 거리가 가장 짧은 4번 노드가 선택된다.   최단 거리 테이블을 또 갱신해보자.                  1       2       3       4       5       6                       0       2       4       1       2       ∞           2, 5번 노드의 최단 거리 값이 같은데, 이럴 때는 일반적으로 번호가 작은 노드를 선택한다.   2번 노드를 선택했으나 현재 최단 거리 테이블에서 변경되는 것은 없다.       2번 노드 다음으로 5번 노드가 선택된다.   현재 5번 노드까지 가는 최단 거리가 2이므로 3번, 6번 노드의 값이 다음과 같이 갱신된다.                  1       2       3       4       5       6                       0       2       3       1       2       4               최단 거리 테이블이 의미하는 것은 1번 노드부터 출발했을 때   2, 3, 4, 5, 6번 노드까지의 최단 경로가 각각   2, 3, 1, 2, 4 라는 의미다.       다익스트라 최단 경로 알고리즘에서 ‘방문하지 않은 노드 중에서 가장 최단 거리가 짧은 노드를 선택’하는 과정을 반복하는데,  이렇게 선택된 노드는 ‘최단 거리’가 완전히 선택된 노드이므로, 더 이상 알고리즘을 반복해도 최단 거리가 줄어들지 않는다.         방법1. 간단한 다익스트라 알고리즘  간단한 다익스트라 알고리즘은 O(V^2)의 시간 복잡도를 가지며, V는 노드의 개수를 의미한다.   각 노드에 대한 최단 거리를 담는 1차원 리스트를 선언하고   단계마다 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드를 선택하기 위해   매 단계마다 1차원 리스트의 모든 원소를 확인(순차 탐색)한다.       이 방법은 매번 선형 탐색, 현재 노드와 연결된 노드를 매번 일일이 확인하기 때문에   총 노드의 개수가 5000개 이하아면 괜찮다.   그런데 10000개를 넘어가거나 간선의 개수가 많을 때는 다음 방법을 이용해야 한다.         방법2. 개선된 다익스트라 알고리즘  이 방법은 최단 경로 문제를 최악의 경우에도 시간 복잡도 O(Elog V)를 보장하여 해결할 수 있다.   V는 노드 개수, E는 간선의 개수이다.   이전에는 매번 최단 거리 테이블을 선형적으로 탐색했는데   단순히 선형 탐색을 하는 것이 아니라 더욱더 빠르게 찾을 수 있다면?       개선된 다익스트라 알고리즘에서는 힙(heap) 자료구조를 사용한다.   힙을 사용하면 특정 노드까지의 최단 거리에 대한 정보를 힙에 담아 처리하므로   출발 노드로부터 가장 거리가 짧은 노드를 더욱 빠르게 찾을 수 있다.       힙 자료구조는 우선 순위 큐를 구현하기 위해 사용하는 자료구조 중 하나이다.   우선순위 큐는 우선순위가 가장 높은 데이터를 가장 먼저 삭제한다는 점이 특징이다.                  자료구조       추출되는 데이터                       스택       가장 나중에 삽입된 데이터                 큐       가장 먼저 삽입된 데이터                 우선순위 큐       가장 우선순위가 높은 데이터               우선순위 큐는 데이터를 우선순위에 따라 처리하고 싶을 때 사용한다.   예) 여러 개의 물건 데이터를 자료구조에 넣었다가 가치가 높은 물건 데이터부터 꺼내서 확인해야 하는 경우       단계별로 우선순위 큐가 어떻게 변하는지 알아보자.   우선순위 큐를 적용해도 다익스트라 알고리즘이 동작하는 기본 원리는 동일하다.   최단 거리를 저장하기 위한 1차원 리스트(최단 거리 테이블)은 동일하다.   현재 가장 가까운 노드를 저장하기 위한 목적으로만 우선순위 큐를 추가로 이용한다고 보면 된다.       1단계)   다시 1번 노드부터 출발해보자.   여기서는 다음과 같이 출발 노드를 제외한 모든 노드의 최단 거리를 무한으로 설정한다.   이후 우선순위 큐에 1번 노드를 넣는데 [거리: 0, 노드: 1] 이 정보를 갖는 객체를 우선순위 큐에 넣으면 된다.   우선순위 큐에 넣으면 거리순으로 정렬된다.                  노드 번호       1       2       3       4       5       6                       거리       0       ∞       ∞       ∞       ∞       ∞           우선순위 큐: (거리: 0, 노드: 1)       거리가 가장 짧은 노드를 선택하기 위해 우선순위 큐에서 노드를 꺼내면 된다.   해당 노드를 이미 방문한 적이 있다면 무시하고,   처리한 적이 없으면 1번 노드를 거쳐서 2, 3, 4 노드로 가는 최소 비용을 계산한다.                  노드 번호       1       2       3       4       5       6                       거리       0       2       5       1       ∞       ∞           우선순위 큐: (거리: 0, 노드: 1) (거리: 2, 노드: 2) (거리: 5, 노드: 3)       2단계)   이번에는 [1, 4]의 값이 꺼내진다.   아직 4번 노드에 방문한 적이 없으므로 노드 4를 기준으로 연결된 간선들을 확인한다.   1 &gt; 4 &gt; 3과 1 &gt; 4 &gt; 5 경로의 최소 비용은 기존 테이블의 값들보다 작기 때문에 테이블이 갱신된다.                  노드 번호       1       2       3       4       5       6                       거리       0       2       4       1       2       ∞           우선순위 큐: (거리: 2, 노드: 2) (거리: 2, 노드: 5) (거리: 4, 노드: 3) (거리: 5, 노드: 3)       3단계)   다음으로 선택되는 노드는 2번 노드이다.   2번 노드를 거쳐서 가는 경우 중 최단 거리를 더 짧게 갱신할 수 있는 방법이 없기 때문에 다음 단계로 넘어간다.       4단계)   이번엔 5번 노드를 꺼냈다.   5번 노드에서는 3, 6번 노드로 갈 수 있고 5번 노드를 거치는 경우   최단 거리가 줄어들기 때문에 테이블이 다음과 같이 갱신된다.                  노드 번호       1       2       3       4       5       6                       거리       0       2       3       1       2       4           우선순위 큐: (거리: 3, 노드: 3) (거리: 4, 노드: 3) (거리: 4, 노드: 6) (거리: 5, 노드: 3)       5단계)   다음으로 [거리: 3, 노드: 3]을 꺼낸다.   이 경우 최단 거리 테이블이 갱신되지 않는다.       6단계)   다음으로 [거리: 4, 노드: 3]을 꺼낸다.   3번 노드는 앞서 처리된 적이 있다.   이미 처리되었기 때문에 무시한다.       7단계)   이어서 [거리: 4, 노드: 6]이 꺼내진다.                  노드 번호       1       2       3       4       5       6                       거리       0       2       3       1       2       4           우선순위 큐: (거리: 5, 노드: 3)       8단계)   마지막 원소도 확인해보니 이미 처리된 노드이므로 무시한다.       모든 단계를 거치고 최단 거리 테이블에 남아 있는 0, 2, 3, 1, 2, 4가 각 노드로의 최단 거리이다.         2) 플로이드 워셜 알고리즘  다익스트라 알고리즘은 ‘한 지점에서 다른 특정 지점까지의 최단 경로를 구해야 하는 경우’에 사용할 수 있는 최단 경로 알고리즘이다.   플로이드 워셜 알고리즘은 ‘모든 지점에서 다른 모든 지점까지의 최단 경로를 구해야 하는 경우’에 사용할 수 있는 알고리즘이다.       다익스트라 알고리즘은 단계마다 최단 거리를 가지는 노드를 하나씩 반복적으로 선택한다.   그리고 해당 노드를 거쳐 가는 경로를 확인하며, 최단 거리 테이블을 갱신하는 방식으로 동작한다.   플로이드 워셜 알고리즘도 단계마다 ‘거쳐 가는 노드’를 기준으로 알고리즘을 수행한다.   매번 방문하지 않은 노드 중에서 최단 거리를 갖는 노드를 찾을 필요가 없다는 점이 다르다.   또한 점화식에 맞게 2차원 리스트를 갱신하기 때문에 다이나믹 프로그래밍으로 볼 수 있다.       각 단계에서는 해당 노드를 거쳐 가는 경우를 고려한다.   예를 들어 1번 노드에 대해 확인할 때 1번 노드를 중간에 거쳐 지나가는 모든 경우를 고려하는 것이다.   A &gt; 1번 노드 &gt; B로 가는 비용을 확인하고 최단 거리를 갱신한다.   A &gt; B의 비용이 3이고 A &gt; 1번 노드 &gt; B로 가는 비용이 2이면 A &gt; B의 이동 비용을 2로 갱신하는 것이다.         플로이드 워셜 예제          위와 같은 그래프는 다음처럼 초기 테이블을 설정할 수 있다.                  출발 \\ 도착       1번       2번       3번       4번                       1번       0       4       무한       6                 2번       3       0       7       무한                 3번       5       무한       0       4                 4번       무한       무한       2       0               1단계)   1번 노드를 거쳐 가는 경우를 고려한다.   계산해야 할 값들은 다음과 같다.   D23 = min(D23, D21+D13) D24 = min(D24, D21+D14) D32 = min(D32, D31+D12) D34 = min(D34, D31+D14) D42 = min(D42, D41+D12) D43 = min(D43, D41+D13)   1번을 제외한 2, 3, 4 노드에서 2개의 노드를 뽑는 방식으로   하나씩 확인하며 값을 계산하고 갱신하는 것인데   예를 들어 D23 = min(D23, D21+D13)은   ‘기존의 2번에서 3번으로 가는 비용’ 보다 ‘2번에서 1번을 거쳐 3번을 가는 비용’이 더 작다면   갱신한다는 의미를 갖고 있다.                  출발 \\ 도착       1번       2번       3번       4번                       1번       0       4       무한       6                 2번       3       0       7       9                 3번       5       9       0       4                 4번       무한       무한       2       0               2단계)   이번에는 2번 노드를 거쳐 가는 경우를 계산한다.                  출발 \\ 도착       1번       2번       3번       4번                       1번       0       4       11       6                 2번       3       0       7       9                 3번       5       9       0       4                 4번       무한       무한       2       0           노드의 개수가 총 4개이므로 4단계까지 수행한다.   최종 결과는 다음과 같다.   1번 노드에서 3번 노드로 가는 최단 거리가 8이라는 의미다.                  출발 \\ 도착       1번       2번       3번       4번                       1번       0       4       8       6                 2번       3       0       7       9                 3번       5       9       0       4                 4번       7       11       2       0                 예제 코드     간단한 다익스트라 알고리즘   개선된 다익스트라 알고리즘   플로이드 워셜 알고리즘      ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-11-04/dijkstra/",
        "teaser": null
      },{
        "title": "artillery란?",
        "excerpt":"    artillery 란?  artillery는 node.js로 작성된 스트레스 테스트 도구이다.   가벼운 테스트부터 시나리오 테스트까지 가능하고 리포트 페이지를 제공한다.   artillery는 스크립트를 yaml로 작성할 수 있고 원한다면 node.js로도 작성할 수 있다.   Document 에 테스트 스크립트 작성법도 상세하게 나와있어서 참고하기 좋았다.       테스트 프로그램은 다음 기준으로 선택하면 된다.      스트레스 테스트로 수집되는 지표 중 나에게 필요한 지표가 있는가?   테스트 스크립트로 내가 원하는 시나리오대로 테스트할 수 있는가?   artillery는 위 기준에 부합하는 툴이기 때문에 사용했다.       특징은 다음과 같다.      HTTP(S), Socket.io, Websocket 등 다양한 프로토콜을 지원한다.   시나리오 테스트를 할 수 있다.   JavaScript로 로직을 작성해서 추가할 수 있다.   statsd를 지원해서 Datadog이나 InfluxDB 등에 실시간으로 결과를 등록할 수 있다.           artillery 사용법  1) Node.js 설치  https://nodejs.org/ko/       2) 스크립트 작성  yaml로 작성한다.   다음 공식 문서에 스크립트 작성법이 자세하게 나와있기 때문에 기본적인 설정부터   시나리오 설정까지 따라할 수 있다.   yaml로 작성했기 때문에 가끔 space를 tap으로 인식할 수 있는데 이 경우에는 yaml editor을 사용하면 해결된다.   첫 테스트를 간단히 진행해보고 싶다면 아래 링크의 공식 문서, 스크립트를 참고하면 된다.   https://artillery.io/docs/guides/getting-started/writing-your-first-test.html#Load-Phases   config:   target: \"https://example.com/api\"   phases:     - duration: 60       arrivalRate: 5       name: Warm up     - duration: 120       arrivalRate: 5       rampTo: 50       name: Ramp up load     - duration: 600       arrivalRate: 50       name: Sustained load       3) 테스트  artillery run --output report.json test-script.yaml   report.json 파일에 결과가 저장된다.       4) 테스트 결과 확인 및 저장   artillery report report.json     위 명령어를 통해 html 파일을 만들고 볼 수 있다.         결과     결과는 위와 같은 화면으로 확인할 수 있다.   결과를 보는 법과 테스트 진행에 자세한 개념은 다음 게시물에서 확인할 수 있다.   https://hyerin6.github.io/2021-11-05/stress-test/      ","categories": ["Spring","Artillery"],
        "tags": ["spring","artillery"],
        "url": "/2021-11-05/artillery/",
        "teaser": null
      },{
        "title": "어떤 부분을 테스트하고 분석해야 할까?",
        "excerpt":"    성능 테스트 vs 부하 테스트 vs 스트레스 테스트            1) 성능 테스트  특정 상황에서 시스템의 구성 요소가 어떻게 수행되는지 확인하기 위한 테스트이다.   광범위한 의미를 가지고 있는데 성능테스트(Performance Test)는 부하테스트 중 하나의 관점, 즉 성능적 관점만 측정하겠다는 뜻이 담겨 있다.   해당 시스템 혹은 어플리케이션의 성능을 측정한다함은 점진적인 부하량 증가 과정에서 더 이상 단위시간당 최대 처리량(TPS)이 증가하지 않을 때,   그 때의 수치를 측정하고 그 수치를 해석하는 과정을 의미한다.       성능테스트의 일반적인 목적은 현재의 시스템 혹은 어플리케이션이 최대로 수용가능한 동시단말사용자수가 몇 명인지,   혹은 목표로 정한 성능이 도출되지 않을 때 병목지점이 어딘지를 밝히고 목표성능을 획득하기 위해 무엇을 시정해야하는지를 찾아내기 위함이다.   성능테스트 과정에서 매우 중요한 부분은 목표성능을 설정하고 그러한 목표성능을 확인/측정하기 위해   향후 시스템 운영 중에 실제로 발생할 접속사용자의 호출패턴이 어떠하냐를 분석/추정하는 과정이 반드시 필요하고,   이를 근간으로 점진적 부하를 발생시켜야 의미있는 성능테스트 결과를 도출할 수 있다.   그렇지 않을 경우 성능테스트가 자칫 스트레스테스트로 끝나고 만다.       2) 부하 테스트  적절한 부하를 발생시켜 통계적으로 의미있는 수치를 측정하는 테스트이다.   발생시키는 부하는 실제 시스템에 적용될 예상 트래픽이어야 한다.   부하테스트의 두 가지 중요한 목적 중 하나는 장시간 서비스 가능 여부를 확인하는 신뢰성(reliability) 테스트와   두 번째는 성능 테스트(Performance Test)이다.       버퍼 오버플로우, 메모리 leak, 메모리 오류등의 문제를 밝혀내기 위한 것이다.   시스템을 구성하는 DB, HW 등 모든 요소가 갖는 한계를 찾아서 장래의 부하를 대응하기 위함이다.   특정된 비즈니스 시나리오 상에서 예상되는 동시 접속자 수가 최대인 것을 골라서 테스트한다.   예) 수강 신청하는 인원이 어느정도 예상되는지 알고 싶은 경우       3) 스트레스 테스트  시스템이 과부하 상태에서 어떻게 작동하는지를 검사한다.   시스템의 실패를 확인하고 모니터링하는 과정이 정상적으로 이루어지는지 확인한다.   부가적으로 장애 조치와 복구 절차가 효과적이고 효율적인지 판단하는 것도 중요하다.   스트레스 테스트 시의 부하(일련의 들어오는 요청)는 이처럼 시스템 리소스의 한계점을 시험하려는 의도이기 때문에,   다분히 의도적으로 왜곡되는 경향이 있으며, 향후 실제 접속자에 의해 발생하는 부하량 패턴과는 거리가 멀 수도 있다.         어느 부분을 테스트 해야 할까?  Application     TPS(Transaction Per Second)   응답 시간(Response Time)       Middleware     Message Queue            RabbitMQ           Database            MySQL(slow query, Index)           Web Server            Apache(Network outbound io (bandwidth))       Tomcat(Idle Thread)               Infra     CPU   Memory(Swapping)   Disk IO(파일 시스템)   Network IO(고용량의 파일이나 이미지 전송에서 병목)         테스트 결과에서 어떤 데이터를 확인해야 할까?  TPS (Transaction per second)     DB: 초당 트랜잭션 (커밋이나 롤백이 일어나는 횟수)   web server: 테스트를 위해 정의한 행위의 횟수       Latency At Intervals  요청으로부터 응답을 받아내기 까지 걸리는 시간       Concurrent users  해당 웹 서비스에 동시에 접속할 수 있는 유저의 수를 의미한다.       RPS (Request per second)  1초에 처리할 수 있는 요청의 최대 개수를 의미한다.   QPS(Queries per second)라고도 부른다.   서버의 환경, HTTP의 요청 타입, 컨텐츠의 캐싱 여부 등에 따라서 달라진다.         artillery에서 확인할 부분   Latency   Latency는 지연시간이라는 의미이다. 그래프의 세로는 지연시간(Latency), 가로는 시간을 의미한다.   0으로 갈수록 HTTP 트랜잭션 (요청 → 응답까지의 과정을 HTTP 트랜잭션이라고 한다.)   1회당 요청 → 응답까지 짧은 시간 안에 왔다는 것이다.   그러나 이 시간은 네트워크 시간 + 애플리케이션에서 처리하는 시간이 포함되어 있기 때문에 0에 가깝게 낮추는 것은 어렵다.       그래프 보는 법          max: 가장 오래 걸린 요청 → 응답 시간            p95: 전체 HTTP 트랜잭션 중 가장 빠른 것부터 95%까지 (대부분의 트래픽)            p50: 전체 HTTP 트랜잭션 중 가장 빠른 것부터 50%까지 (절반의 트래픽)            min: 가장 빠르게 온 요청 → 응답 시간            이 외에 p99도 많이 사용하는데 거의 모든 트래픽을 의미하기 때문에           TPS 측정  TPS는 arrivalRate로 측정할 수 있다.   대부분의 경우 스트레스 테스트는 목표로 하는 TPS가 고정되어 있고 그 TPS를 맞춰야 하기 때문에   TPS를 고정 시킨 상태에서 코드나 인프라를 수정하면서 목표로 하는 TPS가 안정적인지 보면 된다.       성능 향상을 위해 유의미하게 봐야 하는 내용은 가급적 스트레스 테스트를 길게 해봐야 한다는 것이고   실제 유저들의 패턴과 비슷하게 시나리오를 작성해 테스트해야 한다는 것이다.         참고     https://xpace.tistory.com/21       ","categories": ["Spring","Artillery"],
        "tags": ["spring","artillery"],
        "url": "/2021-11-05/stress-test/",
        "teaser": null
      },{
        "title": "CQRS(2)",
        "excerpt":"    CQRS   Command and Query     명령            시스템 데이터 변경       예) 주문 취소, 배송 완료           쿼리            시스템 데이터 조회       예) 주문 목록               Responsibility Segregation     책임            구성 요소의 역할       예) 클래스, 함수, 모듈, 서버, DB, 컨테이너           분리            역할에 따라 구성 요소 나누기                          CQRS가 왜 좋다는 걸까?      위 이미지는 CQRS의 예를 간단하게 나타낸 것이다.   코드가 중복되는 느낌과 개발이 느려지는 느낌인데 CQRS는 뭐가 좋다는걸까?         명령과 조회에 단일 모델을 사용하는 경우              한 모델에 이것 저것 기능을 추가하니 코드가 뒤섞였다.           코드 역할/책임 모호            의미/가독성 등 나빠짐            유지보수성이 떨어짐           Member 클래스는 더 이상 Member 테이블에 대응하는 모델이 아닌   로그인 로직, Order 테이블과도 엮여있다.   가장 나쁜 부분은 기능에 따라 사용하는 필드가 달라진다는 것이다.         단일 모델로 복잡해지는 예시) JPA          기능에 따라 연관을 로딩하는 방식이 달라져야 한다.   이렇게 단일 모델을 유지하려고 노력하다 보면 다른 부분에서 복잡한 일이 발생한다.   1) 명령과 쿼리는 다루는 데이터가 다르기 때문이다.      명령 → 한 영역의 데이터   쿼리 → 여러 영역의 데이터       2) 명령과 쿼리는 코드 변경 빈도, 사용자에 따라서도 다르다.     예시            백오피스의 주문 목록 조회 기능       사용자의 주문 기능           변경 빈도가 다른 기능이 한 코드에 있으면 서로 다른 이유로 코드가 바뀌고   이는 곧 책임의 크기가 적당하지 않다는 것이다.   (단일 책임 원칙을 따르지 않는 코드가 생성되는 것)       3) 기능마다 성능 요구가 다르다.      기능마다 트패픽 패턴, 성능 요구 다르다.            사용자의 상품 목록 조회, 상품 상세 조회       백오피스의 판매 수치           기능마다 서로 다른 성능 향상 방법 필요            단일 모델로는 다양한 성능 향상 기법 적용이 어려울 수 있다.                 명령과 쿼리를 구분하자.      명령과 쿼리를 위한 모델을 분리하면 모델의 모호함이 없어진다.   명령 영역의 모델과 쿼리 영역의 모델이 무엇을 표현하고 있는지 명확해져 코드 가독성과 유지보수성이 좋아질 가능성이 높아진다.   예를들어 쿼리는 캐시, 명령은 비동기를 사용하는 방식으로 성능 향상 기법을 다르게 적용하는 것도 가능해진다.         참고     https://youtu.be/xf0kXMTFJm8      ","categories": [],
        "tags": [],
        "url": "/2021-11-08/cqrs1/",
        "teaser": null
      },{
        "title": "CQRS(2)",
        "excerpt":"    구현1: 같은 프로세스, 같은 DB     코드 수준에서만 명령과 쿼리가 분리가 된다.   데이터 수준에서는 분리하지 않는다.   가장 단순하고 명령/쿼리 동일 데이터 보장된다. (트랜잭션 처리 쉬움)         구현2: 같은 프로세스, 같은 DB, 다른 테이블      명령과 쿼리가 코드, 데이터 수준에서 분리된다.   별도의 테이블을 가지고 구현하기 때문에 같은 DB를 사용한다.      쿼리 전용 테이블 사용            예) 최근 조회수 많은 글 목록           명령이 쿼리 전용 데이터 변경 유발         구현3:  같은 프로세스, 다른 DB      상품 목록을 Redis와 같은 저장소에 캐싱하고 쿼리 모델은 Redis를 사용한다.   명령이 데이터를 변경하면 변경 내역을 쿼리 쪽 DB에 전달하게 된다.         구현4: 다른 프로세스, 다른 DB      명령이 데이터를 변경하면 변경 내역을 쿼리 쪽 DB에 전달       다른 DB로 변경 전파      왼쪽부터 방법 1, 2, 3에 해당하는 그림이다.       방법1) 명령이 직접 쿼리 디비를 수정하는 방식           구현이 단순한게 장점이다.            카프카와 같은 메시징 수단을 이용해서 전달하는 변형도 있다.            데이터 유실 가능성이 있다. 쿼리 디비나 메시징이 일시적으로 문제가 발생하게 되면 쿼리 디비를 반영해야 할 데이터가 유실될 수 있다.           방법2) 변경 내역을 기록하고 별도의 전파기를 이용해 변경 내용 전달          별도 테이블에 변경 내역 저장 → 한 트랜잭션으로 처리되기 때문에 변경 내역이 유실되지 않음            전파기를 따로 구현해야 한다는 부담이 생긴다.            이 방법도 중간에 메시징을 두는 변형이 있다.           방법3) 디비가 제공하는 CDC 사용   디비에 바이너리 로그를 읽어서 변경 데이터를 확인하고   변경된 데이터를 쿼리에 전달하는 방식   두번째 방법과 비슷한데 명령쪽 코드에서 변경 내용을 저장하지 않아도 되기 때문에   명령 코드가 단순해진다는 장점이 있다.   메시징을 중간에 두는 변형이 존재한다.       다른 DB 사용시 주의 사항     데이터 유실            유실 허용 여부에 따라 DB 트랜잭션 범위 중요                허용 가능 지연 시간       중복 전달         참고      https://youtu.be/H1IF3BUeFb8      ","categories": [],
        "tags": [],
        "url": "/2021-11-08/cqrs2/",
        "teaser": null
      },{
        "title": "RabbitMQ를 이용한 SNS 글쓰기 성능 개선",
        "excerpt":"    톰캣은 사용자의 요청을 어떻게 처리할까?  사용자의 요청은 우선 큐에 들어가고 큐에 들어간 요청이 늘고있는 스레드가 있다면   그 스레드에 할당되어 처리된다.   톰캣 기본 설정은 큐 사이즈는 100, 스레드 사이즈는 200이다.   모든 스레드가 사용 중이면 새로운 요청이 들어왔을 때 그 요청은 큐에서 대기하는 것이다.       큐 사이즈를 모두 채우고 나서도 계속 요청이 들어오면 그 요청들은 버려진다.   큐에 들어온 요청도 30초가 지나면 타임아웃 처리된다. (기본설정이 30초)       물론 이 기본 설정들을 변경할 수 있지만 결과적으로 해결 방법이 되는 것은 아니다.   실제 처리 속도를 올리지 않으면 결국 요청이 큐에 쌓일 것이다.         Message Queue   이전 게시글에서 CQRS 구현 방법에 대해 알아보면서 메시징 수단을 이용해 DB에 반영할 데이터를 전달할 수 있다고 했다.   여기서 메시징 수단이 바로 Message Queue이다.      Producer: 메시지를 큐에 전송   Consumer: 큐의 메시지를 처리하는 방식   MQ 사용 목적은 비동기로 요청을 처리하고 큐에 저장하여 Consumer의 명목을 줄이는 것에 있다.         RabbitMQ   RabbitMQ는 AMQP(Advanced Message Queueing Protocol)을 구현한 오픈소스 메세지 브로커(중개자)이다.   Rabbit MQ는 데이터를 일단 어딘가에 쌓아두고 나중에 비동기적으로 적절한 처리를 하고 싶은 경우를 위한 데이터 저장소이다.              위 이미지가 AMQP을 나타낸 것이다.   예) 업무 내용을 분류해서 메신저로 보내주시면 처리 후에 결과 알려드리겠습니다.      Publisher: ‘다른 직원들’   Exchange: ‘분류해서’   binding: ‘보내주시면’   Queue: ‘메신저’   Consumer: ‘처리 후에 알려드리겠습니다.’         Message와 Queue 보존   메시징이 일시적으로 문제가 발생하게 되면 쿼리 디비를 반영해야 할 데이터가 유실될 수 있다고 한다.   RabbitMQ가 종료되면 Queue와 안에있는 message는 모두 제거된다.   하지만 Queue를 선언할 때 durable 속성을 true로 설정하면 RabbitMQ가 종료된 후 다시 시작될 때 해당 Queue는 다시 자동으로 생성된다.   하지만 이렇게 해도 Queue 내부의 메세지는 여전히 삭제된다.   이를 방지하려면 Publisher가 message를 Exchange로 보낼 때 persistent 속성을 부여하면 된다.   그러면 메세지도 다시 생성될 것이다.                현재 개발하고 있는 SNS 프로젝트에 Message Queue를 적용하면 위와 같은 모습이다.   DB에 데이터를 저장하기 전에 사용자의 글 작성 요청을 모두 Queue에 넣었다가 처리한다.   이렇게 한다고 톰캣 큐를 사용하지 않는 것이 아니다.   여전히 Nginx에게 요청을 받을 때는 여전히 톰캣 큐를 사용하고 있다.       Q. 그렇다면 Tomcat의 Queue에 넣었다가 처리하는 것과 무슨 차이가 있는걸까?   A. Tomcat 큐에 넣는건 메모리에 저장된 데이터로 애프리케이션 강제 종료시 전부 날아갈 수 있다.   반면 Message 큐를 별도로 사용하면 디스크에 저장하는 등 여러가지 옵션을 줄 수 있다.         Message Queue 특징 &amp; 장점   비동기(Asynchronous)   요청이 몰릴 때에도 저장했다가 처리할 수 있다.   즉 DB 속도와 무관하게 모든 요청을 처리할 수 있다는 것이다.   앞쪽 애플리케이션은 실제 로직이 수행되는 것과 무관하게   단순히 큐에 넣고 다음 요청을 받을 수 있는 상태가 되는 것이다.       애플리케이션간 의존성 제거(비동조, Decoupling)   API를 직접 호출하는 것과 중간에 큐가 있는 것 중 뒷쪽에 있는 애플리케이션이 중단되었을 때에도 메시지가 유실되지 않는다.       과잉(Redundancy)   실패할 경우 재실행 가능하다.       보증(Guarantees)   Queue에 따로 적재된 작업들을 모니터링 할 수 있다.       확장성(Scalable)   다양한 애플리케이션이 message를 생산할 수 있다.       이중화   큐도 결국 애플리케이션이다. 큐도 죽을 수 있는데 이중화도 가능하다.   큐끼리 동기화하기 때문에 우리는 하나의 큐인 것처럼 사용하지만 실제 이중화된 큐를 사용할 수 있다.       신뢰성   실패한 메시지는 큐로 Ack하지 않기 때문에 그 메시지는 큐에서 빠져나가지 않는다.   하지만 절대로 유실되지 않는다고 보장할 수는 없다.   유실되면 안되는 메시지는 로깅을 철저히하여 유실되더라도 복구할 수 있게 준비해야 한다.       확장성   애플리케이션이 스케일 아웃 하더라도 메시지큐에서 따로 처리해줄 필요는 없다.   사용하던 큐를 그대로 사용할 수 있다.         RabbitMQ 사용법   설치   docker run -d --hostname my-rabbit --name some-rabbit -p 5672:5672 -p 15672:15672 rabbitmq:3-management       Consumer 예제 코드   @Component public class Consumer {      @Autowired     ObjectMapper objectMapper;      @Autowired     PostRepository postRepository;      @RabbitListener(queues = \"CREATE_POST_QUEUE\")     public void handler(String message) throws JsonProcessingException {         Post post = objectMapper.readValue(message, Post.class);         postRepository.save(post);     } }       Producer 예제 코드   @Component public class Producer {      @Autowired     private RabbitTemplate rabbitTemplate;      public void sendTo(String message) {         this.rabbitTemplate.convertAndSend(\"CREATE_POST_QUEUE\", message);     }  }         Producer, Consumer 애플리케이션 분리          위에서 mq를 적용한 것은 하나의 애플리케이션에 producer와 consumer가 존재하는 구조이다.   하지만 producer 애플리케이션과 cunsumer 애플리케이션을 분리해서 사용하는 것이 좋다.   분리되지 않는 것과 분리된 것의 차이는 consumer 애플리케이션을 배포할 때 얼마나 까다롭냐이다.   분리된 형태에서는 consumer를 배포할 때 앞쪽에 mq가 존재하기 때문에 모든 consumer가 종료되어도 문제가 없다.   무중단 배포도 쉽게 구축할 수 있다.   하지만 분리되지 않은 형태의 경우 consumer 기능을 배포하기 위해   애플리케이션을 배포할 때 무중단 배포를 위한 요소들이 고려되어야 한다.         MQ 적용하면 요청 처리 시간이 감소할까?  MQ 서버와 통신하기 위한 네트워크 I/O가 늘어나는데 성능에 문제가 없을까?   현재 MQ를 도입하는 이유는 사용자가 보낸 요청을 처리하지 못해 요청이 유실되는 경우를 방지하는 것이 주목적이다.   즉 요청 하나를 처리하는 시간 자체가 빨라진다기 보다는 더 많은 요청이 들어 왔을 때 유실 없이 처리 가능하다.         MQ는 어느 상황에 필요한가?  비동기 작업을 처리할 때 좋다.   즉 사용자가 요청했지만 응답을 받을 필요가 없거나 즉시 받을 필요가 없는 경우에 해당한다.   예) 클라이언트가 응답을 받을 필요가 없는 경우    여러 서버에서 발생한 로그를 쌓는 작업    → 로그를 정상적으로 발송했고 MQ에 넣었다면 저장이 잘 되었는지 클라이언트는 알 필요가 없다.            메시지를 Consume 하는 주체는 애플리케이션이다.   1. 애플리케이션은 MQ에서 일정 개수 만큼 Consume한다.  2. 애플리케이션은 Consnume한 메시지를 들고있고 DB에 insert한다.  3. 메시지 하나를 insert하면 다음 메시지를 consume한다.    위 과정이 반복된다.   결과적으로 애플리케이션이 메시지를 Consume하고 싶을 때 한다.   DB에 insert하는 속도가 느리다면 애플리케이션은 Consume을 느리게 할 것이다.   MQ가 애플리케이션에 강제로 메시지를 보내지 않는다.   애플리케이션이 주체이다.         MQ가 하나이고 Consume가 여러개인 경우 경쟁상태가 발생하는가?  하나의 메시지를 두 개의 Consumer가 동시에 coonsume하는 경우는 발생하지 않는다.   내부적으로 그렇게 구현되어 있기 때문에 경쟁상태는 발생하지 않는다.       ","categories": [],
        "tags": [],
        "url": "/2021-11-08/rabbitmq/",
        "teaser": null
      },{
        "title": "타임라인 querydsl로 구현",
        "excerpt":"    타임라인을 구현하며 작성한 게시글      No Offset Paging 구현   JPA JOIN   QueryDsl 개념 &amp; 사용법       querydsl을 사용하기로한 이유   처음에 내가 팔로우한 사용자들이 작성한 게시글을 조회(타임라인 조회) 기능을 구현할 때   다음과 같이 JPQL을 직접 작성했었다.   @Query(value = \"SELECT p\"     + \" FROM Post p\"     + \" JOIN Follow f ON p.user.id = f.following.id\"     + \" WHERE f.follower.id = :userId\") List&lt;Post&gt; findByJoinFollow(@Param(\"userId\") Long userId, Pageable pageable);  @Query(value = \"SELECT p\"     + \" FROM Post p\"     + \" JOIN Follow f ON p.user.id = f.following.id\"     + \" WHERE f.follower.id = :userId\"     + \" AND p.id &lt; :lastPostId\") List&lt;Post&gt; findByJoinFollowAndLastIdLessThan(@Param(\"userId\") Long userId,  @Param(\"lastPostId\") Long lastPostId, Pageable pageable);       이미 완성한 쿼리고 테스트를 거치며 조회가 되는지 확인했기 때문에   빠르게 이해할 수 있는 코드지만, JPQL을 완성하기 전에   N+1 문제, 불필요한 조회 등 많은 문제를 만났었다.       아직도 문제가 남아있다.      Type-check 불가능   실수가 있어도 컴파일 시점에 알 수 있는 방법이 없다.   해당 로직 실행 전까지 작동여부 확인을 할 수 없고 해당 쿼리 실행 시점에 오류가 발생한다.       querydsl을 사용하면 위 문제들이 해결된다.         querydsl 사용   @RequiredArgsConstructor @Repository public class TimelineRepository {  \tprivate final JPAQueryFactory queryFactory;  \tpublic List&lt;Post&gt; findByJoinFollow(Long userId, Long lastPostId, Pageable pageable) { \t\tQueryResults&lt;Post&gt; result = queryFactory \t\t\t.selectFrom(post) \t\t\t.join(follow) \t\t\t.on(eqFollowing(follow.following)) \t\t\t.where(post.id.lt(lastPostId).and(eqFollower(userId))) \t\t\t.limit(pageable.getPageSize()) \t\t\t.orderBy(post.id.desc()) \t\t\t.fetchResults(); \t\treturn result.getResults(); \t}  \tprivate BooleanExpression eqFollowing(QUser user) { \t\tif (ObjectUtils.isEmpty(user)) { \t\t\treturn null; \t\t} \t\treturn post.user.eq(user); \t}  \tprivate BooleanExpression eqFollower(Long id) { \t\tif (ObjectUtils.isEmpty(id)) { \t\t\treturn null; \t\t} \t\treturn follow.follower.id.eq(id); \t}  }       위 코드를 보면 querydsl의 Custom Repository를 사용하지 않았다.   보통 Querydsl을 사용할 때 다음 파일들을 작성한다.      JpaRepository와 CustomRepository를 확장(extends)한 Repository Interface   Querydsl을 사용하는 메소드 시그니처를 정의하는 RepositoryCustom Inteface   실제로 Querydsl을 사용하여 CustomRepository를 구현하는 RepositoryImpl Class          자세한 설명은 jojoldu - Spring Boot Data Jpa 프로젝트에 Querydsl 적용하기 에서 확인할 수 있다.       2020년 우아한테크콘서트에서 JPAQueryFactory만 있다면 Querydsl을 사용할 수 있다는 것을 발표했고   타임라인 구현에 적합한 방법인 것이라 판단하여 Custom Repository를 만들지 않고 JPAQueryFactory만 주입받아 구현했다.         Custom Repository를 제거해도 될까?   이 방법의 단점은 상속으로 얻는 이점이 사라진다는 것이다.   기본 repository와 Custom repository의 메소드를 하나의 인터페이스로 참조하며 사용할 수 없게 된다.   1개의 엔티티에 접근하기 위해 다수의 repository 인스턴스를 만들게 되는 것이다.       따라서 특정 상황에서만 이 상속 구조를 제거해야 한다.   어떤 기능을 구현하기 위해 다양한 엔티티를 Join하여 함께 참조해야 하는데,   이걸 A엔티티 Repository의 역할로 봐야할지, B엔티티 Repository의 역할로 봐야할지 애매모호한 상황이 발생하는데   이런 경우 특정 엔티티를 메인으로 하지 않는 기능이기 때문에, 위처럼 JPAQueryFactory만 주입받아 사용하는 Repository를 사용하면 좋다.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-11-09/querydsl/",
        "teaser": null
      },{
        "title": "BFS & DFS",
        "excerpt":"    basic      탐색: 많은 양의 데이터 중에서 원하는 데이터를 찾는 과정   스택: 선입후출   큐: 선입선출   재귀함수: 자기 자신을 호출하는 함수         DFS(깊이 우선 탐색)   그래프에서 깊은 부분을 우선적으로 탐색하는 알고리즘이다.   주로 재귀함수로 구현한다.   그래프는 크게 2가지 방식으로 표현한다.      인접 행렬: 2차원 배열로 그래프의 연결 관계를 표현하는 방식   인접 리스트: 리스트로 그래프의 연결 관계를 표현하는 방식       DFS는 특정한 경로로 탐색하다가 특정한 상황에서 최대한 깊숙이 들어가서 노드를 방문한 후,   다시 돌아가 다른 경로로 탐색하는 알고리즘이다.   DFS는 스택 자료구조를 이용하며 구체적인 동작은 다음과 같다.   1. 탐색 시작 노드를 스택에 삽입하고 방문 처리를 한다.  2. 스택의 최상단 노드에 방문하지 않은 인접 노드가 없으면 스택에서 최상단 노드를 꺼낸다.  3. 2번의 과정을 더 이상 수행할 수 없을 때까지 반복한다.          BFS(너비 우선 탐색)  가까운 노드부터 탐색하는 알고리즘이다.   인접한 노드를 반복적으로 큐에 넣어 먼저 들어온 것이 먼저 나가는 선입선출 구조를 이용해   가까운 노드부터 탐색을 진행하는 방식이다.   정확한 동작 방식은 다음과 같다.   1. 탐색 시작 노드를 큐에 삽입하고 방문 처리를 한다.  2. 큐에서 노드를 꺼내 해당 노드의 인접 노드 중에서 방문하지 않은 노드를 모두 큐에 삽입하고 방문 처리를 한다.  3. 2번 과정을 더 이상 수행할 수 없을 때까지 반복한다.          DFS 예제   백준 2667번 단지번호붙이기   private static void dfs(int x, int y) {     visited[x][y] = true;     aparts[apartNum]++;      for (int i = 0; i &lt; 4; i++) {         int nx = x + dx[i];         int ny = y + dy[i];          if (invalid(nx, ny)) {             if (map[nx][ny] == 1 &amp;&amp; !visited[nx][ny]) {                 dfs(nx, ny);             }         }     } }         BFS 예제  백준 2146번 다리 만들기   private static void bfs(int r, int c) {     Queue&lt;Point&gt; queue = new LinkedList&lt;Point&gt;();     queue.offer(new Point(r, c, 0));     int currentLandNum = map[r][c];     isVisited[r][c] = true;     while (!queue.isEmpty()) {         Point point = queue.poll();         for (int i = 0; i &lt; 4; i++) {             int r2 = point.r + dr[i];             int c2 = point.c + dc[i];             if ((r2 &gt;= 0 &amp;&amp; r2 &lt; N &amp;&amp; c2 &gt;= 0 &amp;&amp; c2 &lt; N)              &amp;&amp; !isVisited[r2][c2] &amp;&amp; map[r2][c2] != currentLandNum) {                  isVisited[r2][c2] = true;                 if (map[r2][c2] == 0) {                      queue.offer(new Point(r2, c2, point.cnt + 1));                 } else { //다른 섬                     answer = Math.min(answer, point.cnt);                 }             }         }     } }      ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-11-10/graph/",
        "teaser": null
      },{
        "title": "Redis Cache 이용한 성능 개선",
        "excerpt":"    CQRS와 Message Queue에 대해서 알아보면서   RabbitMQ를 이용해 요청에 대한 성능을 개선했었다.   https://hyerin6.github.io/2021-11-08/rabbitmq/   이후 SNS 특성상 Insert 요청보다 Read 요청이 훨씬 많기 때문에   어떻게 Cache를 적용할지 많은 고민을 했다.       특히 타임라인 조회는 내가 팔로우하고 있는 사용자들이 작성한 게시글을 조회하는 것이기 때문에   User, Post, Follow 테이블이 전부 관련되어 있고 N+1 문제 등을 해결하면서   Join 연산으로 타임라인을 조회하기로 결정했기 때문에 Cache를 적용하는게 적합한지 의문이었다.       우선 데이터의 변경이 적고 조회가 많은 특정 게시글 1개 조회, 특정 사용자의 게시글 목록에 적용했고   팔로우 목록, 댓글, 타임라인 조회에도 캐싱을 적용해 놓은 상태지만   테스트를 해보면서 캐싱하는게 적절한지 확인해 볼 필요가 있을 것 같다.       Spring Boot Redis Cache 적용      application.yml   spring:   redis:     session:       host:        port:        password:      cache:       host:        port:        password:   JWT 토큰을 redis에 저장하고 있었기 때문에 session과 cache로 분리하여 설정했다.          RedisConfig   @RequiredArgsConstructor @Configuration public class RedisConfig {  \t@Value(\"${spring.redis.session.port}\") \tprivate int redisPort;  \t@Value(\"${spring.redis.session.host}\") \tprivate String redisHost;  \t@Value(\"${spring.redis.session.password}\") \tprivate String redisPassword;  \t@Bean \tpublic RedisConnectionFactory redisConnectionFactory() { \t\tRedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(); \t\tredisStandaloneConfiguration.setPassword(redisPassword); \t\tredisStandaloneConfiguration.setHostName(redisHost); \t\tredisStandaloneConfiguration.setPort(redisPort); \t\tLettuceConnectionFactory lettuceConnectionFactory = new LettuceConnectionFactory(redisStandaloneConfiguration); \t\treturn lettuceConnectionFactory; \t}  \t@Bean(name = \"redisTemplate\") \tpublic StringRedisTemplate redisTemplate() { \t\tStringRedisTemplate stringRedisTemplate = new StringRedisTemplate(); \t\tstringRedisTemplate.setConnectionFactory(redisConnectionFactory()); \t\treturn stringRedisTemplate; \t} }   Lettuce는 Netty (비동기 이벤트 기반 고성능 네트워크 프레임워크) 기반의 Redis 클라이언트이다.   비동기로 요청을 처리하기 때문에 Jedis에 비해 몇배 이상의 성능과 하드웨어 자원 절약이 가능하다.   자세한 정보는 이 블로그에 정리되어 있다.   https://jojoldu.tistory.com/418          CacheConfig   @EnableCaching @Configuration public class CacheConfig {  \t@Value(\"${spring.redis.cache.host}\") \tprivate String redisHost;  \t@Value(\"${spring.redis.cache.port}\") \tprivate int redisPort;  \t@Bean(name = \"redisCacheConnectionFactory\") \tpublic RedisConnectionFactory redisCacheConnectionFactory() { \t\tLettuceConnectionFactory lettuceConnectionFactory = new LettuceConnectionFactory(redisHost, \t\t\tredisPort); \t\treturn lettuceConnectionFactory; \t}  \t@Bean \tpublic CacheManager cacheManager( \t\t@Qualifier(\"redisCacheConnectionFactory\") RedisConnectionFactory redisConnectionFactory) { \t\tRedisCacheManager.RedisCacheManagerBuilder builder = RedisCacheManager.RedisCacheManagerBuilder \t\t\t.fromConnectionFactory(redisConnectionFactory); \t\tRedisCacheConfiguration configuration = RedisCacheConfiguration.defaultCacheConfig() \t\t\t.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) \t\t\t.serializeValuesWith( \t\t\t\tRedisSerializationContext.SerializationPair.fromSerializer( \t\t\t\t\tnew GenericJackson2JsonRedisSerializer(objectMapper()))) \t\t\t.entryTtl(Duration.ofMinutes(3L)); \t\tbuilder.cacheDefaults(configuration); \t\treturn builder.build(); \t}  \tprivate ObjectMapper objectMapper() { \t\tPolymorphicTypeValidator ptv = BasicPolymorphicTypeValidator \t\t\t.builder() \t\t\t.allowIfSubType(Object.class) \t\t\t.build(); \t\tObjectMapper mapper = new ObjectMapper(); \t\tmapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS); \t\tmapper.registerModule(new JavaTimeModule()); \t\tmapper.activateDefaultTyping(ptv, ObjectMapper.DefaultTyping.NON_FINAL); \t\treturn mapper; \t}  }   ObjectMapper는 LocalDateTime 직렬화/역직렬화를 위해 추가한 bean이다.   모듈은 ObjectMapper에게 LocalDateTime으로 작업하는 방법을 가르치고,   매개변수 WRITE_DATES_AS_TIMESTAMPS는 JSON에서 LocalDateTime을 문자열로 표시하도록한다.   스프링 부트를 사용하면 ObjectMapper는 Bean 형태로 주입하여 제공한다.   이 설정이 없으면 다음 링크에서 말하는 에러와 동일한 에러가 발생한다.   https://stackoverflow.com/questions/27952472/serialize-deserialize-java-8-java-time-with-jackson-json-mapper          PostSerevice   // 데이터를 조회할 때 레디스 캐시에 저장된다.  @Cacheable(value = \"post\", key = \"#id\") @Transactional(readOnly = true) public Post getPost(Long id) throws ResponseException { \treturn postRepository.findById(id) \t\t.orElseThrow(NotFoundException.POST); }  // 데이터 변경이 있을 때 캐시가 삭제된다. @CacheEvict(value = \"post\", key = \"#id\") @Transactional public void modify(Long id, ModifyPostRequest request) throws ResponseException { \tPost post = postRepository.findById(id) \t\t.orElseThrow(NotFoundException.POST);  \tpost.modifyContent(request.getContent()); }         Redis에 캐싱되는지 확인   redis-cli에 접속해서 확인해본 결과 원하는대로 캐싱되었다.      위와 같이 redis에 데이터가 들어간걸 확인할 수 있다.         캐시 적용 전후 조회 시간 차이   DB에서 조회         캐싱된 데이터 조회     postman으로 테스트해본 결과 조회하는데 소요되는 시간이 개선된 것을 확인할 수 있었다.       ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-11-11/cache/",
        "teaser": null
      },{
        "title": "이분그래프란?",
        "excerpt":"    이분 그래프란 모든 꼭짓점을 빨강과 파랑으로 색칠하되,   모든 변이 빨강과 파랑 꼭짓점을 포함하도록 색칠할 수 있는 그래프이다.   따라서 왼쪽 그래프는 이분 그래프이고 오른쪽은 이분 그래프가 아니다.                이분 그래프 판별   이분 그래프인지 확인하는 방법은 다음과 같은 절차로 진행된다.   1. 모든 정점을 방문했는가?  YES &gt;&gt;️ 2.YES 출력   NO  &gt;&gt;️ 3. 방문하지 않은 정점을 한 곳 방문하고 빨간색으로 칠한다.           queue에 해당 정점을 push      4. queue에서 하나의 정점을 꺼내고 그 정점과 연결된 모든 정점을 가져온다.      4-1. 연결된 정점이 이미 방문한 적이 있다면 연결된 정점과 현재 정점의 색을 비교, 같으면 NO      4-2. 연결된 정점을 방문한 적이 없다면 현재 정점과 다른 색을 칠하고 queue에 넣는다.      4-3. queue에 아무것도 없을때까지 4-1 과정을 반복한다.       5. 1번부터 반복한다.           코드   static boolean bfs(int idx) { \t// 임의의 노드 방문 \tQueue&lt;Node&gt; q = new LinkedList&lt;&gt;(); \tq.add(nodes[idx]);  \twhile (!q.isEmpty()) { \t\tNode node = q.poll();  \t\t// 이미 방문했는데 같은 색이라면 NO \t\tif (check(node)) { \t\t\treturn false; \t\t} else { \t\t\tfor (Node child : node.child) { \t\t\t\tif (!visited[child.idx]) { \t\t\t\t\tvisited[child.idx] = true; \t\t\t\t\tchild.setColor(1 - node.color); \t\t\t\t\tq.add(child); \t\t\t\t} \t\t\t} \t\t}  \t}  \treturn true; }   인접한 노드들을 check 해야하므로 Queue를 사용한 BFS로 탐색한다.         예제     https://www.acmicpc.net/problem/1707   https://programmers.co.kr/learn/courses/30/parts/12486       ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-11-13/bipartite-graph/",
        "teaser": null
      },{
        "title": "이진탐색이란?",
        "excerpt":"    순차 탐색   순차 탐색은 리스트 안에 있는 특정한 데이터를 찾기 위해 앞에서부터 데이터를 하나씩 차례대로 확인하는 방법이다.   보통 정렬되지 않은 리스트에서 데이터를 찾아야할 때 사용한다.   데이터가 아무리 많아도 시간이 충분하면 원하는 원소를 찾을 수 있다.   데이터 개수가 N개일 때 최악의 시간 복잡도는 O(N)이다.         이진 탐색: 반으로 쪼개면서 탐색   이진 탐색은 배열 내부의 데이터가 정렬되어 있어야만 사용할 수 있는 알고리즘이다.   데이터가 무작위일 때는 사용할 수 없지만, 이미 정렬된 데이터는 빠르게 찾을 수 있다.   이진 탐색은 위치를 나타내는 변수 3개를 이용하는데 시작점, 끝점, 중간점을 기준으로   반복적으로 데이터를 비교해서 원하는 데이터를 찾는 게 이진 탐색 과정이다.       public int binarySearch(int[] arr, int target, int start, int end) {     while(start &lt;= end) {         int mid = (start+end)/2;         if(arr[mid] == target) {             return mid;         } else if (arr[mid] &gt; target) {             end = mid - 1;         } else {             start = mid + 1;         }     }      return -1; }       코딩 테스트에서의 이진 탐색   이진 탐색 코드는 쉬워보이지만 문제를 풀어보면 구현이 까다로울 수 있다.   이진 탐색의 원리는 다른 알고리즘에서도 폭넓게 적용되는 원리와 유사하기 때문에 매우 중요하다.   또 높은 난이도의 문제에서 여러 알고리즘과 함께 사용되기도 한다.   탐색 범위가 큰 상황에서 (2,000만 이상) 이진 탐색으로 접근해보길 권한다.         예제 문제1: 부품 찾기   전자 매장에 부품이 N개 있다.   각 부품은 정수 형태의 고유한 번호가 있다.   손님이 M개 종류의 부품을 대량으로 구매하겠다며 당일 날 견적서를 요청했다.   손님이 문의한 부품 M개 종류를 모두 확인해서 견적서를 작성해야 한다.   이때 가게 안에 부품이 모두 있는지 확인하는 프로그램을 작성해보자.   N = 5 [8, 3, 7, 9, 2]  M = 3 [5, 7, 9]   위에서 봤던 이진 탐색 코드를 그대로 사용하면 된다.   전체 코드 보러가기       위 문제는 이진 탐색 말고도 계수 정렬의 개념을 이용해서 문제를 풀 수도 있다.   또는 단순하게 Set 자료형을 이용해서 해결할 수도 있다.         예제 문제2: 떡볶이 떡 만들기   오늘은 떡볶이 떡을 만드는 날이다. 떡의 길이가 일정하지 않다.   대신에 한 봉지 안에 들어가는 떡의 총 길이는 절단기로 잘라서 맞춰준다.   절단기 높이(H)를 지정하면 줄지어진 떡을 한 번에 전달한다.   높이가 H보다 긴 떡은 H 위의 부분이 잘릴 것이고, 낮은 떡은 잘리지 않는다.   N: 떡의 개수, M: 손님이 요청한 최소한의 떡의 길이   N: 4  M: 6 19 15 10 17   [19, 15, 10, 17] 높이의 떡이 나란히 있다. 절단기 높이를 15로 지정하면   자른 뒤 떡의 높이는 [15, 15, 10, 15]가 될 것이다.   잘린 떡의 길이는 차례대로 [4, 0, 0, 2] 이다.   손님은 6cm 만큼의 길이를 가져간다.   손님이 왔을 때 요청한 총 길이가 M일 때 적어도 M 만큼의 떡을 얻기 위해   절단기에 설정할 수 있는 높이의 최댓값을 구하는 프로그램을 작성하라.       이 문제는 전형적인 이진 탐색 문제이다.   ‘원하는 조건을 만족하는 가장 알맞은 값을 찾는 문제’에 주로 사용한다.   예를 들어 범위 내에서 조건을 만족하는 가장 큰 값을 찾으라는 최적화 문제라면   이진 탐색으로 결정 문제를 해결하면서 범위를 좁혀갈 수 있다.       이 문제는 적절한 높이를 찾을 때까지 절단기의 높이 H를 반복해서 조정하면 된다.   범위를 좁힐 때는 이진 탐색의 원리를 이용해 절반씩 탐색 범위를 좁혀나가면 된다.   시작은 다음과 같이 지정하여 시작한다.   시작점: 0 끝점: 19 중간점: 9  잘린 떡의 길이: [10, 6, 1, 8]   전체 코드 보러가기         연습 문제      랜선 자르기   공유기 설치   민호와 강호      ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-11-16/binary-search/",
        "teaser": null
      },{
        "title": "액티브 유저 3억명 이상인 SNS를 개발한다면?",
        "excerpt":"    SNS 프로젝트는 현재 다음과 같은 서버 구조를 갖고 있다.      메시지큐, 캐싱, 로드밸런싱 등 성능 개선을 위해 노력했고 실제로 성능이 개선되기는 했으나   프리티어로 구성한 서버라 한계가 있었고 특히 좋아요, 타임라인 기능 개선이 쉽지 않았다.   실제로 3억명 이상의 액티브 유저를 보유한 트위터의 타임라인 시스템을 알아보고   현재 프로젝트에 적용해볼 수 있는 부분이 있다면 학습해보고 적용해보기로 했다.         SNS 특징   트위터는 다음과 같은 통계를 내고 있다.      액티브 유저 3억명 이상   초당 600개 이상의 트윗 생성, 초당 60만건 이상의 조회 발생       위 통계는 트위터 기준이지만 대부분 SNS는 다음과 같은 특징을 갖고 있다.      읽기 요청이 엄청나다.   Eventually Consistent(언젠가는 동기화됨을 보장) 특성이 있기 때문에 약간의 딜레이는 허용한다.   데이터 저장소 비용을 최적화해야 한다.       쓰기 요청은 메시지큐를 적용했기 때문에 약간의 딜레이가 있을 수 있지만   데이터가 유실되지 않고 많은 요청을 받을 수 있게 개선된 상태이다.   문제는 읽기 요청이다. 캐싱을 적용하긴 했지만 읽기 요청이 엄청나기 때문이다.         팔로워 수에 따른 타임라인 구현   트위터는 새로운 트윗을 작성한 트위터의 팔로워 수에 따라 타임라인 캐시를 만드는 방식이 다르다고 한다.      출처: https://medium.com/@narengowda/system-design-for-twitter-e737284afc95       1) 팔로우 수가 많은 셀럽      유명 트윗터인 경우 팔로워가 8000만명이 넘는 경우도 있다고 한다.   위 사진은 많은 팔로워 수로 유명한 배우의 SNS이다.   2,361만명으로 이 경우, 팬아웃 방식을 사용하는 것은 시스템 부담이 있다.   이 경우, 타임라인 조회 요청 시, 일반 타임라인 캐시에 유명 트윗터의 트윗을 합쳐주는 방식을 사용해야한다.   현재 프로젝트에서도 사용하는 방식이다.   쿼리는 다음과 같다.   SELECT          *       FROM          post         JOIN USER ON post.user_id = user.id          JOIN follows ON follows.following_id = user.id       WHERE          follows.follower_id = user_id   RDB에서 데이터를 조회한다.         2) 일반 팔로워   매번 Post 테이블을 search하기엔 부담되기 때문에 일반 사용자들의   트위터 쓰기 요청이 들어오면, 팔로워의 타임라인 캐시에 새로운 트윗 아이디를 추가해주는 방식이다.   이를 fan-out 방법이라고 한다.       1. 사용자가 게시글 작성을 요청한다.  2. 게시글 요청은 로드밸런싱을 통해 서버로 전달된다.  3. 서버는 DB와 Cache 저장소에 해당 데이터를 저장한다.  4. 서버는 cache 저장소에서 해당 유저를 팔로우 한 사람의 유저 정보들을 가져 온다. 5. 해당(팔로우한 유저들) 유저들의 in-memory(Redis)에 해당 데이터를 저장한다. 6. 트윗을 작성한 유저를 팔로우한 유저들은 타임라인에서 해당 트윗을 볼 수있다.   * 모든 팔로우 유저의 in-memory에 데이터를 저장하지 않고  2주내로 접속한 액티브 유저들의 타임라인에만 저장한다.    타임라인 조회 시 DB를 접근할 필요 없이 해당 유저의 in memory 데이터에서 타임라인 데이터를 가져오면 된다.       대용량 트래픽을 감당하는 시스템에 대해 알아봤다.   현재 개발중인 SNS 프로젝트에서 사용자를 이렇게 구분할 수 없어서 DB에서 조회한 데이터를   캐싱처리해서 DB에 읽기 요청을 최대한 줄이는 방법으로 구현했다.         좋아요 기능   현재 많은 SNS에서 좋아요 수를 보여주는 기능을 없애는 분위기지만 좋아요 기능은 아직 남아있다.   좋아요를 요청하고 취소하는 작업은 자주 발생하기 때문에 개선할 부분이라고 생각하고 개선 방법을 찾아봤다.      가장 유명한 방법은 Redis의 Set을 이용해 중복 검사를 따로 하지 않고   RDB에는 Spring Batch를 이용하여 bulk insert로 데이터를 저장하는 것이다.   redis와 spring batch를 학습해보고 적용해보면 좋을 것 같다.         참고           개발자를 위한 레디스 튜토리얼 02            개발자를 위한 레디스 튜토리얼 04            System design for Twitter            Timeline Service Write API Fanout            Twitter system design, twitter Software architecture, twitter interview questions            Building a follower model from scratch          ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-11-17/sns/",
        "teaser": null
      },{
        "title": "분할 정복이란?",
        "excerpt":"    분할정복법이란?  주어진 문제를 작은 사례로 나누고(divide) 각각의 작은 문제들을 해결하여 정복(conquer)하는 방법이다.   작은 사례의 해답을 바로 얻을 수 있으면 해를 구하고 아니면 더 작은 사례로 나눈다.   해를 구할 수 있을 만큼 충분히 작은 사례로 나눠서 해결하는 방법이다.   1. 문제 사례를 하나 이상의 작은 사례로 분할  2. 작은 사례들을 각각 정복한다. (재귀) 3. 필요하다면, 작은 사례에 대한 해답을 통합하여 원하는 해답을 구한다.          장단점   장점   문제를 나눔으로써 어려운 문제를 해결한다.   문제를 나누어 해결한다는 특징상 병렬적으로 문제를 해결하느 데 큰 강점이 있다.       단점   함수를 재귀적으로 호출한다는 점에서 함수 호출로 인한 오버헤드가 발생하며,   스택에 다영한 데이터를 보관하고 있어야 하므로 스택오버플로우가 발생하거나 과도한 메모리를 사용하게 된다.         문제: 종이의 개수   N(1 ≤ N ≤ 37, N은 3k 꼴)의 범위가 문제를 나누는 기준이 된다.   int newSize = size / 3;  partition(row, col, newSize); partition(row, col + newSize, newSize); partition(row, col + 2 * newSize, newSize);  partition(row + newSize, col, newSize); partition(row + newSize, col + newSize, newSize); partition(row + newSize, col + 2 * newSize, newSize);  partition(row + 2 * newSize, col, newSize); partition(row + 2 * newSize, col + newSize, newSize); partition(row + 2 * newSize, col + 2 * newSize, newSize);       문제: 하노이 탑 이동 순서   // N-1 개의 원판을 목적지가 아닌 곳으로 옮긴다. move(N - 1, start, sub, end); // 제일 큰 원판을 목표 타워로 옮긴다. move(1, start, end, sub); // 서브 타워로 옮겨놨던 원판을 목적지로 옮긴다. move(N - 1, sub, end, start);       문제: 쿼드트리   int newSize = size / 2;  sb.append(\"(\"); // 왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래 순서가 정해져있음 partition(newSize, x, y); partition(newSize, x, y + newSize); partition(newSize, x + newSize, y); partition(newSize, x + newSize, y + newSize); sb.append(')');       ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-11-18/divide-conquer/",
        "teaser": null
      },{
        "title": "Java 11을 사용하는 이유",
        "excerpt":"    Java 8에서는 기존 버전들과 비교해서 가장 큰 변화가 있었다. 간략하게 정리하면 다음과 같다.     스트림 API   메서드에 코드를 전달하는 기법(메서드 레퍼런스와 람다)   인터페이스의 디폴트 메서드   Java 8을 공부하고 써오다가 Java 11로 변환한 이유를 정리해보려고 한다.       1. 람다 파라미터를 위한 지역변수 표현  Java 10에서 var 구문이 생겼다.   Java 11에서는 람다 파라미터에서 좀 더 명시적으로 var를 사용할 수 있게 되었다.   list.stream()     .map((@NotNull var s) -&gt; s.toLowerCase())     .collect(Collectors.toList());      Java 8에 등장했으나 Java 10에서 사라졌다가 Java 11에서 복귀   람다는 타입을 스킵할 수 있는데 이걸 사용하는 이유는, 1@Nullable1 등의 어노테이션을 사용하기 위해 타입을 명시해야 할 때   var 를 사용하려면 괄호를 써야하며 모든 파라미터에 사용해야 하고 다른 타입과 혼용하거나 일부 스킵은 불가능하다.         2. HTTP Client (Standard)  Non-Blocking request and response 지원 (with CompletableFuture)  Backpressure 지원(java.util.concurrent.Flow 패키지를 통해 Rx Flow를 구현체에 적용)  Factory method 형태로 지원  HTTP/2 지원      spring5에서는 Rest Client에 RestTemplate 대신해 WebClient를 사용하여 비동기 구현을 할 수 있다.  기존 멀티스레드 방식을 버리고 Reactor(WebFlux)와 함께 스프링 기반 웹서비스를 구현할 경우,   그에 따른 성능과 효율 향상은 어마어마하다.        3. 모듈  모듈을 통해 애플리케이션에 필요한 구성 요소만 포함하는 런타임 구성을 사용자 지정할 수 있다.     이 사용자 지정은 메모리 공간을 더 적게 사용하며 애플리케이션이 jlink를 사용하여    배포용 사용자 지정 런타임에 정적으로 연결될 수 있게 해준다.   메모리 공간을 적게 사용하면 특히 마이크로서비스 아키텍처에서 유용할 수 있다.   내부적으로 JVM은 모듈을 활용하여 클래스 로딩을 보다 효율적으로 만들 수 있다.     그 결과 런타임이 더 작아지고, 더 가벼워져서 더 빠르게 시작할 수 있습니다.       모듈은 클래스에 필요한 구성 요소를 인코딩하기 때문에   JVM에서 애플리케이션 성능을 개선하기 위해 사용하는   최적화 기법의 효과가 더 좋아질 수 있다.   프로그래머의 경우 모듈은 모듈이 내보내는 패키지와 필요한 구성 요소를 명시적으로 선언하고   반사적 액세스를 제한하여 강력한 캡슐화를 적용하는 데 도움이 된다.     이 캡슐화 수준을 사용하면 애플리케이션을 더 안전하고 쉽게 유지 관리할 수 있다.         4. 프로파일링 및 진단   Java Flight Recorder  JFR(Java Flight Recorder)은 실행 중인 Java 애플리케이션에서 진단 및 프로파일링 데이터를 수집한다.     JFR 및 JMC는 Java 8에서 상용 기능이지만 Java 11에서는 둘 다 오픈 소스이다.       Java Mission Control  JMC(Java Mission Control)는 JFR(Java Flight Recorder)에서     수집한 데이터를 그래픽으로 표시하고 Java에서는 오픈 소스로 제공된다.         JFR 및 JMC를 사용하면 메모리 누수, GC 오버헤드, 핫 메서드,   스레드 병목 상태 및 I/O 블로킹과 같은 런타임 문제를 진단할 수 있다.       통합 로깅  Java 11에는 JVM의 모든 구성 요소에 대한 일반적인 로깅 시스템이 있다.       이 세분화된 로깅은 JVM 충돌에 대한 근본 원인 분석을 수행하고      프로덕션 환경에서 성능 문제를 진단하는 데 유용하다.       오버헤드가 낮은 힙 프로파일링  Java 힙 할당을 샘플링하는 데 사용할 수 있는 새 API가      JVMTI(Java Virtual Machine Tool Interface)에 추가되었다.     JFR 구현에서는 할당이 누락될 수도 있다.     반면 Java 11의 힙 샘플링은 라이브 개체와 데드 개체 모두에 대한 정보를 제공할 수 있다.      APM(애플리케이션 성능 모니터링) 공급업체가 이 새로운 기능을 활용하기 시작했다.       StackWalker  현재 스레드의 스택에 대한 스냅샷 가져오기는 로깅할 때 주로 사용된다.         5. Garbage 수집  Java 11에서 사용할 수 있는 가비지 수집기는 직렬, 병렬, 가비지 우선 및 엡실론(Epsilon)이다.     Java 11의 기본 가비지 수집기는 G1GC(가비지 우선 가비지 수집기)이다.   ZGC는 일시 중지 시간을 10ms 미만으로 유지하려고 하는 대기 시간이 짧은 동시 수집기이다.      ZGC는 Java 11에서 실험적 기능으로 사용할 수 있다.     CMS(Concurrent Mark and Sweep) 수집기는 사용할 수 있지만 Java 9 이후에는 사용되지 않는다.       Epsilon(엡실론)  엡실론 가비지 수집기는 할당을 처리하지만 메모리를 회수하지는 않는다.    힙이 소진되면 JVM이 종료된다.    엡실론은 수명이 짧은 서비스와 가비지를 사용하지 않는 것으로 알려진 애플리케이션에 유용하다.       Docker 컨테이너의 향상된 기능  Java 10 이전에 컨테이너에 설정된 메모리 및 CPU 제약 조건은 JVM에서 인식되지 않았다.   예를 들어 Java 8에서 JVM은 최대 힙 크기의 기본값을 기본 호스트의 실제 메모리의 ¼로 설정한다.    Java 10부터 JVM은 컨테이너 제어 그룹(cgroup)에 의해 설정된 제약 조건을 사용하여 메모리 및 CPU 제한을 설정한다.   예를 들어 기본 최대 힙 크기는 컨테이너의 메모리 제한의 ¼이다. (예: -m2G의 경우 500MB)       다중 릴리스 jar 파일  Java 11에서 클래스 파일의 여러 Java 릴리스별 버전을 포함하는 jar 파일을 만들 수 있다.         6. 성능 향상  JVM 성능 향상          Segmented Code Cache: 코드 캐시를 고유 세그먼트로 나눈다.     이는 JVM 메모리 공간을 효율적으로 제어하고 컴파일된 메서드의 검색시간을 단축하고   코드 캐시의 조각화를 줄여 성능을 향상시킨다.            Compact Strings: 문자열을 저장하는 데 필요한 공간이 효율적으로 변경되었다.            Application Class-Data Sharing: 클래스-데이터 공유는 보관된 클래스가 런타임 시 메모리에 매핑될 수 있게 하여 시작 시간을 줄여준다.     애플리케이션 클래스-데이터 공유는 애플리케이션 클래스를 CDS 보관함에 배치할 수 있도록 하여 클래스-데이터 공유를 확장한다.      여러 JVM이 동일한 보관 파일을 공유하는 경우 메모리가 저장되고 전체 시스템 응답 시간이 단축된다.            Thread-Local Handshakes: 글로벌 VM 세이프포인트를 수행하지 않고 스레드에 대한 콜백을 실행하여  VM이 글로벌 세이프포인트의 수를 줄여 대기 시간을 단축할 수 있게 해준다.            Lazy Allocation of Compiler Threads: VM은 단계별 컴파일 모드에서 다량의 컴파일러 스레드를 시작한다.   이 모드는 CPU가 여러 개 있는 시스템에서 기본값이다. 이러한 스레드는 사용 가능한 메모리 또는 컴파일 요청 수에 관계없이 생성된다.   스레드는 유휴 상태일 때(거의 모든 시간) 메모리를 사용하므로 리소스를 비효율적으로 사용한다.   이 문제를 해결하기 위해 시작 시 각 유형의 컴파일러 스레드를 하나씩만 시작하도록 구현이 변경되었다. 추가 스레드를 시작하고 사용하지 않는 스레드를 종료하는 것은 동적으로 처리된다.           핵심 라이브러리 성능 향상          Variable Handles: 표준을 정의한다는 것은 개체 필드 및 배열 요소, 메모리 정렬의 세부적인 제어를 위한 표준 펜스 작업 세트,   참조된 개체의 강력한 연결성을 유지하기 위한 표준 연결성 펜스 작업에 대한 다양한    java.util.concurrent.atomic 및 sun.misc.Unsafe 작업의 동급 요소를 호출하는 것을 의미한다.            Convenience Factory Methods for Collections: 소량의 요소를 사용하여 컬렉션 및 맵 인스턴스를   편리하게 만들 수 있게 해주는 라이브러리 API를 정의한다.   컬렉션 인터페이스에서 간결하고 수정할 수 없는 컬렉션 인스턴스를 만드는 고정 팩터리 메서드이다.     이러한 인스턴스는 본질적으로 더 효율적이다. API는 조밀하게 표시되고 래퍼 클래스가 없는 컬렉션을 만든다.            Spin-Wait Hints: Java에서 스핀 루프에 있음을 런타임 시스템에 암시할 수 있게 해주는 API를 제공한다.   특정 하드웨어 플랫폼은 스레드가 바쁜 대기(busy-wait) 상태라고 소프트웨어가 알려주면 이점을 얻을 수 있다.            HTTP Client(Standard): HTTP/2 및 WebSocket을 구현하고 레거시 HttpURLConnection API를 대체할 수 있는 새로운 HTTP 클라이언트 API를 제공한다.             7. Nest-Based Access Control   class Test {       static class Nest1 {           private int nest1Var;       }       static class Nest2 {           private int nest2Var;       } }   위 코드와 같이 Nested class의 경우, Test, Nest1, Nest2는 모두 nestmate이다.    기존 JVM 상에서는 nestmate끼리 private 멤버 변수를 접근하려면 컴파일러가 중간에 bridge method를 만들어야 했다.   따라서, reflection을 사용하여 nestmate class의 private 멤버 변수에 접근하려고 하면,   llegalAccessException이 발생한다.   이러한 모순을 해결하고자, 새로운 ‘nest’라는 class file 개념을 도입해 하나의 중첩 클래스이지만   서로 다른 클래스파일로 분리하여 bridge method의 도움 없이도 서로의 private 멤버에 접근할 수 있도록 하였다.         참고     microsoft Java 11 이상으로 이동 하는 이유       ","categories": ["Java"],
        "tags": ["java"],
        "url": "/2021-11-26/java11/",
        "teaser": null
      },{
        "title": "Kafka 사용 이유",
        "excerpt":"    SNS 글 작성 요청을 누락시키지 않기 위해 RabbitMQ를 사용했었다.   ➡️ Message Queue(RabbitMQ) 포스팅 보러가기   많은 기업에서 Kafka를 사용하고, RabbitMQ 보단 카프카가 빠르다는 이야기를 많이 들었는데   왜 Kafka를 선호하는지 자세히 알아보자.       메시지큐  Kafka는 메시지큐이다. 메시지큐는 이전 포스팅에서 자세히 알아봤었는데 요청을 한곳에 모으고 필요한 주체가 가져가 처리하는 것으로 이해할 수 있다.   RabbitMQ, Kafka, Memcache 등 다수의 제품들의 기본 기능이다.       메시지 큐의 장점          비동기(Asynchronous): Queue에 넣기 때문에 나중에 처리할 수 있습니다.            비동조(Decoupling): 애츨리케이션과 분리할 수 있습니다.            탄력성(Resilience): 일부가 실패 시 전체에 영향을 받지 않습니다.            과잉(Redundancy): 실패할 경우 재실행 가능합니다.            보증(Guarantees): 작업이 처리된걸 확인할 수 있습니다.            확장성(Scalable): 다수의 프로세스들이 큐에 메시지를 보낼 수 있습니다.           메시지 큐 사용          다른 곳의 API로 부터 데이터 송수신이 가능합니다.            다양한 애플리케이션에서 비동기 통신을 할 수 있습니다.            이메일 발송 및 문서 업로드가 가능합니다.            많은 양의 프로세스들을 처리할 수 있습니다.             Kafka vs RabbitMQ  다양한 메시지큐가 있는데 용도와 환경에 따라 선택할 수 있어야 한다.   RabbitMQ           구성이 쉽다.            유연한 라우팅이 가능하면 관리 UI 가 편리하다.            제품 성숙도가 높다.            개방형 프로토콜을 위한 AMQP 를 구현 위해 개발            필요에 따라 동기/비동기식이 가능함            소비자중심의 설계            20k/sec 처리를 보장           Apache Kafka           구독방식의 비동기식 구성            고성능 고가용성            분산처리에 효과적으로 설계 됨.            생산자 중심의 설계            범용 메세징 시스템에서 제공되는 다양한 기능은 제공되지 않음.            100k/sec 처리를 보장                    결론   Kafka와 RabbitMQ은 다른 점이 꽤 있다.   내가 개발 중인 SNS 프로젝트에서는 실제로 운영되는 대용량 트래픽을 받는 게 아니라 학습이 목적이었기 때문에 내가 설정한 스트레스 테스트 시나리오의 수준을 감당하면 된다. RabbitMQ 사용이 적절했던 것 같다.         참고     카프카 기본 개념: https://ellune.tistory.com/22?category=769027   카프카 사용법: https://ellune.tistory.com/48?category=769027       ","categories": [],
        "tags": [],
        "url": "/2021-11-26/kafka/",
        "teaser": null
      },{
        "title": "ES에 데이터 적재 후 검색해보기",
        "excerpt":"    ES 적용이 얼마나 성능을 개선시키는지 확인해보기 위해 약 50만개의 영화 관련 데이터를   DB와 ES 클러스터에 채우고 검색 결과를 비교해봤다.      영화 관련 데이터이기 때문에 영화 키워드가 압도적으로 많아 다른 키워드에 비해 시간이 더 소요된다.        DB vs shard1 vs shard8 vs shard8 replica1      shard8, replica1 으로 구성했을 때 가장 많이 개선된 결과를 얻을 수 있었다.       결과     shard가 1개인 경우 DB 보다 성능이 안나올 수도 있다.   키워드로 검색되는 문서의 개수가 많은 경우 DB가 성능이 더 좋을 수 있다.   노드, 샤드가 여러개 늘어날수록 경우 성능이 개선됨   매칭되는 문서 개수가 적은 겨우 ES가 더 빠른 검색 성능을 보임         ElasticSearch      클러스터          1개 이상의 노드로 구성된 것            하나 이상의 노드(=서버)가 모인 것            클러스터를 통해, 데이터를 저장하고, 색인 및 검색 기능을 제공한다.       노드          클러스터에 포함되는 단일 서버            데이터를 저장하고 클러스터의 색인, 검색 기능에 참여한다.       인덱스(색인, index)          인덱스 = 데이터 저장 공간            1개 노드에 여러 개 인덱스 가능            1개 인덱스는 여러 개 노드에 분산 저장되어 관리            1개 인덱스는 1개 타입 가능            elasticsearch의 index 생성 시 기본 구조: 5개의 primary shard + 1개의 replica shard       타입(유형)          하나의 색인에서 하나 이상의 타입을 정의할 수 있다.            DB의 table과 대응된다.       도큐먼트          색인화 할 수 있는 기본 정보 단위이다.            예를 들어 어떠한 단일 제품, 단일 고객, 단일 주문에 대한 도큐먼트가 각각 존재할 수 있다.            이 문서는 JSON 형식이다.       Shard and Replica          색인은 방대한 양의 데이터를 저장할 수 있다.            데이터가 단일 노드의 하드웨어 한도를 초과할 수도 있다. (수용하지 못하거나 느려지는 등의 문제 발생)            Elasticsearch에서는 이러한 문제를 해결하기 위해, 샤드(Shard)라는 조각으로 색인을 분할하는 기능을 제공한다.            Replication은 샤드를 완전히 복사하면서 진행이 되고,       복사된 샤드를 replica shard 기존 샤드를 primary shard라고 부른다.            replica 샤드는 primary 샤드와 반드시 다른 노드에 저장해야 한다.            replication은 인덱스의 처리량(throughput)을 높이는 역할도 한다.            sharding이 query parallelization을 해주는 덕분에     검색 쿼리를 여러 샤드에서 동시에 실행할 수 있으며 성능 및 처리량을 향상시킨다.            sharding을 통해 수많은 데이터를 하나의 인덱스 내 저장 가능하다.            sharding은 노드, 클러스터 레벨이 아닌 인덱스 레벨에서 시행되는데        이는 각각의 인덱스가 포함하는 document들의 개수가 다르기 때문이다.             ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-12-12/es-search/",
        "teaser": null
      },{
        "title": "Dynamic Programming",
        "excerpt":"    다이나믹 프로그래밍  메모리 공간을 약간 더 사용하면 연산 속도를 비약적으로 증가시킬 수 있는 방법이 있다.        대표적인 방법이 다이나믹 프로그래밍 기법으로 동적 게획법이라고 표현하기도 한다.   다이나믹 프로그래밍으로 해결할 수 있는 대표적인 예시로 피보나치 수열이 있다.     n번째 피보나치 수 = (n-1)번째 피보나치 수 + (n-2)번째 피보나치 수   단 1번째, 2번째 피보나치 수 = 1       위 식을 프로그래밍으로 표현하려면 재귀 함수를 사용할 수 있다.   def fibo(x):     if x == 1 or x == 2:         return 1     return fibo(x - 1) + fibo(x - 2)  print(fibo(4))   그러나 fibo(n) 함수에서 n이 커지면 커질수록 수행 시간이 기하급수적으로 늘어나기 때문에 심각한 문제가 생길 수 있다.       호출되는 함수를 생각해보면 동일한 함수가 반복적으로 호촐되는 것을 알 수 있다.       이러한 문제는 다이나믹 프로그래밍을 사용하면 효율적으로 해결할 수 있다.     다만 항상 사용할 수는 없고 다음 조건을 만족할 때 사용할 수 있다.   1. 큰 문제를 작은 문제로 나눌 수 있다.  2. 작은 문제에서 구한 정답은 그것을 포함하는 큰 문제에서도 동일하다.       이 문제를 메모제이션 기법을 사용해 해결할 수 있다.    한 번 구한 결과를 메모리 공간에 메모해두고 같은 식을 다시 호출하면 메모한 결과를 그대로 가져오는 기법을 의미한다.   d = [0] * 100   def fibo(x):     if x == 1 or x == 2:         return 1     if d[x] != 0:         return d[x]     d[x] = fibo(x - 1) + fibo(x - 2)     return d[x]      print(fibo(99))   다이나믹 프로그래밍이란 큰 문제를 작게 나누고, 같은 문제라면 한 번씩만 풀어 문제를 효율적으로 해결하는 알고리즘 기법이다.         탑다운(top-down) &amp; 보텀업(bottom-up) 방식      탑다운 방식(메모제이션): 재귀 함수를 이용해 큰 문제를 해결하기 위해 작은 문제를 호출하는 것   보텀업 방식: 반복문을 이용해 작은 문제를 차근차근 답을 도출하는 것         문제: 1로 만들기      점화식: min(Ai-1, Ai/2, Ai/3, Ai/5) + 1  1을 더해주는 이유는 함수의 호출 횟수를 구해야 하기 때문이다.     1을 빼는 연산을 제외하고 해당 수로 나누어떨어질 때만 더 작은 수를 비교하면 된다.       풀이 코드   private static void solution(int x) { \tint[] dp = new int[x + 1]; \t \tfor (int i = 2; i &lt; x + 1; ++i) { \t\tdp[i] = dp[i - 1] + 1; \t\tif (i % 2 == 0) { \t\t\tdp[i] = Math.min(dp[i], dp[i / 2] + 1); \t\t} \t\tif (i % 3 == 0) { \t\t\tdp[i] = Math.min(dp[i], dp[i / 3] + 1); \t\t} \t\tif (i % 5 == 0) { \t\t\tdp[i] = Math.min(dp[i], dp[i / 5] + 1); \t\t} \t}  \tSystem.out.println(dp[x]); }         문제: 개미 전사      i번째 식량창고에 대해서 털지 안털지의 여부를 결정할 때, 2가지 경우만 비교하면 된다.      (1) i-1번째 식량창고를 털기로 결정한 경우 현재의 식량창고를 털 수 없다.      (2) i-2번째 식량창고를 텅ㅇ기로 결정한 경우 현재의 식량창고를 털 수 있다.   한 칸 이상 떨어진 식량창고는 항상 털 수 있기 때문에 i-3번째 이하의 식량창고에 대해서는 고려할 필요가 없다.   더 많은 식량을 털 수 있는 경우를 선택하면 된다.   dp[i] = Math.max(dp[i-1], dp[i-2]+arr[i]);       풀이 코드   d[0] = arr[0]; d[1] = Math.max(arr[0], arr[1]); for (int i = 2; i &lt; n; ++i) {     d[i] = Math.max(d[i - 1], d[i - 2] + arr[i]); }  System.out.println(d[n - 1]);         문제: 바닥 공사             풀이 코드   d[1] = 1; d[2] = 3;  for (int i = 3; i &lt;= n; ++i) {     d[i] = (d[i - 1] + 2 * d[i - 2]) % 796796; }  System.out.println(d[n]);         문제: 효율적인 화폐 구성      화폐 단위가 큰 단위가 작은 단위의 배수가 아니기 때문에        매번 가장 큰 화폐 단위로부터 처리하는 방법으로는 해결할 수 없고 다이나믹 프로그래밍을 이용해야 한다.   금액 i를 만들 수 있는 최소한의 화폐 개수를 ai, 화폐의 단위를 k라고 했을 때       (ai-k는 금액 i-k를 만들 수 있는 최소한의 화폐 개수를 의미)      ai-k를 만드는 방법이 존재하는 경우, ai = min(ai, ai-k + 1)   ai-k를 만드는 방법이 존재하지 않는 경우, ai = 10001       풀이 코드  private static void solution(int n, int m, int[] coin) {     int[] dp = new int[m + 1]; \tArrays.fill(dp, 10001);  \tdp[0] = 0; \tfor (int i = 0; i &lt; n; i++) { \t\tfor (int j = coin[i]; j &lt;= m; j++) { \t\t\tif (dp[j - coin[i]] != 10001) { \t\t\t\tdp[j] = Math.min(dp[j], dp[j - coin[i]] + 1); \t\t\t} \t\t\tSystem.out.println(Arrays.toString(dp)); \t\t} \t}  \tif (dp[m] == 10001) {  \t\tSystem.out.println(-1); \t} else { \t\tSystem.out.println(dp[m]); \t} }       ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-12-17/dp/",
        "teaser": null
      },{
        "title": "Sort",
        "excerpt":"    선택 정렬  가장 작은 데이터를 선택해 맨 앞에 있는 데이터와 바꾸고,      그다음 작은 데이터를 선택해 앞에서 두 번째 데이터와 바꾸는 과정을 반복하면 어떨까?   가장 원시적인 방법으로 매번 가장 작은 것을 선택한다는 의미에서 선택 정렬 알고리즘이라고 한다.   static void swap(int[] a, int i, int j) { \tint temp = a[i]; \ta[i] = a[j]; \ta[j] = temp; }  static void selectionSort(int[] a) { \tfor(int i = 0; i &lt; a.length-1; ++i) { \t\tint min = i; // 아직 정렬되지 않은 부분에서 가장 작은 요소의 인덱스를 기록한다.  \t\tfor(int j = i+1; j &lt; a.length; ++j)  \t\t\tif(a[j] &lt; a[min]) { \t\t\t\tmin = j; \t\t\t}  \t\tswap(a, i, min); // 아직 정렬되지 않은 부분의 첫 요소와 가장 작은 요소의 자리를 바꾼다. \t} }   선택 정렬은 N-1번 만큼 가장 작은 수를 찾아 맨 앞으로 보내야 한다.     선택 정렬의 시간 복잡도는 O(N^2) 이다.   선택 정렬은 기본 정렬 라이브러리를 포함해 다른 알고리즘과 비교했을 때 매우 비효율적이다.    다만 특정 리스트에서 가장 작은 데이터를 찾는 일에서 선택 정렬 소스코드가 필요할 수 있다.         삽입 정렬  삽입 정렬을 느린 편이다.   데이터를 하나씩 확인하며, 각 데이터를 적절한 위치에 삽입하면?   삽입 정렬은 필요할 때만 위치를 바꾸므로 데이터가 거의 정렬되어 있을 때 훨씬 효율적이다.   static void insertionSort(int[] a) {     for (int i = 1; i &lt; a.length; ++i) { \t\tint value = a[i]; // 삽입할 값 보관 \t\tint j; \t\tfor (j = i - 1; j &gt;= 0; --j) { // 뒤로 이동 \t\t\tif (a[j] &gt; value) { \t\t\t\ta[j + 1] = a[j]; \t\t\t} else {  \t\t\t    break; \t\t\t} \t\t} \t\ta[j + 1] = value; // 값 삽입 \t} }         퀵 정렬  퀵 정렬과 병합 정렬은 대부분의 프로그래밍 언어에서 정렬 라이브러리의 근간이 되는 알고리즘이기도 하다.   기준 데이터를 설정하고 그 기준보다 큰 데이터와 작은 데이터의 위치를 바꾸면 어떨까?   퀵 정렬은 기준을 설정한 다음 큰 수와 작은 수를 교환한 후 리스트를 반으로 나누는 방식으로 동작한다.    퀵 정렬에서는 pivot이라는 기준 값이 사용된다.   static void swap(int[] a, int i, int j) {     int temp = a[i]; \ta[i] = a[j]; \ta[j] = temp; }  static int partition(int[] a, int start, int end) { \tint i = start - 1; \tint value = a[end];  \tfor(int j = start; j &lt; end; ++j) { \t\tif(a[j] &lt; value)  \t\t\tswap(a, ++i, j); \t} \tswap(a, i + 1, end); \treturn i + 1; }  static void quickSort(int[] a, int start, int end) { \tif(start &gt;= end) return; \tint middle = partition(a, start, end); // 배열 나누기 \tquickSort(a, start, middle-1);         // 1구역 정렬 \tquickSort(a, middle+1, end);           // 2구역 정렬 }         계수 정렬 &amp; 기수 정렬  https://hyerin6.github.io/2021-01-20/countingSort/       문제: 두 배열의 원소 교체  문제)  두 배열 A, B를 가지고 있다. 두 배열은 N개의 원소로 구성되어 있으며 배열의 원소는 모두 자연수이다.    최대 K번 바꿔치기 연산을 수행할 수 있는데 바꿔치기 연산이란     배열 A에 있는 원소 하나와 배열 B에 있는 원소 하나를 골라서 두 원소를 서로 바꾸는 것을 말한다.     최종 목표는 배열 A의 모든 원소의 합이 최대가 되도록 하는 것이다.   [Input] 5 3  1 2 5 4 3  5 5 6 6 5  [Output] 26       풀이 코드   public class Main {  \tpublic static void main(String[] args) { \t\tint n = 5; \t\tint k = 3;  \t\tint[] a = {1, 2, 5, 4, 3}; \t\tInteger[] b = {5, 5, 6, 6, 5};  \t\t// 배열 A는 오름차순 정렬 수행 \t\tArrays.sort(a); \t\t// 배열 B는 내림차순 정렬 수행 \t\tArrays.sort(b, Collections.reverseOrder());  \t\t// 첫 번째 인덱스부터 확인하며, 두 배열의 원소를 최대 K번 비교 \t\tfor (int i = 0; i &lt; k; i++) { \t\t\t// A의 원소가 B의 원소보다 작은 경우 \t\t\tif (a[i] &lt; b[i]) { \t\t\t\t// 두 원소를 교체 \t\t\t\tint temp = a[i]; \t\t\t\ta[i] = b[i]; \t\t\t\tb[i] = temp; \t\t\t} \t\t\t// A의 원소가 B의 원소보다 크거나 같을 때, 반복문을 탈출 \t\t\telse \t\t\t\tbreak; \t\t}  \t\t// 배열 A의 모든 원소의 합을 출력 \t\tlong result = 0; \t\tfor (int i = 0; i &lt; n; i++) { \t\t\tresult += a[i]; \t\t} \t\t \t\tSystem.out.println(result); \t} }       ","categories": ["Algorithm"],
        "tags": ["algorithm"],
        "url": "/2021-12-19/sort/",
        "teaser": null
      },{
        "title": "HttpMessageNotReadableException 해결하기",
        "excerpt":"    로깅 기능 개발  로깅 기능 개발 과정을 포스팅한 적이 있다.     로그를 남기기 위해 request를 읽어야 했는데           왜 ContentCachingRequestWrapper, ContentCachingResponseWrapper를 사용해서 읽었을까?   request를 getInputStream()이나 getReader()로 두번 읽으면 다음과 같은 exception이 발생한다.   [org.springframework.http.converter.HttpMessageNotReadableException: Required request body is missing       코드를 보면 getInputStream()이나 getReader()는 두 번 읽어서 처리할 수 없게 되어 있다.      스프링의 유틸 클래스인 ContentCachingRequestWrapper 를 사용한 이유이다.     ContentCachingRequestWrapper는 입력 스트림 과 리더 에서 읽은 모든 내용을 캐싱한다.       참고     https://meetup.toast.com/posts/44      ","categories": ["Spring"],
        "tags": ["spring"],
        "url": "/2021-12-23/request/",
        "teaser": null
      },{
        "title": "lambda 와 effectively final",
        "excerpt":"    Effectively final 이란?   A non-final local variable or method parameter whose value is never changed  after initialization is known as effectively final.   Java 8 에 추가된 syntactic sugar 일종으로, 초기화 된 이후 값이 한번도 변경되지 않았다면 effectively final 이라고 할 수 있다.    effectively final 변수는 final 키워드가 붙어있지 않았지만 final 키워드를 붙힌 것과 동일하게 컴파일러에서 처리한다.    의미상 final 하다 라고 생각하는 사람들이 많다.   java 7 에서는 anonymous class 가 외부지역변수 가 final 인 경우에만 접근이 가능했기에 항상 final 키워드를 추가해줘야 했다.     java 8 에서는 effectively final 인 경우에도 접근이 가능하게 바뀌어 조건을 만족한다면 final 키워드를 생략할 수 있다.       // Java 7 public void testPlus() {     final int number = 1;      Addable addableImple = new Addable() {         @Override         public int plusOne() {             return number + 1;         }     }; }  // Java 8 public void testPlus() {     int number = 1; // Effectively final      Addable addableImple = new Addable() {         @Override         public int plusOne() {             return number + 1;         }     }; }  // Java 8 public void testPlus() {     int number = 1; // Effectively final      Addable addableImple = () -&gt; number + 1; }         람다에서 사용되는 지역 변수가 final 혹은 effectively final 이어야 하는 이유  람다식에서 참조하는 외부 변수는 final 혹은 effectively final이어야 한다.가 100% 맞는 말은 아니다.         외부 변수는 지역변수, 인스턴스 변수, 클래스 변수가 모두 포함될 수 있는데      인스턴스 변수나 클래스 변수는 final 혹은 effective final 하지 않아도 람다식에서 사용할 수 있기 때문이다.       private int instanceNumber = 1; private static int staticNumber = 1;          // Error, 외부 지역변수는 final 혹은 effectively final 이어야 람다식에서 사용할 수 있다. public void testPlusByLocalVariable() {     int localNumber = 1;      localNumber = 2;     Addable addableImple = () -&gt; localNumber + 1;  }      // OK, 값을 변경하더라도 문제 없다. public void testPlusByInstanceVariable() {     instanceNumber = 2;     Addable addableImple = () -&gt; instanceNumber + 1; }  // OK, 값을 변경하더라도 문제 없다. public void testPlusByStaticVariable() {     staticNumber = 2;     Addable addableImple = () -&gt; staticNumber + 1; }   람다식에서 사용되는 지역 변수가 final 혹은 effective final이어야 하는 이유를 알아보자.         Capturing lambda &amp; Non-Capturing lambda  람다식에는 2가지 타입이 존재한다.      Capturing lambda            Local Capturing lambda       Non-Local Capturing lambda           Non-Capturing lambda       Capturing lambda  외부 변수를 이용하는 람다식을 의미한다.     외부 변수는 지역변수, 인스턴스 변수, 클래스 변수를 모두 포함한다.  String message = \"CapturingLambda\"; Runnable runnable = () -&gt; System.out.println(message);       Non-Capturing lambda  외부 변수를 이용하지 않는 람다식을 의미한다.  Runnable runnable = () -&gt; System.out.println(\"NonCapturingLambda\");  Runnable runnable = () -&gt; {     String message = \"NonCapturingLambda\";     System.out.println(message); }   Capturing lambda는 다시 local capturing lambda와 non-local capturing lambda로 구분할 수 있다.      local과 non-local을 구분하는 이유는 지역 변수가 가지는 특징으로 인해 내부 동작 방식이 다르기 때문이다.       Local Capturing lambda  public void testPlusByLocalVariable() {     int localNumber = 1;     Addable addableImple = () -&gt; localNumber + 1;  }   외부 변수로 지역 변수를 이용하는 람다식을 의미한다.    다음과 같은 특징이 있다.   (1) 람다식에서 사용되는 일부 지역 변수는 복사본이다.  (2) final 혹은 effectively final인 지역 변수만 람다식에서 사용할 수 있다.  (3) 복사된 지역 변수 값은 람다식 내부에서도 변경할 수 없다. 즉 final 변수로 다뤄야 한다.    위와 같은 특징이 생긴 이유를 알아보자.       1. 람다식에서 사용되는 외부 지역변수는 복사본이다.  람다식에서는 외부 지역변수를 그대로 사용하지 못하고 복사본을 사용하는 이유는 다음과 같다.           지역 변수는 스택 영역에 생성된다. 따라서 지역 변수가 선언된 block이 끝나면 스택에서 제거된다.    → 메소드 내 지역 변수를 참조하는 람다식을 리턴하는 메소드가 있을 경우, 메소드 block이 끝나면    지역 변수가 스택에서 제거되므로 추후에 람다식이 수행될 때 참조할 수 없다.            지역 변수를 관리하는 스레드와 람다식이 실행되는 스레드가 다를 수 있다.    → 스택은 각 스레드의 고유의 공간이고, 스레드끼리 공유되지 않기 때문에       마찬가지로 람다식이 수해오딜 때 값을 참조할 수 없다.       위와 같은 이유로 인해 람다식에서는 외부 지역 변수를 직접 참조하지 않고 복사본을 전달받아 사용하게 된다.       2. final 혹은 effectively final인 지역 변수만 람다식에서 사용할 수 있다.  만약 참조하고자 하는 지역 변수가 final 혹은 effectively final이 아닐 경우   즉 변경이 가능할 경우 어떤 문제가 발생할까?   public void executelocalVariableInMultiThread() {     boolean shouldRun = true;     executor.execute(() -&gt; {         while (shouldRun) {             // do operation         }     });          shouldRun = false; }   람다식이 어떤 스레드에서 수행될지는 미리 알 수 없다.     이 얘기는 곧 외부 지역 변수를 다루는 스레드와 람다식이 수행되는 스레드가 다를 수 있다는 의미이다.   지역 변수 값(shouldRun)을 제어하는 스레드 A, 람다식이 수행되는 스레드 B가 있다고 가정해보자.   스레드 B의 shouldRun 값이 가장 최신 값으로 복사되어 전달 됐는지 확신할 수 없다.  shouldRun은 변경이 가능한 지역 변수이고, 지역 변수를 스레드 간에 sync 해주는 것이 불가능하기 때문이다.   지역 변수는 스레드 A의 스택 영역에 존재하기 때문에 다른 스레드에서 접근이 불가능하다.  volatile과 같은 키워드가 로컬 변수에서 사용될 수 없는 이유도 이와 같다.    값이 보장되지 않는다면 매번 다른 결과가 도출될 수 있다.     이러한 이유로 인해 외부 지역 변수는 전달되는 복사본이 변경되지 않은        최신 값이라는 것을 보장하기 위해 final 혹은 effectively final이어야 한다.       3.  복사된 지역 변수 값은 람다식 내부에서도 변경할 수 없다. 즉 final 변수로 다뤄야 한다.  이미 복사된 값이므로 변경해도 문제가 없는거 아닐까? 아니다.     복사될 값의 변조를 막아 최신 값임을 보장하기 위해 final 제약을 걸었는데 람다식 내부에서 변경이 가능할 경우 다시 제자리로 돌아온다.   또한 컴파일 된 람다식은 static 메소드 형태로 변경이 되는데 이때 복사된 값이 파라미터로 전달되므로   마찬가지로 스택 영역에 존재하기 때문에 sync를 해주는 것도 불가능하다.   따라서 람다식 내부에서도 값이 변경 되어서는 안된다.   컴파일러 레벨에서 앞, 뒤로 final 제약을 걸어줌으로써 멀티 스레드 환경에서 대응하기 어려운 이슈를 미연에 방지한 것이다.       Non - local capturing lambda   private int instanceNumber = 1; private static int staticNumber = 1;   public void testPlusByInstanceVariable() {     instanceNumber = 2;     Addable addableImple = () -&gt; instanceNumber + 1; }  public void testPlusByStaticVariable() {     staticNumber = 2;     Addable addableImple = () -&gt; staticNumber + 1; }   외부 변수로 인스턴스 변수 혹은 클래스 변수를 이용하는 람다식을 의미한다.     local capturing lambda와 다르게 final 제약 조건이 없고 외부 변수 값도 복사하지 않는다.   이유는 인스턴스 변수나 클래스 변수를 저장하고 있는 메모리 영역은 공통 영역이고    값이 메모리에서 바로 회수되지 않기 때문에 람다식에서 바로 참조가 가능하다.    따라서 복사 과정이 불필요하고 참조 시 최신 값 임을 보장할 수 있다.   단, 멀티 스레드 환경일 경우 volatile, synchronized 등을 이용하여 sync를 맞춰주는 작업을 잊어서는 안된다.       정리  람다식에서 외부 지역 변수를 이용할 경우 final 혹은 effectively final 이어야 하는 이유는 지역 변수가 스택에 저장되기 때문에 람다식에서 값을 바로 참조하는 것에 제약이 있어 복사된 값을 이용하게 되는데, 이때 멀티 쓰레드 환경에서 복사 될/복사된 값이 변경 가능 할 경우 이로 인한 동시성 이슈를 대응할 수 없기 때문이다.       참고     https://www.baeldung.com/java-effectively-final   https://www.baeldung.com/java-lambda-effectively-final-local-variables   https://dzone.com/articles/how-lambdas-and-anonymous-inner-classesaic-work       ","categories": ["Java"],
        "tags": ["java","lambda"],
        "url": "/2021-12-28/lambda/",
        "teaser": null
      },{
        "title": "Jekyll - minimal mistakes 사용법",
        "excerpt":"    검색 기능, 목차, 페이징 기능이 없어 블로그 테마를 minimal mistakes로 변경했다.             커스텀 할 수 있게 문서도 잘 정리되어 있는 편이다.   목차 띄우기  목차는 게시글 작성 시 상단에 다음 설정들을 추가하면 된다.   toc: true  toc_sticky: true       문자 박스 적용   Default → .notice  Primary\t→ .notice–primary  Info\t→ .notice–info  Warning\t→ .notice–warning  Success\t→ .notice–success  Danger\t→ .notice–danger   {: .notice--success} 형식으로 작성하면 다음과 같이 문자 박스를 만들 수 있다.   블로그 테마 변경 성공 :)       본문 텍스트 색상 변경   &lt;span style=\"color:red\"&gt;Red&lt;/span&gt;   &lt;span style=\"color:blue\"&gt;Blue&lt;/span&gt;   &lt;span style=\"color:lightGreen\"&gt;lightGreen&lt;/span&gt;    Red  Blue  lightGreen      ","categories": ["Blog"],
        "tags": ["blog"],
        "url": "/2022-01-05/blog/",
        "teaser": null
      }]
